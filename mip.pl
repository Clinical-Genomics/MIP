#!/usr/bin/env perl

###Master script for analysing paired end reads from the Illumina plattform in fastq(.gz) format to annotated ranked disease causing variants. The program performs QC, aligns reads using Mosaik or BWA, performs variant discovery and annotation as well as ranking the found variants according to disease potential.

###Copyright 2011 Henrik Stranneheim

use v5.18;  #Require at least perl 5.18
use Modern::Perl qw(2014);
use autodie qw(open close :all);

##Unicode boilerplate
use warnings qw( FATAL utf8 );
use utf8;  #Allow unicode characters in this script
use open qw( :encoding(UTF-8) :std );
use charnames qw( :full :short );


use Getopt::Long;
use POSIX;
use Params::Check qw[check allow last_error];
$Params::Check::PRESERVE_CASE = 1;  #Do not convert to lower case
use Cwd;
use Cwd qw(abs_path);  #Import absolute path function
use File::Basename qw(dirname basename);
use File::Spec::Functions qw(catdir catfile devnull);
use File::Path qw(make_path);
use File::Copy qw(copy);
use FindBin qw($Bin);  #Find directory of script
use IPC::Cmd qw[can_run run];
use IPC::System::Simple;  #Required for autodie :all
use Time::Piece;

## Third party module(s)
use Path::Iterator::Rule;
use List::Util qw(any all);

##MIPs lib/
use lib catdir($Bin, "lib");
use File::Format::Yaml qw(load_yaml write_yaml);
use MIP_log::Log4perl qw(initiate_logger);

our $USAGE;

BEGIN {

    my @modules = ("YAML", "Log::Log4perl", "Path::Iterator::Rule", "List::Util");

    ## Evaluate that all modules required are installed
    eval_modules({modules_ref => \@modules,
		 });

    $USAGE =
	qq{
mip.pl  -ifd [infile_dirs=sample_id] -sd [script_dir] -rd [reference_dir] -p [project_id] -s [sample_ids,.,.,.,n] -em [email] -osd [outscript_dir] -odd [outdata_dir] -f [family_id] -p[program] -at [sample_id=analysis_type]
               ####MIP
               -ifd/--infile_dirs Infile directory(s) (Hash infile_dirs=sample_id; mandatory)
               -sd/--script_dir The pipeline custom script in directory (mandatory)
               -rd/--reference_dir Reference(s) directory (mandatory)
               -p/--project_id The project ID (mandatory)
               -s/--sample_ids The sample ID(s)(comma sep; mandatory)
               -em/--email E-mail (defaults to "")
               -emt/--email_type E-mail type (defaults to F (=FAIL);Options: B (=BEGIN) and/or F (=FAIL) and/or E=(END))
               -odd/--outdata_dir The data output directory (mandatory)
               -osd/--outscript_dir The script files (.sh) output directory (mandatory)
               -f/--family_id Group id of samples to be compared (defaults to "", (Ex: 1 for IDN 1-1-1A))
               -ped/--pedigree_file Meta data on samples (defaults to "")
               -hgr/--human_genome_reference Fasta file for the human genome reference (defaults to "GRCh37_homo_sapiens_-d5-.fasta;1000G decoy version 5")
               -ald/--outaligner_dir Setting which aligner out directory was used for alignment in previous analysis (defaults to "{outdata_dir}{outaligner_dir}")
               -at/--analysis_type Type of analysis to perform (sample_id=analysis_type, defaults to "wgs";Valid entries: "wgs", "wes", "rapid")
               -pl/--platform Platform/technology used to produce the reads (defaults to "ILLUMINA")
               -ec/--expected_coverage Expected mean target coverage for analysis (sample_id=expected_coverage, defaults to "")
               -cpn/--core_processor_number The maximum number of processor cores per node used in the analysis (defaults to "16")
               -c/--config_file YAML config file for analysis parameters (defaults to "")
               -ccp/--cluster_constant_path Set the cluster constant path (defaults to "")
               -acp/--analysis_constant_path Set the analysis constant path (defaults to "analysis")
               -cfa/--config_file_analysis Write YAML configuration file for analysis parameters (defaults to "")
               -sif/--sample_info_file YAML file for sample info used in the analysis (defaults to "{outdata_dir}/{family_id}/{family_id}_qc_sample_info.yaml")
               -dra/--dry_run_all Sets all programs to dry run mode i.e. no sbatch submission (defaults to "0" (=no))
               -tmd/--temp_directory Set the temporary directory for all programs (defaults to "/scratch/SLURM_JOB_ID";supply whole path)
               -jul/--java_use_large_pages Use large page memory. (defaults to "0" (=no))
               -nrm/--node_ram_memory The RAM memory size of the node(s) in GigaBytes (Defaults to 24)
               -qos/--slurm_quality_of_service SLURM quality of service command in sbatch scripts (defaults to "normal")
               -sen/--source_environment_commands Source environment command in sbatch scripts (defaults to "")

               -ges/--genomic_set Selection of relevant regions post alignment (Format=sorted BED; defaults to "")
               -rio/--reduce_io Run consecutive models at nodes (defaults to "0" (=no))
               -riu/--replace_iupac Replace IUPAC code in alternative alleles with N (defaults to "0" (=no))
               -pp/--print_program Print all programs that are supported
               -ppm/--print_program_mode Print all programs that are supported in: 0 (off mode), 1 (on mode), 2 (dry run mode; defaults to "2")
               -l/--log_file Mip log file (defaults to "{outdata_dir}/{family_id}/mip_log/{date}/{scriptname}_{timestamp}.log")
               -h/--help Display this help message
               -v/--version Display version of MIP

               ####Programs
               -psfq/--psplit_fastq_file Split fastq files in batches of X reads and exits (defaults to "0" (=no))
                 -sfqrdb/--split_fastq_file_read_batch The number of sequence reads to place in each batch (defaults to "25,000,000")
               -pgz/--pgzip_fastq Gzip fastq files (defaults to "1" (=yes))
               -pfqc/--pfastqc Sequence quality analysis using FastQC (defaults to "1" (=yes))
               -pmad/--pmadeline Pedigree drawing engine (defaults to "0" (=no))

               ##Mosaik
               -pmob/--pmosaik_build  Convert reads to Mosaik format using MosaikBuild (defaults to "1" (=yes))
                -mobmfl/--mosaik_build_median_frag_length Flag for setting the mean fragment length, mfl, (defaults to (=375) bp)
               -pmoa/--pmosaik_aligner Align reads using MosaikAligner (defaults to "1" (=yes))
                 -moaref/--mosaik_align_reference MosaikAligner reference (defaults to "{human_genome_reference}")
                 -moaape/--mosaik_align_neural_network_pe_file MosaikAligner Neural Network PE File (defaults to "2.1.78.pe.ann")
                 -moaase/--mosaik_align_neural_network_se_file MosaikAligner Neural Network SE File (defaults to "2.1.78.se.ann")
                 -mojdb/--mosaik_jump_db_stub MosaikJump stub (defaults to "{human_genome_reference}")

               ##BWA
               -pmem/--pbwa_mem Align reads using Bwa Mem (defaults to "0" (=no))
                 -memhla/--bwa_mem_hla Apply HLA typing (defaults to "1" (=yes))
                 -memrdb/--bwa_mem_rapid_db Selection of relevant regions post alignment (defaults to "")
                 -memcrm/--bwa_mem_cram Use CRAM-format for additional output file (defaults to "1" (=yes))
                 -memsts/--bwa_mem_bamstats Collect statistics from BAM files (defaults to "1" (=yes))
                 -memssm/--bwa_sambamba_sort_memory_limit Set the memory limit for Sambamba sort after bwa alignment (defaults to "32G")
               -paln/--pbwa_aln Index reads using BWA Aln (defaults to "0" (=no))
                 -alnq/--bwa_aln_quality_trimming BWA Aln quality threshold for read trimming (defaults to "20")
               -psap/--pbwa_sampe Align reads using BWA Sampe (defaults to "0" (=no))

               ##Picardtools
               -ptp/--picardtools_path Path to Picardtools. Mandatory for use of Picardtools (defaults to "")
               -pptm/--ppicardtools_mergesamfiles Merge (BAM file(s) ) using Picardtools mergesamfiles or rename single samples for downstream processing (Mandatory)
                 -ptmp/--picardtools_mergesamfiles_previous_bams Picardtools mergesamfiles on merged current files and previous BAM-file(s) (supply whole path and name, name must contain sample id, and lanes_Xn info)
               -pptmr/--ppicardtools_mergerapidreads Merge Read batch processed (BAM file(s)) using Picardtools mergesamfiles (Only relevant in rapid mode;defaults to "0" (=no))

               ##Markduplicates
               -ppmd/--ppicardtools_markduplicates Markduplicates using Picardtools markduplicates (defaults to "1" (=yes))
               -psmd/--psambamba_markduplicates Markduplicates using Sambamba markduplicates (defaults to "0" (=no))
                 -smdhts/--sambamba_markdup_hash_table_size Sambamba size of hash table for finding read pairs (defaults to "500000")
                 -smdols/--sambamba_markdup_overflow_list_size Sambamba size of the overflow list (defaults to "500000")
                 -smdibs/--sambamba_markdup_io_buffer_size Sambamba size of the io buffer for reading and writing BAM during the second pass (defaults to "2048")

               ###Coverage calculations
               -pchs/--pchanjo_sexcheck Predicts gender from sex chromosome coverage (defaults to "1")
               -psdt/--psambamba_depth Sambamba depth coverage analysis (defaults to "1" (=yes))
                 -sdtcut/--sambamba_depth_cutoffs Read depth cutoff (comma sep; defaults to "10", "20", "30", "50", "100")
                 -sdtbed/--sambamba_depth_bed Reference database (defaults to "CCDS.current.bed")
                 -sdtbaq/--sambamba_depth_base_quality Do not count bases with lower base quality (defaults to "10")
                 -stdmaq/--sambamba_depth_mapping_quality  Do not count reads with lower mapping quality (defaults to "10")
                 -stdndu/--sambamba_depth_noduplicates Do not include duplicates in coverage calculation (defaults to "1" (=yes))
                 -stdfqc/--sambamba_depth_quality_control Do not include reads with failed quality control (defaults to "1" (=yes))
               -pgcb/--pgenomecoveragebed Genome coverage calculation using genomeCoverageBED (defaults to "0" (=no))
                -gcbcov/--genomecoveragebed_max_coverage Max coverage depth when using '-pgenomecoveragebed' (defaults to "30")
               -pptcmm/--ppicardtools_collectmultiplemetrics Metrics calculation using Picardtools CollectMultipleMetrics (defaults to "1" (=yes))
               -pptchs/--ppicardtools_calculatehsmetrics Capture calculation using Picardtools CalculateHSmetrics (defaults to "1" (=yes))
                 -extb/--exome_target_bed Exome target bed file per sample_id (defaults to "latest_supported_capturekit.bed"; -extb file.bed=Sample_idX,Sample_idY -extb file.bed=Sample_idZ)
               -prcp/--prcovplots Plots of genome coverage using rcovplots (defaults to "0" (=no))

               ###Structural variant callers
               -pcnv/--pcnvnator Structural variant calling using CNVnator (defaults to "1" (=yes))
                 -cnvhbs/--cnv_bin_size CNVnator bin size (defaults to "1000")
               -pdelc/--pdelly_call Structural variant calling using Delly (defaults to "1" (=yes))
               -pdel/--pdelly_reformat Merge, regenotype and filter using Delly (defaults to "1" (=yes))
                 -deltyp/--delly_types Type of SV to call (defaults to "DEL,DUP,INV,TRA"; comma sep)
                 -delexc/--delly_exclude_file Exclude centomere and telemore regions in delly calling (defaults to "hg19_human_excl_-0.7.6-.tsv")
               -pmna/--pmanta Structural variant calling using Manta (defaults to "1" (=yes))
               -pfit/--pfindtranslocations Structural variant calling using Findtranslocations (defaults to "0" (=no))
                 -fitmsp/--findtranslocations_minimum_supporting_pairs The minimum number of supporting reads (defaults to "6")
               -psvc/--psv_combinevariantcallsets Combine variant call sets (defaults to "1" (=yes))
                 -svcvtd/--sv_vt_decompose Split multi allelic records into single records (defaults to "1" (=yes))
                 -svcbtv/--sv_bcftools_view_filter Include structural variants with PASS in FILTER column (defaults to "1" (=yes))
                 -svcvan/--sv_vcfanno Annotate structural variants (defaults to "1" (=yes)
                 -svcval/--sv_vcfanno_lua vcfAnno lua postscripting file (defaults to "")
                 -svcvac/--sv_vcfanno_config vcfAnno toml config (defaults to "")
                 -svcvacf/--sv_vcfanno_config_file Annotation file within vcfAnno config toml file (defaults to "GRCh37_all_sv_-phase3_v2.2013-05-02-.vcf.gz")
                 -svcvah/--sv_vcfannotation_header_lines_file Adjust for postscript by adding required header lines to vcf (defaults to "")
                 -svcgmf/--sv_genmod_filter Remove common structural variants from vcf (defaults to "1" (=yes))
                 -svcgfr/--sv_genmod_filter_1000g Genmod annotate structural variants from 1000G reference (defaults to "GRCh37_all_wgs_-phase3_v5b.2013-05-02-.vcf.gz")
                 -svcgft/--sv_genmod_filter_threshold Threshold for filtering structural variants (defaults to "0.10")
                 -svcbcf/--sv_combinevariantcallsets_bcf_file Produce a bcf from the CombineStructuralVariantCallSet vcf (defaults to "1" (=yes))
               -psvv/--psv_varianteffectpredictor Annotate SV variants using VEP (defaults to "1" (=yes))
               -svvepf/--sv_vep_features VEP features (defaults to ("hgvs","symbol","numbers","sift","polyphen","humdiv","domains","protein","ccds","uniprot","biotype","regulatory", "tsl", "canonical", "per_gene", "appris"); comma sep)
               -svveppl/--sv_vep_plugins VEP plugins (defaults to ("UpDownDistance, LoFtool, LoF"); comma sep)
               -psvvcp/--psv_vcfparser Parse structural variants using vcfParser.pl (defaults to "1" (=yes))
                 -svvcpvt/--sv_vcfparser_vep_transcripts Parse VEP transcript specific entries (defaults to "0" (=no))
                 -vcppg/--vcfparser_per_gene Keep only most severe consequence per gene (defaults to "1" (=yes))
                 -svvcprff/--sv_vcfparser_range_feature_file Range annotations file (defaults to ""; tab-sep)
                 -svvcprfa/--sv_vcfparser_range_feature_annotation_columns Range annotations feature columns (defaults to ""; comma sep)
                 -svvcpsf/--sv_vcfparser_select_file File containging list of genes to analyse seperately (defaults to "";tab-sep file and HGNC Symbol required)
                 -svvcpsfm/--sv_vcfparser_select_file_matching_column Position of HGNC Symbol column in select file (defaults to "")
                 -svvcpsfa/--sv_vcfparser_select_feature_annotation_columns Feature columns to use in annotation (defaults to ""; comma sep)
               -psvr/--psv_rankvariant Ranking of annotated SV variants (defaults to "1" (=yes))
                 -svravanr/--sv_genmod_annotate_regions Use predefined gene annotation supplied with genmod for defining genes (defaults to "1" (=yes))
                 -svravgft/--sv_genmod_models_family_type Use one of the known setups (defaults to "mip")
                 -svravwg/--sv_genmod_models_whole_gene Allow compound pairs in intronic regions (defaults to "0" (=yes))
                 -svravrpf/--sv_genmod_models_reduced_penetrance_file File containg genes with reduced penetrance (defaults to "")
                 -svravrm/--sv_rank_model_file Rank model config file (defaults to "")
                 -svravbf/--sv_rankvariant_binary_file Produce binary file from the rank variant chromosome sorted vcfs (defaults to "1" (=yes))

               ##Samtools
               -psmp/--psamtools_mpileup Variant calling using samtools mpileup and bcftools (defaults to "1" (=yes))

               ##Freebayes
               -pfrb/--pfreebayes Variant calling using Freebayes and bcftools (defaults to "1" (=yes))

               ##GATK
               -gtp/--gatk_path  Path to GATK. Mandatory for use of GATK (defaults to "")
               -gbdv/--gatk_bundle_download_version  GATK FTP bundle download version.(defaults to "2.8")
               -gdco/--gatk_downsample_to_coverage Coverage to downsample to at any given locus (defaults to "1000")
               -gdai/--gatk_disable_auto_index_and_file_lock Disable auto index creation and locking when reading rods (defaults to "0" (=no))
               -pgra/--pgatk_realigner Realignments of reads using GATK ReAlignerTargetCreator/IndelRealigner (defaults to "0" (=no))
                 -graks/--gatk_realigner_indel_known_sites GATK ReAlignerTargetCreator/IndelRealigner known indel site (defaults to "GRCh37_1000g_indels_-phase1-.vcf", "GRCh37_mills_and_1000g_indels_-gold_standard-.vcf")
               -pgbr/--pgatk_baserecalibration Recalibration of bases using GATK BaseReCalibrator/PrintReads (defaults to "1" (=yes))
                 -gbrcov/--gatk_baserecalibration_covariates GATK BaseReCalibration covariates (defaults to "ReadGroupCovariate", "ContextCovariate", "CycleCovariate", "QualityScoreCovariate")
                 -gbrkst/--gatk_baserecalibration_known_sites GATK BaseReCalibration known SNV and INDEL sites (defaults to "GRCh37_dbsnp_-138-.vcf", "GRCh37_1000g_indels_-phase1-.vcf", "GRCh37_mills_and_1000g_indels_-gold_standard-.vcf")
                 -gbrocr/--gatk_baserecalibration_over_clipped_read Filter out reads that are over-soft-clipped (defaults to "1" (=yes))
                 -gbrdiq/--gatk_baserecalibration_disable_indel_qual Disable indel quality scores (defaults to "1" (=yes))
                 -gbrsqq/--gatk_baserecalibration_static_quantized_quals Static binning of base quality scores (defaults to "10,20,30,40"; comma sep)
               -pghc/--pgatk_haplotypecaller Variant discovery using GATK HaplotypeCaller (defaults to "1" (=yes))
                 -ghcann/--gatk_haplotypecaller_annotation GATK HaploTypeCaller annotations (defaults to "BaseQualityRankSumTest", "ChromosomeCounts", "Coverage", "DepthPerAlleleBySample", "FisherStrand", "MappingQualityRankSumTest", "QualByDepth", "RMSMappingQuality", "ReadPosRankSumTest", "StrandOddsRatio")
                 -ghckse/--gatk_haplotypecaller_snp_known_set GATK HaplotypeCaller dbSNP set for annotating ID columns (defaults to "GRCh37_dbsnp_-138-.vcf")
                 -ghcscb/--gatk_haplotypecaller_soft_clipped_bases Do not include soft clipped bases in the variant calling (defaults to "1" (=yes))
                 -ghcpim/--gatk_haplotypecaller_pcr_indel_model The PCR indel model to use (defaults to "None"; Set to "0" to disable)
               -pggt/--pgatk_genotypegvcfs Merge gVCF records using GATK GenotypeGVCFs (defaults to "1" (=yes))
                 -ggtgrl/--gatk_genotypegvcfs_ref_gvcf GATK GenoTypeGVCFs gVCF reference infile list for joint genotyping (defaults to "")
                 -ggtals/--gatk_genotypegvcfs_all_sites Emit non-variant sites to the output vcf file (defaults to "0" (=no))
                 -ggbcf/gatk_concatenate_genotypegvcfs_bcf_file Produce a bcf from the GATK ConcatenateGenoTypeGVCFs vcf (defaults to "1" (=yes))
               -pgvr/--pgatk_variantrecalibration Variant recalibration using GATK VariantRecalibrator/ApplyRecalibration (defaults to "1" (=yes))
                 -gvrtsh/--gatk_variantrecalibration_training_set_hapmap GATK VariantRecalibrator HapMap training set (defaults to "GRCh37_hapmap_-3.3-.vcf")
                 -gvrtss/--gatk_variantrecalibration_training_set_dbsnp GATK VariantRecalibrator dbSNP training set (defaults to "GRCh37_dbsnp_-138-.vcf")
                 -gvrtsg/--gatk_variantrecalibration_training_set_1000gsnp GATK VariantRecalibrator 1000G high confidence SNP training set (defaults to "GRCh37_1000g_snps_high_confidence_-phase1-.vcf")
                 -gvrtso/--gatk_variantrecalibration_training_set_1000g_omni GATK VariantRecalibrator 1000G_omni training set (defaults to "GRCh37_1000g_omni_-2.5-.vcf")
                 -gvrtsm/--gatk_variantrecalibration_training_set_mills GATK VariantRecalibrator Mills training set (defaults to "GRCh37_mills_and_1000g_indels_-gold_standard-.vcf")
                 -gvrstf/--gatk_variantrecalibration_snv_tsfilter_level The truth sensitivity level for snvs at which to start filtering used in GATK VariantRecalibrator (defaults to "99.9")
                 -gvritf/--gatk_variantrecalibration_indel_tsfilter_level The truth sensitivity level for indels at which to start filtering used in GATK VariantRecalibrator (defaults to "99.9")
                 -gvrdpa/--gatk_variantrecalibration_dp_annotation Use the DP annotation in variant recalibration. (defaults to "1" (=yes))
                 -gvrsmg/--gatk_variantrecalibration_snv_max_gaussians Use hard filtering for snvs (defaults to "0" (=no))
                 -gvrimg/--gatk_variantrecalibration_indel_max_gaussians Use hard filtering for indels (defaults to "1" (=yes))
                 -gvrevf/--gatk_variantrecalibration_exclude_nonvariants_file Produce a vcf containing non-variant loci alongside the vcf only containing non-variant loci after GATK VariantRecalibrator (defaults to "0" (=no))
                 -gvrbcf/--gatk_variantrecalibration_bcf_file Produce a bcf from the GATK VariantRecalibrator vcf (defaults to "1" (=yes))
                 -gcgpss/--gatk_calculategenotypeposteriors_support_set GATK CalculateGenotypePosteriors support set (defaults to "1000g_sites_GRCh37_phase3_v4_20130502.vcf")
               -pgcv/--pgatk_combinevariantcallsets Combine variant call sets (defaults to "1" (=yes))
                 -gcvbcf/--gatk_combinevariantcallsets_bcf_file Produce a bcf from the GATK CombineVariantCallSet vcf (defaults to "1" (=yes))
                 -gcvpc/gatk_combinevariants_prioritize_caller The prioritization order of variant callers.(defaults to ""; comma sep; Options: gatk|samtools|freebayes)
               -pgpt/--pgatk_phasebytransmission Computes the most likely genotype and phases calls were unamibigous using GATK PhaseByTransmission (defaults to "0" (=no))
               -pgrp/--pgatk_readbackedphasing Performs physical phasing of SNP calls, based on sequencing reads using GATK ReadBackedPhasing (defaults to "0" (=no))
                 -grpqth/--gatk_readbackedphasing_phase_quality_threshold The minimum phasing quality score required to output phasing (defaults to "20")
               -pgvea/--pgatk_variantevalall Variant evaluation using GATK varianteval for all variants  (defaults to "1" (=yes))
               -pgvee/--pgatk_variantevalexome Variant evaluation using GATK varianteval for exonic variants  (defaults to "1" (=yes))
                 -gveedbs/--gatk_varianteval_dbsnp DbSNP file used in GATK varianteval (defaults to "dbsnp_GRCh37_138_esa_129.vcf")
                 -gveedbg/--gatk_varianteval_gold Gold indel file used in GATK varianteval (defaults to "GRCh37_mills_and_1000g_indels_-gold_standard-.vcf")

               ###Annotation
               -ppvab/--pprepareforvariantannotationblock Prepare for variant annotation block by copying and splitting files per contig (Mandatory)
               -prhc/--prhocall Rhocall performs annotation of variants in autozygosity regions (defaults to "1" (=yes))
               -rhcf/--rhocall_frequency_file Frequency file for bcftools roh calculation (defaults to "GRCh37_anon_swegen_snp_-2016-10-19-.tab.gz", tab sep)
               -pvt/--pvt VT decompose and normalize (defaults to "1" (=yes))
                 -vtdec/--vt_decompose Split multi allelic records into single records (defaults to "1" (=yes))
                 -vtnor/--vt_normalize Normalize variants (defaults to "1" (=yes))
                 -vtmaa/--vt_missing_alt_allele Remove missing alternative alleles '*' (defaults to "1" (=yes))
                 -vtgmf/--vt_genmod_filter Remove common variants from vcf file (defaults to "1" (=yes))
                 -vtgfr/--vt_genmod_filter_1000g Genmod annotate 1000G reference (defaults to "GRCh37_all_wgs_-phase3_v5b.2013-05-02-.vcf.gz")
                 -vtmaf/--vt_genmod_filter_max_af Annotate MAX_AF from reference (defaults to "")
                 -vtgft/--vt_genmod_filter_threshold Threshold for filtering variants (defaults to "0.10")
               -pvep/--pvarianteffectpredictor Annotate variants using VEP (defaults to "1" (=yes))
                 -vepp/--vep_directory_path Path to VEP script directory (defaults to "")
                 -vepc/--vep_directory_cache Specify the cache directory to use (defaults to "")
                 -vepr/--vep_reference Use Human reference file with VEP (defaults to "0" (=no))
                 -vepf/--vep_features VEP features (defaults to ("hgvs","symbol","numbers","sift","polyphen","humdiv","domains","protein","ccds","uniprot","biotype","regulatory", "tsl", "canonical", "appris"); comma sep)
                 -veppl/--vep_plugins VEP plugins (defaults to ("UpDownDistance, LoFtool, LoF"); comma sep)
               -pvcp/--pvcfparser Parse variants using vcfParser.pl (defaults to "1" (=yes))
                 -vcpvt/--vcfparser_vep_transcripts Parse VEP transcript specific entries (defaults to "0" (=no))
                 -vcprff/--vcfparser_range_feature_file Range annotations file (defaults to ""; tab-sep)
                 -vcprfa/--vcfparser_range_feature_annotation_columns Range annotations feature columns (defaults to ""; comma sep)
                 -vcpsf/--vcfparser_select_file File containging list of genes to analyse seperately (defaults to "";tab-sep file and HGNC Symbol required)
                 -vcpsfm/--vcfparser_select_file_matching_column Position of HGNC symbol column in SelectFile (defaults to "")
                 -vcpsfa/--vcfparser_select_feature_annotation_columns Feature columns to use in annotation (defaults to ""; comma sep)
               -panv/--pannovar Annotate variants using annovar (defaults to "0" (=no))
                 -anvp/--annovar_path  Path to annovar script directory (defaults to "". NOTE: Assumes that the annovar db files are located in annovar/humandb)
                 -anvgbv/--annovar_genome_build_version annovar genome build version (defaults to "hg19")
                 -anvtn/--annovar_table_names annovar table names (defaults to ("refGene","mce46way","gerp++elem","segdup","tfbs","mirna","snp137NonFlagged","1000g2012apr_all","esp6500si_all","ljb2_sift","ljb2_pp2hdiv","ljb2_pp2hvar","ljb2_mt","ljb2_lrt","ljb2_gerp++","ljb2_phylop"); comma sep)
                 -anvstn/--annovar_supported_table_names Print annovar MIP supported table names
                 -anvarmafth/--annovar_maf_threshold Sets the minor allele frequency threshold in annovar (defaults to "0")
               -psne/--psnpeff Variant annotation using snpEff (defaults to "1" (=yes))
#snpEffAnn
                 -snep/--snpeff_path Path to snpEff. Mandatory for use of snpEff (defaults to "")
                 -sneann/--snpeff_ann Annotate variants using snpeff (defaults to "1" (=yes))
                 -snegbv/--snpeff_genome_build_version snpeff genome build version (defaults to "GRCh37.75")
                 -snesaf/--snpsift_annotation_files Annotation files to use with snpsift (default to (GRCh37_all_wgs_-phase3_v5b.2013-05-02-.vcf.gz=AF GRCh37_exac_reheader_-r0.3.1-.vcf.gz=AF GRCh37_anon-swegen_snp_-1000samples-.vcf.gz=AF GRCh37_anon-swegen_indel_-1000samples-.vcf.gz=AF); Hash flag i.e. --Flag key=value)
                 -snesaoi/--snpsift_annotation_outinfo_key snpsift output INFO key (default to (GRCh37_all_wgs_-phase3_v5b.2013-05-02-.vcf=1000G GRCh37_exac_reheader_-r0.3.1-.vcf.gz=EXAC GRCh37_anon-swegen_snp_-1000samples-.vcf.gz=SWEREF GRCh37_anon-swegen_indel_-1000samples-.vcf.gz=SWEREF); Hash flag i.e. --Flag key=value)
                 -snesdbnsfp/--snpsift_dbnsfp_file DbNSFP File (defaults to "GRCh37_dbnsfp_-v2.9-.txt.gz")
                 -snesdbnsfpa/--snpsift_dbnsfp_annotations DbNSFP annotations to use with snpsift (defaults to ("SIFT_pred","Polyphen2_HDIV_pred","Polyphen2_HVAR_pred","GERP++_NR","GERP++_RS","phastCons100way_vertebrate"); comma sep)

               ##Rankvariant
               -prav/--prankvariant Ranking of annotated variants (defaults to "1" (=yes))
                 -ravgft/--genmod_models_family_type Use one of the known setups (defaults to "mip")
                 -ravanr/--genmod_annotate_regions Use predefined gene annotation supplied with genmod for defining genes (defaults to "1" (=yes))
                 -ravcad/--genmod_annotate_cadd_files CADD score files (defaults to ""; comma sep)
                 -ravspi/--genmod_annotate_spidex_file Spidex database for alternative splicing (defaults to "")
                 -ravwg/--genmod_models_whole_gene Allow compound pairs in intronic regions (defaults to "1" (=yes))
                 -ravrpf/--genmod_models_reduced_penetrance_file File containg genes with reduced penetrance (defaults to "")
                 -ravrm/--rank_model_file Rank model config file (defaults to "")
                 -ravbf/--rankvariant_binary_file Produce binary file from the rank variant chromosomal sorted vcfs (defaults to "1" (=yes))

               ###Utility
               -psck/--psamplecheck QC for samples gender and relationship (defaults to "1" (=yes) )
               -pevl/--pevaluation Compare concordance with NIST data set (defaults to "0" (=no) )
                 -evlnid/--nist_id NIST high-confidence sample_id (defaults to "NA12878")
                 -evlnhc/--nist_high_confidence_call_set NIST high-confidence variant calls (defaults to "GRCh37_nist_na12878_hg001_-v2.19-.vcf")
                 -evlnil/--nist_high_confidence_call_set_bed NIST high-confidence variant calls interval list (defaults to "GRCh37_nist_na12878_hg001_-v2.19-.bed")
               -pqcc/--pqccollect Collect QC metrics from programs processed (defaults to "1" (=yes) )
                 -qccsi/--qccollect_sampleinfo_file SampleInfo file containing info on what to parse from this analysis run (defaults to "{outdata_dir}/{family_id}/{family_id}_qc_sample_info.yaml")
                 -qccref/--qccollect_regexp_file Regular expression file containing the regular expression to be used for each program (defaults to "qc_regexp_-v1.13-.yaml")
                 -qccske/--qccollect_skip_evaluation Skip evaluation step in qccollect (boolean)
               -pmqc/--pmultiqc Create aggregate bioinformatics analysis report across many samples (defaults to "1" (=yes))
               -prem/--premoveredundantfiles Generating sbatch script for deletion of redundant files (defaults to "1" (=yes);Note: Must be submitted manually to SLURM)
               -pars/--panalysisrunstatus Sets the analysis run status flag to finished in sample_info_file (defaults to "1" (=yes))
               -psac/--psacct Generating sbatch script for SLURM info on each submitted job (defaults to "1" (=yes);Note: Must be submitted manually to SLURM)
	   };

    sub eval_modules {

	##eval_modules

	##Function : Evaluate that all modules required are installed
	##Returns  : ""
	##Arguments: $modules_ref
	##         : $modules_ref => Array of module names

	local $Params::Check::PRESERVE_CASE = 1;

	my ($arg_href) = @_;

	##Flatten argument(s)
	my $modules_ref;

	my $tmpl = {
	    modules_ref => { required => 1, default => [], strict_type => 1, store => \$modules_ref},
	};

	check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

	foreach my $module (@$modules_ref) {

	    $module =~s/::/\//g;  #Replace "::" with "/" since the automatic replacement magic only occurs for barewords.
	    $module .= ".pm";  #Add perl module ending for the same reason

	    eval {

		require $module;
	    };
	    if($@) {

		warn("NOTE: ".$module." not installed - Please install to run MIP.\n");
		warn("NOTE: Aborting!\n");
		exit 1;
	    }
	}
    }
}

####Script parameters

my %parameter;  #Holds all parameters for MIP
my %active_parameter;  #Holds all active parameters after the value has been set

my @order_parameters;  #To add/write parameters in the correct order
my @broadcasts;  #Holds all set parameters info after add_to_active_parameter

## Add date_time_stamp for later use in log and qc_metrics yaml file
my $date_time = localtime;
my $date_time_stamp = $date_time->datetime;
my $date = $date_time->ymd;
my $script = (`basename $0`);  #Catches script name
chomp($date_time_stamp, $date, $script);  #Remove \n;

####Set program parameters

###Project specific

## Loads a YAML file into an arbitrary hash and returns it.
%parameter = File::Format::Yaml::load_yaml({yaml_file => catfile($Bin, "definitions", "define_parameters.yaml"),
					   });

## Adds the order of first level keys from yaml file to array
order_parameter_names({order_parameters_ref => \@order_parameters,
		       file_path => catfile($Bin, "definitions", "define_parameters.yaml"),
		      });

## Eval parameter hash
eval_parameter_hash({parameter_href => \%parameter,
		     file_path => catfile($Bin, "definitions", "define_parameters.yaml"),
		    });

my $mip_version = "v4.0.13";	#Set MIP version

## Directories, files, sample_info and job_ids
my (%infile, %indir_path, %infile_lane_no_ending, %lane, %infile_both_strands_no_ending, %job_id, %sample_info);


####Staging/Sanity Check Area

my %file_info = (mosaik_align_reference => ".dat",
		 mosaik_jump_db_stub => "_jdb_15",
		 bwa_build_reference => "",
		 exome_target_bed => [".infile_list", ".pad100.infile_list", ".pad100.interval_list"],
		 mosaik_jump_db_stub_file_endings => ["_keys.jmp", "_meta.jmp", "_positions.jmp"],  #MosaikJumpDatabase file endings
		 bwa_build_reference_file_endings => [".amb", ".ann", ".bwt", ".pac", ".sa"],  #BWA human genome reference file endings
		 human_genome_reference_file_endings => [".dict", ".fai"],  #Meta files
    );

## Capture kit aliases supported from pedigree file.
my %supported_capture_kit = ('nimblegen_seqcapezexome.v2' => "genome_reference_source_version_nimblegen_seqcapezexome_targets_-v2-.bed",
			     'nimblegen_seqcapezexome.v3' => "genome_reference_source_version_nimblegen_seqcapezexome_targets_-v3-.bed",
			     'agilent_sureselect.v2' => "genome_reference_source_version_agilent_sureselect_targets_-v2-.bed",
			     'agilent_sureselect.v3' => "genome_reference_source_version_agilent_sureselect_targets_-v3-.bed",
			     'agilent_sureselect.v4' => "genome_reference_source_version_agilent_sureselect_targets_-v4-.bed",
			     'agilent_sureselect.v5' => "genome_reference_source_version_agilent_sureselect_targets_-v5-.bed",
			     'agilent_sureselect_cre.v1' => "genome_reference_source_version_agilent_sureselect_targets_cre_-v1-.bed",
			     'agilent_sureselect_focusedexome.v1' => "genome_reference_source_version_agilent_sureselect_targets_focusedexome_-v1-.bed",
			     'latest' => "genome_reference_source_version_agilent_sureselect_targets_cre_-v1-.bed",
    );

my %supported_cosmid_reference;  #References supported as downloads from Cosmid. Hash is populated after user options are processed

## Reference that should be decomposed and normalized using vt
my @vt_references = ("gatk_realigner_indel_known_sites",
		     "gatk_baserecalibration_known_sites",
		     "gatk_haplotypecaller_snp_known_set",
		     "gatk_variantrecalibration_training_set_hapmap",
		     "gatk_variantrecalibration_training_set_mills",
		     "gatk_variantrecalibration_training_set_1000g_omni",
		     "gatk_variantrecalibration_training_set_1000gsnp",
		     "gatk_variantrecalibration_training_set_dbsnp",
		     "vt_genmod_filter_1000g",
		     "gatk_varianteval_gold",
		     "gatk_varianteval_dbsnp",
		     "snpsift_annotation_files",
    );

## Set supported annovar table name filtering options
my @annovar_supported_table_names = ("refGene", "knownGene", "ensGene", "mce46way", "gerp++elem", "segdup", "gwascatalog", "tfbs", "mirna", "snp137", "snp135", "snp132", "snp131", "snp130", "snp129", "snp137NonFlagged", "snp135NonFlagged", "snp132NonFlagged", "snp131NonFlagged", "snp130NonFlagged", "1000g2012apr_all", "1000g2012apr_amr", "1000g2012apr_eur", "1000g2012apr_asn", "1000g2012apr_afr", "1000g2012feb_all", "esp6500si_all", "esp6500_all", "esp6500_aa", "esp6500_ea", "esp5400_all", "esp5400_aa", "esp5400_ea","clinvar_20131105", "ljb2_sift", "ljb2_pp2hdiv", "ljb2_pp2hvar", "ljb2_mt", "ljb2_ma", "ljb2_fathmm", "ljb2_siphy", "ljb2_lrt", "ljb_all", "ljb2_gerp++", "ljb2_phylop", "caddgt20", "caddgt10");  #Used to print list of supported table names

my %annovar_table;  #Holds annovar tables and features


## Enables cmd "mip.pl" to print usage help
if(!@ARGV) {

    help({USAGE => $USAGE,
	  exit_code => 0,
	 });
}

###User Options
GetOptions('ifd|infile_dirs:s' => \%{ $parameter{infile_dirs}{value} },  #Hash infile_dirs=sample_id
	   'sd|script_dir:s' => \$parameter{script_dir}{value},  #Directory for custom scripts required by the pipeline
	   'rd|reference_dir:s' => \$parameter{reference_dir}{value},  #directory containing references
	   'p|project_id:s' => \$parameter{project_id}{value},
	   's|sample_ids:s' => \@{ $parameter{sample_ids}{value} },  #Comma separated list
	   'em|email:s' => \$parameter{email}{value},  #Email adress
	   'emt|email_type:s' => \$parameter{email_type}{value},  #Email type
	   'odd|outdata_dir:s' => \$parameter{outdata_dir}{value},  #One dir above sample id, must supply whole path i.e. /proj/...
	   'osd|outscript_dir:s' => \$parameter{outscript_dir}{value},   #One dir above sample id, must supply whole path i.e. /proj/...
	   'f|family_id:s' => \$parameter{family_id}{value},  #Family group ID (Merged to same vcf file after GATK Base Recalibration)
	   'ped|pedigree_file:s' => \$parameter{pedigree_file}{value},  #Pedigree file
	   'hgr|human_genome_reference:s' => \$parameter{human_genome_reference}{value},  #Human genome reference
	   'al|outaligner_dir:s' => \$parameter{outaligner_dir}{value},  #determining which aligner out data directory was used previously (if not specified)
	   'at|analysis_type:s' => \%{ $parameter{analysis_type}{value} },  #sample_id=analysis_type
	   'pl|platform:s' => \$parameter{platform}{value},  #Platform/technology used to produce the reads
	   'ec|expected_coverage:s' => \%{ $parameter{expected_coverage}{value} },  #sample_id=expected_coverage
	   'cpn|core_processor_number=n' => \$parameter{core_processor_number}{value},  #Per node
	   'c|config_file:s' => \$parameter{config_file}{value},
	   'ccp|cluster_constant_path:s' => \$parameter{cluster_constant_path}{value},
	   'acp|analysis_constant_path:s' => \$parameter{analysis_constant_path}{value},
	   'cfa|config_file_analysis:s' => \$parameter{config_file_analysis}{value},
	   'sif|sample_info_file:s' => \$parameter{sample_info_file}{value},  #Write all info on samples and run to YAML file
	   'dra|dry_run_all=i' => \$parameter{dry_run_all}{value},
	   'tmd|temp_directory:s' => \$parameter{temp_directory}{value},
	   'sen|source_environment_commands=s{,}' => \@{ $parameter{source_environment_commands}{value} },
	   'jul|java_use_large_pages=n' => \$parameter{java_use_large_pages}{value},
	   'nrm|node_ram_memory=n' => \$parameter{node_ram_memory}{value},  #Per node
	   'qos|slurm_quality_of_service=s' => \$parameter{slurm_quality_of_service}{value},
           'ges|genomic_set:s' => \$parameter{genomic_set}{value},  #Selection of relevant regions post alignment and sort
	   'rio|reduce_io=n' => \$parameter{reduce_io}{value},
	   'riu|replace_iupac=n' => \$parameter{replace_iupac}{value},
	   'ppm|print_program_mode=n' => \$parameter{print_program_mode}{value},
	   'pp|print_program' => sub { GetOptions('ppm|print_program_mode=n' => \$parameter{print_program_mode}{value});  #Force ppm to be read before function call
				       print_program({parameter_href => \%parameter,
						      print_program_mode => $parameter{print_program_mode}{value},
						     }); exit;},
	   'l|log_file:s' => \$parameter{log_file}{value},
	   'h|help' => sub { say STDOUT $USAGE; exit;},  #Display help text
	   'v|version' => sub { say STDOUT "\nMip.pl ".$mip_version, "\n"; exit;},  #Display version number
	   'psfq|psplit_fastq_file=n' => \$parameter{psplit_fastq_file}{value},
	   'sfqrdb|split_fastq_file_read_batch=n' => \$parameter{split_fastq_file_read_batch}{value},
	   'pgz|pgzip_fastq=n' => \$parameter{pgzip_fastq}{value},
	   'pfqc|pfastqc=n' => \$parameter{pfastqc}{value},
	   'pmad|pmadeline=n' => \$parameter{pmadeline}{value},
	   'pmob|pmosaik_build=n' => \$parameter{pmosaik_build}{value},
	   'mobmfl|mosaik_build_median_frag_length=n' => \$parameter{mosaik_build_median_frag_length}{value},  #For fragment length estimation and local search
	   'pmoa|pmosaik_aligner=n' => \$parameter{pmosaik_aligner}{value},
	   'moaref|mosaik_align_reference:s' => \$parameter{mosaik_align_reference}{value},  #MosaikAlign reference file assumes existance of jump database files in same dir
	   'moaape|mosaik_align_neural_network_pe_file:s' => \$parameter{mosaik_align_neural_network_pe_file}{value},
	   'moaase|mosaik_align_neural_network_se_file:s' => \$parameter{mosaik_align_neural_network_se_file}{value},
	   'mojdb|mosaik_jump_db_stub:s' => \$parameter{mosaik_jump_db_stub}{value},  #Stub for MosaikJump database
	   'pmem|pbwa_mem=n' => \$parameter{pbwa_mem}{value},
	   'memhla|bwa_mem_hla=n' => \$parameter{bwa_mem_hla}{value},
	   'memrdb|bwa_mem_rapid_db:s' => \$parameter{bwa_mem_rapid_db}{value},
	   'memcrm|bwa_mem_cram=n' => \$parameter{bwa_mem_cram}{value},
	   'memsts|bwa_mem_bamstats=n' => \$parameter{bwa_mem_bamstats}{value},
	   'memssm|bwa_sambamba_sort_memory_limit:s' => \$parameter{bwa_sambamba_sort_memory_limit}{value},
	   'paln|pbwa_aln=n' => \$parameter{pbwa_aln}{value},
	   'alnq|bwa_aln_quality_trimming=n' => \$parameter{bwa_aln_quality_trimming}{value},  #BWA aln quality threshold for read trimming down to 35bp
	   'psap|pbwa_sampe=n' => \$parameter{pbwa_sampe}{value},
	   'pptm|ppicardtools_mergesamfiles=n' => \$parameter{ppicardtools_mergesamfiles}{value},  #Picardtools mergeSamFiles
	   'ptmp|picardtools_mergesamfiles_previous_bams:s' => \@{ $parameter{picardtools_mergesamfiles_previous_bams}{value} },  #Comma separated list
	   'pptmr|ppicardtools_mergerapidreads=n' => \$parameter{ppicardtools_mergerapidreads}{value},  #Picardtools mergeSamFiles - rapid mode
	   'ptp|picardtools_path:s' => \$parameter{picardtools_path}{value},  #Path to picardtools
	   'ppmd|ppicardtools_markduplicates=n' => \$parameter{ppicardtools_markduplicates}{value},  #Picardtools markduplicates
	   'psmd|psambamba_markduplicates=n' => \$parameter{psambamba_markduplicates}{value},  #Sambamba markduplicates
	   'smdhts|sambamba_markdup_hash_table_size=n' => \$parameter{sambamba_markdup_hash_table_size}{value},
	   'smdols|sambamba_markdup_overflow_list_size=n' => \$parameter{sambamba_markdup_overflow_list_size}{value},
	   'smdibs|sambamba_markdup_io_buffer_size=n' => \$parameter{sambamba_markdup_io_buffer_size}{value},
	   'pchs|pchanjo_sexcheck=n' => \$parameter{pchanjo_sexcheck}{value},   #Chanjo coverage analysis on sex chromosomes
	   'psdt|psambamba_depth=n' => \$parameter{psambamba_depth}{value},   #Chanjo coverage analysis
	   'sdtcut|sambamba_depth_cutoffs:s' => \@{ $parameter{sambamba_depth_cutoffs}{value} },   # Cutoff used for completeness
	   'sdtbed|sambamba_depth_bed:s' => \$parameter{sambamba_depth_bed}{value},
	   'sdtbaq|sambamba_depth_base_quality=n' => \$parameter{sambamba_depth_base_quality}{value},
	   'sdtmaq|sambamba_depth_mapping_quality=n' => \$parameter{sambamba_depth_mapping_quality}{value},
	   'sdtndu|sambamba_depth_noduplicates=n' => \$parameter{sambamba_depth_noduplicates}{value},
	   'sdtfqc|sambamba_depth_quality_control=n' => \$parameter{sambamba_depth_quality_control}{value},
	   'pgcb|pgenomecoveragebed=n' => \$parameter{pgenomecoveragebed}{value},
	   'xcov|genomecoveragebed_max_coverage=n' => \$parameter{genomecoveragebed_max_coverage}{value},  #Sets max depth to calculate coverage
	   'pptcmm|ppicardtools_collectmultiplemetrics=n' => \$parameter{ppicardtools_collectmultiplemetrics}{value},
	   'pptchs|ppicardtools_calculatehsmetrics=n' => \$parameter{ppicardtools_calculatehsmetrics}{value},
	   'extb|exome_target_bed=s' => \%{ $parameter{exome_target_bed}{value} },  #Hash value file.bed=sample_id
	   'prcp|prcovplots=n' => \$parameter{prcovplots}{value},
	   'pcnv|pcnvnator=n' => \$parameter{pcnvnator}{value},
	   'cnvhbs|cnv_bin_size=n' => \$parameter{cnv_bin_size}{value},
	   'pdelc|pdelly_call=n' => \$parameter{pdelly_call}{value},
	   'pdel|pdelly_reformat=n' => \$parameter{pdelly_reformat}{value},
	   'deltyp|delly_types:s' => \@{ $parameter{delly_types}{value} },
	   'delexc|delly_exclude_file:s' => \$parameter{delly_exclude_file}{value}, 
	   'pmna|pmanta=n' => \$parameter{pmanta}{value},
	   'pfit|pfindtranslocations=n' => \$parameter{pfindtranslocations}{value},
	   'fitmsp|findtranslocations_minimum_supporting_pairs=n' => \$parameter{findtranslocations_minimum_supporting_pairs}{value},
	   'psvc|psv_combinevariantcallsets=n' => \$parameter{psv_combinevariantcallsets}{value},  #Combine structural variant call sets
	   'svcvtd|sv_vt_decompose=n' => \$parameter{sv_vt_decompose}{value},  #VT decompose (split multiallelic variants)
	   'svcbtv|sv_bcftools_view_filter=n' => \$parameter{sv_bcftools_view_filter}{value},  #Include structural variants with PASS in FILTER column
	   'svcvan|sv_vcfanno=n' => \$parameter{sv_vcfanno}{value},
	   'svcval|sv_vcfanno_lua:s' => \$parameter{sv_vcfanno_lua}{value},  #Lua file postscripting
	   'svcvac|sv_vcfanno_config:s' => \$parameter{sv_vcfanno_config}{value},  #Toml config of what to annotate
	   'svcvacf|sv_vcfanno_config_file:s' => \$parameter{sv_vcfanno_config_file}{value},  #Annotation file within vcfAnno config toml file
	   'svcvah|sv_vcfannotation_header_lines_file:s' => \$parameter{sv_vcfannotation_header_lines_file}{value},  #Adjust for postscript by adding required header lines to vcf
	   'svcgmf|sv_genmod_filter=n' => \$parameter{sv_genmod_filter}{value},  #Remove common structural variants from vcf
	   'svcgfr|sv_genmod_filter_1000g:s' => \$parameter{sv_genmod_filter_1000g}{value},  #Genmod annotate structural variants from 1000G reference
	   'svcgft|sv_genmod_filter_threshold:s' => \$parameter{sv_genmod_filter_threshold}{value},  #Threshold for filtering structural variants
	   'svcbcf|sv_combinevariantcallsets_bcf_file=n' => \$parameter{sv_combinevariantcallsets_bcf_file}{value},  #Produce compressed vcf
	   'psvv|psv_varianteffectpredictor=n' => \$parameter{psv_varianteffectpredictor}{value},
	   'svvepf|sv_vep_features:s' => \@{ $parameter{sv_vep_features}{value} },  #Comma separated list
	   'svvepl|sv_vep_plugins:s' => \@{ $parameter{sv_vep_plugins}{value} },  #Comma separated list
	   'psvvcp|psv_vcfparser=n' => \$parameter{psv_vcfparser}{value},
	   'svvcpvt|sv_vcfparser_vep_transcripts=n' => \$parameter{sv_vcfparser_vep_transcripts}{value},
	   'svvcppg|sv_vcfparser_per_gene=n' => \$parameter{sv_vcfparser_per_gene}{value},
	   'svvcprff|sv_vcfparser_range_feature_file:s' => \$parameter{sv_vcfparser_range_feature_file}{value},  #path to vcfparser_range_feature_file
	   'svvcprfa|sv_vcfparser_range_feature_annotation_columns:s' => \@{ $parameter{sv_vcfparser_range_feature_annotation_columns}{value} },  #Comma separated list
	   'svvcpsf|sv_vcfparser_select_file:s' => \$parameter{sv_vcfparser_select_file}{value},  #path to vcfparser_select_file
	   'svvcpsfm|sv_vcfparser_select_file_matching_column=n' => \$parameter{sv_vcfparser_select_file_matching_column}{value},  #Column of HGNC Symbol in SelectFile
	   'svvcpsfa|sv_vcfparser_select_feature_annotation_columns:s' => \@{ $parameter{sv_vcfparser_select_feature_annotation_columns}{value} },  #Comma separated list
	   'psvr|psv_rankvariant=n' => \$parameter{psv_rankvariant}{value},  #Ranking of SV variants
	   'svravanr|sv_genmod_annotate_regions:n' => \$parameter{sv_genmod_annotate_regions}{value},
	   'svravgft|sv_genmod_models_family_type:s' => \$parameter{sv_genmod_models_family_type}{value},
	   'svravrpf|sv_genmod_models_reduced_penetrance_file:s' => \$parameter{sv_genmod_models_reduced_penetrance_file}{value},
	   'svravwg|sv_genmod_models_whole_gene=n' => \$parameter{sv_genmod_models_whole_gene}{value},  #Allow compound pairs in intronic regions
	   'svravrm|sv_rank_model_file:s' => \$parameter{sv_rank_model_file}{value},  #The rank modell config.ini path
	   'svravbf|sv_rankvariant_binary_file=n' => \$parameter{sv_rankvariant_binary_file}{value},  #Produce compressed vcfs
	   'psmp|psamtools_mpileup=n' => \$parameter{psamtools_mpileup}{value},
	   'pfrb|pfreebayes=n' => \$parameter{pfreebayes}{value},
	   'gtp|gatk_path:s' => \$parameter{gatk_path}{value},  #GATK whole path
	   'gbdv|gatk_bundle_download_version:s' => \$parameter{gatk_bundle_download_version}{value},  #Sets the GATK FTP Bundle Download version
	   'gdco|gatk_downsample_to_coverage=n' => \$parameter{gatk_downsample_to_coverage}{value},  #GATK downsample to coverage
	   'gdai|gatk_disable_auto_index_and_file_lock=n' => \$parameter{gatk_disable_auto_index_and_file_lock}{value},
	   'pgra|pgatk_realigner=n' => \$parameter{pgatk_realigner}{value},  #GATK ReAlignerTargetCreator/IndelRealigner
	   'graks|gatk_realigner_indel_known_sites:s' => \@{ $parameter{gatk_realigner_indel_known_sites}{value} },  #Comma separated list
	   'pgbr|pgatk_baserecalibration=n' => \$parameter{pgatk_baserecalibration}{value},  #GATK baserecalibrator/printreads
	   'gbrcov|gatk_baserecalibration_covariates:s' => \@{ $parameter{gatk_baserecalibration_covariates}{value} },  #Comma separated list
	   'gbrkst|gatk_baserecalibration_known_sites:s' => \@{ $parameter{gatk_baserecalibration_known_sites}{value} },  #Comma separated list
	   'gbrocr|gatk_baserecalibration_over_clipped_read=n' => \$parameter{gatk_baserecalibration_over_clipped_read}{value},  #Filter out reads that are over-soft-clipped
	   'gbrdiq|gatk_baserecalibration_disable_indel_qual=n' => \$parameter{gatk_baserecalibration_disable_indel_qual}{value},  #Disable indel quality scores
	   'gbrsqq|gatk_baserecalibration_static_quantized_quals:s' => \@{ $parameter{gatk_baserecalibration_static_quantized_quals}{value} },  #Comma separated list
	   'pghc|pgatk_haplotypecaller=n' => \$parameter{pgatk_haplotypecaller}{value},  #GATK Haplotypecaller
	   'ghcann|gatk_haplotypecaller_annotation:s' => \@{ $parameter{gatk_haplotypecaller_annotation}{value} },  #Comma separated list
	   'ghckse|gatk_haplotypecaller_snp_known_set:s' => \$parameter{gatk_haplotypecaller_snp_known_set}{value},  #Known SNP set to be used in GATK HaplotypeCaller
	   'ghcscb|gatk_haplotypecaller_soft_clipped_bases=n' => \$parameter{gatk_haplotypecaller_soft_clipped_bases}{value},  #Do not include soft clipped bases in the variant calling
	   'ghcpim|gatk_haplotypecaller_pcr_indel_model:s' => \$parameter{gatk_haplotypecaller_pcr_indel_model}{value},  #The PCR indel model to use
	   'pggt|pgatk_genotypegvcfs=n' => \$parameter{pgatk_genotypegvcfs}{value},  #Merge gVCF records using GATK GenotypeGVCFs
	   'ggtgrl|gatk_genotypegvcfs_ref_gvcf:s' => \$parameter{gatk_genotypegvcfs_ref_gvcf}{value},  #GATK GenoTypeGVCFs gVCF reference infile list for joint genotyping
	   'ggtals|gatk_genotypegvcfs_all_sites=n' => \$parameter{gatk_genotypegvcfs_all_sites}{value},  #Emit non-variant sites to the output VCF
	   'ggbcf|gatk_concatenate_genotypegvcfs_bcf_file=n' => \$parameter{gatk_concatenate_genotypegvcfs_bcf_file}{value},  #Produce compressed vcf
	   'pgvr|pgatk_variantrecalibration=n' => \$parameter{pgatk_variantrecalibration}{value},  #GATK VariantRecalibrator/ApplyRecalibration
	   'gvrtsh|gatk_variantrecalibration_training_set_hapmap:s' => \$parameter{gatk_variantrecalibration_training_set_hapmap}{value},  #GATK VariantRecalibrator resource
	   'gvrtss|gatk_variantrecalibration_training_set_dbsnp:s' => \$parameter{gatk_variantrecalibration_training_set_dbsnp}{value},  #GATK VariantRecalibrator resource
	   'gvrtsg|gatk_variantrecalibration_training_set_1000gsnp:s' => \$parameter{gatk_variantrecalibration_training_set_1000gsnp}{value},  #GATK VariantRecalibrator resource
	   'gvrtso|gatk_variantrecalibration_training_set_1000g_omni:s' => \$parameter{gatk_variantrecalibration_training_set_1000g_omni}{value},  #GATK VariantRecalibrator resource
	   'gvrtsm|gatk_variantrecalibration_training_set_mills:s' => \$parameter{gatk_variantrecalibration_training_set_mills}{value},  #GATK VariantRecalibrator resource
	   'gvrstf|gatk_variantrecalibration_snv_tsfilter_level:s' => \$parameter{gatk_variantrecalibration_snv_tsfilter_level}{value},  #Snv truth sensativity level
	   'gvritf|gatk_variantrecalibration_indel_tsfilter_level:s' => \$parameter{gatk_variantrecalibration_indel_tsfilter_level}{value},  #Indel truth sensativity level
	   'gvrdpa|gatk_variantrecalibration_dp_annotation=n' => \$parameter{gatk_variantrecalibration_dp_annotation}{value},
	   'gvrsmg|gatk_variantrecalibration_snv_max_gaussians=n' => \$parameter{gatk_variantrecalibration_snv_max_gaussians}{value},
	   'gvrimg|gatk_variantrecalibration_indel_max_gaussians=n' => \$parameter{gatk_variantrecalibration_indel_max_gaussians}{value},
	   'gvrevf|gatk_variantrecalibration_exclude_nonvariants_file=n' => \$parameter{gatk_variantrecalibration_exclude_nonvariants_file}{value},
	   'gvrbcf|gatk_variantrecalibration_bcf_file=n' => \$parameter{gatk_variantrecalibration_bcf_file}{value},  #Produce compressed vcf
	   'gcgpss|gatk_calculategenotypeposteriors_support_set:s' => \$parameter{gatk_calculategenotypeposteriors_support_set}{value},  #GATK CalculateGenotypePosteriors support set
	   'pgcv|pgatk_combinevariantcallsets=n' => \$parameter{pgatk_combinevariantcallsets}{value},  #Combine variant call sets
	   'gcvpc|gatk_combinevariants_prioritize_caller:s' => \$parameter{gatk_combinevariants_prioritize_caller}{value},  #Prioritize variant calls
	   'gcvbcf|gatk_combinevariantcallsets_bcf_file=n' => \$parameter{gatk_combinevariantcallsets_bcf_file}{value},  #Produce compressed vcf
	   'pgpt|pgatk_phasebytransmission=n' => \$parameter{pgatk_phasebytransmission}{value},  #GATK phasebytransmission to produce phased genotype calls
	   'pgrp|pgatk_readbackedphasing=n' => \$parameter{pgatk_readbackedphasing}{value},  #GATK ReadBackedPhasing
	   'grpqth|gatk_readbackedphasing_phase_quality_threshold=n' => \$parameter{gatk_readbackedphasing_phase_quality_threshold}{value},  #quality score required to output phasing
	   'pgvea|pgatk_variantevalall=n' => \$parameter{pgatk_variantevalall}{value},  #GATK varianteval all variants
	   'pgvee|pgatk_variantevalexome=n' => \$parameter{pgatk_variantevalexome}{value},  #GATK varianteval only exonic variants
	   'gveedbs|gatk_varianteval_dbsnp:s' => \$parameter{gatk_varianteval_dbsnp}{value},
	   'gveedbg|gatk_varianteval_gold:s' => \$parameter{gatk_variantrecalibration_training_set_mills}{value},
	   'ppvab|pprepareforvariantannotationblock=n' => \$parameter{pprepareforvariantannotationblock}{value},
	   'prhc|prhocall=n' => \$parameter{prhocall}{value},  #rhocall program
	   'rhcf|rhocall_frequency_file:s' => \$parameter{rhocall_frequency_file}{value},
	   'pvt|pvt=n' => \$parameter{pvt}{value},  #VT program
	   'vtddec|vt_decompose=n' => \$parameter{vt_decompose}{value},  #vt decompose (split multiallelic variants)
	   'vtdnor|vt_normalize=n' => \$parameter{vt_normalize}{value},  #vt normalize varaints according to genomic reference
	   'vtmaa|vt_missing_alt_allele=n' => \$parameter{vt_missing_alt_allele}{value},  #vt remove '*' entries from vcf
	   'vtgmf|vt_genmod_filter=n' => \$parameter{vt_genmod_filter}{value},  #vt Remove common variants from vcf
	   'vtgfr|vt_genmod_filter_1000g:s' => \$parameter{vt_genmod_filter_1000g}{value},  #vt Genmod annotate 1000G reference
	   'vtmaf|vt_genmod_filter_max_af=n' => \$parameter{vt_genmod_filter_max_af}{value},
	   'vtgft|vt_genmod_filter_threshold:s' => \$parameter{vt_genmod_filter_threshold}{value},  #vt Threshold for filtering variants
	   'pvep|pvarianteffectpredictor=n' => \$parameter{pvarianteffectpredictor}{value},  #Annotation of variants using vep
	   'vepp|vep_directory_path:s' => \$parameter{vep_directory_path}{value},  #path to vep script dir
	   'vepc|vep_directory_cache:s' => \$parameter{vep_directory_cache}{value},  #path to vep cache dir
	   'vepr|vep_reference:n' => \$parameter{vep_reference}{value},  #Use Human reference file with VEP
	   'vepf|vep_features:s' => \@{ $parameter{vep_features}{value} },  #Comma separated list
	   'veppl|vep_plugins:s' => \@{ $parameter{vep_plugins}{value}},  #Comma separated list
	   'pvcp|pvcfparser=n' => \$parameter{pvcfparser}{value},
	   'vcpvt|vcfparser_vep_transcripts=n' => \$parameter{vcfparser_vep_transcripts}{value},
	   'vcprff|vcfparser_range_feature_file:s' => \$parameter{vcfparser_range_feature_file}{value},  #path to vcfparser_range_feature_file
	   'vcprfa|vcfparser_range_feature_annotation_columns:s' => \@{ $parameter{vcfparser_range_feature_annotation_columns}{value} },  #Comma separated list
	   'vcpsf|vcfparser_select_file:s' => \$parameter{vcfparser_select_file}{value},  #path to vcfparser_select_file
	   'vcpsfm|vcfparser_select_file_matching_column=n' => \$parameter{vcfparser_select_file_matching_column}{value},  #Column of HGNC Symbol in SelectFile
	   'vcpsfa|vcfparser_select_feature_annotation_columns:s' => \@{ $parameter{vcfparser_select_feature_annotation_columns}{value} },  #Comma separated list
	   'panv|pannovar=n' => \$parameter{pannovar}{value},  #Performs annovar filter gene, region and filter analysis
	   'anvp|annovar_path:s' => \$parameter{annovar_path}{value},  #path to annovar script dir
	   'anvgbv|annovar_genome_build_version:s' => \$parameter{annovar_genome_build_version}{value},
	   'anvtn|annovar_table_names:s' => \@{ $parameter{annovar_table_names}{value} },  #Comma separated list
	   'anvstn|annovar_supported_table_names' => sub { print_supported_annovar_table_names({active_parameter_href => \%active_parameter,
												annovar_supported_table_names_ref => \@annovar_supported_table_names,
											       })},  #Generates a list of supported table names
	   'anvarmafth|annovar_maf_threshold=n' => \$parameter{annovar_maf_threshold}{value},
	   'psne|psnpeff=n' => \$parameter{psnpeff}{value},
	   'snep|snpeff_path:s' => \$parameter{snpeff_path}{value},  #path to snpEff directory
	   'sneann|snpeff_ann=n' => \$parameter{snpeff_ann}{value},
	   'snegbv|snpeff_genome_build_version:s' => \$parameter{snpeff_genome_build_version}{value},
	   'snesaf|snpsift_annotation_files=s' => \%{ $parameter{snpsift_annotation_files}{value} },
	   'snesaoi|snpsift_annotation_outinfo_key=s' => \%{ $parameter{snpsift_annotation_outinfo_key}{value} },
	   'snesdbnsfp|snpsift_dbnsfp_file:s' => \$parameter{snpsift_dbnsfp_file}{value},  #DbNSFP file
	   'snesdbnsfpa|snpsift_dbnsfp_annotations:s' => \@{ $parameter{snpsift_dbnsfp_annotations}{value} },  #Comma separated list
	   'prav|prankvariant=n' => \$parameter{prankvariant}{value},  #Ranking variants
	   'ravgft|genmod_models_family_type:s' => \$parameter{genmod_models_family_type}{value},
	   'ravanr|genmod_annotate_regions:n' => \$parameter{genmod_annotate_regions}{value},
	   'ravcad|genmod_annotate_cadd_files:s' => \@{ $parameter{genmod_annotate_cadd_files}{value} },  #Comma separated list
	   'ravspi|genmod_annotate_spidex_file:s' => \$parameter{genmod_annotate_spidex_file}{value},
	   'ravwg|genmod_models_whole_gene=n' => \$parameter{genmod_models_whole_gene}{value},  #Allow compound pairs in intronic regions
	   'ravrpf|genmod_models_reduced_penetrance_file:s' => \$parameter{genmod_models_reduced_penetrance_file}{value},
	   'ravrm|rank_model_file:s' => \$parameter{rank_model_file}{value},  #The rank modell config.ini path
	   'ravbf|rankvariant_binary_file=n' => \$parameter{rankvariant_binary_file}{value},  #Produce compressed vcfs
	   'psck|psamplecheck=n' => \$parameter{psamplecheck}{value},  #QC for samples gender and relationship
	   'pevl|pevaluation=n' => \$parameter{pevaluation}{value},  #Compare concordance with NIST data set
	   'evlnid|nist_id:s' => \$parameter{nist_id}{value},
	   'evlnhc|nist_high_confidence_call_set:s' => \$parameter{nist_high_confidence_call_set}{value},
	   'evlnil|nist_high_confidence_call_set_bed:s' => \$parameter{nist_high_confidence_call_set_bed}{value},
	   'pqcc|pqccollect=n' => \$parameter{pqccollect}{value},  #QCmetrics collect
	   'qccsi|qccollect_sampleinfo_file:s' => \$parameter{qccollect_sampleinfo_file}{value},  #SampleInfo yaml file produced by MIP
	   'qccref|qccollect_regexp_file:s' => \$parameter{qccollect_regexp_file}{value},  #Regular expression yaml file
	   'qccske|qccollect_skip_evaluation' => \$parameter{qccollect_skip_evaluation}{value},
	   'pmqc|pmultiqc=n' => \$parameter{pmultiqc}{value},  #Aggregate bioinformatics reports
	   'prem|premoveredundantfiles=n' => \$parameter{premoveredundantfiles}{value},
	   'pars|panalysisrunstatus=n' => \$parameter{panalysisrunstatus}{value},  #analysisrunstatus change flag in sample_info file if allowed to execute
	   'psac|psacct=n' => \$parameter{psacct}{value},
    ) or help({USAGE => $USAGE,
	       exit_code => 1,
	      });


## Change relative path to absolute path for certain parameters
update_to_absolute_path({parameter_href => \%parameter,
			});


##Special case:Enable/activate MIP. Cannot be changed from cmd or config
$active_parameter{mip} = $parameter{mip}{default};

if (defined($parameter{config_file}{value})) {  #Input from cmd

    ## Loads a YAML file into an arbitrary hash and returns it.
    %active_parameter = File::Format::Yaml::load_yaml({yaml_file => $parameter{config_file}{value},
						      });

    ##Special case:Enable/activate MIP. Cannot be changed from cmd or config
    $active_parameter{mip} = $parameter{mip}{default};

    ##Special case:Required when turning of vcfParser to know how many files should be analysed (.select.vcf or just .vcf)
    $active_parameter{vcfparser_outfile_count} = $parameter{vcfparser_outfile_count}{default};

    ## Compare keys in two hashes
    compare_hash_keys({reference_href => \%active_parameter,
		       comparison_href => \%parameter,
		      });

    my @config_dynamic_parameters = ("cluster_constant_path", "analysis_constant_path", "outaligner_dir");

    ## Replace config parameter with cmd info for config dynamic parameter
    replace_config_parameters_with_cmd_info({parameter_href => \%parameter,
					     active_parameter_href => \%active_parameter,
					     parameter_names_ref => \@config_dynamic_parameters,
					    });

    foreach my $order_parameter_element (@order_parameters) {  #Loop through all parameters and update info

	## Updates the config file to particular user/cluster for entries following specifications. Leaves other entries untouched.
	update_config_file({active_parameter_href => \%active_parameter,
			    parameter_name_ref => \$order_parameter_element,
			    family_id_ref => \$parameter{family_id}{value},
			   });
    }

    ##Remove previous analysis specific info not relevant for current run e.g. log file, sample_ids which are read from pedigree or cmd
    my @remove_keys = ("log_file", "sample_ids");
    foreach my $key (@remove_keys) {

	delete($active_parameter{$key});
    }
}


###Populate active_parameters{parameter_name} => 'Value'
foreach my $order_parameter_element (@order_parameters) {

    ## Type of variables: mip, path or program/program_parameters each is handled in the add_to_active_parameter subroutine.
    ## Checks and sets user input or default values to active_parameters
    add_to_active_parameter({parameter_href => \%parameter,
			     active_parameter_href => \%active_parameter,
			     sample_info_href => \%sample_info,
			     file_info_href => \%file_info,
			     supported_capture_kit_href => \%supported_capture_kit,
			     broadcasts_ref => \@broadcasts,
			     associated_programs_ref => \@{ $parameter{$order_parameter_element}{associated_program} },
			     parameter_name => $order_parameter_element,
			    });

    ## Special case for parameters that are dependent on other parameters values
    if ($order_parameter_element eq "outdata_dir") {  #Set defaults depending on $active_parameter{outdata_dir} value that now has been set

	$parameter{sample_info_file}{default} = catfile($active_parameter{outdata_dir}, $active_parameter{family_id}, $active_parameter{family_id}."_qc_sample_info.yaml");

	## Set the default Log4perl file using supplied dynamic parameters.
	$parameter{log_file}{default} = deafult_log4perl_file({active_parameter_href => \%active_parameter,
							       cmd_input_ref => \$parameter{log_file}{value},
							       script_ref => \$script,
							       date_ref => \$date,
							       date_time_stamp_ref => \$date_time_stamp,
							      });

	$parameter{qccollect_sampleinfo_file}{default} = $parameter{sample_info_file}{default};
    }
    if ($order_parameter_element eq "log_file") {

	## Creates log object
	my $log = initiate_logger({file_path_ref => \$active_parameter{log_file},
				      log_name => "MIP",
				     });
    }
    if ($order_parameter_element eq "pedigree_file") {  #Write QC for only pedigree data used in analysis

	if (defined($active_parameter{pedigree_file})) {

	    ## Retrieve logger object now that log_file has been set
	    my $log = Log::Log4perl->get_logger("MIP");

	    make_path(catdir($active_parameter{outdata_dir}, $active_parameter{family_id}));  #Create family directory
	    my $yaml_file = catfile($active_parameter{outdata_dir}, $active_parameter{family_id}, "qc_pedigree.yaml");

	    ## Writes a YAML hash to file
	    File::Format::Yaml::write_yaml({yaml_href => \%sample_info,
					    yaml_file_path_ref => \$yaml_file,
					   });
	    $log->info("Wrote: ".$yaml_file, "\n");

	    ## Removes all elements at hash third level except keys in allowed_entries
	    remove_pedigree_elements({hash_ref => \%sample_info,
				     });
	}
    }
    if ($order_parameter_element eq "analysis_type") {

	## Detect if all samples has the same sequencing type and return consensus if reached
	$parameter{dynamic_parameter}{consensus_analysis_type} = detect_overall_analysis_type({analysis_type_hef => \%{ $active_parameter{analysis_type} },
											      });
    }
}


## Retrieve logger object now that log_file has been set
my $log = Log::Log4perl->get_logger("MIP");


###Checks

## Check Existance of files and directories
foreach my $parameter_name (keys %parameter) {

    if (exists($parameter{$parameter_name}{exists_check})) {

	check_parameter_files({parameter_href => \%parameter,
			       active_parameter_href => \%active_parameter,
			       sample_info_href => \%sample_info,
			       file_info_href => \%file_info,
			       supported_capture_kit_href => \%supported_capture_kit,
			       annovar_table_href => \%annovar_table,
			       broadcasts_ref => \@broadcasts,
			       annovar_supported_table_names_ref => \@annovar_supported_table_names,
			       associated_programs_ref => \@{ $parameter{$parameter_name}{associated_program} },
			       parameter_name => $parameter_name,
			       parameter_exists_check => $parameter{$parameter_name}{exists_check},
			      });
    }
}


## Detect family constellation based on pedigree file
$parameter{dynamic_parameter}{trio} = detect_trio({active_parameter_href => \%active_parameter,
						   sample_info_href => \%sample_info,
						  });

## Detect number of founders (i.e. parents ) based on pedigree file
detect_founders({active_parameter_href => \%active_parameter,
		 sample_info_href => \%sample_info,
		});


## Check email adress format
if (exists($active_parameter{email})) {  #Allow no malformed email adress

    check_email_address({email_ref => \$active_parameter{email},
			});
}


## Check programs in path, and executable
check_commandin_path({parameter_href => \%parameter,
		      active_parameter_href => \%active_parameter,
		     });


## Test that the family_id and the sample_id(s) exists and are unique. Check if id sample_id contains "_".
check_unique_ids({active_parameter_href => \%active_parameter,
		  sample_ids_ref => \@{ $active_parameter{sample_ids} },
		 });


## Check sample_id provided in hash parameter is included in the analysis and only represented once
check_sample_id_in_parameter({active_parameter_href => \%active_parameter,
			      sample_ids_ref => \@{ $active_parameter{sample_ids} },
			      parameter_names_ref => ["expected_coverage", "analysis_type"],
			     });


## Check sample_id provided in hash path parameter is included in the analysis and only represented once
check_sample_id_in_parameter_path({active_parameter_href => \%active_parameter,
				   sample_ids_ref => \@{ $active_parameter{sample_ids} },
				   parameter_names_ref => ["infile_dirs", "exome_target_bed"],
				  });


## Check that VEP directory and VEP cache match
check_vep_directories({vep_directory_path_ref => \$active_parameter{vep_directory_path},
		       vep_directory_cache_ref => \$active_parameter{vep_directory_cache},
		      });

## Check that the supplied vcfanno toml frequency file match record 'file=' within toml config file
check_vcfanno_toml({vcfanno_file_toml => $active_parameter{sv_vcfanno_config},
		    vcfanno_file_freq => $active_parameter{sv_vcfanno_config_file},
		   });


## picardtools_mergesamfiles_previous_bams
if(@{ $parameter{picardtools_mergesamfiles_previous_bams}{value} }) {

    ## Checks if previous alignments have been supplied for each sample_id. Saves merge info in sample_info hash.
    check_merge_picardtools_mergesamfiles_previous_bams({active_parameter_href => \%active_parameter,
							 file_info_href => \%file_info,
							});
}
else {  #Not supplied - Set to 0 to handle correctly in program subroutines

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {  #Set for all sample_ids

	$file_info{ $active_parameter{family_id} }{$sample_id}{picardtools_mergesamfiles_previous_bams} = 0;
    }
}


## Adds dynamic aggregate information from definitions to parameter hash
add_to_parameter({parameter_href => \%parameter,
		  aggregates_ref => ["type:program",  #Collects all programs that MIP can handle
				     "program_type:variant_callers",  #Collects all variant_callers
				     "program_type:structural_variant_callers",  #Collects all structural variant_callers
				     "program_type:aligners",
				     "reference:reference_dir",  #Collects all references in that are supposed to be in referenceDirectory
				     "remove_redundant_file:yes"],  #Collect all programs outfiles that are redundant
		 });


## Check correct value for program mode in MIP
check_program_mode({parameter_href => \%parameter,
		    active_parameter_href => \%active_parameter
		   });


## Check that the correct number of aligners is used in MIP and sets the aligner flag accordingly
check_aligner({parameter_href => \%parameter,
	       active_parameter_href => \%active_parameter,
	       broadcasts_ref => \@broadcasts,
	      });


## Broadcast set parameters info
foreach my $parameter_info (@broadcasts) {

    $log->info($parameter_info, "\n");
}


### Cosmid references
## Defines the Cosmid manager hash keys and populates it from arguments
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "human_genome_reference",
				    cosmid_resource_name => "decoy",
				    cosmid_resource_version => "5",
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				    compressed_switch => "compressed",
				   });
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "sambamba_depth_bed",
				    cosmid_resource_name => "ccds",
				    cosmid_resource_version => "latest",
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });
## Has changed to array parameter fix in future bioconda download
#define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
#				  parameter_name => "GATKReAlignerINDELKnownSet1",
#				  cosmid_resource_name => "indels",
#				  cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
#				  human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
#				 });
## Has changed to array parameter fix in future bioconda download
#define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
#				  parameter_name => "GATKReAlignerINDELKnownSet2",
#				  cosmid_resource_name => "mills",
#				  cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
#				  human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
#				 });
## Has changed to array parameter fix in future bioconda download
#define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
#				  parameter_name => "gatk_baserecalibration_known_sites",
#				  cosmid_resource_name => "dbsnp",
#				  cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
#				  human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
#				 });
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "gatk_haplotypecaller_snp_known_set",
				    cosmid_resource_name => "dbsnp",
				    cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "gatk_variantrecalibration_training_set_hapmap",
				    cosmid_resource_name => "hapmap",
				    cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "gatk_variantrecalibration_training_set_mills",
				    cosmid_resource_name => "mills",
				    cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "gatk_variantrecalibration_training_set_1000g_omni",
				    cosmid_resource_name => "1000g_omni",
				    cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "gatk_variantrecalibration_training_set_1000gsnp",
				    cosmid_resource_name => "1000g_snps",
				    cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "gatk_variantrecalibration_training_set_dbsnp",
				    cosmid_resource_name => "dbsnp",
				    cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "gatk_varianteval_gold",
				    cosmid_resource_name => "mills",
				    cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "gatk_varianteval_dbsnp",
				    cosmid_resource_name => "dbsnpex",
				    cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });

##Flag -> array parameters to enable multiple download via Cosmid using the same flag
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "dbsnp_138.b37.vcf",
				    cosmid_resource_name => "dbsnp",
				    cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "dbsnp_138.b37.excluding_sites_after_129.vcf",
				    cosmid_resource_name => "dbsnpex",
				    cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "1000G_phase1.indels.b37.vcf",
				    cosmid_resource_name => "1000g_omni",
				    cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });
define_supported_cosmid_references({supported_cosmid_reference_href => \%supported_cosmid_reference,
				    parameter_name => "1000G_phase1.snps.high_confidence.b37.vcf",
				    cosmid_resource_name => "1000g_snps",
				    cosmid_resource_version => $active_parameter{gatk_bundle_download_version}."/b".$file_info{human_genome_reference_version},
				    human_genome_reference_version_ref => \$file_info{human_genome_reference_version},
				   });


## Check that a Cosmid installation exists
check_cosmid_installation({parameter_href => \%parameter,
			   active_parameter_href => \%active_parameter,
			   supported_cosmid_reference_href => \%supported_cosmid_reference
			  });


if ($active_parameter{config_file_analysis} ne 0) {  #Write config file for family

    make_path(dirname($active_parameter{config_file_analysis}));  #Create directory unless it already exists

    ## Writes a YAML hash to file
    File::Format::Yaml::write_yaml({yaml_href => \%active_parameter,
				    yaml_file_path_ref => \$active_parameter{config_file_analysis},
				   });
    $log->info("Wrote: ".$active_parameter{config_file_analysis}, "\n");

    ## Add to qc_sample_info
    $sample_info{config_file_analysis} = $active_parameter{config_file_analysis};
}


## Check that all active variant callers have a prioritization order and that the prioritization elements match a supported variant caller.
check_prioritize_variant_callers({parameter_href => \%parameter,
				  active_parameter_href => \%active_parameter,
				 });


## Set contig prefix and contig names depending on reference used
set_contigs({active_parameter_href => \%active_parameter,
	     file_info_href => \%file_info,
	    });


## Detect the gender included in current analysis
($active_parameter{male_found}, $active_parameter{female_found}, $active_parameter{other_found})  = detect_sample_id_gender({active_parameter_href => \%active_parameter,
															     sample_info_href => \%sample_info,
															    });
## Removes contig_names from contigs array if no male or 'other' found
remove_contigs({active_parameter_href => \%active_parameter,
		contigs_ref => \@{ $file_info{select_file_contigs} },
		contig_names_ref => ["Y"],
	       });


## Sorts array depending on reference array. NOTE: Only entries present in reference array will survive in sorted array.
@{ $file_info{sorted_select_file_contigs} } = size_sort_select_file_contigs({file_info_href =>\%file_info,
									     consensus_analysis_type_ref => \$parameter{dynamic_parameter}{consensus_analysis_type},
									     hash_key_to_sort => "select_file_contigs",
									     hash_key_sort_reference => "contigs_size_ordered",
									    });


## Write CMD to MIP log file
write_cmd_mip_log({parameter_href => \%parameter,
		   active_parameter_href => \%active_parameter,
		   order_parameters_ref => \@order_parameters,
		   script_ref => \$script,
		   log_file_ref => \$active_parameter{log_file},
		   mip_version_ref => \$mip_version,
		  });


## Collects the ".fastq(.gz)" files from the supplied infiles directory. Checks if any of the files exist
collect_infiles({active_parameter_href => \%active_parameter,
		 indir_path_href => \%indir_path,
		 infile_href => \%infile,
		});


## Reformat files for MIP output, which have not yet been created into, correct format so that a sbatch script can be generated with the correct filenames
my $uncompressed_file_switch = infiles_reformat({active_parameter_href => \%active_parameter,
						 sample_info_href => \%sample_info,
						 file_info_href => \%file_info,
						 infile_href => \%infile,
						 indir_path_href => \%indir_path,
						 infile_lane_no_ending_href => \%infile_lane_no_ending,
						 infile_both_strands_no_ending_href => \%infile_both_strands_no_ending,
						 lane_href => \%lane,
						 job_id_href => \%job_id,
						 outaligner_dir_ref => \$active_parameter{outaligner_dir},
						 program_name => "infiles_reformat",
						});


## Creates all fileendings as the samples is processed depending on the chain of modules activated
create_file_endings({parameter_href => \%parameter,
		     active_parameter_href => \%active_parameter,
		     file_info_href => \%file_info,
		     infile_lane_no_ending_href => \%infile_lane_no_ending,
		     order_parameters_ref => \@order_parameters,
		    });


## Create .fam file to be used in variant calling analyses
create_fam_file({parameter_href => \%parameter,
		 active_parameter_href => \%active_parameter,
		 sample_info_href => \%sample_info,
		 execution_mode => "system",
		 fam_file_path => catfile($active_parameter{outdata_dir}, $active_parameter{family_id}, $active_parameter{family_id}.".fam"),
		});


## Add to SampleInfo
add_to_sampleInfo({active_parameter_href => \%active_parameter,
		   sample_info_href => \%sample_info,
		   file_info_href => \%file_info,
		  });


############
####MAIN####
############

if ($active_parameter{dry_run_all} == 0) {

    $sample_info{analysis_date} = $date_time_stamp;
    $sample_info{mip_version} = $mip_version;
}

## Check if vt has processed references, if not try to reprocesses them before launcing modules
check_vt_for_references({parameter_href => \%parameter,
			 active_parameter_href => \%active_parameter,
			 sample_info_href => \%sample_info,
			 infile_lane_no_ending_href => \%infile_lane_no_ending,
			 job_id_href => \%job_id,
			 vt_references_ref => \@vt_references,
			 vt_decompose => $active_parameter{vt_decompose},
			 vt_normalize => $active_parameter{vt_normalize},
			});

if ($active_parameter{psplit_fastq_file} > 0) {  #Split of fastq files in batches

    $log->info("[Split fastq files in batches]\n");

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	## Split input fastq files into batches of reads, versions and compress. Moves original file to subdirectory
	split_fastq_file({parameter_href => \%parameter,
			  active_parameter_href => \%active_parameter,
			  sample_info_href => \%sample_info,
			  infile_href => \%infile,
			  indir_path_href => \%indir_path,
			  infile_lane_no_ending_href => \%infile_lane_no_ending,
			  job_id_href => \%job_id,
			  sample_id_ref => \$sample_id,
			  program_name => "split_fastq_file",
			  sequence_read_batch => $active_parameter{split_fastq_file_read_batch},
			 });
    }
    exit;  #End here if this module is turned on
}

if ( ($active_parameter{pgzip_fastq} > 0) && ($uncompressed_file_switch eq "uncompressed") ) {  #GZip of fastq files

    $log->info("[Gzip for fastq files]\n");

  SAMPLES:
    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {  #Restrict to subset if subset supplied

      INFILES:
	foreach my $infile (@{ $infile{$sample_id} }) {  #To determine which sample_id had the uncompressed files

	    if ($infile =~/.fastq$/) {

		## Automatically gzips fastq files
		gzip_fastq({parameter_href => \%parameter,
			    active_parameter_href => \%active_parameter,
			    sample_info_href => \%sample_info,
			    infile_href => \%infile,
			    indir_path_href => \%indir_path,
			    infile_lane_no_ending_href => \%infile_lane_no_ending,
			    job_id_href => \%job_id,
			    sample_id => $sample_id,
			    program_name => "gzip_fastq"
			   });
		last;  #Return to sample_id loop i.e. only call subroutine gzip_fastq once per sample_id
	    }
	}
    }
}

if ($active_parameter{pfastqc} > 0) {  #Run FastQC

    $log->info("[Fastqc]\n");

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	fastqc({parameter_href => \%parameter,
		active_parameter_href => \%active_parameter,
		sample_info_href => \%sample_info,
		infile_href => \%infile,
		indir_path_href => \%indir_path,
		infile_lane_no_ending_href => \%infile_lane_no_ending,
		job_id_href => \%job_id,
		sample_id_ref => \$sample_id,
		program_name => "fastqc",
	       });
    }
}

if ($active_parameter{pmadeline} > 0) {  #Run madeline

    $log->info("[Madeline]\n");

    madeline({parameter_href => \%parameter,
	      active_parameter_href => \%active_parameter,
	      sample_info_href => \%sample_info,
	      infile_lane_no_ending_href => \%infile_lane_no_ending,
	      job_id_href => \%job_id,
	      program_name => "madeline",
	     });
}

if ($active_parameter{pmosaik_build} > 0) {  #Run MosaikBuild

    $log->info("[MosaikBuild]\n");

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	mosaik_build({parameter_href => \%parameter,
		      active_parameter_href => \%active_parameter,
		      sample_info_href => \%sample_info,
		      infile_href => \%infile,
		      indir_path_href => \%indir_path,
		      infile_lane_no_ending_href => \%infile_lane_no_ending,
		      lane_href => \%lane,
		      job_id_href => \%job_id,
		      sample_id_ref => \$sample_id,
		      outaligner_dir => \$active_parameter{outaligner_dir},
		      program_name => "mosaik_build",
		     });
    }
}

if ($active_parameter{pmosaik_aligner} > 0) {  #Run mosaik_aligner

    $log->info("[MosaikAlign]\n");

    if ($active_parameter{dry_run_all} != 1) {

	if ( ($parameter{human_genome_reference}{build_file} eq 1) || ($parameter{mosaik_align_reference}{build_file} eq 1) || ($parameter{mosaik_jump_db_stub}{build_file} eq 1) ) {

	    build_mosaikaligner_prerequisites(\%parameter, \%active_parameter, \%sample_info, \%file_info, \%infile_lane_no_ending, \%job_id, \%supported_cosmid_reference, \@{ $file_info{mosaik_jump_db_stub_file_endings} }, \$file_info{human_genome_reference_source}, \$file_info{human_genome_reference_version}, $active_parameter{family_id}, $active_parameter{outaligner_dir}, "mosaik_aligner");

	}
	if ( ($parameter{mosaik_align_neural_network_pe_file}{build_file} eq 1) || ($parameter{mosaik_align_neural_network_se_file}{build_file} eq 1) ){

	    ## Locate MOSAIK path and move neural network files in place if lacking
	    move_mosaik_nn(\%active_parameter);
	}
    }
    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	mosaik_aligner(\%parameter, \%active_parameter, \%sample_info, \%file_info, \%infile, \%indir_path, \%infile_lane_no_ending, \%job_id, $sample_id, $active_parameter{outaligner_dir}, "mosaik_aligner");
    }
}


if ($active_parameter{pbwa_mem} > 0) {  #Run BWA Mem

    $log->info("[BWA Mem]\n");

    if ($active_parameter{dry_run_all} != 1) {

	if ( ($parameter{human_genome_reference}{build_file} eq 1) || ($parameter{bwa_build_reference}{build_file} eq 1) ) {

	    build_bwa_prerequisites({parameter_href => \%parameter,
				     active_parameter_href => \%active_parameter,
				     sample_info_href => \%sample_info,
				     file_info_href => \%file_info,
				     infile_lane_no_ending_href => \%infile_lane_no_ending,
				     job_id_href => \%job_id,
				     supported_cosmid_reference_href => \%supported_cosmid_reference,
				     bwa_build_reference_file_endings_ref => \@{ $file_info{bwa_build_reference_file_endings} },
				     program_name => "bwa_mem",
				    });
	}
    }
    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	bwa_mem({parameter_href => \%parameter,
		 active_parameter_href => \%active_parameter,
		 sample_info_href => \%sample_info,
		 file_info_href => \%file_info,
		 infile_href => \%infile,
		 indir_path_href => \%indir_path,
		 infile_lane_no_ending_href => \%infile_lane_no_ending,
		 job_id_href => \%job_id,
		 sample_id_ref => \$sample_id,
		 program_name => "bwa_mem",
		});
    }
}

if ($active_parameter{ppicardtools_mergerapidreads} > 0) {  #Run PicardtoolsMergeRapidReads - Relevant only in rapid mode

    $log->info("[Picardtools mergerapidreads]\n");

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

        #Merge all read batch processes to 1 file again containing sorted & indexed reads matching clinical test genes
	picardtools_mergerapidreads({parameter_href => \%parameter,
				     active_parameter_href => \%active_parameter,
				     sample_info_href => \%sample_info,
				     file_info_href => \%file_info,
				     infile_lane_no_ending_href => \%infile_lane_no_ending,
				     lane_href => \%lane,
				     job_id_href => \%job_id,
				     sample_id_ref => \$sample_id,
				     outaligner_dir_ref => \$active_parameter{outaligner_dir},
				     program_name => "picardtools_mergerapidreads",
				    });
    }
}

if ($active_parameter{pbwa_aln} > 0) {  #Run BWA Aln

    $log->info("[BWA Aln]\n");

    if ($active_parameter{dry_run_all} != 1) {

	if ( ($parameter{human_genome_reference}{build_file} eq 1) || ($parameter{bwa_build_reference}{build_file} eq 1) ) {

	    build_bwa_prerequisites({parameter_href => \%parameter,
				     active_parameter_href => \%active_parameter,
				     sample_info_href => \%sample_info,
				     file_info_href => \%file_info,
				     infile_lane_no_ending_href => \%infile_lane_no_ending,
				     job_id_href => \%job_id,
				     supported_cosmid_reference_href => \%supported_cosmid_reference,
				     bwa_build_reference_file_endings_ref => \@{ $file_info{bwa_build_reference_file_endings} },
				     program_name => "bwa_aln",
				    });
	}
    }
    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	bwa_aln(\%parameter, \%active_parameter, \%sample_info, \%infile, \%indir_path, \%infile_lane_no_ending, \%infile_both_strands_no_ending, \%job_id, $sample_id, $active_parameter{outaligner_dir}, "bwa_aln");
    }
}

if ($active_parameter{pbwa_sampe} > 0) {  #Run BWA Sampe

    $log->info("[BWA Sampe]\n");

    if ($active_parameter{dry_run_all} != 1) {

	if ( ($parameter{human_genome_reference}{build_file} eq 1) || ($parameter{bwa_build_reference}{build_file} eq 1) ) {

	    build_bwa_prerequisites({parameter_href => \%parameter,
				     active_parameter_href => \%active_parameter,
				     sample_info_href => \%sample_info,
				     file_info_href => \%file_info,
				     infile_lane_no_ending_href => \%infile_lane_no_ending,
				     job_id_href => \%job_id,
				     supported_cosmid_reference_href => \%supported_cosmid_reference,
				     bwa_build_reference_file_endings_ref => \@{ $file_info{bwa_build_reference_file_endings} },
				     program_name => "bwa_sampe",
				    });
	}
    }
    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {
	bwa_sampe(\%parameter, \%active_parameter, \%sample_info, \%infile, \%indir_path, \%infile_lane_no_ending, \%infile_both_strands_no_ending, \%job_id, $sample_id, $active_parameter{outaligner_dir}, "bwa_sampe");
    }
}


if ($active_parameter{reduce_io}) {  #Run consecutive models

    $active_parameter{pbamcalibrationblock} = 1;  #Enable as program
    $log->info("[Bamcalibrationblock]\n");

    bamcalibrationblock({parameter_href => \%parameter,
			 active_parameter_href => \%active_parameter,
			 sample_info_href => \%sample_info,
			 file_info_href => \%file_info,
			 infile_lane_no_ending_href => \%infile_lane_no_ending,
			 lane_href => \%lane,
			 job_id_href => \%job_id,
			 supported_cosmid_reference_href => \%supported_cosmid_reference,
			 outaligner_dir_ref => \$active_parameter{outaligner_dir},
			 program_name => "bamcalibrationblock",
			});

}
else {

    ##Always run even for single samples to rename them correctly for standardised downstream processing.
    ##Will also split alignment per contig and copy to temporary directory for '-rio 1' block to enable selective removal of block submodules.
    $log->info("[Picardtools mergesamfiles]\n");

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	picardtools_mergesamfiles({parameter_href => \%parameter,
				   active_parameter_href => \%active_parameter,
				   sample_info_href => \%sample_info,
				   file_info_href => \%file_info,
				   infile_lane_no_ending_href => \%infile_lane_no_ending,
				   lane_href => \%lane,
				   job_id_href => \%job_id,
				   sample_id_ref => \$sample_id,
				   program_name => "picardtools_mergesamfiles",
				  });
    }

    if ($active_parameter{ppicardtools_markduplicates} > 0) {  #Picardtools markduplicates

	$log->info("[Picardtools markduplicates]\n");

	foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	    picardtools_markduplicates({parameter_href => \%parameter,
					active_parameter_href => \%active_parameter,
					sample_info_href => \%sample_info,
					file_info_href => \%file_info,
					infile_lane_no_ending_href => \%infile_lane_no_ending,
					lane_href => \%lane,
					job_id_href => \%job_id,
					sample_id_ref => \$sample_id,
					program_name => "picardtools_markduplicates",
				       });
	}
    }

    if ($active_parameter{psambamba_markduplicates} > 0) {  #Sambamba markduplicates

	$log->info("[Sambamba markduplicates]\n");

	foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	    sambamba_markduplicates({parameter_href => \%parameter,
				     active_parameter_href => \%active_parameter,
				     sample_info_href => \%sample_info,
				     file_info_href => \%file_info,
				     infile_lane_no_ending_href => \%infile_lane_no_ending,
				     lane_href => \%lane,
				     job_id_href => \%job_id,
				     sample_id_ref => \$sample_id,
				     program_name => "sambamba_markduplicates",
				    });
	}
    }

    if ($active_parameter{pgatk_realigner} > 0) {  #Run GATK realignertargetcreator/indelrealigner

	$log->info("[GATK realignertargetcreator/indelrealigner]\n");

	check_build_human_genome_prerequisites({parameter_href => \%parameter,
						active_parameter_href => \%active_parameter,
						sample_info_href => \%sample_info,
						file_info_href => \%file_info,
						infile_lane_no_ending_href => \%infile_lane_no_ending,
						job_id_href => \%job_id,
						supported_cosmid_reference_href => \%supported_cosmid_reference,
						program_name => "gatk_realigner",
					       });

	check_build_download_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "gatk_realigner",
					   });

	if ($active_parameter{dry_run_all} != 1) {

	    check_build_ptchs_metric_prerequisites({parameter_href => \%parameter,
						    active_parameter_href => \%active_parameter,
						    sample_info_href => \%sample_info,
						    file_info_href => \%file_info,
						    infile_lane_no_ending_href => \%infile_lane_no_ending,
						    job_id_href => \%job_id,
						    program_name => "gatk_realigner",
						   });
	}
	foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	    gatk_realigner({parameter_href => \%parameter,
			    active_parameter_href => \%active_parameter,
			    sample_info_href => \%sample_info,
			    file_info_href => \%file_info,
			    infile_lane_no_ending_href => \%infile_lane_no_ending,
			    job_id_href => \%job_id,
			    sample_id_ref => \$sample_id,
			    program_name => "gatk_realigner",
			   });
	}
    }

    if ($active_parameter{pgatk_baserecalibration} > 0) {  #Run GATK baserecalibrator/printreads

	$log->info("[GATK baserecalibrator/printreads]\n");

	check_build_human_genome_prerequisites({parameter_href => \%parameter,
						active_parameter_href => \%active_parameter,
						sample_info_href => \%sample_info,
						file_info_href => \%file_info,
						infile_lane_no_ending_href => \%infile_lane_no_ending,
						job_id_href => \%job_id,
						supported_cosmid_reference_href => \%supported_cosmid_reference,
						program_name => "gatk_baserecalibration",
					       });

	check_build_download_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "gatk_baserecalibration",
					   });

	if ($active_parameter{dry_run_all} != 1) {

	    check_build_ptchs_metric_prerequisites({parameter_href => \%parameter,
						    active_parameter_href => \%active_parameter,
						    sample_info_href => \%sample_info,
						    file_info_href => \%file_info,
						    infile_lane_no_ending_href => \%infile_lane_no_ending,
						    job_id_href => \%job_id,
						    program_name => "gatk_baserecalibration",
						   });
	}
	foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	    gatk_baserecalibration({parameter_href => \%parameter,
				    active_parameter_href => \%active_parameter,
				    sample_info_href => \%sample_info,
				    file_info_href => \%file_info,
				    infile_lane_no_ending_href => \%infile_lane_no_ending,
				    job_id_href => \%job_id,
				    sample_id_ref => \$sample_id,
				    program_name => "gatk_baserecalibration",
				   });
	}
    }
}


if ($active_parameter{pchanjo_sexcheck} > 0) {

    $log->info("[Chanjo sexcheck]\n");

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	chanjo_sexcheck({parameter_href => \%parameter,
			 active_parameter_href => \%active_parameter,
			 sample_info_href => \%sample_info,
			 file_info_href => \%file_info,
			 infile_lane_no_ending_href => \%infile_lane_no_ending,
			 job_id_href => \%job_id,
			 sample_id_ref => \$sample_id,
			 program_name => "chanjo_sexcheck",
			});
    }
}

if ($active_parameter{psambamba_depth} > 0) {

    $log->info("[Sambamba depth]\n");

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	sambamba_depth({parameter_href => \%parameter,
			active_parameter_href => \%active_parameter,
			sample_info_href => \%sample_info,
			file_info_href => \%file_info,
			infile_lane_no_ending_href => \%infile_lane_no_ending,
			job_id_href => \%job_id,
			sample_id_ref => \$sample_id,
			program_name => "sambamba_depth",
		       });
    }
}


if ($active_parameter{pgenomecoveragebed} > 0) {  #Run genomecoveragebed

    $log->info("[Genomecoveragebed]\n");

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	genomecoveragebed({parameter_href => \%parameter,
			   active_parameter_href => \%active_parameter,
			   sample_info_href => \%sample_info,
			   file_info_href => \%file_info,
			   infile_lane_no_ending_href => \%infile_lane_no_ending,
			   job_id_href => \%job_id,
			   sample_id_ref => \$sample_id,
			   program_name => "genomecoveragebed",
			  });
    }
}

if ($active_parameter{ppicardtools_collectmultiplemetrics} > 0) {  #Run picardtools_collectmultiplemetrics

    $log->info("[Picardtools collectmultiplemetrics]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "picardtools_collectmultiplemetrics",
					   });

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	picardtools_collectmultiplemetrics({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    sample_id_ref => \$sample_id,
					    program_name => "picardtools_collectmultiplemetrics",
					   });
    }
}

if ($active_parameter{ppicardtools_calculatehsmetrics} > 0) {  #Run Picardtools_calculatehsmetrics

    $log->info("[Picardtools calculatehsmetrics]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "picardtools_calculatehsmetrics",
					   });

    if ($active_parameter{dry_run_all} != 1) {

	check_build_ptchs_metric_prerequisites({parameter_href => \%parameter,
						active_parameter_href => \%active_parameter,
						sample_info_href => \%sample_info,
						file_info_href => \%file_info,
						infile_lane_no_ending_href => \%infile_lane_no_ending,
						job_id_href => \%job_id,
						program_name => "picardtools_calculatehsmetrics",
					       });
    }
    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	picardtools_calculatehsmetrics({parameter_href => \%parameter,
					active_parameter_href => \%active_parameter,
					sample_info_href => \%sample_info,
					file_info_href => \%file_info,
					infile_lane_no_ending_href => \%infile_lane_no_ending,
					job_id_href => \%job_id,
					sample_id_ref => \$sample_id,
					program_name => "picardtools_calculatehsmetrics",
				       });
    }
}

if ($active_parameter{prcovplots} > 0) {  #Run Rcovplot scripts

    $log->info("[Rcovplots]\n");

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	rcoverageplots(\%parameter, \%active_parameter, \%sample_info, \%file_info, \%lane, \%infile_lane_no_ending, \%job_id, $sample_id, $active_parameter{outaligner_dir}, "rcovplots");
    }
}


if ($active_parameter{pcnvnator} > 0) {  #Run CNVnator

    $log->info("[CNVnator]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "cnvnator",
					   });
    check_build_download_prerequisites({parameter_href => \%parameter,
					active_parameter_href => \%active_parameter,
					sample_info_href => \%sample_info,
					infile_lane_no_ending_href => \%infile_lane_no_ending,
					job_id_href => \%job_id,
					supported_cosmid_reference_href => \%supported_cosmid_reference,
					program_name => "cnvnator",
				       });
    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	cnvnator({parameter_href => \%parameter,
		  active_parameter_href => \%active_parameter,
		  sample_info_href => \%sample_info,
		  file_info_href => \%file_info,
		  infile_lane_no_ending_href => \%infile_lane_no_ending,
		  job_id_href => \%job_id,
		  sample_id_ref => \$sample_id,
		  program_name => "cnvnator",
		 });
    }
}


if ($active_parameter{pdelly_call} > 0) {  #Run delly_call

    $log->info("[Delly_call]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "delly_call",
					   });
    check_build_download_prerequisites({parameter_href => \%parameter,
					active_parameter_href => \%active_parameter,
					sample_info_href => \%sample_info,
					infile_lane_no_ending_href => \%infile_lane_no_ending,
					job_id_href => \%job_id,
					supported_cosmid_reference_href => \%supported_cosmid_reference,
					program_name => "delly_call",
				       });

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	delly_call({parameter_href => \%parameter,
		    active_parameter_href => \%active_parameter,
		    sample_info_href => \%sample_info,
		    file_info_href => \%file_info,
		    infile_lane_no_ending_href => \%infile_lane_no_ending,
		    job_id_href => \%job_id,
		    sample_id_ref => \$sample_id,
		    program_name => "delly_call",
	      });
    }
}


if ($active_parameter{pdelly_reformat} > 0) {  #Run Delly merge, regenotype, bcftools merge

    $log->info("[delly_reformat]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "delly_reformat",
					   });
    check_build_download_prerequisites({parameter_href => \%parameter,
					active_parameter_href => \%active_parameter,
					sample_info_href => \%sample_info,
					infile_lane_no_ending_href => \%infile_lane_no_ending,
					job_id_href => \%job_id,
					supported_cosmid_reference_href => \%supported_cosmid_reference,
					program_name => "delly_reformat",
				       });

    delly_reformat({parameter_href => \%parameter,
		    active_parameter_href => \%active_parameter,
		    sample_info_href => \%sample_info,
		    file_info_href => \%file_info,
		    infile_lane_no_ending_href => \%infile_lane_no_ending,
		    job_id_href => \%job_id,
		    program_name => "delly_reformat",
		   });
}

if ($active_parameter{pmanta} > 0) {  #Run Manta

    $log->info("[Manta]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "manta",
					   });
    check_build_download_prerequisites({parameter_href => \%parameter,
					active_parameter_href => \%active_parameter,
					sample_info_href => \%sample_info,
					infile_lane_no_ending_href => \%infile_lane_no_ending,
					job_id_href => \%job_id,
					supported_cosmid_reference_href => \%supported_cosmid_reference,
					program_name => "manta",
				       });
    manta({parameter_href => \%parameter,
	   active_parameter_href => \%active_parameter,
	   sample_info_href => \%sample_info,
	   file_info_href => \%file_info,
	   infile_lane_no_ending_href => \%infile_lane_no_ending,
	   job_id_href => \%job_id,
	   program_name => "manta",
	  });
}

if ($active_parameter{pfindtranslocations} > 0) {  #Run FindTranslocations

    $log->info("[Findtranslocations]\n");

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	findtranslocations({parameter_href => \%parameter,
			    active_parameter_href => \%active_parameter,
			    sample_info_href => \%sample_info,
			    file_info_href => \%file_info,
			    infile_lane_no_ending_href => \%infile_lane_no_ending,
			    job_id_href => \%job_id,
			    sample_id_ref => \$sample_id,
			    program_name => "findtranslocations",
			   });
    }
}


if ($active_parameter{psv_combinevariantcallsets} > 0) {  #Run combinevariantcallsets. For all Sample_ids and StructuralVariantCallers

    $log->info("[SV combinevariantcallsets]\n");

    sv_combinevariantcallsets({parameter_href => \%parameter,
			       active_parameter_href => \%active_parameter,
			       sample_info_href => \%sample_info,
			       file_info_href => \%file_info,
			       infile_lane_no_ending_href => \%infile_lane_no_ending,
			       job_id_href => \%job_id,
			       program_name => "sv_combinevariantcallsets",
			      });
}

if ($active_parameter{psv_varianteffectpredictor} > 0) {  #Run sv_varianteffectpredictor. Done per family

    $log->info("[SV varianteffectpredictor]\n");

    sv_varianteffectpredictor({parameter_href => \%parameter,
			       active_parameter_href => \%active_parameter,
			       sample_info_href => \%sample_info,
			       file_info_href => \%file_info,
			       infile_lane_no_ending_href => \%infile_lane_no_ending,
			       job_id_href => \%job_id,
			       program_name => "sv_varianteffectpredictor",
			      });
}


if ($active_parameter{psv_vcfparser} > 0) {  #Run sv_vcfparser. Done per family

    $log->info("[SV vcfparser]\n");

    sv_vcfparser({parameter_href => \%parameter,
		  active_parameter_href => \%active_parameter,
		  sample_info_href => \%sample_info,
		  file_info_href => \%file_info,
		  infile_lane_no_ending_href => \%infile_lane_no_ending,
		  job_id_href => \%job_id,
		  program_name => "sv_vcfparser",
		 });
}


if ($active_parameter{psv_rankvariant} > 0) {  #Run sv_rankvariant. Done per family

    $log->info("[SV rankvariant]\n");

    sv_rankvariant({parameter_href => \%parameter,
		    active_parameter_href => \%active_parameter,
		    sample_info_href => \%sample_info,
		    file_info_href => \%file_info,
		    infile_lane_no_ending_href => \%infile_lane_no_ending,
		    job_id_href => \%job_id,
		    program_name => "sv_rankvariant",
		   });
}


if ($active_parameter{psamtools_mpileup} > 0) {  #Run samtools mpileup

    $log->info("[Samtools mpileup]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "samtools_mpileup",
					   });
    check_build_download_prerequisites({parameter_href => \%parameter,
					active_parameter_href => \%active_parameter,
					sample_info_href => \%sample_info,
					infile_lane_no_ending_href => \%infile_lane_no_ending,
					job_id_href => \%job_id,
					supported_cosmid_reference_href => \%supported_cosmid_reference,
					program_name => "samtools_mpileup",
				       });

    samtools_mpileup({parameter_href => \%parameter,
		      active_parameter_href => \%active_parameter,
		      sample_info_href => \%sample_info,
		      file_info_href => \%file_info,
		      infile_lane_no_ending_href => \%infile_lane_no_ending,
		      job_id_href => \%job_id,
		      program_name => "samtools_mpileup",
		     });
}

if ($active_parameter{pfreebayes} > 0) {  #Run Freebayes

    $log->info("[Freebayes]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "freebayes",
					   });
    check_build_download_prerequisites({parameter_href => \%parameter,
					active_parameter_href => \%active_parameter,
					sample_info_href => \%sample_info,
					infile_lane_no_ending_href => \%infile_lane_no_ending,
					job_id_href => \%job_id,
					supported_cosmid_reference_href => \%supported_cosmid_reference,
					program_name => "freebayes",
				       });

    freebayes({parameter_href => \%parameter,
	       active_parameter_href => \%active_parameter,
	       sample_info_href => \%sample_info,
	       file_info_href => \%file_info,
	       infile_lane_no_ending_href => \%infile_lane_no_ending,
	       job_id_href => \%job_id,
	       program_name => "freebayes",
	      });
}


if ($active_parameter{pgatk_haplotypecaller} > 0) {  #Run GATK haplotypecaller

    $log->info("[GATK haplotypecaller]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "gatk_haplotypecaller",
					   });

    check_build_download_prerequisites({parameter_href => \%parameter,
					active_parameter_href => \%active_parameter,
					sample_info_href => \%sample_info,
					infile_lane_no_ending_href => \%infile_lane_no_ending,
					job_id_href => \%job_id,
					supported_cosmid_reference_href => \%supported_cosmid_reference,
					program_name => "gatk_haplotypecaller",
				       });

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	if ( ($active_parameter{dry_run_all} != 1) && ($active_parameter{analysis_type}{$sample_id} ne "wgs") ) {

	    check_build_ptchs_metric_prerequisites({parameter_href => \%parameter,
						    active_parameter_href => \%active_parameter,
						    sample_info_href => \%sample_info,
						    file_info_href => \%file_info,
						    infile_lane_no_ending_href => \%infile_lane_no_ending,
						    job_id_href => \%job_id,
						    program_name => "gatk_haplotypecaller",
						   });
	}

	gatk_haplotypecaller({parameter_href => \%parameter,
			      active_parameter_href => \%active_parameter,
			      sample_info_href => \%sample_info,
			      file_info_href => \%file_info,
			      infile_lane_no_ending_href => \%infile_lane_no_ending,
			      job_id_href => \%job_id,
			      sample_id_ref => \$sample_id,
			      program_name => "gatk_haplotypecaller",
			     });
    }
}

if ($active_parameter{pgatk_genotypegvcfs} > 0) {  #Run GATK genotypegvcfs. Done per family

    $log->info("[GATK genotypegvcfs]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "gatk_genotypegvcfs",
					   });

    gatk_genotypegvcfs({parameter_href => \%parameter,
			active_parameter_href => \%active_parameter,
			sample_info_href => \%sample_info,
			file_info_href => \%file_info,
			infile_lane_no_ending_href => \%infile_lane_no_ending,
			job_id_href => \%job_id,
			program_name => "gatk_genotypegvcfs",
		       });

    gatk_concatenate_genotypegvcfs({parameter_href => \%parameter,
				    active_parameter_href => \%active_parameter,
				    sample_info_href => \%sample_info,
				    file_info_href => \%file_info,
				    infile_lane_no_ending_href => \%infile_lane_no_ending,
				    job_id_href => \%job_id,
				    program_name => "gatk_genotypegvcfs",
				   });
}

if ($active_parameter{pgatk_variantrecalibration} > 0) {  #Run GATK VariantRecalibrator/ApplyRecalibration. Done per family

    $log->info("[GATK variantrecalibrator/applyrecalibration]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "gatk_variantrecalibration",
					   });
    check_build_download_prerequisites({parameter_href => \%parameter,
					active_parameter_href => \%active_parameter,
					sample_info_href => \%sample_info,
					infile_lane_no_ending_href => \%infile_lane_no_ending,
					job_id_href => \%job_id,
					supported_cosmid_reference_href => \%supported_cosmid_reference,
					program_name => "gatk_variantrecalibration",
				       });

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	if ( ($active_parameter{dry_run_all} != 1) && ($active_parameter{analysis_type}{$sample_id} ne "wgs") ) {

	    check_build_ptchs_metric_prerequisites({parameter_href => \%parameter,
						    active_parameter_href => \%active_parameter,
						    sample_info_href => \%sample_info,
						    file_info_href => \%file_info,
						    infile_lane_no_ending_href => \%infile_lane_no_ending,
						    job_id_href => \%job_id,
						    program_name => "gatk_variantrecalibration",
						   });
	}
    }
    gatk_variantrecalibration({parameter_href => \%parameter,
			       active_parameter_href => \%active_parameter,
			       sample_info_href => \%sample_info,
			       file_info_href => \%file_info,
			       infile_lane_no_ending_href => \%infile_lane_no_ending,
			       job_id_href => \%job_id,
			       program_name => "gatk_variantrecalibration",
			      });
}


if ($active_parameter{pgatk_combinevariantcallsets} > 0) {  #Run gatk_combinevariantcallsets. Done per family

    $log->info("[GATK combinevariantcallsets]\n");

    gatk_combinevariantcallsets({parameter_href => \%parameter,
				 active_parameter_href => \%active_parameter,
				 sample_info_href => \%sample_info,
				 file_info_href => \%file_info,
				 infile_lane_no_ending_href => \%infile_lane_no_ending,
				 job_id_href => \%job_id,
				 program_name => "gatk_combinevariantcallsets",
				});
}

if ($active_parameter{psamplecheck} > 0) {  #Run samplecheck. Done per family

    $log->info("[Samplecheck]\n");

    samplecheck({parameter_href => \%parameter,
		 active_parameter_href => \%active_parameter,
		 sample_info_href => \%sample_info,
		 file_info_href => \%file_info,
		 infile_lane_no_ending_href => \%infile_lane_no_ending,
		 job_id_href => \%job_id,
		 program_name => "samplecheck",
		});
}

if ($active_parameter{pevaluation} > 0) {  #Run evaluation. Done per family

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	if ($sample_id =~/$active_parameter{nist_id}/) {

	    $log->info("[Evaluation]\n");

	    evaluation({parameter_href => \%parameter,
			active_parameter_href => \%active_parameter,
			sample_info_href => \%sample_info,
			file_info_href => \%file_info,
			infile_lane_no_ending_href => \%infile_lane_no_ending,
			job_id_href => \%job_id,
			sample_id_ref => \$sample_id,
			call_type => "BOTH",
			program_name => "evaluation",
		       });
	}

	
    }
}


if ($active_parameter{pgatk_phasebytransmission} > 0) {  #Run GATK phasebytransmission. Done per family

    $log->info("[GATK phasebytransmission]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "gatk_phasebytransmission",
					   });
    gatk_phasebytransmission(\%parameter, \%active_parameter, \%sample_info, \%file_info, \%infile_lane_no_ending, \%job_id, $active_parameter{family_id}, $active_parameter{outaligner_dir}, "BOTH", "gatk_phasebytransmission");
}

if ($active_parameter{pgatk_readbackedphasing} > 0) {  #Run GATK ReadBackedPhasing. Done per family. NOTE: Needs phased calls

    $log->info("[GATK ReadBackedPhasing]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "gatk_readbackedphasing",
					   });
    gatk_readbackedphasing(\%parameter, \%active_parameter, \%sample_info, \%file_info, \%lane, \%infile_lane_no_ending, \%job_id, $active_parameter{family_id}, $active_parameter{outaligner_dir}, "BOTH", "gatk_readbackedphasing");
}

if ($active_parameter{pgatk_variantevalall} > 0) {  #Run GATK varianteval for all variants. Done per sample_id

    $log->info("[GATK variantevalall]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "gatk_variantevalall",
					   });

    check_build_download_prerequisites({parameter_href => \%parameter,
					active_parameter_href => \%active_parameter,
					sample_info_href => \%sample_info,
					infile_lane_no_ending_href => \%infile_lane_no_ending,
					job_id_href => \%job_id,
					supported_cosmid_reference_href => \%supported_cosmid_reference,
					program_name => "gatk_variantevalall",
				       });

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	gatk_variantevalall({parameter_href => \%parameter,
			     active_parameter_href => \%active_parameter,
			     sample_info_href => \%sample_info,
			     file_info_href => \%file_info,
			     infile_lane_no_ending_href => \%infile_lane_no_ending,
			     job_id_href => \%job_id,
			     sample_id_ref => \$sample_id,
			     program_name => "gatk_variantevalall",
			    });
    }
}

### If no males or other remove contig Y from all downstream analysis
my @file_info_contig_keys = ("contigs_size_ordered", "contigs");

foreach my $key (@file_info_contig_keys) {

    ## Removes contig_names from contigs array if no male or 'other' found
    remove_contigs({active_parameter_href => \%active_parameter,
		    contigs_ref => \@{ $file_info{$key} },
		    contig_names_ref => ["Y"],
		   });
}

if ($active_parameter{reduce_io}) {  #Run consecutive models

    $active_parameter{pvariantannotationblock} = 1;  #Enable as program
    $log->info("[Variantannotationblock]\n");

    variantannotationblock({parameter_href => \%parameter,
			    active_parameter_href => \%active_parameter,
			    sample_info_href => \%sample_info,
			    file_info_href => \%file_info,
			    infile_lane_no_ending_href => \%infile_lane_no_ending,
			    job_id_href => \%job_id,
			    annovar_table_href => \%annovar_table,
			    supported_cosmid_reference_href => \%supported_cosmid_reference,
			    outaligner_dir_ref => \$active_parameter{outaligner_dir},
			    call_type => "BOTH",
			    program_name => "variantannotationblock",
			   });
}
else {

    $log->info("[Prepareforvariantannotationblock]\n");

    prepareforvariantannotationblock({parameter_href => \%parameter,
				      active_parameter_href => \%active_parameter,
				      sample_info_href => \%sample_info,
				      file_info_href => \%file_info,
				      infile_lane_no_ending_href => \%infile_lane_no_ending,
				      job_id_href => \%job_id,
				      call_type => "BOTH",
				      program_name => "prepareforvariantannotationblock",
				     });

    if ($active_parameter{prhocall} > 0) {  #Run rhocall. Done per family

	$log->info("[Rhocall]\n");

	rhocall({parameter_href => \%parameter,
		 active_parameter_href => \%active_parameter,
		 sample_info_href => \%sample_info,
		 file_info_href => \%file_info,
		 infile_lane_no_ending_href => \%infile_lane_no_ending,
		 job_id_href => \%job_id,
		 call_type => "BOTH",
		 program_name => "rhocall",
		});
    }
    if ($active_parameter{pvt} > 0) {  #Run vt. Done per family

	$log->info("[Vt]\n");

	vt({parameter_href => \%parameter,
	    active_parameter_href => \%active_parameter,
	    sample_info_href => \%sample_info,
	    file_info_href => \%file_info,
	    infile_lane_no_ending_href => \%infile_lane_no_ending,
	    job_id_href => \%job_id,
	    call_type => "BOTH",
	    program_name => "vt",
	   });
    }
    if ($active_parameter{pvarianteffectpredictor} > 0) {  #Run varianteffectpredictor. Done per family

	$log->info("[varianteffectpredictor]\n");

	varianteffectpredictor({parameter_href => \%parameter,
				active_parameter_href => \%active_parameter,
				sample_info_href => \%sample_info,
				file_info_href => \%file_info,
				infile_lane_no_ending_href => \%infile_lane_no_ending,
				job_id_href => \%job_id,
				call_type => "BOTH",
				program_name => "varianteffectpredictor",
			       });
    }
    if ($active_parameter{pvcfparser} > 0) {  #Run pvcfparser. Done per family

	$log->info("[Vcfparser]\n");

	vcfparser({parameter_href => \%parameter,
		   active_parameter_href => \%active_parameter,
		   sample_info_href => \%sample_info,
		   file_info_href => \%file_info,
		   infile_lane_no_ending_href => \%infile_lane_no_ending,
		   job_id_href => \%job_id,
		   call_type => "BOTH",
		   program_name => "vcfparser",
		  });
    }

    if ($active_parameter{pannovar} > 0) {  #Run annovar. Done per family

	$log->info("[Annovar]\n");

	check_build_human_genome_prerequisites({parameter_href => \%parameter,
						active_parameter_href => \%active_parameter,
						sample_info_href => \%sample_info,
						file_info_href => \%file_info,
						infile_lane_no_ending_href => \%infile_lane_no_ending,
						job_id_href => \%job_id,
						supported_cosmid_reference_href => \%supported_cosmid_reference,
						program_name => "annovar",
					       });

	for (my $table_names_counter=0;$table_names_counter<scalar(@{ $active_parameter{annovar_table_names} });$table_names_counter++) {  #For all specified table names

	    if ($parameter{ $active_parameter{annovar_table_names}[$table_names_counter] }{build_file} eq 1) {

		build_annovar_prerequisites({parameter_href => \%parameter,
					     active_parameter_href => \%active_parameter,
					     sample_info_href => \%sample_info,
					     infile_lane_no_ending_href => \%infile_lane_no_ending,
					     job_id_href => \%job_id,
					     annovar_table_href => \%annovar_table,
					     program_name => "annovar",
					    });
		last;  #Will handle all build tables within sbatch script
	    }
	}
	annovar({parameter_href => \%parameter,
		 active_parameter_href => \%active_parameter,
		 sample_info_href => \%sample_info,
		 file_info_href => \%file_info,
		 infile_lane_no_ending_href => \%infile_lane_no_ending,
		 job_id_href => \%job_id,
		 annovar_table_href => \%annovar_table,
		 call_type => "BOTH",
		 program_name => "annovar",
		});
    }

    if ($active_parameter{psnpeff} > 0) {  #Run snpEff. Done per family

	$log->info("[Snpeff]\n");

	check_build_download_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "snpeff",
					   });

	snpeff({parameter_href => \%parameter,
		active_parameter_href => \%active_parameter,
		sample_info_href => \%sample_info,
		file_info_href => \%file_info,
		infile_lane_no_ending_href => \%infile_lane_no_ending,
		job_id_href => \%job_id,
		call_type => "BOTH",
		program_name => "snpeff",
	       });
    }
    if ($active_parameter{prankvariant} > 0) {  #Run rankvariant. Done per family

	$log->info("[Rankvariant]\n");

	rankvariant({parameter_href => \%parameter,
		     active_parameter_href => \%active_parameter,
		     sample_info_href => \%sample_info,
		     file_info_href => \%file_info,
		     infile_lane_no_ending_href => \%infile_lane_no_ending,
		     job_id_href => \%job_id,
		     call_type => "BOTH",
		     program_name => "rankvariant",
		    });
    }
}

if ($active_parameter{pgatk_variantevalexome} > 0) {  #Run GATK varianteval for exome variants. Done per sample_id

    $log->info("[GATK variantevalexome]\n");

    check_build_human_genome_prerequisites({parameter_href => \%parameter,
					    active_parameter_href => \%active_parameter,
					    sample_info_href => \%sample_info,
					    file_info_href => \%file_info,
					    infile_lane_no_ending_href => \%infile_lane_no_ending,
					    job_id_href => \%job_id,
					    supported_cosmid_reference_href => \%supported_cosmid_reference,
					    program_name => "gatk_variantevalexome",
					   });
    check_build_download_prerequisites({parameter_href => \%parameter,
					active_parameter_href => \%active_parameter,
					sample_info_href => \%sample_info,
					infile_lane_no_ending_href => \%infile_lane_no_ending,
					job_id_href => \%job_id,
					supported_cosmid_reference_href => \%supported_cosmid_reference,
					program_name => "gatk_variantevalexome",
				       });

    foreach my $sample_id (@{ $active_parameter{sample_ids} }) {

	gatk_variantevalexome({parameter_href => \%parameter,
			       active_parameter_href => \%active_parameter,
			       sample_info_href => \%sample_info,
			       file_info_href => \%file_info,
			       infile_lane_no_ending_href => \%infile_lane_no_ending,
			       job_id_href => \%job_id,
			       sample_id_ref => \$sample_id,
			       program_name => "gatk_variantevalexome",
			      });
    }
}

if ($active_parameter{pqccollect} > 0) {  #Run qccollect. Done per family

    $log->info("[Qccollect]\n");

    qccollect({parameter_href => \%parameter,
	       active_parameter_href => \%active_parameter,
	       sample_info_href => \%sample_info,
	       infile_lane_no_ending_href => \%infile_lane_no_ending,
	       job_id_href => \%job_id,
	       program_name => "qccollect",
	      });
}


if ($active_parameter{pmultiqc} > 0) {

    $log->info("[Multiqc]\n");

    multiqc({parameter_href => \%parameter,
	     active_parameter_href => \%active_parameter,
	     sample_info_href => \%sample_info,
	     infile_lane_no_ending_href => \%infile_lane_no_ending,
	     job_id_href => \%job_id,
	     program_name => "multiqc",
	    });
}


if ($active_parameter{premoveredundantfiles} > 0) {  #Sbatch generation of removal of alignment files

    $log->info("[Removal of redundant files]\n");

    removeredundantfiles({parameter_href => \%parameter,
			  active_parameter_href => \%active_parameter,
			  sample_info_href => \%sample_info,
			  file_info_href => \%file_info,
			  infile_lane_no_ending_href => \%infile_lane_no_ending,
			  job_id_href => \%job_id,
			  lane_href => \%lane,
			  program_name => "removeredundantfiles",
			 });
}

if ( ($active_parameter{panalysisrunstatus} == 1) && (! $active_parameter{dry_run_all}) ) {

    $sample_info{analysisrunstatus} = "not_finished";  #Add analysis run status flag.
}

if ($active_parameter{panalysisrunstatus} > 0) {

    $log->info("[Analysis run status]\n");

    analysisrunstatus({parameter_href => \%parameter,
		       active_parameter_href => \%active_parameter,
		       sample_info_href => \%sample_info,
		       infile_lane_no_ending_href => \%infile_lane_no_ending,
		       job_id_href => \%job_id,
		       program_name => "analysisrunstatus",
		      });
}

if ( ($active_parameter{psacct} > 0) && ($active_parameter{dry_run_all} == 0) ) {  #Sbatch generation of sacct job_id data info

    $log->info("[Sacct]\n");

    sacct({parameter_href => \%parameter,
	   active_parameter_href => \%active_parameter,
	   sample_info_href => \%sample_info,
	   infile_lane_no_ending_href => \%infile_lane_no_ending,
	   job_id_href => \%job_id,
	   program_name => "sacct",
	  });
}

#Write QC for programs used in analysis
if ($active_parameter{sample_info_file} ne 0) {#Write SampleInfo to yaml file

    ## Writes a YAML hash to file
    File::Format::Yaml::write_yaml({yaml_href => \%sample_info,
				    yaml_file_path_ref =>  \$active_parameter{sample_info_file},
				   });
    $log->info("Wrote: ".$active_parameter{sample_info_file}, "\n");
}


######################
####Sub routines#######
######################

sub sacct {

##sacct

##Function : Output SLURM info on each job via sacct command
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $family_id_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 1;

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => lc($program_name),
					    });

    print $FILEHANDLE "sacct --format=jobid,jobname%50,account,partition,alloccpus,TotalCPU,elapsed,start,end,state,exitcode -j ";

    ## If run in dry run mode this will be empty
    if (keys %$job_id_href) {

	say $FILEHANDLE join(',', @{ $job_id_href->{PAN}{PAN} });
    }
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "chain_and_parallel_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name,
		    job_dependency_type => "afterany",
		   });
    }
}


sub analysisrunstatus {

##analysisrunstatus

##Function : Execute last in MAIN chain, tests that all recorded files exists, have a file sixe greater than zero, checks QC-metrics for PASS or FAIL and sets analysis run status flag to finished.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $family_id_ref,
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => lc($program_name),
					    });

    say $FILEHANDLE q?status="0"?;  #Set status flagg so that perl notFinished remains in sample_info_file

    ###Test all file that are supposed to exists as they are present in the sample_info file
    my @paths_ref;

    ## Collects all programs file path(s) created by MIP located in %sample_info
    collect_path_entries({sample_info_href => $sample_info_href,
			  paths_ref => \@paths_ref,
			 });

    print $FILEHANDLE q?files=(?;  #Create bash array
    foreach my $path (@paths_ref) {

	if (defined($path)) {  #First analysis and dry run will otherwise cause try to print uninitialized values

	    print $FILEHANDLE q?"?.$path.q?" ?;  #Add to array
	}
    }
    say $FILEHANDLE ")";  #Close bash array
    say $FILEHANDLE q?for file in ${files[@]}?;  #loop over files
    say $FILEHANDLE "do ";  #for each element in array do
    say $FILEHANDLE "\t".q?if [ -s $file ]; then?;  #file exists and is larger than zero
    say $FILEHANDLE "\t\t".q?echo "Found file $file"?;  #Echo
    say $FILEHANDLE "\t".q?else?;
    say $FILEHANDLE "\t\t".q?echo "Could not find $file" >&2?;  #Redirect to STDERR
    say $FILEHANDLE "\t\t".q?status="1"?;  #Set status flagg so that perl notFinished remains in sample_info_file
    say $FILEHANDLE "\t".q?fi?;
    say $FILEHANDLE q?done ?, "\n";

    ## Test varianteffectpredictor fork status. If varianteffectpredictor is unable to fork it will prematurely end the analysis and we will lose variants.
    if (defined($sample_info_href->{program}{varianteffectpredictor}{outfile})) {

	my $variant_effect_predictor_file = catfile($sample_info_href->{program}{varianteffectpredictor}{outdirectory}, $sample_info_href->{program}{varianteffectpredictor}{outfile});

	print $FILEHANDLE q?if grep -q "WARNING Unable to fork" ?;  #not output the matched text only return the exit status code
	say $FILEHANDLE $variant_effect_predictor_file.q?; then?;  #Infile
	say $FILEHANDLE "\t".q?status="1"?;  #Found pattern
	say $FILEHANDLE "\t".q?echo "VariantEffectorPredictor fork status=FAILED for file: ?.$variant_effect_predictor_file.q?" >&2?;  #Echo
	say $FILEHANDLE q?else?;  #Infile is clean
	say $FILEHANDLE "\t".q?echo "VariantEffectorPredictor fork status=PASSED for file: ?.$variant_effect_predictor_file.q?" >&2?;  #Echo
	say $FILEHANDLE q?fi?, "\n";
    }

    ## Test if FAIL exists in qccollect file i.e. issues with samples e.g. Sex and seq data correlation, relationship etc
    if (! $active_parameter_href->{qccollect_skip_evaluation}) {

	if (defined($sample_info_href->{program}{qccollect}{outfile})) {

	    my $qccollect_file = catfile($sample_info_href->{program}{qccollect}{outdirectory}, $sample_info_href->{program}{qccollect}{outfile});

	    print $FILEHANDLE q?if grep -q "FAIL" ?;  #not output the matched text only return the exit status code
	    say $FILEHANDLE $qccollect_file.q?; then?;  #Infile
	    say $FILEHANDLE "\t".q?status="1"?;  #Found pattern
	    say $FILEHANDLE "\t".q?echo "qccollect status=FAILED for file: ?.$qccollect_file.q?" >&2?;  #Echo
	    say $FILEHANDLE q?else?;  #Infile is clean
	    say $FILEHANDLE "\t".q?echo "qccollect status=PASSED for file: ?.$qccollect_file.q?" >&2?;  #Echo
	    say $FILEHANDLE q?fi?, "\n";
	}
    }

    ## Test integrity of vcf data keys in header and body
    if ( (defined($sample_info_href->{vcf_file}{clinical}{path}))
	 || (defined($sample_info_href->{vcf_file}{research}{path}))
	 || (defined($sample_info_href->{sv_vcf_file}{clinical}{path}))
	 || (defined($sample_info_href->{sv_vcf_file}{research}{path})) ) {

	print $FILEHANDLE q?perl -MTest::Harness -e ' ?;  #Execute on cmd
	print $FILEHANDLE q?my %args = (?;  #Adjust arguments to harness object
	print $FILEHANDLE q?verbosity => 1, ?;  #Print individual test results to STDOUT
	print $FILEHANDLE q?test_args => { ?;  #Argument to test script

	if (defined($sample_info_href->{vcf_file}{clinical}{path})) {

	    print $FILEHANDLE q?"test select file" => [ ?;  #Add test for select file using alias
	    print $FILEHANDLE q?"?.$sample_info_href->{vcf_file}{clinical}{path}.q?", ?;  #Infile
	    print $FILEHANDLE q?"?.$active_parameter_href->{config_file_analysis}.q?", ?;  #ConfigFile
	    print $FILEHANDLE q?], ?;
	}

	if (defined($sample_info_href->{vcf_file}{research}{path})) {

	    print $FILEHANDLE q?"test research file" => [ ?;  #Add test research file using alias
	    print $FILEHANDLE q?"?.$sample_info_href->{vcf_file}{research}{path}.q?", ?;  #Infile
	    print $FILEHANDLE q?"?.$active_parameter_href->{config_file_analysis}.q?", ?;  #ConfigFile
	    print $FILEHANDLE q?], ?;
	}
	if (defined($sample_info_href->{sv_vcf_file}{clinical}{path})) {

	    print $FILEHANDLE q?"test sv select file" => [ ?;  #Add test for select file using alias
	    print $FILEHANDLE q?"?.$sample_info_href->{vcf_file}{clinical}{path}.q?", ?;  #Infile
	    print $FILEHANDLE q?"?.$active_parameter_href->{config_file_analysis}.q?", ?;  #ConfigFile
	    print $FILEHANDLE q?], ?;
	}

	if (defined($sample_info_href->{sv_vcf_file}{research}{path})) {

	    print $FILEHANDLE q?"test sv research file" => [ ?;  #Add test research file using alias
	    print $FILEHANDLE q?"?.$sample_info_href->{vcf_file}{research}{path}.q?", ?;  #Infile
	    print $FILEHANDLE q?"?.$active_parameter_href->{config_file_analysis}.q?", ?;  #ConfigFile
	    print $FILEHANDLE q?], ?;
	}

	print $FILEHANDLE q?}); ?;
	print $FILEHANDLE q?my $harness = TAP::Harness->new( \%args ); ?;  #Create harness using arguments provided
	print $FILEHANDLE q?$harness->runtests( ?;  #Execute test(s)

	if (defined($sample_info_href->{vcf_file}{clinical}{path})) {

	    print $FILEHANDLE q?["?.catfile($Bin, "t", "test.t").q?", "test select file"], ?;
	}

	if (defined($sample_info_href->{vcf_file}{research}{path})) {

	    print $FILEHANDLE q?["?.catfile($Bin, "t", "test.t").q?", "test research file"], ?;
	}
	if (defined($sample_info_href->{sv_vcf_file}{clinical}{path})) {

	    print $FILEHANDLE q?["?.catfile($Bin, "t", "test.t").q?", "test sv select file"], ?;
	}

	if (defined($sample_info_href->{sv_vcf_file}{research}{path})) {

	    print $FILEHANDLE q?["?.catfile($Bin, "t", "test.t").q?", "test sv research file"], ?;
	}
	print $FILEHANDLE q?)'?;
	say $FILEHANDLE "\n";
    }

    say $FILEHANDLE q?if [ $status -ne 1 ]; then?;  #eval status flag
    say $FILEHANDLE "\t".q?perl -i -p -e 'if($_=~/analysisrunstatus\:/) { s/not_finished/finished/g }' ?.$active_parameter_href->{sample_info_file}.q? ?;
    say $FILEHANDLE q?else?;  #Found discrepancies - exit
    say $FILEHANDLE "\t".q?exit 1?;
    say $FILEHANDLE q?fi?, "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "chain_and_parallel_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
    return;
}


sub removeredundantfiles {

##removeredundantfiles

##Function : Generates a sbatch script, which removes redundant files.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $lane_href, $program_name, family_id_ref, $outaligner_dir_ref, $call_type
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $lane_href                  => The lane info hash {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $lane_href = $arg_href->{lane_href};
    my $program_name = $arg_href->{program_name};

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	lane_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$lane_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $time = 10;
    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $xargs_file_name;

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => $$outaligner_dir_ref,
					    });

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	## Sample files
	##Removes intermediate files from the MIP analysis depending on set MIP parameters
	remove_files({parameter_href => $parameter_href,
		      active_parameter_href => $active_parameter_href,
		      infile_lane_no_ending_href => $infile_lane_no_ending_href,
		      sample_info_href => $sample_info_href,
		      file_info_href => $file_info_href,
		      lane_href => $lane_href,
		      FILEHANDLE => $FILEHANDLE,
		      sample_id => $sample_id,
		      reduce_io_ref => $reduce_io_ref,
		      outaligner_dir_ref => $outaligner_dir_ref,
		      program_name => "remove_files",
		     });
    }

    ## Family files
    ##Removes intermediate files from the MIP analysis depending on set MIP parameters
    remove_files({parameter_href => $parameter_href,
		  active_parameter_href => $active_parameter_href,
		  infile_lane_no_ending_href => $infile_lane_no_ending_href,
		  sample_info_href => $sample_info_href,
		  file_info_href => $file_info_href,
		  lane_href => $lane_href,
		  FILEHANDLE => $FILEHANDLE,
		  reduce_io_ref => $reduce_io_ref,
		  outaligner_dir_ref => $outaligner_dir_ref,
		  program_name => "remove_files",
		 });
    close($FILEHANDLE);
}


sub multiqc {

##multiqc

##Function : Aggregate bioinforamtics reports per case
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $family_id_ref,
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 1;

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => lc($program_name),
					    });

    ## Assign directories
    my $program_outdirectory_name = $parameter_href->{"p".$program_name}{outdir_name};

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id);
	my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, $program_outdirectory_name);

	print $FILEHANDLE "multiqc ";
	print $FILEHANDLE "--force ";
	print $FILEHANDLE "--outdir ".$outsample_directory." ";
	say $FILEHANDLE $insample_directory;
    }

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "chain_and_parallel_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub qccollect {

##qccollect

##Function : Collect qc metrics for this analysis run.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, family_id_ref, $call_type,
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $call_type                  => The variant call type

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => lc($program_name),
					    });

    my $infile = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, "qc_sample_info.yaml");
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref);
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref);

    print $FILEHANDLE "perl ".$active_parameter_href->{script_dir}."/qccollect.pl ";
    print $FILEHANDLE "-sample_info_file ".$active_parameter_href->{qccollect_sampleinfo_file}." ";
    print $FILEHANDLE "-regexp_file ".$active_parameter_href->{qccollect_regexp_file}." ";

    if ($active_parameter_href->{qccollect_skip_evaluation}) {

	print $FILEHANDLE "--skip_evaluation ";
    }
    say $FILEHANDLE "-o ".$outfamily_directory."/".$$family_id_ref."_qc_metrics.yaml ", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "qccollect",
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref."_qc_metrics.yaml",
			outdata_type => "infile_dependent"
		       });

	## Add qc_metrics path to sample_info
	$sample_info_href->{program}{qccollect}{qccollect_metrics_file}{path} = $outfamily_directory."/".$$family_id_ref."_qc_metrics.yaml";

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "chain_and_parallel_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub evaluation {

##evaluation

##Function : Compare metrics for this analysis run with the NIST reference dataset.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, family_id_ref, $temp_directory_ref, $reference_dir_ref, $outaligner_dir_ref, $call_type
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $reference_dir_ref          => MIP reference directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $reference_dir_ref = $arg_href->{reference_dir_ref} //= \$arg_href->{active_parameter_href}{reference_dir};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	reference_dir_ref => { default => \$$, strict_type => 1, store => \$reference_dir_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => catfile($$outaligner_dir_ref, lc($program_name)),
					     temp_directory => $$temp_directory_ref,
					     error_trap => 0,  #Special case to allow "vcf.idx" to be created
					    });

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, lc($program_name));
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{pgatk_combinevariantcallsets}{file_tag};

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($infamily_directory, $$family_id_ref.$infile_tag.$call_type.".vcf*"),
			  temp_directory => $$temp_directory_ref
			 });
    say $FILEHANDLE "wait", "\n";

    ## Rename vcf samples. The samples array will replace the sample names in the same order as supplied.
    rename_vcf_samples({sample_ids_ref => [$active_parameter_href->{nist_id}."-NIST"],
			temp_directory_ref => $temp_directory_ref,
			infile => $active_parameter_href->{nist_high_confidence_call_set},
			outfile => catfile($$temp_directory_ref, "NIST_refrm.vcf"),
			FILEHANDLE => $FILEHANDLE,
		       });

    ## Modify since different ref genomes
    say $FILEHANDLE "## Modify since different ref genomes";
    print $FILEHANDLE q?perl -nae 'unless($_=~/##contig=<ID=GL\d+/) {print $_}' ?;
    print $FILEHANDLE catfile($$temp_directory_ref, "NIST_refrm.vcf")." ";  #Infile
    print $FILEHANDLE "> ".catfile($$temp_directory_ref, "NIST.vcf")." ";  #Outfile
    say $FILEHANDLE "\n";

    ## BcfTools Stats
    say $FILEHANDLE "## bcftools stats";
    print $FILEHANDLE "bcftools stats ";
    print $FILEHANDLE catfile($$temp_directory_ref, "NIST.vcf")." ";
    print $FILEHANDLE "> ".catfile($$temp_directory_ref, "NIST.vcf.stats")." ";
    say $FILEHANDLE "\n";

    ## Generate ".idx" for downstream Picard by failling this process
    say $FILEHANDLE "## Generate '.idx' for downstream Picard by failling this process";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $$temp_directory_ref,
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T SelectVariants ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
    print $FILEHANDLE "-V: ".catfile($$temp_directory_ref, "NIST.vcf")." ";
    print $FILEHANDLE "-o ".catfile($$temp_directory_ref, "NISTXXX.vcf")." ";
    print $FILEHANDLE "-sn ".$$sample_id_ref."XXX ";  #Include genotypes from this sample
    say $FILEHANDLE "\n";

    ## Create .interval_list file from NIST union bed
    say $FILEHANDLE "## Prepare .interval_list file from NIST union bed\n";

    print $FILEHANDLE q?perl -nae 'unless($_=~/NC_007605/ || $_=~/hs37d5/ || $_=~/GL\d+/) {print $_}' ?;
    print $FILEHANDLE catfile($$reference_dir_ref, $file_info_href->{human_genome_reference_name_no_ending}.".dict")." ";
    print $FILEHANDLE "> ".catfile($$temp_directory_ref, $file_info_href->{human_genome_reference_name_no_ending}.".dict")." ";
    say $FILEHANDLE "\n";

    print $FILEHANDLE "cat ";
    print $FILEHANDLE catfile($$temp_directory_ref, $file_info_href->{human_genome_reference_name_no_ending}.".dict")." ";
    print $FILEHANDLE $active_parameter_href->{nist_high_confidence_call_set_bed}." ";
    print $FILEHANDLE "> ".catfile($$temp_directory_ref, "NIST.bed.dict_body")." ";
    say $FILEHANDLE "\n";

    say $FILEHANDLE "## Remove target annotations, 'track', 'browse' and keep only 5 columns";
    print $FILEHANDLE q?perl  -nae 'if ($_=~/@/) {print $_;} elsif ($_=~/^track/) {} elsif ($_=~/^browser/) {} else {print @F[0], "\t", (@F[1] + 1), "\t", @F[2], "\t", "+", "\t", "-", "\n";}' ?;
    print $FILEHANDLE catfile($$temp_directory_ref, "NIST.bed.dict_body")." ";  #Infile
    print $FILEHANDLE "> ".catfile($$temp_directory_ref, "NIST.bed.dict_body_col_5.interval_list")." ";  #Remove unnecessary info and reformat
    say $FILEHANDLE "\n";

    say $FILEHANDLE "## Create ".$active_parameter_href->{nist_high_confidence_call_set_bed}.".interval_list";
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $active_parameter_href->{temp_directory},
	       java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
	      });

    print $FILEHANDLE "IntervalListTools ";
    print $FILEHANDLE "INPUT=".catfile($$temp_directory_ref, "NIST.bed.dict_body_col_5.interval_list")." ";
    print $FILEHANDLE "OUTPUT=".catfile($$temp_directory_ref, "NIST.bed.interval_list")." ";
    say $FILEHANDLE "\n";

    ### MIP data
    ## GATK SelectVariants
    say $FILEHANDLE "## GATK SelectVariants";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $$temp_directory_ref,
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T SelectVariants ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
    print $FILEHANDLE "-V: ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf")." ";  #Family_id infile
    print $FILEHANDLE "-o ".catfile($$temp_directory_ref, "MIP.vcf")." ";  #Sample_id exome outfile
    print $FILEHANDLE "-sn ".$$sample_id_ref." ";  #Include genotypes from this sample
    print $FILEHANDLE "-env ";
    say $FILEHANDLE "\n";

    ## Left align, trim and split allels
    say $FILEHANDLE "## GATK LeftAlignAndTrimVariants";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $$temp_directory_ref,
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T LeftAlignAndTrimVariants ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
    print $FILEHANDLE "--splitMultiallelics ";
    print $FILEHANDLE "--variant ".catfile($$temp_directory_ref, "MIP.vcf")." ";  #Sample_id infile
    print $FILEHANDLE "-o ".catfile($$temp_directory_ref, "MIP_lts.vcf")." ";  #Outfile
    say $FILEHANDLE "\n";

    ## Modify since different ref genomes
    say $FILEHANDLE "## Modify since different ref genomes";
    print $FILEHANDLE q?perl -nae 'unless($_=~/##contig=<ID=NC_007605,length=171823>/ || $_=~/##contig=<ID=hs37d5,length=35477943>/ || $_=~/##contig=<ID=GL\d+/) {print $_}' ?;
    print $FILEHANDLE catfile($$temp_directory_ref, "MIP_lts.vcf")." ";  #Infile
    print $FILEHANDLE "> ".catfile($$temp_directory_ref, "MIP_lts_refrm.vcf")." ";  #Outfile
    say $FILEHANDLE "\n";

    ## BcfTools Stats
    say $FILEHANDLE "## bcftools stats";
    print $FILEHANDLE "bcftools stats ";
    print $FILEHANDLE catfile($$temp_directory_ref, "MIP_lts_refrm.vcf")." ";
    print $FILEHANDLE "> ".catfile($$temp_directory_ref, "MIP_lts_refrm.vcf.stats")." ";
    say $FILEHANDLE "\n";

    ## Generate ".idx" for downstream Picard by failling this process
    say $FILEHANDLE "## Generate '.idx' for downstream Picard by failling this process";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $$temp_directory_ref,
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T SelectVariants ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
    print $FILEHANDLE "-V: ".catfile($$temp_directory_ref, "MIP_lts_refrm.vcf")." ";
    print $FILEHANDLE "-o ".catfile($$temp_directory_ref, "MIPXXX.vcf")." ";
    print $FILEHANDLE "-sn ".$$sample_id_ref."XXX ";  #Include genotypes from this sample
    say $FILEHANDLE "\n";


    say $FILEHANDLE "## Picard GenotypeConcordance - Genome restricted by union - good quality ";
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $active_parameter_href->{temp_directory},
	       java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
	      });

    print $FILEHANDLE "GenotypeConcordance ";
    print $FILEHANDLE "TRUTH_VCF=".catfile($$temp_directory_ref, "NIST.vcf")." ";
    print $FILEHANDLE "CALL_VCF=".catfile($$temp_directory_ref, "MIP_lts_refrm.vcf")." ";
    print $FILEHANDLE "OUTPUT=".catfile($$temp_directory_ref, "compMIP.Vs.".$active_parameter_href->{nist_id}."-NIST_genome_bed")," ";
    print $FILEHANDLE "TRUTH_SAMPLE=".$active_parameter_href->{nist_id}."-NIST ";
    print $FILEHANDLE "CALL_SAMPLE=".$$sample_id_ref." ";
    print $FILEHANDLE "MIN_GQ=20 ";
    print $FILEHANDLE "MIN_DP=10 ";
    print $FILEHANDLE "INTERVALS=".catfile($$temp_directory_ref, "NIST.bed.interval_list")." ";
    say $FILEHANDLE "\n";

    say $FILEHANDLE "## Picard GenotypeConcordance - Genome - good quality ";
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $active_parameter_href->{temp_directory},
	       java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
	      });

    print $FILEHANDLE "GenotypeConcordance ";
    print $FILEHANDLE "TRUTH_VCF=".catfile($$temp_directory_ref, "NIST.vcf")." ";
    print $FILEHANDLE "CALL_VCF=".catfile($$temp_directory_ref, "MIP_lts_refrm.vcf")." ";
    print $FILEHANDLE "OUTPUT=".catfile($$temp_directory_ref, "compMIP.Vs.".$active_parameter_href->{nist_id}."-NIST_genome")." ";
    print $FILEHANDLE "TRUTH_SAMPLE=".$active_parameter_href->{nist_id}."-NIST ";
    print $FILEHANDLE "CALL_SAMPLE=".$$sample_id_ref." ";
    print $FILEHANDLE "MIN_GQ=20 ";
    print $FILEHANDLE "MIN_DP=10 ";
    say $FILEHANDLE "\n";

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    my @outfiles = ("compMIP.Vs.NIST_ADM1059A3_genome*", "*vcf.stats");
    foreach my $outfile (@outfiles) {

	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $outfile),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    }
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency_dead_end",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub rankvariant {

##rankvariant

##Function : Annotate and score variants depending on mendelian inheritance, frequency and phenotype etc.
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $program_info_path, $file_name, $FILEHANDLE, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $FILEHANDLE                 => Sbatch filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;
    my $program_info_path;
    my $file_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => { strict_type => 1, store => \$file_name},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 20;
    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};

    ## Set the number of cores
    my $core_number = $active_parameter_href->{core_processor_number};
    my $genmod_core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
						     core_number => 16,
						    });  #Detect the number of cores to use per genmod process.
    my $xargs_file_name;

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$family_id_ref,
								  program_name => $program_name,
								  program_directory => catfile(lc($$outaligner_dir_ref)),
								  core_number => $core_number,
								  process_time => 10,
								  temp_directory => $$temp_directory_ref
								 });
    }

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_file_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref);

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{psnpeff}{file_tag};
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};

    my $vcfparser_analysis_type = "";
    my $contigs_size_ordered_ref = \@{ $file_info_href->{contigs_size_ordered} };  #Set default for size ordered contigs
    my @contigs = @{ $file_info_href->{contigs} };  #Set default for contigs
    my $family_file = catfile($outfamily_file_directory, $$family_id_ref.".fam");

    ## Create .fam file to be used in variant calling analyses
    create_fam_file({parameter_href => $parameter_href,
		     active_parameter_href => $active_parameter_href,
		     sample_info_href => $sample_info_href,
		     FILEHANDLE => $FILEHANDLE,
		     fam_file_path => $family_file,
		    });

    for (my $vcfparser_outfile_counter=0;$vcfparser_outfile_counter<$active_parameter_href->{vcfparser_outfile_count};$vcfparser_outfile_counter++) {

	if ($vcfparser_outfile_counter == 1) {

	    $vcfparser_analysis_type = ".selected";  #SelectFile variants
	    $contigs_size_ordered_ref = \@{ $file_info_href->{sorted_select_file_contigs} };  #Selectfile contigs
	    @contigs = @{ $file_info_href->{select_file_contigs} };

	    if ($consensus_analysis_type eq "wes" ) {  #Remove MT|M since no exome kit so far has mitochondrial probes

		## Removes an element from array and return new array while leaving orginal elements_ref untouched
		@contigs = remove_element({elements_ref => \@{ $file_info_href->{select_file_contigs} },
					   remove_contigs_ref => ["MT", "M"],
					   contig_switch => 1,
					  });
	    }
	}

	if ( ! $$reduce_io_ref) { #Run as individual sbatch script

	    ## Copy file(s) to temporary directory
	    say $FILEHANDLE "## Copy file(s) to temporary directory";
	    $xargs_file_counter = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
							      XARGSFILEHANDLE => $XARGSFILEHANDLE,
							      contigs_ref => $contigs_size_ordered_ref,
							      file_name => $file_name,
							      program_info_path => $program_info_path,
							      core_number => $core_number,
							      xargs_file_counter => $xargs_file_counter,
							      infile => $$family_id_ref.$infile_tag.$call_type,
							      file_ending => $vcfparser_analysis_type.".vcf*",
							      indirectory => $infamily_directory,
							      temp_directory => $active_parameter_href->{temp_directory},
							     });
	}

	if ($consensus_analysis_type eq "wes" ) {

	    ## Clear trap for signal(s)
	    clear_trap({FILEHANDLE => $FILEHANDLE,
		       });
	}

	## Genmod
	say $FILEHANDLE "## GeneMod";

	## Create file commands for xargs
	($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
								 XARGSFILEHANDLE => $XARGSFILEHANDLE,
								 file_name => $file_name,
								 program_info_path => $program_info_path,
								 core_number => $genmod_core_number,
								 xargs_file_counter => $xargs_file_counter,
								 first_command => "genmod",
								});

	my $genmod_module = "";  #Track which genmod modules has been processed

	## Process per contig
	while ( my ($contig_index, $contig) = each(@$contigs_size_ordered_ref) ) {

	    $genmod_module = "";  #Restart for next contig
	    my $genmod_indata = catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf")." ";  #InFile

	    ## Check affected/unaffected status
	    if ( (defined($parameter_href->{dynamic_parameter}{unaffected}))
		 && (@{ $parameter_href->{dynamic_parameter}{unaffected} } eq @{ $active_parameter_href->{sample_ids} }) ) {  #Only unaffected

		if ( (! $contig_index) && (! $vcfparser_outfile_counter) ) {

		    $log->warn("Only unaffected sample in pedigree - skipping genmod 'models', 'score' and 'compound'");
		}
	    }

	    ## Genmod Annotate
	    $genmod_module = "_annotate";
	    print $XARGSFILEHANDLE "-v ";  #Increase output verbosity
	    print $XARGSFILEHANDLE "annotate ";  #Annotate vcf variants
	    print $XARGSFILEHANDLE "--temp_dir ".$$temp_directory_ref." ";  #Temporary directory

	    if ($active_parameter_href->{genmod_annotate_regions}) {
		
		print $XARGSFILEHANDLE "--regions ";  #Use predefined annotation file distributed with genmod
	    }
	    foreach my $cadd_file (@{ $active_parameter_href->{genmod_annotate_cadd_files} }) {

		print $XARGSFILEHANDLE "--cadd-file ".$cadd_file." ";  #CADD score file(s)
	    }
	    if (defined($active_parameter_href->{genmod_annotate_spidex_file})) {

		print $XARGSFILEHANDLE "--spidex ".$active_parameter_href->{genmod_annotate_spidex_file}." ";  #Spidex file
	    }
	    if ( (defined($parameter_href->{dynamic_parameter}{unaffected})) && (@{ $parameter_href->{dynamic_parameter}{unaffected} } eq @{ $active_parameter_href->{sample_ids} }) ) {  #Only unaffected

		## Write to outputFile - last genmod module
		print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.$vcfparser_analysis_type.$genmod_module.".vcf")." ";  #OutFile
		print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.$genmod_module.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		say $XARGSFILEHANDLE $genmod_indata;  #Infile
	    }
	    else {

		## Write to outputstream
		print $XARGSFILEHANDLE "-o ".catfile(dirname(devnull()), "stdout")." ";  #OutFile
		print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.$genmod_module.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		print $XARGSFILEHANDLE $genmod_indata;  #InStream or Infile
		print $XARGSFILEHANDLE "| ";  #Pipe

		$genmod_indata = "- ";  #Preparation for next module

		## Genmod Models
		$genmod_module .= "_models";
		print $XARGSFILEHANDLE "genmod ";
		print $XARGSFILEHANDLE "-v ";  #Increase output verbosity
		print $XARGSFILEHANDLE "models ";  #Annotate genetic models for vcf variants
		print $XARGSFILEHANDLE "--temp_dir ".$$temp_directory_ref." ";  #Temporary directory
		print $XARGSFILEHANDLE "--family_file ".$family_file." ";  #Pedigree file
		print $XARGSFILEHANDLE "--family_type ".$active_parameter_href->{genmod_models_family_type}." ";  #Family type

		if (defined($active_parameter_href->{genmod_models_reduced_penetrance_file})) {

		    print $XARGSFILEHANDLE "--reduced_penetrance ".$active_parameter_href->{genmod_models_reduced_penetrance_file}." ";  #Use list of genes that have been shown to display reduced penetrance
		}
		print $XARGSFILEHANDLE "--processes 4 ";  #Define how many processes that should be use for annotation

		if ( ($active_parameter_href->{pvarianteffectpredictor} > 0)
		    && (! $active_parameter_href->{genmod_annotate_regions}) ) {  #Use VEP annotations in compound models

		    print $XARGSFILEHANDLE "--vep ";
		}
		if ($active_parameter_href->{genmod_models_whole_gene}) {

		    print $XARGSFILEHANDLE "--whole_gene ";
		}

		print $XARGSFILEHANDLE "-o ".catfile(dirname(devnull()), "stdout")." ";  #OutFile
		print $XARGSFILEHANDLE $genmod_indata;  #InFile
		print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.$genmod_module.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		print $XARGSFILEHANDLE "| ";  #Pipe

		## Genmod Score
		$genmod_module .= "_score";
		print $XARGSFILEHANDLE "genmod ";
		print $XARGSFILEHANDLE "-v ";  #Increase output verbosity
		print $XARGSFILEHANDLE "score ";  #Score variants in a vcf file using Weighted sums
		print $XARGSFILEHANDLE "--family_file ".$family_file." ";  #Pedigree file
		print $XARGSFILEHANDLE "--family_type ".$active_parameter_href->{genmod_models_family_type}." ";  #Family type
		print $XARGSFILEHANDLE "--rank_results ";  #Add a info field that shows how the different categories contribute to the rank score

		if (defined($active_parameter_href->{rank_model_file})) {

		    print $XARGSFILEHANDLE "--score_config ".$active_parameter_href->{rank_model_file}." ";  #Rank model config.ini file
		}

		print $XARGSFILEHANDLE "-o ".catfile(dirname(devnull()), "stdout")." ";  #OutFile
		print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.$genmod_module.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		print $XARGSFILEHANDLE $genmod_indata;  #InStream or Infile

		##Genmod Compound
		$genmod_module .= "_compound";

		print $XARGSFILEHANDLE "| ";  #Pipe
		print $XARGSFILEHANDLE "genmod ";
		print $XARGSFILEHANDLE "-v ";  #Increase output verbosity
		print $XARGSFILEHANDLE "compound ";  #Adjust score for compound variants in a vcf file
		print $XARGSFILEHANDLE "--temp_dir ".$$temp_directory_ref." ";  #Temporary directory

		if ( ($active_parameter_href->{pvarianteffectpredictor} > 0)
		    && (! $active_parameter_href->{genmod_annotate_regions}) ) {  #Use VEP annotations in compound models

		    print $XARGSFILEHANDLE "--vep ";
		}

		print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.$vcfparser_analysis_type.$genmod_module.".vcf")." ";  #OutFile
		print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.$genmod_module.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		say $XARGSFILEHANDLE $genmod_indata;  #InFile
	    }
	}

	## Writes sbatch code to supplied filehandle to concatenate variants in vcf format. Each array element is combined with the infilePre and Postfix.
	concatenate_variants({active_parameter_href => $active_parameter_href,
			      FILEHANDLE => $FILEHANDLE,
			      elements_ref => \@contigs,
			      infile_prefix => catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_"),
			      infile_postfix => $vcfparser_analysis_type.$genmod_module.".vcf",
			      outfile => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf"),
			     });

	if ($consensus_analysis_type eq "wes" ) {

	    ## Enable trap for signal(s) and function
	    enable_trap({FILEHANDLE => $FILEHANDLE,
			});
	}

	if ($active_parameter_href->{rankvariant_binary_file}) {

	    ## Compress or decompress original file or stream to outfile (if supplied)
	    bgzip({FILEHANDLE => $FILEHANDLE,
		   infile_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf"),
		   outfile_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf.gz"),
		  });
	    say $FILEHANDLE "\n";

	    ## Index file using tabix
	    tabix({FILEHANDLE => $FILEHANDLE,
		   infile_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf.gz"),
		  });
	    say $FILEHANDLE "\n";
	}

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf*"),
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
	say $FILEHANDLE "wait", "\n";

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    if ($vcfparser_outfile_counter == 1) {

		$sample_info_href->{vcf_file}{clinical}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf");
		$sample_info_href->{program}{rankvariant}{clinical}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf");   #Save clinical candidate list path

		if ($active_parameter_href->{rankvariant_binary_file}) {

		    $sample_info_href->{vcf_binary_file}{clinical}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf.gz");
		}
	    }
	    else {

		$sample_info_href->{vcf_file}{research}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf");
		$sample_info_href->{program}{rankvariant}{research}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf");   #Save research candidate list path

		if ($active_parameter_href->{rankvariant_binary_file}) {

		    $sample_info_href->{vcf_binary_file}{research}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf.gz");
		}
	    }
	}
    }

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	if (defined($active_parameter_href->{rank_model_file})) {  #Add to SampleInfo

	    if ($active_parameter_href->{rank_model_file}=~/v(\d+\.\d+.\d+|\d+\.\d+)/) {

		$sample_info_href->{program}{rankvariant}{rank_model}{version} = $1;
	    }
	    $sample_info_href->{program}{rankvariant}{rank_model}{file} = basename($active_parameter_href->{rank_model_file});
	    $sample_info_href->{program}{rankvariant}{rank_model}{path} = $active_parameter_href->{rank_model_file};

	}
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "genmod",
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf",
			outdata_type => "static"
		       });
	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
    if ($$reduce_io_ref) {

	return $xargs_file_counter;  #Track the number of created xargs scripts per module for Block algorithm
    }
}


sub gatk_variantevalexome {

##gatk_variantevalexome

##Function : GATK varianteval for exome variants.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type,
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name {REF}
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$sample_id_ref,
					     program_name => $program_name,
					     program_directory => catfile(lc($$outaligner_dir_ref), lc($program_name)),
					     call_type => $call_type,
					     process_time => 2,
					     temp_directory => $$temp_directory_ref
					    });

    ## Assign directories
    my $outsample_directory = catfile($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref, lc($program_name) );
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{pgatk_combinevariantcallsets}{file_tag};
    my $outfile_tag = $file_info_href->{$$family_id_ref}{pgatk_combinevariantcallsets}{file_tag};

    my $extract_exonic_regexp = q?perl -ne ' if ( ($_=~/exonic/) || ($_=~/splicing/) ) {print $_;}' ?;

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($infamily_directory, $$family_id_ref.$infile_tag.$call_type.".vcf*"),
			  temp_directory => $$temp_directory_ref
			 });

    say $FILEHANDLE "wait", "\n";

    ## Select Sample_id from family_id vcf file

    ## GATK SelectVariants
    say $FILEHANDLE "## GATK SelectVariants";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $$temp_directory_ref,
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T SelectVariants ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
    print $FILEHANDLE "-V: ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf")." ";  #Family_id infile
    print $FILEHANDLE "-o ".catfile($$temp_directory_ref, $infile.$outfile_tag.$call_type."_temp.vcf")." ";  #Sample_id exome outfile
    say $FILEHANDLE "-sn ".$$sample_id_ref, "\n";  #Include genotypes from this sample

    $infile_tag = $file_info_href->{$$family_id_ref}{prankvariant}{file_tag};

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($infamily_directory, $$family_id_ref.$infile_tag.$call_type.".vcf*"),
			  temp_directory => $$temp_directory_ref
			 });
    say $FILEHANDLE "wait", "\n";

    ## Extract exonic variants
    say $FILEHANDLE "## Extract exonic variants";
    print $FILEHANDLE $extract_exonic_regexp;
    print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf")." ";  #InFile
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$sample_id_ref.$infile_tag.$call_type."_exonic_variants.vcf"), "\n";  #OutFile

    ## Include potential SelectFile variants
    if ($active_parameter_href->{vcfparser_outfile_count} == 2) {

	my $vcfparser_analysis_type = ".selected";  #SelectFile variants

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			      path => catfile($infamily_directory, $$family_id_ref.$infile_tag.$call_type.$vcfparser_analysis_type.".vcf*"),
			      temp_directory => $$temp_directory_ref
			     });
	say $FILEHANDLE "wait", "\n";

	## Extract exonic variants
	say $FILEHANDLE "## Extract exonic variants";
	print $FILEHANDLE $extract_exonic_regexp;
	print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.$vcfparser_analysis_type.".vcf")." ";  #InFile
	say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$sample_id_ref.$infile_tag.$call_type."_exonic_variants".$vcfparser_analysis_type.".vcf"), "\n";  #OutFile

	## Merge orphans and selectfiles
	say $FILEHANDLE "## Merge orphans and selectfile(s)";
	print $FILEHANDLE "cat ";
	print $FILEHANDLE catfile($$temp_directory_ref, $$sample_id_ref.$infile_tag.$call_type."_exonic_variants.vcf")." ";  #Orphan file
	print $FILEHANDLE catfile($$temp_directory_ref, $$sample_id_ref.$infile_tag.$call_type."_exonic_variants".$vcfparser_analysis_type.".vcf")." ";  #SelectFile variants
	say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$sample_id_ref.$infile_tag.$call_type."_exonic_variants_combined.vcf"), "\n";  #OutFile

	## Sort combined file
	say $FILEHANDLE "## Sort combined file";
	print $FILEHANDLE "sort ";
	print $FILEHANDLE "-k1,1 -k2,2n ";  #Numerically by chromosome and start position
	print $FILEHANDLE catfile($$temp_directory_ref, $$sample_id_ref.$infile_tag.$call_type."_exonic_variants_combined.vcf")." ";
	say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$sample_id_ref.$infile_tag.$call_type."_exonic_variants.vcf"), "\n";  #OutFile
    }

    print $FILEHANDLE q?perl -ne ' if ($_=~/^#/) {print $_;}' ?;
    print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf")." ";  #InFile
    print $FILEHANDLE "| ";  #Pipe
    print $FILEHANDLE "cat ";
    print $FILEHANDLE "- ";
    print $FILEHANDLE catfile($$temp_directory_ref, $$sample_id_ref.$infile_tag.$call_type."_exonic_variants.vcf")." ";  #infile
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$sample_id_ref.$infile_tag.$call_type."_exonic_variants_head.vcf"), "\n";  #OutFile

    ## Intersect exonic variants from created sample_id vcf file (required for gatk_varianteval for exonic variants)
    say $FILEHANDLE "## Intersect exonic variants from created sample_id vcf file";
    print $FILEHANDLE "intersectBed ";
    print $FILEHANDLE "-header ";  #Print the header from the A file prior to results.
    print $FILEHANDLE "-a ".catfile($$temp_directory_ref, $infile.$outfile_tag.$call_type."_temp.vcf")." ";  #Sample_id temp exome vcf infile
    print $FILEHANDLE "-b ".catfile($$temp_directory_ref, $$sample_id_ref.$infile_tag.$call_type."_exonic_variants_head.vcf")." ";  #Sample_id exonic variants
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $infile.$outfile_tag.$call_type."_exome.vcf"), "\n";  #OutFile (VCF-format)

    ## VariantEval
    say $FILEHANDLE "## GATK varianteval";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $$temp_directory_ref,
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T VariantEval ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
    print $FILEHANDLE "-D ".$active_parameter_href->{gatk_varianteval_dbsnp}." ";  #dbSNP file
    print $FILEHANDLE "-gold ".$active_parameter_href->{gatk_varianteval_gold}." ";  #Evaluations that count calls at sites of true variation (e.g., indel calls) will use this argument as their gold standard for comparison
    print $FILEHANDLE "--eval ".catfile($$temp_directory_ref, $infile.$outfile_tag.$call_type."_exome.vcf")." ";  #InFile
    say $FILEHANDLE "-o ".catfile($$temp_directory_ref, $infile.$outfile_tag.$call_type."_exome.vcf.varianteval"), "\n";  #OutFile

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $infile.$outfile_tag.$call_type."_exome.vcf.varianteval"),
			    file_path => $outsample_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			sample_id => $$sample_id_ref,
			program_name => "variantevalexome",
			infile => $infile,
			outdirectory => $outsample_directory,
			outfile_ending => $outfile_tag.$call_type."_exome.vcf.varianteval",
			outdata_type => "infile_dependent"
		       });
    }
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency_dead_end",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub gatk_variantevalall {

##gatk_variantevalall

##Function : GATK varianteval for all variants.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name,
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$sample_id_ref,
					     program_name => $program_name,
					     program_directory => catfile(lc($$outaligner_dir_ref),  lc($program_name)),
					     call_type => $call_type,
					     process_time => 2,
					     temp_directory => $$temp_directory_ref,
					    });

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref, lc($program_name));
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{pgatk_combinevariantcallsets}{file_tag};
    my $outfile_tag = $file_info_href->{$$family_id_ref}{pgatk_combinevariantcallsets}{file_tag};

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($infamily_directory, $$family_id_ref.$infile_tag.$call_type.".vcf*"),
			  temp_directory => $$temp_directory_ref
			 });
    say $FILEHANDLE "wait", "\n";

    ## Select Sample_id from family_id vcf file

    ## GATK SelectVariants
    say $FILEHANDLE "## GATK SelectVariants";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $$temp_directory_ref,
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T SelectVariants ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
    print $FILEHANDLE "-V: ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf")." ";  #Family_id infile
    print $FILEHANDLE "-o ".catfile($$temp_directory_ref, $infile.$outfile_tag.$call_type.".vcf")." ";  #Sample_id outfile
    say $FILEHANDLE "-sn ".$$sample_id_ref, "\n";  #Include genotypes from this sample

    ## GATK varianteval
    say $FILEHANDLE "## GATK varianteval";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $$temp_directory_ref,
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T VariantEval ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
    print $FILEHANDLE "-D ".$active_parameter_href->{gatk_varianteval_dbsnp}." ";  #dbSNP file
    print $FILEHANDLE "-gold ".$active_parameter_href->{gatk_varianteval_gold}." ";  #Evaluations that count calls at sites of true variation (e.g., indel calls) will use this argument as their gold standard for comparison
    print $FILEHANDLE "--eval ".catfile($$temp_directory_ref, $infile.$infile_tag.$call_type.".vcf")." ";  #InFile
    say $FILEHANDLE "-o ".catfile($$temp_directory_ref, $infile.$outfile_tag.$call_type.".vcf.varianteval"), "\n";  #OutFile

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $infile.$outfile_tag.$call_type.".vcf.varianteval"),
			    file_path => $outsample_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			sample_id => $$sample_id_ref,
			program_name => "variantevalall",
			infile => $infile,
			outdirectory => $outsample_directory,
			outfile_ending => $outfile_tag.$call_type.".vcf.varianteval",
			outdata_type => "infile_dependent"
		       });
    }
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency_dead_end",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub snpeff {

##snpeff

##Function : snpeff annotates variants from different sources.
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $program_info_path, $file_name, $FILEHANDLE, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $FILEHANDLE                 => Sbatch filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;
    my $program_info_path;
    my $file_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => {  strict_type => 1, store => \$file_name},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 20;
    my $xargs_file_name;

    ## Set the number of cores to allocate per sbatch job.
    my $core_number = $active_parameter_href->{core_processor_number};

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$family_id_ref,
								  program_name => $program_name,
								  program_directory => catfile(lc($$outaligner_dir_ref)),
								  call_type => $call_type,
								  core_number => $core_number,
								  process_time => 10,
								  temp_directory => $$temp_directory_ref
								 });
    }

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{pannovar}{file_tag};
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};

    my $vcfparser_analysis_type = "";
    my $vcfparser_contigs_ref = \@{ $file_info_href->{contigs_size_ordered} };  #Set default

    for (my $vcfparser_outfile_counter=0;$vcfparser_outfile_counter<$active_parameter_href->{vcfparser_outfile_count};$vcfparser_outfile_counter++) {

	if ($vcfparser_outfile_counter == 1) {

	    $vcfparser_analysis_type = ".selected";  #SelectFile variants
	    $vcfparser_contigs_ref = \@{ $file_info_href->{sorted_select_file_contigs} };  #Selectfile contigs
	}

	if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	    ## Copy file(s) to temporary directory
	    say $FILEHANDLE "## Copy file(s) to temporary directory";
	    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
										  XARGSFILEHANDLE => $XARGSFILEHANDLE,
										  contigs_ref => $vcfparser_contigs_ref,
										  file_name =>$file_name,
										  program_info_path => $program_info_path,
										  core_number => $core_number,
										  xargs_file_counter => $xargs_file_counter,
										  infile => $$family_id_ref.$infile_tag.$call_type,
										  file_ending => $vcfparser_analysis_type.".vcf*",
										  indirectory => $infamily_directory,
										  temp_directory => $$temp_directory_ref,
										 });
	}

	## SnpSift Annotation
	say $FILEHANDLE "## SnpSift Annotation";

	my $annotation_file_counter = 0;

	if ($active_parameter_href->{snpeff_ann} eq 1) {  #Annotate using snpeff

	    ## Create file commands for xargs
	    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
								     XARGSFILEHANDLE => $XARGSFILEHANDLE,
								     file_name => $file_name,
								     program_info_path => $program_info_path,
								     core_number => $core_number,
								     xargs_file_counter => $xargs_file_counter,
								     first_command => "java",
								     memory_allocation => "Xmx4g -XX:-UseConcMarkSweepGC",
								     java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
								     java_temporary_directory => $$temp_directory_ref,
								     java_jar => catfile($active_parameter_href->{snpeff_path}, "snpEff.jar"),
								    });

	    foreach my $contig (@$vcfparser_contigs_ref) {

		print $XARGSFILEHANDLE "ann ";
		print $XARGSFILEHANDLE "-v ";  #Verbose mode
		print $XARGSFILEHANDLE $active_parameter_href->{snpeff_genome_build_version}." ";  #Reference genome
		print $XARGSFILEHANDLE "-c ".catfile($active_parameter_href->{snpeff_path}, "snpEff.config")." ";  #Specify config file
		print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf")." "; #Infile
		print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		say $XARGSFILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf.".$xargs_file_counter)." "; #Outfile;
	    }
	    $annotation_file_counter = $xargs_file_counter;
	}

	for my $annotation_file (keys $active_parameter_href->{snpsift_annotation_files}){

	    my $info_key = $active_parameter_href->{snpsift_annotation_files}{$annotation_file};

	    ## Create file commands for xargs
	    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
								     XARGSFILEHANDLE => $XARGSFILEHANDLE,
								     file_name => $file_name,
								     program_info_path => $program_info_path,
								     core_number => $core_number,
								     xargs_file_counter => $xargs_file_counter,
								     first_command => "java",
								     memory_allocation => "Xmx2g -XX:-UseConcMarkSweepGC",
								     java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
								     java_temporary_directory => $$temp_directory_ref,
								     java_jar => catfile($active_parameter_href->{snpeff_path}, "SnpSift.jar"),
								    });

	    foreach my $contig (@$vcfparser_contigs_ref) {

		print $XARGSFILEHANDLE "annotate ";

		if (defined($active_parameter_href->{snpsift_annotation_files}{$annotation_file})) {

		    ## Apply specific INFO field output key for easier downstream processing
		    if (defined($active_parameter_href->{snpsift_annotation_outinfo_key}{$annotation_file})) {

			print $XARGSFILEHANDLE "-name ".$active_parameter_href->{snpsift_annotation_outinfo_key}{$annotation_file}." ";
		    }
		    print $XARGSFILEHANDLE "-info ".$active_parameter_href->{snpsift_annotation_files}{$annotation_file}." ";  #Database
		}
		print $XARGSFILEHANDLE $annotation_file." ";  #Database

		if (! $annotation_file_counter) {  #First file per contig

		    print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf")." "; #Infile
		}
		else {

		    my $annotation_infile_number = $xargs_file_counter - 1;
		    print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf.".$annotation_infile_number)." ";  #Infile from previous round
		}

		print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		say $XARGSFILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf.".$xargs_file_counter)." ";  #Outfile
	    }
	    $annotation_file_counter++;  #Increment counter
	    close($XARGSFILEHANDLE);
	}

	if (@{ $active_parameter_href->{snpsift_dbnsfp_annotations} }) {

	    ## SnpSiftDbNSFP Annotation
	    say $FILEHANDLE "## SnpSiftDnNSFP Annotation";

	    ## Create file commands for xargs
	    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
								     XARGSFILEHANDLE => $XARGSFILEHANDLE,
								     file_name => $file_name,
								     program_info_path => $program_info_path,
								     core_number => $core_number,
								     xargs_file_counter => $xargs_file_counter,
								     first_command => "java",
								     memory_allocation => "Xmx2g -XX:-UseConcMarkSweepGC",
								     java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
								     java_temporary_directory => $$temp_directory_ref,
								     java_jar => catfile($active_parameter_href->{snpeff_path}, "SnpSift.jar"),
								    });

	    my $annotation_infile_number = $xargs_file_counter - 1;

	    foreach my $contig (@$vcfparser_contigs_ref) {

		print $XARGSFILEHANDLE "dbnsfp ";
		print $XARGSFILEHANDLE "-db ".$active_parameter_href->{snpsift_dbnsfp_file}." ";  #DbNSFP file
		print $XARGSFILEHANDLE "-f ";  #fields to add
		print $XARGSFILEHANDLE join(',', @{ $active_parameter_href->{snpsift_dbnsfp_annotations} })." ";  #Databases
		print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf.".$annotation_infile_number)." ";  #Infile
		print $XARGSFILEHANDLE "2>> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		say $XARGSFILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf.".$xargs_file_counter)." ";  #Outfile
	    }
	    close($XARGSFILEHANDLE);
	}

	## Add INFO headers and FIX_INFO for annotations using vcfparser
	say $FILEHANDLE "## Add INFO headers and FIX_INFO for annotations using vcfparser";

	## Create file commands for xargs
	($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
								 XARGSFILEHANDLE => $XARGSFILEHANDLE,
								 file_name => $file_name,
								 program_info_path => $program_info_path,
								 core_number => $core_number,
								 xargs_file_counter => $xargs_file_counter,
								 first_command => "perl",
								});

	my $annotation_infile_number = $xargs_file_counter - 1;

	foreach my $contig (@$vcfparser_contigs_ref) {

	    print $XARGSFILEHANDLE catfile($active_parameter_href->{script_dir}, "vcfparser.pl")." ";  #Parses the vcf output
	    print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf.".$annotation_infile_number)." ";  #Infile
	    print $XARGSFILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf")." ";  #Outfile
	    say $XARGSFILEHANDLE "2>> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	}

	if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	    ## Copies file from temporary directory. Per contig
	    say $FILEHANDLE "## Copy file from temporary directory";
	    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
										  XARGSFILEHANDLE => $XARGSFILEHANDLE,
										  contigs_ref => $vcfparser_contigs_ref,
										  file_name =>$file_name,
										  program_info_path => $program_info_path,
										  core_number => $active_parameter_href->{core_processor_number},
										  xargs_file_counter => $xargs_file_counter,
										  outfile => $$family_id_ref.$outfile_tag.$call_type,
										  file_ending => $vcfparser_analysis_type.".vcf*",
										  outdirectory => $outfamily_directory,
										  temp_directory => $$temp_directory_ref,
										 });
	}
	else {

	    ## QC Data File(s)
	    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$file_info_href->{contigs_size_ordered}[0].$vcfparser_analysis_type.".vcf"),
				    file_path => $outfamily_directory,
				    FILEHANDLE => $FILEHANDLE,
				   });
	    say $FILEHANDLE "wait", "\n";
	}

	## Adds the most complete vcf file to sample_info
	add_most_complete_vcf({active_parameter_href => $active_parameter_href,
			       sample_info_href => $sample_info_href,
			       program_name => $program_name,
			       path => catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf"),
			       vcfparser_outfile_counter => $vcfparser_outfile_counter,
			      });
    }

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => $program_name,
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.$outfile_tag.$call_type."_".$file_info_href->{contigs_size_ordered}[0].$vcfparser_analysis_type.".vcf",
			outdata_type => "static"
		       });
    }

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	close($FILEHANDLE);

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			dependencies => "case_dependency",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name
		       });
	}
    }
    if ($$reduce_io_ref) {

	return $xargs_file_counter;  #Track the number of created xargs scripts per module for Block algorithm
    }
}


sub annovar {

##annovar

##Function : Annotate and filter SNVs by gene, region and databases.
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $annovar_table_href, $program_name, $program_info_path, $file_name, $FILEHANDLE, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $annovar_table_href         => annovar_table_href {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $FILEHANDLE                 => Sbatch filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $annovar_table_href;
    my $program_name;
    my $program_info_path;
    my $file_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	annovar_table_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$annovar_table_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => { strict_type => 1, store => \$file_name},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 20;
    my $xargs_file_name;

    ## Set the number of cores to allocate per sbatch job.
    my $core_number = $active_parameter_href->{core_processor_number};

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$family_id_ref,
								  program_name => $program_name,
								  program_directory => catfile(lc($$outaligner_dir_ref)),
								  call_type => $call_type,
								  core_number => $core_number,
								  process_time => 7,
								  temp_directory => $$temp_directory_ref
								 });
    }

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{pvcfparser}{file_tag};
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};

    my $vcfparser_analysis_type = "";
    my $vcfparser_contigs_ref = \@{ $file_info_href->{contigs_size_ordered} };  #Set default

    for (my $vcfparser_outfile_counter=0;$vcfparser_outfile_counter<$active_parameter_href->{vcfparser_outfile_count};$vcfparser_outfile_counter++) {

	if ($vcfparser_outfile_counter == 1) {

	    $vcfparser_analysis_type = ".selected";  #SelectFile variants
	    $vcfparser_contigs_ref = \@{ $file_info_href->{sorted_select_file_contigs} };  #Selectfile contigs
	}

	if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	    ## Copy file(s) to temporary directory
	    say $FILEHANDLE "## Copy file(s) to temporary directory";
	    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
										  XARGSFILEHANDLE => $XARGSFILEHANDLE,
										  contigs_ref => $vcfparser_contigs_ref,
										  file_name =>$file_name,
										  program_info_path => $program_info_path,
										  core_number => $core_number,
										  xargs_file_counter => $xargs_file_counter,
										  infile => $$family_id_ref.$infile_tag.$call_type,
										  file_ending => $vcfparser_analysis_type.".vcf*",
										  indirectory => $infamily_directory,
										  temp_directory => $$temp_directory_ref,
										 });
	}

	## annovar
	say $FILEHANDLE "## annovar";

	## Create file commands for xargs
	($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
								 XARGSFILEHANDLE => $XARGSFILEHANDLE,
								 file_name => $file_name,
								 program_info_path => $program_info_path,
								 core_number => $core_number,
								 xargs_file_counter => $xargs_file_counter,
								 first_command => "perl",
								});

	foreach my $contig (@$vcfparser_contigs_ref) {

	    print $XARGSFILEHANDLE catfile($active_parameter_href->{annovar_path}, "table_annovar.pl")." ";  #annovar script
	    print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf")." ";  #Infile
	    print $XARGSFILEHANDLE catfile($active_parameter_href->{annovar_path}, "humandb")." ";  #annovar/humandb directory is assumed
	    print $XARGSFILEHANDLE "-buildver ".$active_parameter_href->{annovar_genome_build_version}." ";  #Genome build version
	    print $XARGSFILEHANDLE "-vcfinput ";  #Input format
	    print $XARGSFILEHANDLE "--remove ";  #Remove all temporary files
	    print $XARGSFILEHANDLE "-out ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf")." ";  #Outfile prefix
	    print $XARGSFILEHANDLE "-protocol ";  #Comma-delimited string specifying database protocol

	    print $XARGSFILEHANDLE join(',', @{ $active_parameter_href->{annovar_table_names} })." ";  #Databases to use

	    print $XARGSFILEHANDLE "-operation ";  #Comma-delimited string specifying type of operation

	    for (my $table_names_counter=0;$table_names_counter<scalar(@{ $active_parameter_href->{annovar_table_names} });$table_names_counter++) {  #For all specified table names

		if ($annovar_table_href->{$active_parameter_href->{annovar_table_names}[$table_names_counter]}{annotation} eq "geneanno") {

		    print $XARGSFILEHANDLE "g";
		}
		elsif ($annovar_table_href->{$active_parameter_href->{annovar_table_names}[$table_names_counter]}{annotation} eq "regionanno") {

		    print $XARGSFILEHANDLE "r";
		}
		elsif ($annovar_table_href->{$active_parameter_href->{annovar_table_names}[$table_names_counter]}{annotation} eq "filter") {

		    print $XARGSFILEHANDLE "f";
		}
		unless ($table_names_counter == scalar(@{ $active_parameter_href->{annovar_table_names} }) - 1) {

		    print $XARGSFILEHANDLE ",";
		}
	    }
	    print $XARGSFILEHANDLE " ";

	    print $XARGSFILEHANDLE "-argument ";
	    for (my $table_names_counter=0;$table_names_counter<scalar(@{ $active_parameter_href->{annovar_table_names} });$table_names_counter++) {  #For all specified table names

		if ($annovar_table_href->{$active_parameter_href->{annovar_table_names}[$table_names_counter]}{annotation} eq "geneanno" ) {  #Use hgvs output style

		    print $XARGSFILEHANDLE q?\'--hgvs ?;  #Use hgvs annotation
		    print $XARGSFILEHANDLE q?--exonicsplicing\' ?;  #Annotate variants near intron/exonic borders
		}
		if ($active_parameter_href->{annovar_table_names}[$table_names_counter] =~/^1000g/) {#Set MAF TH

		    print $XARGSFILEHANDLE "'--maf_threshold ".$active_parameter_href->{annovar_maf_threshold}."'";
		}
		if ( ($active_parameter_href->{annovar_table_names}[$table_names_counter] =~/^snp/) || ($active_parameter_href->{annovar_table_names}[$table_names_counter] =~/_esp/) ) {#Set MAF TH

		    print $XARGSFILEHANDLE "'--score_threshold ".$active_parameter_href->{annovar_maf_threshold}."'"; #score_threshold since annovar reserved the maf_threshold for 1000G
		}
		unless ($table_names_counter == scalar(@{ $active_parameter_href->{annovar_table_names} }) - 1) {

		    print $XARGSFILEHANDLE ",";
		}
	    }
	    print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    print $XARGSFILEHANDLE "; ";
	    print $XARGSFILEHANDLE "mv ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf.".$active_parameter_href->{annovar_genome_build_version}."_multianno.vcf")." ";
	    say $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.$vcfparser_analysis_type.".vcf");
	}
	if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	    ## Copies file from temporary directory.
	    say $FILEHANDLE "## Copy file from temporary directory";
	    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
										  XARGSFILEHANDLE => $XARGSFILEHANDLE,
										  contigs_ref => $vcfparser_contigs_ref,
										  file_name =>$file_name,
										  program_info_path => $program_info_path,
										  core_number => $core_number,
										  xargs_file_counter => $xargs_file_counter,
										  outfile => $$family_id_ref.$outfile_tag.$call_type,
										  file_ending => $vcfparser_analysis_type.".vcf*",
										  outdirectory => $outfamily_directory,
										  temp_directory => $$temp_directory_ref,
										 });
	}

	## Adds the most complete vcf file to sample_info
	add_most_complete_vcf({active_parameter_href => $active_parameter_href,
			       sample_info_href => $sample_info_href,
			       program_name => $program_name,
			       path => catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf"),
			       vcfparser_outfile_counter => $vcfparser_outfile_counter,
			      });
    }

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	close($FILEHANDLE);

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			dependencies => "case_dependency",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name
		       });
	}
    }
    if ($$reduce_io_ref) {

	return $xargs_file_counter;  #Track the number of created xargs scripts per module for Block algorithm
    }
}


sub vcfparser {

##vcfparser

##Function : vcfparser performs parsing of varianteffectpredictor annotated variants
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $program_info_path, $file_name, $FILEHANDLE, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $FILEHANDLE                 => Sbatch filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_info_path;
    my $program_name;
    my $file_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => {  strict_type => 1, store => \$file_name},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $core_number = $active_parameter_href->{core_processor_number};
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 5;
    my $xargs_file_name;

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$family_id_ref,
								  program_name => $program_name,
								  program_directory => catfile(lc($$outaligner_dir_ref)),
								  call_type => $call_type,
								  temp_directory => $$temp_directory_ref,
								  process_time => $time,
								 });
    }

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{pvarianteffectpredictor}{file_tag};
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      infile => $$family_id_ref.$infile_tag.$call_type,
									      indirectory => $infamily_directory,
									      temp_directory => $$temp_directory_ref,
									     });
    }

    ## vcfparser
    say $FILEHANDLE "## vcfparser";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "perl",
							    });

    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE catfile($active_parameter_href->{script_dir}, "vcfparser.pl")." ";  #Parses the VEP output to tab-sep format
	print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.".vcf")." ";  #Infile

	if ($active_parameter_href->{pvarianteffectpredictor} > 0) {

	    print $XARGSFILEHANDLE "--parse_vep ".$active_parameter_href->{vcfparser_vep_transcripts}." ";  #Parse VEP transcript specific entries
	}
	if ($contig =~ /MT|M/) {

	    print $XARGSFILEHANDLE "--padding 10 ";  #Special case for mitochondrial contig annotation
	}
	if ($active_parameter_href->{vcfparser_range_feature_file}) {

	    print $XARGSFILEHANDLE "-rf ".$active_parameter_href->{vcfparser_range_feature_file}." ";  #List of genes to analyse separately

	    if ( ($active_parameter_href->{vcfparser_range_feature_annotation_columns})
		  && (@{ $active_parameter_href->{vcfparser_range_feature_annotation_columns} }) ) {
		
		print $XARGSFILEHANDLE "-rf_ac ";  #Range annotation columns
		print $XARGSFILEHANDLE join(',', @{ $active_parameter_href->{vcfparser_range_feature_annotation_columns} })." ";
	    }
	}
	if ($active_parameter_href->{vcfparser_select_file}) {

	    if (! check_entry_hash_of_array({hash_ref => $file_info_href,
					     key => "select_file_contigs",
					     element => $contig,
					    })
		) {

		print $XARGSFILEHANDLE "-sf ".catfile($active_parameter_href->{vcfparser_select_file})." ";  #List of genes to analyse separately
		print $XARGSFILEHANDLE "-sf_mc ".$active_parameter_href->{vcfparser_select_file_matching_column}." ";  #Column of HGNC Symbol in SelectFile (-sf)

		if ( ($active_parameter_href->{sv_vcfparser_select_feature_annotation_columns})
		     && (@{ $active_parameter_href->{vcfparser_select_feature_annotation_columns} }) ) {

		    print $XARGSFILEHANDLE "-sf_ac ";  #Select annotation columns
		    print $XARGSFILEHANDLE join(',', @{ $active_parameter_href->{vcfparser_select_feature_annotation_columns} })." ";
		}
		print $XARGSFILEHANDLE "-sof ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.".selected.vcf")." ";
	    }
	}
	print $XARGSFILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.".vcf")." ";  #outfile
	say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
    }

    ## QC Data File(s)
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$file_info_href->{contigs_size_ordered}[0].".vcf"),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Clear old vcfparser entry if present
	if (defined($sample_info_href->{$program_name})) {

	    delete($sample_info_href->{$program_name});
	}
	if ($active_parameter_href->{vcfparser_range_feature_file}) {

	    ## Collect databases(s) from a potentially merged select_file and adds them to sample_info
	    collect_gene_panels({sample_info_href => $sample_info_href,
				 family_id_ref => $family_id_ref,
				 program_name_ref => \$program_name,
				 aggregate_gene_panel_file => $active_parameter_href->{vcfparser_range_feature_file},
				 aggregate_gene_panels_key => "range_file",
				});

	    if ($active_parameter_href->{vcfparser_range_feature_file}=~/v(\d+\.\d+.\d+|\d+\.\d+)/) {

		$sample_info_href->{$program_name}{range_file}{version} = $1;
	    }
	    $sample_info_href->{$program_name}{range_file}{path} = $active_parameter_href->{vcfparser_range_feature_file};
	}
	if ($active_parameter_href->{vcfparser_select_file}) {

	    ## Collect databases(s) from a potentially merged select_file and adds them to sample_info
	    collect_gene_panels({sample_info_href => $sample_info_href,
				 family_id_ref => $family_id_ref,
				 program_name_ref => \$program_name,
				 aggregate_gene_panel_file => catfile($active_parameter_href->{vcfparser_select_file}),
				 aggregate_gene_panels_key => "select_file",
				});

	    if ($active_parameter_href->{vcfparser_select_file}=~/v(\d+\.\d+.\d+|\d+\.\d+)/) {

		$sample_info_href->{$program_name}{select_file}{version} = $1;
	    }
	    $sample_info_href->{$program_name}{select_file}{path} = catfile($active_parameter_href->{vcfparser_select_file});
	}

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => $program_name,
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.$outfile_tag.$call_type."_".$file_info_href->{contigs_size_ordered}[0].".vcf",
			outdata_type => "static"
		       });
    }

    close($XARGSFILEHANDLE);

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	my $vcfparser_analysis_type = "";
	my @vcfparser_contigs_ref = \@{ $file_info_href->{contigs_size_ordered} };

	for (my $vcfparser_outfile_counter=0;$vcfparser_outfile_counter<$active_parameter_href->{vcfparser_outfile_count};$vcfparser_outfile_counter++) {

	    if ($vcfparser_outfile_counter == 1) {

		$vcfparser_analysis_type = ".selected";  #SelectFile variants
		@vcfparser_contigs_ref = \@{ $file_info_href->{sorted_select_file_contigs} };
	    }

	    ## Copies file from temporary directory.
	    say $FILEHANDLE "## Copy file(s) from temporary directory";
	    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
										  XARGSFILEHANDLE => $XARGSFILEHANDLE,
										  contigs_ref => @vcfparser_contigs_ref,
										  file_name =>$file_name,
										  program_info_path => $program_info_path,
										  core_number => $core_number,
										  xargs_file_counter => $xargs_file_counter,
										  outfile => $$family_id_ref.$outfile_tag.$call_type,
										  file_ending => $vcfparser_analysis_type.".vcf*",
										  outdirectory => $outfamily_directory,
										  temp_directory => $$temp_directory_ref,
										 });

	    ## Adds the most complete vcf file to sample_info
	    add_most_complete_vcf({active_parameter_href => $active_parameter_href,
				   sample_info_href => $sample_info_href,
				   program_name => $program_name,
				   path => catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf"),
				   vcfparser_outfile_counter => $vcfparser_outfile_counter,
				  });
	}
	close($FILEHANDLE);
    }

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			dependencies => "case_dependency",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name
		       });
	}
    }
    if ($$reduce_io_ref) {

	return $xargs_file_counter;  #Track the number of created xargs scripts per module for Block algorithm
    }
}


sub varianteffectpredictor {

##varianteffectpredictor

##Function : varianteffectpredictor performs annotation of variants.
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $program_info_path, $file_name, $stderr_path, $FILEHANDLE, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $stderr_path                => The stderr path of the block script
##         : $FILEHANDLE                 => Sbatch filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;
    my $program_info_path;
    my $file_name;
    my $stderr_path;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => { strict_type => 1, store => \$file_name},
	stderr_path => { strict_type => 1, store => \$stderr_path},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 20;
    my $xargs_file_name;

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    }

    my $fork_number = 4;  #varianteffectpredictor forks

    ## Set the number of cores to allocate per sbatch job.
    my $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					      core_number => scalar(@{ $file_info_href->{contigs} }),
					     });  #Detect the number of cores to use
    $core_number = floor($core_number / $fork_number);  #Adjust for the number of forks

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$family_id_ref,
								  program_name => $program_name,
								  program_directory => catfile(lc($$outaligner_dir_ref)),
								  call_type => $call_type,
								  core_number => $active_parameter_href->{core_processor_number},
								  process_time => 10,
								  temp_directory => $$temp_directory_ref
								 });
	$stderr_path = $program_info_path.".stderr.txt";
    }
    my ($volume, $directory, $stderr_file) = File::Spec->splitpath($stderr_path);  #Split to enable submission to &sample_info_qc later

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{pvt}{file_tag};
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      infile => $$family_id_ref.$infile_tag.$call_type,
									      indirectory => $infamily_directory,
									      temp_directory => $$temp_directory_ref,
									     });
    }

    ## varianteffectpredictor
    say $FILEHANDLE "## varianteffectpredictor";

    my $assembly_version = $file_info_href->{human_genome_reference_source}.$file_info_href->{human_genome_reference_version};

    ## Alias genome source and version to be compatible with VEP
    alias_assembly_version({assembly_version_ref => \$assembly_version
			   });

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "perl",
							    });

    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE catfile($active_parameter_href->{vep_directory_path}, "variant_effect_predictor.pl")." ";  #VEP script
	print $XARGSFILEHANDLE "--assembly ".$assembly_version." ";
	print $XARGSFILEHANDLE "--dir_cache ".$active_parameter_href->{vep_directory_cache}." ";  #Specify the cache directory to use
	print $XARGSFILEHANDLE "--cache ";  #Enables use of the cache.

	if ($active_parameter_href->{vep_reference}) {  #Use reference file for analysis with vep

	    print $XARGSFILEHANDLE "--fasta ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	}

	print $XARGSFILEHANDLE "--force_overwrite ";  #force the overwrite of the existing file
	print $XARGSFILEHANDLE "--format vcf ";  #Input is in the VCF format
	print $XARGSFILEHANDLE "--vcf ";  #Writes output in VCF format.
	print $XARGSFILEHANDLE "--no_progress ";  #Do not show progress in stderr
	print $XARGSFILEHANDLE "--fork ".$fork_number." ";  #Enable forking, using the specified number of forks.
	print $XARGSFILEHANDLE "--buffer_size 20000 ";  #Sets the internal buffer size, corresponding to the number of variations that are read in to memory simultaneously
	print $XARGSFILEHANDLE "--offline ";  #Use installed assembly
	print $XARGSFILEHANDLE "--chr ".$contig." ";

	##VEPPlugins
	foreach my $plugin (@{ $active_parameter_href->{vep_plugins} }) {

	    if ($plugin eq "LoF") {

		print $XARGSFILEHANDLE "--plugin ".$plugin.",human_ancestor_fa:".catfile($active_parameter_href->{vep_directory_cache}, "human_ancestor.fa,filter_position:0.05")." ";
	    }
	    elsif ($plugin eq "UpDownDistance") {  #Special case for mitochondrial contig annotation

		if ($contig =~ /MT|M/) {

		    print $XARGSFILEHANDLE "--plugin UpDownDistance,10,10 ";
		}
	    }
	    else {

		print $XARGSFILEHANDLE "--plugin ".$plugin." ";
	    }
	}

	##VEPFeatures
	foreach my $vep_feature (@{ $active_parameter_href->{vep_features} }) {

	    print $XARGSFILEHANDLE "--".$vep_feature." ";  #Add VEP features to the output.

	    if ( ($contig =~ /MT|M/) && ($vep_feature eq "refseq") ) {  #Special case for mitochondrial contig annotation

		print $XARGSFILEHANDLE "--all_refseq ";
	    }
	    if ( ($vep_feature eq "sift") || ($vep_feature eq "polyphen") )  {  #Protein predictions

		print $XARGSFILEHANDLE "p ";  #Add prediction term
	    }
	}

	print $XARGSFILEHANDLE "-i ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.".vcf")." ";  #InFile (family vcf)
	print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.".vcf")." ";  #OutFile
	print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$contig.".stdout.txt ";  #Redirect xargs output to program specific stdout file
	say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
    }

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => $program_name."summary",
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.$outfile_tag.$call_type."_".$file_info_href->{contigs_size_ordered}[0].".vcf_summary.html",
			outdata_type => "static"
		       });
	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => $program_name,
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.$outfile_tag.$call_type."_".$file_info_href->{contigs_size_ordered}[0].".vcf",
			outdata_type => "static"
		       });
    }

    ## QC Data File(s)
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_*.vcf_s*"),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    close($XARGSFILEHANDLE);

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_*.vcf*"),
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
	say $FILEHANDLE "wait", "\n";

	close($FILEHANDLE);
    }
    else {  #Move file for downstream collection of VEP version

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$file_info_href->{contigs_size_ordered}[0].".vcf"),
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
	say $FILEHANDLE "wait", "\n";
    }

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	    ## Submitt job
	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			dependencies => "case_dependency",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name
		       });
	}
	if ($$reduce_io_ref) {  #Redirect qccollect search to Block File, since VEP will write stderr there

	    $program_name = "variantannotationblock";
	}

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => $program_name,
			outdirectory => $directory,
			outfile_ending => $stderr_file,
			outdata_type => "info_directory"
		       });
    }
    if ($$reduce_io_ref) {

	return $xargs_file_counter;  #Track the number of created xargs scripts per module for Block algorithm
    }
}


sub gatk_readbackedphasing {

##gatk_readbackedphasing

##Function : GATK ReadBackedPhasing performs physical phasing of SNP calls, based on sequencing reads.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $lane_href, $infile_lane_no_ending_href, $job_id_href, $family_id, $outaligner_dir, $call_type, $program_name
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $lane_href                  => The lane info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $family_id                  => The family_id
##         : $outaligner_dir             => The outaligner_dir used in the analysis
##         : $call_type                  => The variant call type
##         : $program_name               => The program name

    my $parameter_href = $_[0];
    my $active_parameter_href = $_[1];
    my $sample_info_href = $_[2];
    my $file_info_href = $_[3];
    my $lane_href = $_[4];
    my $infile_lane_no_ending_href = $_[5];
    my $job_id_href = $_[6];
    my $family_id = $_[7];
    my $outaligner_dir = $_[8];
    my $call_type = $_[9];
    my $program_name = $_[10];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $core_number = 1;

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $family_id,
					     program_name => $program_name,
					     program_directory => catfile(lc($outaligner_dir)),
					     call_type => $call_type,
					     core_number => $core_number,
					     process_time => 15,
					     temp_directory => $active_parameter_href->{temp_directory}
					    });

    ## Assign directories
    my $infamily_directory = catfile($active_parameter_href->{outdata_dir}, $family_id, $outaligner_dir);
    my $outfamily_directory = catfile($active_parameter_href->{outdata_dir}, $family_id, $outaligner_dir);

    ## Assign file_tags
    my $infile_tag;

    ## Choose infile ending depending on GATK PhasebyTransmission swith
    if ($active_parameter_href->{pgatk_phasebytransmission} > 0) {

	$infile_tag = $file_info_href->{ $active_parameter_href->{family_id} }{pgatk_phasebytransmission}{file_tag};
    }
    else {

	$infile_tag = $file_info_href->{ $active_parameter_href->{family_id} }{pgatk_combinevariantcallsets}{file_tag};
    }
    my $outfile_tag = $file_info_href->{ $active_parameter_href->{family_id} }{"p".$program_name}{file_tag};

    ## Copy VCF file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($infamily_directory, $family_id.$infile_tag.$call_type.".vcf*"),
			  temp_directory => $active_parameter_href->{temp_directory}
			 });
    say $FILEHANDLE "wait", "\n";

    ## Copy BAM file(s) to temporary directory
    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, $outaligner_dir);
	my $infile_tag = $file_info_href->{$sample_id}{pgatk_baserecalibration}{file_tag};

	## Add merged infile name after merging all BAM files per sample_id
	my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			      path => catfile($insample_directory, $infile.$infile_tag.".b*"),
			      temp_directory => $active_parameter_href->{temp_directory}
			     });
	say $FILEHANDLE "wait", "\n";
    }

    ## GATK ReadBackedPhasing
    say $FILEHANDLE "## GATK ReadBackedPhasing";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx4g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $active_parameter_href->{temp_directory},
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T ReadBackedPhasing ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
    print $FILEHANDLE "--phaseQualityThresh ".$active_parameter_href->{gatk_readbackedphasing_phase_quality_threshold}." ";

    if ($active_parameter_href->{pgatk_phasebytransmission} > 0) {

	print $FILEHANDLE "-respectPhaseInInput ";  #Already phased data - respect calls
    }

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	my $infile_tag = $file_info_href->{$sample_id}{pgatk_baserecalibration}{file_tag};

	## Add merged infile name after merging all BAM files per sample_id
	my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

	print $FILEHANDLE "-I ".catfile($active_parameter_href->{temp_directory}, $infile.$infile_tag.".bam ");  #InFile
    }
    print $FILEHANDLE "-L: ".catfile($active_parameter_href->{temp_directory}, $family_id.$infile_tag.$call_type.".vcf")." ";  #Limit to  (family vcf)
    print $FILEHANDLE "-V: ".catfile($active_parameter_href->{temp_directory}, $family_id.$infile_tag.$call_type.".vcf")." ";  #InFile (family vcf)
    say $FILEHANDLE "-o ".catfile($active_parameter_href->{temp_directory}, $family_id.$outfile_tag.$call_type.".vcf"), "\n";  #OutFile

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($active_parameter_href->{temp_directory}, $family_id.$outfile_tag.$call_type.".vcf*"),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency_dead_end",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub gatk_phasebytransmission {

##gatk_phasebytransmission

##Function : GATK PhaseByTransmission computes the most likely genotype combination and phases trios and parent/child pairs given their genotype likelihoods and a mutation prior and phases all sites were parent/child transmission can be inferred unambiguously.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $family_id, $outaligner_dir, $call_type, $program_name
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $family_id                  => The family_id
##         : $outaligner_dir             => The outaligner_dir used in the analysis
##         : $call_type                  => The variant call type
##         : $program_name               => The program name

    my $parameter_href = $_[0];
    my $active_parameter_href = $_[1];
    my $sample_info_href = $_[2];
    my $file_info_href = $_[3];
    my $infile_lane_no_ending_href = $_[4];
    my $job_id_href = $_[5];
    my $family_id = $_[6];
    my $outaligner_dir = $_[7];
    my $call_type = $_[8];
    my $program_name = $_[9];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $family_id,
					     program_name => $program_name,
					     program_directory => catfile(lc($outaligner_dir)),
					     call_type => $call_type,
					     process_time => 15,
					     temp_directory => $active_parameter_href->{temp_directory}
					    });

    ## Assign directories
    my $outfamily_file_directory = catfile($active_parameter_href->{outdata_dir}, $family_id);
    my $infamily_directory = catfile($active_parameter_href->{outdata_dir}, $family_id, $outaligner_dir);
    my $outfamily_directory = catfile($active_parameter_href->{outdata_dir}, $family_id, $outaligner_dir);

    ## Assign file_tags
    my $infile_tag = $file_info_href->{ $active_parameter_href->{family_id} }{pgatk_combinevariantcallsets}{file_tag};
    my $outfile_tag = $file_info_href->{ $active_parameter_href->{family_id} }{"p".$program_name}{file_tag};

    ## Create .fam file to be used in variant calling analyses
    create_fam_file({parameter_href => $parameter_href,
		     active_parameter_href => $active_parameter_href,
		     sample_info_href => $sample_info_href,
		     fam_file_path => catfile($outfamily_file_directory, $family_id.".fam"),
		    });

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($infamily_directory, $family_id.$infile_tag.$call_type.".vcf*"),
			  temp_directory => $active_parameter_href->{temp_directory}
			 });
    say $FILEHANDLE "wait", "\n";

    ## GATK PhaseByTransmission
    say $FILEHANDLE "## GATK PhaseByTransmission";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx4g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $active_parameter_href->{temp_directory},
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T PhaseByTransmission ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
    print $FILEHANDLE "-V: ".catfile($active_parameter_href->{temp_directory}, $family_id.$infile_tag.$call_type.".vcf")." ";  #InFile (family vcf)

    ## Check if "--pedigree" and "--pedigreeValidationType" should be included in analysis
    gatk_pedigree_flag({active_parameter_href => $active_parameter_href,
			FILEHANDLE => $FILEHANDLE,
			outfamily_file_directory => $outfamily_file_directory,
			program_name => $program_name,
		       });

    say $FILEHANDLE "-o ".catfile($active_parameter_href->{temp_directory}, $family_id.$outfile_tag.$call_type.".vcf"), "\n";  #OutFile

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($active_parameter_href->{temp_directory}, $family_id.$outfile_tag.$call_type.".vcf*"),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub samplecheck {

##samplecheck

##Function : Tests sample for correct relatives (only performed for samples with relatives defined in pedigree file) performed on sequence data.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $xargs_file_name;
    my $xargs_file_counter = 0;

    ## Set the number of cores to allocate per sbatch job.
    my $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					      core_number => scalar(@{ $active_parameter_href->{sample_ids} }),
					     });

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$family_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref), lc($program_name)),
								 call_type => $call_type,
								 core_number => $core_number,
								 process_time => 10,
								});

    my ($volume, $directory, $program_info_file) = File::Spec->splitpath($program_info_path);  #Split to enable submission to &sample_info_qc later
    my $stderr_file = $program_info_file.".stderr.txt";  #To enable submission to &sample_info_qc later
    my $stdout_file = $program_info_file.".stdout.txt";  #To enable submission to &sample_info_qc later

    ## Assign Directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, lc($program_name));
    my $outfamily_file_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref);

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{pgatk_combinevariantcallsets}{file_tag};

    my $family_file = catfile($outfamily_file_directory, $$family_id_ref.".fam");

    ## Create .fam file to be used in variant calling analyses
    create_fam_file({parameter_href => $parameter_href,
		     active_parameter_href => $active_parameter_href,
		     sample_info_href => $sample_info_href,
		     FILEHANDLE => $FILEHANDLE,
		     fam_file_path => $family_file,
		    });

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($infamily_directory, $$family_id_ref.$infile_tag.$call_type.".vcf*"),
			  temp_directory => $$temp_directory_ref
			 });
    say $FILEHANDLE "wait", "\n";

    my $founderCount = detect_founders({active_parameter_href => $active_parameter_href,
					sample_info_href => $sample_info_href,
				       });

    ## GATK SelectVariants and Plink2 bed, bim and .fam file
    say $FILEHANDLE "## GATK SelectVariants and Plink2 bed, bim and .fam file";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "java",
							     memory_allocation => "Xmx2g",
							     java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
							     java_temporary_directory => $$temp_directory_ref,
							     java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
							    });

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	print $XARGSFILEHANDLE "-T SelectVariants ";  #Type of analysis to run
	print $XARGSFILEHANDLE "-l INFO ";  #Set the minimum level of logging
	print $XARGSFILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	print $XARGSFILEHANDLE "-V: ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf")." ";  #Family_id infile
	print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $sample_id.".vcf")." ";  #Sample_id outfile
	print $XARGSFILEHANDLE "-sn ".$sample_id." ";  #Include genotypes from this sample
	print $XARGSFILEHANDLE "-env ";
	print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$sample_id."_SelectVariants.stderr.txt ";  #Redirect xargs output to program specific stderr file
	print $XARGSFILEHANDLE "; ";

	## Generate Plink bed and bim (as well as fam) files
	print $XARGSFILEHANDLE "plink2 ";
	print $XARGSFILEHANDLE "--vcf ".catfile($$temp_directory_ref, $sample_id.".vcf")." ";  #InFile
	print $XARGSFILEHANDLE "--chr 23-24 ";  #Only analyse sex chromosomes
	print $XARGSFILEHANDLE "--out ".catfile($$temp_directory_ref, $sample_id."_vcf_data_unsplit")." ";  #OutFile (.ped and .map)
	say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$sample_id."_plink2.stderr.txt ";  #Redirect xargs output to program specific stderr file
    }

    ## Add a subsetet and correct .fam file for analysis
    say $FILEHANDLE "## Add a subsetet and correct .fam file for analysis";
    while (my ($sample_id_index, $sample_id) = each(@{ $active_parameter_href->{sample_ids} }) ) {  #Collect infiles for all sample_ids

	my $lineCounter = 2 + $sample_id_index;  #Skip header line
	print $FILEHANDLE q?perl -nae 'if($F[1] eq "?.$sample_id.q?") {print $F[0]."\t".$F[1]."\t0\t0\t".$F[4]."\t".$F[5]}' ?;  #Include 1 line and remove founders
	print $FILEHANDLE catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, $$family_id_ref.".fam")." ";
	print $FILEHANDLE "> ";
	print $FILEHANDLE catfile($$temp_directory_ref, $sample_id."_vcf_data_unsplit.fam")." ";
	say $FILEHANDLE "2> ".$xargs_file_name.".".$sample_id."_sampleFam.stderr.txt ", "\n";  #Redirect xargs output to program specific stderr file
    }

    ## Perform sex-check on individual samples and sample_id.fam  using Plink2
    say $FILEHANDLE "## Perform sex-check on individual samples and sample_id.fam  using Plink2";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "plink2",
							    });

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	## Split X to remove PAR regions
	print $XARGSFILEHANDLE "--bfile ".catfile($$temp_directory_ref, $sample_id."_vcf_data_unsplit")." ";
	print $XARGSFILEHANDLE "--split-x ";

	if($file_info_href->{human_genome_reference_source} eq "GRCh") {

	    print $XARGSFILEHANDLE "b".$file_info_href->{human_genome_reference_version}." ";
	}
	else {

	    print $XARGSFILEHANDLE "hg".$file_info_href->{human_genome_reference_version}." ";
	}
	print $XARGSFILEHANDLE "no-fail ";  #By default, PLINK errors out when no variants would be affected by --split-x;the 'no-fail' modifier overrides this.
	print $XARGSFILEHANDLE "--make-bed ";
	print $XARGSFILEHANDLE "--out ".catfile($$temp_directory_ref, $sample_id."_vcf_data")." ";
	print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$sample_id."_plink2_splitX.stderr.txt ";  #Redirect xargs output to program specific stderr file
	print $XARGSFILEHANDLE "; ";

	print $XARGSFILEHANDLE "plink2 ";
	print $XARGSFILEHANDLE "--bfile ".catfile($$temp_directory_ref, $sample_id."_vcf_data")." ";
	print $XARGSFILEHANDLE "--check-sex ";

	unless ($sample_info_href->{sample}{$sample_id}{sex} =~/2|female/) {

	    print $XARGSFILEHANDLE "y-only ";
	}
	print $XARGSFILEHANDLE "--out ".catfile($outfamily_directory, $sample_id."_vcf_data")." ";
	say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$sample_id."_plink2_check-sex.stderr.txt ";  #Redirect xargs output to program specific stderr file
    }

    ## Concatenate files for qc downsteam
    print $FILEHANDLE "cat ";
    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	print $FILEHANDLE catfile($outfamily_directory, $sample_id."_vcf_data.sexcheck")." ";
    }
    print $FILEHANDLE "| ";  #Pipe
    print $FILEHANDLE q?perl -nae 'if ($.==1) {chomp($_);  print $_; if ($F[5] eq "F") {print "/YCOUNT\n"} else {print "/F\n"} } elsif ($_!~/FID/) {print $_}' ?;  #Print first header and sampleId lines
    print $FILEHANDLE "> ".catfile($outfamily_directory, $$family_id_ref.".sexcheck")." ";
    say $FILEHANDLE "\n";

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "plink_sexcheck",
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.".sexcheck",
			outdata_type => "infile_dependent"
		       });
    }

    if (scalar(@{ $active_parameter_href->{sample_ids} }) > 1) {  #Only perform if more than 1 sample

	say $FILEHANDLE "## Calculate F-score";
	say $FILEHANDLE "# Remove indels using vcfTools ";
	print $FILEHANDLE "vcftools ";
	print $FILEHANDLE "--remove-indels ";  #Exclude sites that contain an indel
	print $FILEHANDLE "--vcf ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf")." ";  #InFile;
	print $FILEHANDLE "--recode ";  #Keep INFO fields
	print $FILEHANDLE "--recode-INFO-all ";  #Recode all INFO-fields
	say $FILEHANDLE "--out ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_no_indels")."\n";

	say $FILEHANDLE "# Create uniq IDs and remove duplicate variants";
	print $FILEHANDLE "bcftools annotate ";
	print $FILEHANDLE "-Ov ";  #Output type: b: compressed BCF, u: uncompressed BCF, z: compressed VCF, v: uncompressed VCF [v]
	print $FILEHANDLE "-x ID ";  #List of annotations to remove
	print $FILEHANDLE q?-I +'%CHROM:%POS:%REF:%ALT' ?;  #Set ID column
	print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_no_indels.recode.vcf")." ";  #InFile
	print $FILEHANDLE "| ";  #Pipe
	print $FILEHANDLE "vt uniq ";  #Drops duplicate variants that appear later in the the VCF file
	print $FILEHANDLE "- ";
	say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_no_indels_ann_uniq.vcf"), "\n";

	say $FILEHANDLE "# Create pruning set and uniq IDs for plink2";
	print $FILEHANDLE "plink2 ";
	print $FILEHANDLE "--noweb ";  #No web check
	print $FILEHANDLE "--vcf ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_no_indels_ann_uniq.vcf")." ";
	print $FILEHANDLE "--vcf-require-gt ";  #Skip variants where the GT field is absent
	print $FILEHANDLE "--vcf-half-call haploid ";  #Treat half-calls as haploid/homozygous
	print $FILEHANDLE q?--set-missing-var-ids @:#[?.$file_info_href->{human_genome_reference_version}.q?]\$1,\$2 ?;  #Assign chromosome-and-position-based IDs
	say $FILEHANDLE "--indep 50 5 2 ", "\n";  #Produce a pruned subset of markers that are in approximate linkage equilibrium with each other

	print $FILEHANDLE "plink2 ";
	print $FILEHANDLE "--noweb ";  #No web check
	print $FILEHANDLE "--vcf ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_no_indels_ann_uniq.vcf")." ";
	print $FILEHANDLE "--vcf-require-gt ";  #Skip variants where the GT field is absent
	print $FILEHANDLE "--vcf-half-call haploid ";  #Treat half-calls as haploid/homozygous
	print $FILEHANDLE q?--set-missing-var-ids @:#[?.$file_info_href->{human_genome_reference_version}.q?]\$1,\$2 ?;  #Assign chromosome-and-position-based IDs
	print $FILEHANDLE "--het small-sample ";  #Inlcude n/(n-1) multiplier in Nei's expected homozygosity formula
	print $FILEHANDLE "--ibc ";  #calculates three inbreeding coefficients for each sample
	print $FILEHANDLE "--extract plink.prune.in ";  #Only LD-based pruning snps
	say $FILEHANDLE "--out ".catfile($outfamily_directory, $$family_id_ref), "\n";  #Outfile

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    ## Collect QC metadata info for later use
	    sample_info_qc({sample_info_href => $sample_info_href,
			    program_name => "inbreeding_factor",
			    outdirectory => $outfamily_directory,
			    outfile_ending => $$family_id_ref.".het",
			    outdata_type => "infile_dependent"
			   });
	}
    }

    say $FILEHANDLE "## Create Plink .ped and .map file per family using vcfTools";
    print $FILEHANDLE "vcftools ";
    print $FILEHANDLE "--vcf ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf")." ";  #InFile
    print $FILEHANDLE "--plink ";  #PLINK format
    say $FILEHANDLE "--out ".catfile($outfamily_directory, $$family_id_ref), "\n";  #OutFile (.ped and .map)

    ## Variant_integrity
    if (scalar(@{ $active_parameter_href->{sample_ids} }) > 1) {  #Only perform if more than 1 sample

	if ($parameter_href->{dynamic_parameter}{trio}) {

	    print $FILEHANDLE "variant_integrity ";
	    print $FILEHANDLE "--family_file ".$family_file." ";  #Pedigree file
	    print $FILEHANDLE "--family_type ".$active_parameter_href->{genmod_models_family_type}." ";  #Family type
	    print $FILEHANDLE "--outfile ".catfile($outfamily_directory, $$family_id_ref."_mendel.txt")." ";
	    print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf")." ";  #InFile
	    say $FILEHANDLE "mendel ", "\n";

	    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

		## Collect QC metadata info for later use
		sample_info_qc({sample_info_href => $sample_info_href,
				program_name => "variant_integrity_mendel",
				outdirectory => $outfamily_directory,
				outfile_ending => $$family_id_ref."_mendel.txt",
				outdata_type => "infile_dependent"
			       });
	    }
	}

	foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	    my $father_info = $sample_info_href->{sample}{$sample_id}{father};  #Alias

	    if ($father_info ne 0) {  #Father is included in analysis

		print $FILEHANDLE "variant_integrity ";
		print $FILEHANDLE "--family_file ".$family_file." ";  #Pedigree file
		print $FILEHANDLE "--family_type ".$active_parameter_href->{genmod_models_family_type}." ";  #Family type
		print $FILEHANDLE "--outfile ".catfile($outfamily_directory, $$family_id_ref."_father.txt")." ";
		print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf")." ";  #InFile
		say $FILEHANDLE "father ", "\n";

		if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

		    ## Collect QC metadata info for later use
		    sample_info_qc({sample_info_href => $sample_info_href,
				    program_name => "variant_integrity_father",
				    outdirectory => $outfamily_directory,
				    outfile_ending => $$family_id_ref."_father.txt",
				    outdata_type => "infile_dependent"
				   });
		}
	    }
	}
    }

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "vcftools",
			outdirectory => $directory,
			outfile_ending => $stderr_file,
			outdata_type => "info_directory",
		       });
    }

    if (scalar(@{ $active_parameter_href->{sample_ids} }) > 1) {  #Only perform if more than 1 sample

	say $FILEHANDLE "## Create Plink .mibs per family";
	print $FILEHANDLE "plink2 ";
	print $FILEHANDLE "--noweb ";  #No web check
	print $FILEHANDLE "--ped ".catfile($outfamily_directory, $$family_id_ref.".ped")." ";  #InFile
	print $FILEHANDLE "--map ".catfile($outfamily_directory, $$family_id_ref.".map")." ";  #InFile
	print $FILEHANDLE "--cluster ";  #Perform IBS clustering
	print $FILEHANDLE "--matrix ";  #Create a N x N matrix of genome-wide average IBS pairwise identities
	say $FILEHANDLE "--out ".catfile($outfamily_directory, $$family_id_ref), "\n";  #OutFile

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    ## Collect QC metadata info for later use
	    sample_info_qc({sample_info_href => $sample_info_href,
			    program_name => "relation_check",
			    outdirectory => $outfamily_directory,
			    outfile_ending => $$family_id_ref.".mibs",
			    outdata_type => "infile_dependent"
			   });

	    ## Collect QC metadata info for later use
	    sample_info_qc({sample_info_href => $sample_info_href,
			    program_name => "plink2",
			    outdirectory => $directory,
			    outfile_ending => $stdout_file,
			    outdata_type => "info_directory",
			   });
	}
    }

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency_dead_end",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub vt {

##vt

##Function : Split multi allelic records into single records and normalize
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $program_info_path, $file_name, $stderr_path, $FILEHANDLE, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $stderr_path                => The stderr path of the block script
##         : $FILEHANDLE                 => Filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;
    my $program_info_path;
    my $file_name;
    my $stderr_path;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => { strict_type => 1, store => \$file_name},
	stderr_path => { strict_type => 1, store => \$stderr_path},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $xargs_file_name;
    my $time = 10;

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    }

    ## Set the number of cores to allocate per sbatch job.
    my $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					      core_number => scalar(@{ $file_info_href->{contigs} })
					     });  #Detect the number of cores to use

    if ( ! $$reduce_io_ref) { #Run as individual sbatch script

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$family_id_ref,
								  program_name => $program_name,
								  program_directory => catfile(lc($$outaligner_dir_ref)),
								  call_type => $call_type,
								  core_number => $core_number,
								  process_time => $time,
								  temp_directory => $$temp_directory_ref,
								 });
	$stderr_path = $program_info_path.".stderr.txt";
    }
    my ($volume, $directory, $stderr_file) = File::Spec->splitpath($stderr_path); #Split to enable submission to &sample_info_qc later

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{prhocall}{file_tag};
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      infile => $$family_id_ref.$infile_tag.$call_type,
									      indirectory => $infamily_directory,
									      temp_directory => $$temp_directory_ref,
									     });
    }

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "less",
							    });

    my $remove_star_regexp = q?perl -nae \'unless\($F\[4\] eq \"\*\") \{print $_\}\' ?;  #VEP does not annotate '*' since the alt allele does not exist, this is captured in the upsream indel and SNV record associated with '*'

    ## Split vcf into contigs
    while ( my ($contig_index, $contig) = each(@{ $file_info_href->{contigs_size_ordered} }) ) {

	print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.".vcf.gz")." ";  #Infile

	## vt - Split multi allelic records into single records and normalize
	vt_core({active_parameter_href => $active_parameter_href,
		 sample_info_href => $sample_info_href,
		 infile_lane_no_ending_href => $infile_lane_no_ending_href,
		 job_id_href => $job_id_href,
		 FILEHANDLE => $XARGSFILEHANDLE,
		 infile_path => catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf"),
		 outfile_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.".vcf"),
		 decompose => $active_parameter_href->{vt_decompose},
		 normalize => $active_parameter_href->{vt_normalize},
		 sed => 1,
		 instream => 1,
		 cmd_break => ";",
		 xargs_file_name => $xargs_file_name,
		 contig_ref => \$contig,
		});

	if ( ($contig_index == 0)
	     && ($active_parameter_href->{"p".$program_name} == 1)
	     && (! $active_parameter_href->{dry_run_all})
	    ) {
	    
	    my ($volume, $directory, $stderr_file) = File::Spec->splitpath($xargs_file_name);  #Split to enable submission to &SampleInfoQC later
	    
	    ## Collect QC metadata info for later use
	    sample_info_qc({sample_info_href => $sample_info_href,
			    program_name => "vt",
			    outdirectory => $directory,
			    outfile_ending => $stderr_file.".".$contig.".stderr.txt",
			    outdata_type => "info_directory"
			   });
	}

	my $alt_file_ending = "";

	## Remove decomposed '*' entries
	if ($active_parameter_href->{vt_missing_alt_allele}) {

	    $alt_file_ending = "_nostar";
	    print $XARGSFILEHANDLE catfile($remove_star_regexp.$$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.".vcf")." ";
	    print $XARGSFILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.$alt_file_ending.".vcf")." ";
	    print $XARGSFILEHANDLE "2>> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    print $XARGSFILEHANDLE "; ";
	}

	## Remove common variants
	if ($active_parameter_href->{vt_genmod_filter}) {

	    print $XARGSFILEHANDLE "genmod ";  #Program
	    print $XARGSFILEHANDLE "-v ";  #Increase output verbosity
	    print $XARGSFILEHANDLE "annotate ";  #Command
	    print $XARGSFILEHANDLE "--temp_dir ".$$temp_directory_ref." ";  #Temporary directory
	    print $XARGSFILEHANDLE "--thousand-g ".$active_parameter_href->{vt_genmod_filter_1000g}." ";  #1000G reference

	    if ($active_parameter_href->{vt_genmod_filter_max_af}) {

		print $XARGSFILEHANDLE "--max-af ";  #If the MAX AF should be annotated
	    }
	    print $XARGSFILEHANDLE "-o ".catfile(dirname(devnull()), "stdout")." ";  #OutStream
	    print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.$alt_file_ending.".vcf")." ";
	    print $XARGSFILEHANDLE "2>> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    print $XARGSFILEHANDLE "| ";

	    $alt_file_ending .= "_genmod_filter";  #Update ending

	    print $XARGSFILEHANDLE "genmod ";  #Program
	    print $XARGSFILEHANDLE "-v ";  #Increase output verbosity
	    print $XARGSFILEHANDLE "filter ";  #Command
	    print $XARGSFILEHANDLE "-t ".$active_parameter_href->{vt_genmod_filter_threshold}." ";  #Threshold for filtering variants
	    print $XARGSFILEHANDLE "- ";  #InStream
	    print $XARGSFILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.$alt_file_ending.".vcf")." ";  #OutFile
	    print $XARGSFILEHANDLE "2>> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    print $XARGSFILEHANDLE "; ";
	}

	print $XARGSFILEHANDLE "mv ";
	print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.$alt_file_ending.".vcf")." ";
	say $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.".vcf")." ";
    }

    if ( ! $$reduce_io_ref) { #Run as individual sbatch script

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_*.vcf*"),
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
	say $FILEHANDLE "wait", "\n";

	close($FILEHANDLE);
    }
    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	if ( ! $$reduce_io_ref) { #Run as individual sbatch script

	    ## Submitt job
	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			dependencies => "case_dependency",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name
		       });
	}
    }
    if ($$reduce_io_ref) {

	return $xargs_file_counter;  #Track the number of created xargs scripts per module for Block algorithm
    }
}


sub rhocall {

##rhocall

##Function : Rhocall performs annotation of autozygosity regions
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $program_info_path, $file_name, $stderr_path, $FILEHANDLE, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $stderr_path                => The stderr path of the block script
##         : $FILEHANDLE                 => Filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;
    my $program_info_path;
    my $file_name;
    my $stderr_path;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => { strict_type => 1, store => \$file_name},
	stderr_path => { strict_type => 1, store => \$stderr_path},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $xargs_file_name;
    my $time = 5;

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    }

    ## Set the number of cores to allocate per sbatch job.
    my $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					      core_number => scalar(@{ $file_info_href->{contigs} })
					     });  #Detect the number of cores to use

    if ( ! $$reduce_io_ref) { #Run as individual sbatch script

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$family_id_ref,
								  program_name => $program_name,
								  program_directory => catfile(lc($$outaligner_dir_ref)),
								  call_type => $call_type,
								  core_number => $core_number,
								  process_time => $time,
								  temp_directory => $$temp_directory_ref,
								 });
	$stderr_path = $program_info_path.".stderr.txt";
    }
    my ($volume, $directory, $stderr_file) = File::Spec->splitpath($stderr_path); #Split to enable submission to &sample_info_qc later

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{pgatk_combinevariantcallsets}{file_tag};
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      infile => $$family_id_ref.$infile_tag.$call_type,
									      indirectory => $infamily_directory,
									      temp_directory => $$temp_directory_ref,
									     });
    }

    say $FILEHANDLE "## bcftools rho calculation\n";
    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "bcftools roh",
							    });

    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE "--AF-file ".$active_parameter_href->{rhocall_frequency_file}." ";
	print $XARGSFILEHANDLE "--skip-indels ";  #Skip indels as their genotypes are enriched for errors

	if ( (defined($parameter_href->{dynamic_parameter}{affected}))
	     && (@{ $parameter_href->{dynamic_parameter}{affected} }) ) {

	    print $XARGSFILEHANDLE "--sample ".$parameter_href->{dynamic_parameter}{affected}[0]." ";
	}
	else {

	    print $XARGSFILEHANDLE "--sample ".$active_parameter_href->{sample_ids}[0]." ";  #No affected - pick any sample_id
	}
	print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.".vcf.gz")." ";  #Infile
	print $XARGSFILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.".roh"), "; ";

	print $XARGSFILEHANDLE "rhocall aggregate ";
	print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.".roh")." ";
	print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.".roh.bed")."; ";

	print $XARGSFILEHANDLE "rhocall annotate ";
	print $XARGSFILEHANDLE "-b ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.".roh.bed")." ";
	print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.".vcf")." ";
	say $XARGSFILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_".$contig.".vcf.gz");
    }

    if ( ! $$reduce_io_ref) { #Run as individual sbatch script

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_*.vcf*"),
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
	say $FILEHANDLE "wait", "\n";

	close($FILEHANDLE);
    }
    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	if ( ! $$reduce_io_ref) { #Run as individual sbatch script

	    ## Submitt job
	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			dependencies => "case_dependency",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name
		       });
	}
    }
    if ($$reduce_io_ref) {

	return $xargs_file_counter;  #Track the number of created xargs scripts per module for Block algorithm
    }
}


sub prepareforvariantannotationblock {

##prepareforvariantannotationblock

##Function : Copy files for variantannotationblock to enable restart and skip of modules within block
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $program_info_path, $file_name, $stderr_path, $FILEHANDLE, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $stderr_path                => The stderr path of the block script
##         : $FILEHANDLE                 => Filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;
    my $program_info_path;
    my $file_name;
    my $stderr_path;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => { strict_type => 1, store => \$file_name},
	stderr_path => { strict_type => 1, store => \$stderr_path},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $xargs_file_name;
    my $time = 10;

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    }

    ## Set the number of cores to allocate per sbatch job.
    my $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					      core_number => scalar(@{ $file_info_href->{contigs} })
					     });

    if ( ! $$reduce_io_ref) { #Run as individual sbatch script

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$family_id_ref,
								  program_name => $program_name,
								  program_directory => catfile(lc($$outaligner_dir_ref)),
								  call_type => $call_type,
								  core_number => $core_number,
								  process_time => $time,
								  temp_directory => $$temp_directory_ref,
								 });
	$stderr_path = $program_info_path.".stderr.txt";
    }
    my ($volume, $directory, $stderr_file) = File::Spec->splitpath($stderr_path); #Split to enable submission to &sample_info_qc later

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{pgatk_combinevariantcallsets}{file_tag};
    my $file_name_noending = $$family_id_ref.$infile_tag.$call_type;
    my $file_path_no_ending = catfile($$temp_directory_ref, $file_name_noending);

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($infamily_directory, $file_name_noending.".vcf*"),
			  temp_directory => $$temp_directory_ref
			 });
    say $FILEHANDLE "wait", "\n";

    ## Compress or decompress original file or stream to outfile (if supplied)
    bgzip({FILEHANDLE => $FILEHANDLE,
	   infile_path => $file_path_no_ending.".vcf",
	   outfile_path => $file_path_no_ending.".vcf.gz",
	  });
    say $FILEHANDLE "\n";

    ## Index file using tabix
    tabix({FILEHANDLE => $FILEHANDLE,
	   infile_path => $file_path_no_ending.".vcf.gz",
	  });
    say $FILEHANDLE "\n";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "tabix",
							    });

    ## Split vcf into contigs
    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE "-h ";  #Include header
	print $XARGSFILEHANDLE $file_path_no_ending.".vcf.gz"." ";
	print $XARGSFILEHANDLE $contig." ";
	print $XARGSFILEHANDLE "| ";

	## Compress or decompress original file or stream to outfile (if supplied)
	bgzip({FILEHANDLE => $XARGSFILEHANDLE,
	       infile_path => "-",
	       outfile_path => $file_path_no_ending."_".$contig.".vcf.gz",
	      });
	print $XARGSFILEHANDLE "; ";

	## Index file using tabix
	tabix({FILEHANDLE => $XARGSFILEHANDLE,
	       infile_path => $file_path_no_ending."_".$contig.".vcf.gz",
	      });
	print $XARGSFILEHANDLE "\n";
    }

    if ( ! $$reduce_io_ref) { #Run as individual sbatch script

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => $file_path_no_ending."_*.vcf*",
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
	say $FILEHANDLE "wait", "\n";

	close($FILEHANDLE);
    }
    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	if ( ! $$reduce_io_ref) { #Run as individual sbatch script

	    ## Submitt job
	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			dependencies => "case_dependency",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name
		       });
	}
    }
    if ($$reduce_io_ref) {

	return $xargs_file_counter;  #Track the number of created xargs scripts per module for Block algorithm
    }
}


sub gatk_combinevariantcallsets {

##gatk_combinevariantcallsets

##Function : GATK CombineVariants to combine all variants call from different callers.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my @variant_callers;  #Stores callers that have been executed
    my @parallel_chains;  #Stores the parallel chains that jobIds should be inherited from

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => catfile(lc($$outaligner_dir_ref)),
					     call_type => $call_type,
					     process_time => 2,
					     temp_directory => $$temp_directory_ref,
					    });

    ## Assign directories
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $outfile_tag = $file_info_href->{$$family_id_ref}{pgatk_combinevariantcallsets}{file_tag};

    foreach my $variant_caller (@{ $parameter_href->{dynamic_parameter}{variant_callers} }) {

	if ($active_parameter_href->{$variant_caller} > 0) {  #Expect vcf

	    my $program_outdirectory_name = $parameter_href->{$variant_caller}{outdir_name};
	    my $infamily_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, $program_outdirectory_name);
	    my $infile_tag = $file_info_href->{$$family_id_ref}{$variant_caller}{file_tag};

	    unshift(@variant_callers, $program_outdirectory_name);  #To prioritize downstream - 1. gatk 2. samtools determined by order_parameters order

	    unless ($parameter_href->{$variant_caller}{chain} eq "MAIN") {  #Do not add MAIN chains

		push(@parallel_chains, $parameter_href->{$variant_caller}{chain});
	    }

	    ## Copy file(s) to temporary directory
	    say $FILEHANDLE "## Copy file(s) to temporary directory";
	    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
				  path => catfile($infamily_directory, $$family_id_ref.$infile_tag.$call_type.".vcf*"),
				  temp_directory => $$temp_directory_ref
				 });
	}
    }
    say $FILEHANDLE "wait", "\n";

    ## GATK CombineVariants
    say $FILEHANDLE "## GATK CombineVariants";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $$temp_directory_ref,
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T CombineVariants ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
    print $FILEHANDLE "-env ";  #Do not include loci found to be non-variant after the subsetting procedure.

    foreach my $variant_caller (@{ $parameter_href->{dynamic_parameter}{variant_callers} }) {

	if ($active_parameter_href->{$variant_caller} > 0) {  #Expect vcf

	    my $program_outdirectory_name = $parameter_href->{$variant_caller}{outdir_name};
	    my $infile_tag = $file_info_href->{$$family_id_ref}{$variant_caller}{file_tag};
	    print $FILEHANDLE "-V:".$program_outdirectory_name." ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf")." ";  #Family_id infile
	}
    }

    print $FILEHANDLE "-o ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".vcf")." ";  #Union of variant call sets outfile
    print $FILEHANDLE "-genotypeMergeOptions PRIORITIZE ";

    if (defined($active_parameter_href->{gatk_combinevariants_prioritize_caller})) {

	print $FILEHANDLE "-priority ".$active_parameter_href->{gatk_combinevariants_prioritize_caller};
    }
    else {

	print $FILEHANDLE "-priority ".join(",", @variant_callers);
    }
    say $FILEHANDLE "\n";

    if ($active_parameter_href->{gatk_combinevariantcallsets_bcf_file}) {

	vcf_to_bcf({infile => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type),
		    FILEHANDLE => $FILEHANDLE,
		   });

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".bcf*"),
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
    }

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".vcf"),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	$sample_info_href->{vcf_file}{ready_vcf}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.".vcf");

	if ($active_parameter_href->{gatk_combinevariantcallsets_bcf_file}) {

	    $sample_info_href->{bcf_file}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.".bcf");
	}

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "chain_and_parallel_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name,
		    parallel_chains_ref => \@parallel_chains,
		   });
    }
}


sub gatk_variantrecalibration {

##gatk_variantrecalibration

##Function : GATK VariantRecalibrator/ApplyRecalibration.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $core_number = 4;  #gatk VQSR do not benefit from paralellization ref gatk blog, but we need some java heap allocation
    my $program_outdirectory_name = $parameter_href->{"p".$program_name}{outdir_name};
    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$family_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref), lc($program_outdirectory_name)),
								 call_type => $call_type,
								 core_number => $core_number,
								 process_time => 10,
								 temp_directory => catfile($$temp_directory_ref, "gatk", "intermediary"),
								});
    my ($volume, $directory, $stderr_file) = File::Spec->splitpath($program_info_path.".stderr.txt");  #Split to enable submission to &sample_info_qc later

    ## Assign directories
    my $outfamily_file_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref);  #For ".fam" file
    my $infamily_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, $program_outdirectory_name);
    my $intermediary_sample_directory = catfile($$temp_directory_ref, "gatk", "intermediary");
    my $outfamily_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, $program_outdirectory_name);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{pgatk_genotypegvcfs}{file_tag};
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};
    my $infile_no_ending = $$family_id_ref.$infile_tag.$call_type;
    my $intermediary_file_path_noending = catfile($intermediary_sample_directory, $infile_no_ending);
    my $file_path_no_ending = catfile($$temp_directory_ref, $infile_no_ending);
    my $outfile_no_ending = $$family_id_ref.$outfile_tag.$call_type;
    my $outfile_path_no_ending = catfile($$temp_directory_ref, $outfile_no_ending);
 

    ## Create .fam file to be used in variant calling analyses
    create_fam_file({parameter_href => $parameter_href,
		     active_parameter_href => $active_parameter_href,
		     sample_info_href => $sample_info_href,
		     FILEHANDLE => $FILEHANDLE,
		     fam_file_path => catfile($outfamily_file_directory, $$family_id_ref.".fam"),
		    });

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($infamily_directory, $infile_no_ending.".vcf*"),
			  temp_directory => $$temp_directory_ref
			 });
    say $FILEHANDLE "wait", "\n";

    ## GATK VariantRecalibrator
    my @modes = ("SNP","INDEL");

    if ( ($consensus_analysis_type eq "wes") || ($consensus_analysis_type eq "rapid") ) {  #Exome/rapid analysis

	@modes = ("BOTH");
    }

    foreach my $mode (@modes) {  #SNP and INDEL will be recalibrated successively in the same file because when you specify eg SNP mode, the indels are emitted without modification, and vice-versa. Exome and Rapid will be processed using mode BOTH since there are to few INDELS to use in the recalibration model even though using 30 exome BAMS in Haplotypecaller step.

	say $FILEHANDLE "## GATK VariantRecalibrator";

	## Writes java core commands to filehandle.
	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx6g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $$temp_directory_ref,
		   java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
		  });

	print $FILEHANDLE "-T VariantRecalibrator ";  #Type of analysis to run
	print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
	print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	print $FILEHANDLE "-recalFile ".$intermediary_file_path_noending.".intervals"." ";
	print $FILEHANDLE "-rscriptFile ".$intermediary_file_path_noending.".intervals.plots.R"." ";
	print $FILEHANDLE "-tranchesFile ".$intermediary_file_path_noending.".intervals.tranches"." ";

	if ( ($consensus_analysis_type eq "wes") || ($consensus_analysis_type eq "rapid") ) {  #Exome/rapid analysis use combined reference for more power

	    print $FILEHANDLE "-input ".$file_path_no_ending.".vcf"." ";  #Infile HaplotypeCaller combined vcf which used reference gVCFs to create combined vcf (30> samples gCVFs)
	}
	else {  #WGS

	    if ($mode eq "SNP") {

		print $FILEHANDLE "-input ".$file_path_no_ending.".vcf"." ";

		if ($active_parameter_href->{gatk_variantrecalibration_snv_max_gaussians} ne 0) {

		    print $FILEHANDLE "--maxGaussians 4 ";  #Use hard filtering
		}
	    }
	    if ($mode eq "INDEL") {#Use created recalibrated snp vcf as input

		print $FILEHANDLE "-input ".$outfile_path_no_ending.".SNV.vcf"." ";
	    }
	    if ($active_parameter_href->{gatk_variantrecalibration_dp_annotation}) {  #Special case: Not to be used with hybrid capture. NOTE: Disable when analysing wes + wgs in the same run

		print $FILEHANDLE "-an DP ";  #The names of the annotations which should used for calculations.
	    }
	}
	if ( ($mode eq "SNP") || ($mode eq "BOTH") ) {

	    print $FILEHANDLE "-resource:hapmap,VCF,known=false,training=true,truth=true,prior=15.0 ".$active_parameter_href->{gatk_variantrecalibration_training_set_hapmap}." ";  #A list of sites for which to apply a prior probability of being correct but which are not used by the algorithm
	    print $FILEHANDLE "-resource:omni,VCF,known=false,training=true,truth=false,prior=12.0 ".$active_parameter_href->{gatk_variantrecalibration_training_set_1000g_omni}." ";  #A list of sites for which to apply a prior probability of being correct but which are not used by the algorithm
	    print $FILEHANDLE "-resource:1000G,known=false,training=true,truth=false,prior=10.0 ".$active_parameter_href->{gatk_variantrecalibration_training_set_1000gsnp}." ";  #A list of sites for which to apply a prior probability of being correct but which are not used by the algorithm
	    print $FILEHANDLE "-an MQ ";  #The names of the annotations which should used for calculations.
	}
	if ( ($mode eq "INDEL") || ($mode eq "BOTH") ) {

	    print $FILEHANDLE "-resource:mills,VCF,known=true,training=true,truth=true,prior=12.0 ".$active_parameter_href->{gatk_variantrecalibration_training_set_mills}." ";  #A list of sites for which to apply a prior probability of being correct but which are not used by the algorithm

	    if ($active_parameter_href->{gatk_variantrecalibration_indel_max_gaussians} ne 0) {

		print $FILEHANDLE "--maxGaussians 4 ";  #Use hard filtering
	    }
	}
	print $FILEHANDLE "-resource:dbsnp,known=true,training=false,truth=false,prior=2.0 ".$active_parameter_href->{gatk_variantrecalibration_training_set_dbsnp}." ";  #A list of sites for which to apply a prior probability of being correct but which are not used by the algorithm

	print $FILEHANDLE "-an QD ";  #The names of the annotations which should used for calculations
	print $FILEHANDLE "-an MQRankSum ";  #The names of the annotations which should used for calculations
	print $FILEHANDLE "-an ReadPosRankSum ";  #The names of the annotations which should used for calculations
	print $FILEHANDLE "-an FS ";  #The names of the annotations which should used for calculations
	print $FILEHANDLE "-an SOR ";  #The names of the annotations which should used for calculations
	print $FILEHANDLE "--mode ".$mode." ";  #Recalibration mode to employ (SNP|INDEL|BOTH)

	## Check if "--pedigree" and "--pedigreeValidationType" should be included in analysis
	gatk_pedigree_flag({active_parameter_href => $active_parameter_href,
			    FILEHANDLE => $FILEHANDLE,
			    outfamily_file_directory => $outfamily_file_directory,
			    program_name => $program_name,
			   });

	## GATK ApplyRecalibration
	say $FILEHANDLE "\n\n## GATK ApplyRecalibration";

	## Writes java core commands to filehandle.
	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx6g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $$temp_directory_ref,
		   java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
		  });

	print $FILEHANDLE "-T ApplyRecalibration ";
	print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
	print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	print $FILEHANDLE "-recalFile ".$intermediary_file_path_noending.".intervals"." ";
	print $FILEHANDLE "-tranchesFile ".$intermediary_file_path_noending.".intervals.tranches"." ";

	if ( ($consensus_analysis_type eq "wes") || ($consensus_analysis_type eq "rapid")) {  #Exome/rapid analysis use combined reference for more power

	    print $FILEHANDLE "-input ".$file_path_no_ending.".vcf"." ";  #Infile HaplotypeCaller combined vcf which used reference gVCFs to create combined vcf file
	    print $FILEHANDLE "-o ".$outfile_path_no_ending."_filtered.vcf"." ";
	}
	else  {  #WGS

	    if ($mode eq "SNP") {

		print $FILEHANDLE "-input ".$file_path_no_ending.".vcf"." ";
		print $FILEHANDLE "-o ".$outfile_path_no_ending.".SNV.vcf"." ";
		print $FILEHANDLE "--ts_filter_level ".$active_parameter_href->{gatk_variantrecalibration_snv_tsfilter_level}." ";
	    }
	    if ($mode eq "INDEL") {#Use created recalibrated snp vcf as input

		print $FILEHANDLE "-input ".$outfile_path_no_ending.".SNV.vcf"." ";
		print $FILEHANDLE "-o ".$outfile_path_no_ending.".vcf"." ";
		print $FILEHANDLE "--ts_filter_level ".$active_parameter_href->{gatk_variantrecalibration_indel_tsfilter_level}." ";
	    }
	}

	## Check if "--pedigree" and "--pedigreeValidationType" should be included in analysis
	gatk_pedigree_flag({active_parameter_href => $active_parameter_href,
			    FILEHANDLE => $FILEHANDLE,
			    outfamily_file_directory => $outfamily_file_directory,
			    program_name => $program_name,
			   });

	print $FILEHANDLE "--mode ".$mode." ";  #Recalibration mode to employ (SNP|INDEL|BOTH)
	say $FILEHANDLE "\n";
    }

    if ( ($consensus_analysis_type eq "wes") || ($consensus_analysis_type eq "rapid")) {
	## BcfTools norm, Left-align and normalize indels, split multiallelics
	bcftools_norm({FILEHANDLE => $FILEHANDLE,
		       reference_path_ref => \$active_parameter_href->{human_genome_reference},
		       infile_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_filtered.vcf"),
		       outfile_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_filtered_normalized.vcf"),
		       multiallelic => "-",
		       stderr_file_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_filtered_normalized.stderr"),
		      });
	print $FILEHANDLE "\n";
    }

    ## GATK SelectVariants

    ## Removes all genotype information for exome ref and recalulates meta-data info for remaining samples in new file.
    if ( ($consensus_analysis_type eq "wes") || ($consensus_analysis_type eq "rapid") ) {  #Exome/rapid analysis

	say $FILEHANDLE "## GATK SelectVariants";

	## Writes java core commands to filehandle.
	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx2g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $$temp_directory_ref,
		   java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
		  });

	print $FILEHANDLE "-T SelectVariants ";  #Type of analysis to run
	print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
	print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	print $FILEHANDLE "-env ";  #Do not include loci found to be non-variant after the subsetting procedure.
	print $FILEHANDLE "-V: ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_filtered_normalized.vcf")." ";  #InFile

	foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {  #For all sample_ids

	    print $FILEHANDLE "-sn ".$sample_id." ";  #Include genotypes from this sample
	}
	print $FILEHANDLE "-o ".$outfile_path_no_ending.".vcf"." ";  #OutFile
	print $FILEHANDLE " &";

	## Produces another vcf file containing non-variant loci (useful for example in MAF comparisons), but is not used downstream in MIP
	if ($active_parameter_href->{gatk_variantrecalibration_exclude_nonvariants_file} eq 1) {

	    say $FILEHANDLE "\n\n#GATK SelectVariants","\n";

	    ## Writes java core commands to filehandle.
	    java_core({FILEHANDLE => $FILEHANDLE,
		       memory_allocation => "Xmx2g",
		       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		       java_temporary_directory => $$temp_directory_ref,
		       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
		      });

	    print $FILEHANDLE "-T SelectVariants ";  #Type of analysis to run
	    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
	    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	    print $FILEHANDLE "-V: ".$outfile_path_no_ending."_filtered.vcf"." ";  #InFile
	    print $FILEHANDLE "-o ".$outfile_path_no_ending."_incnonvariantloci.vcf"." ";  #OutFile

	    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {  #For all sample_ids

		print $FILEHANDLE "-sn ".$sample_id." ";  #Include genotypes from this sample
	    }
	    say $FILEHANDLE "\n\nwait\n";

	    ## Copies file from temporary directory.
	    say $FILEHANDLE "## Copy file from temporary directory";
	    migrate_file_from_temp({temp_path => $outfile_path_no_ending."_incnonvariantloci.vcf*",
				    file_path => $outfamily_directory,
				    FILEHANDLE => $FILEHANDLE,
				   });
	}
	say $FILEHANDLE "\n\nwait\n";
    }

    ## GenotypeRefinement
    if ($parameter_href->{dynamic_parameter}{trio}) {

	say $FILEHANDLE "## GATK CalculateGenotypePosteriors";

	## Writes java core commands to filehandle.
	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx6g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $$temp_directory_ref,
		   java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
		  });

	print $FILEHANDLE "-T CalculateGenotypePosteriors ";  #Type of analysis to run
	print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
	print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file

	## Check if "--pedigree" and "--pedigreeValidationType" should be included in analysis
	gatk_pedigree_flag({active_parameter_href => $active_parameter_href,
			    FILEHANDLE => $FILEHANDLE,
			    outfamily_file_directory => $outfamily_file_directory,
			    program_name => $program_name,
			   });

	print $FILEHANDLE "--supporting ".$active_parameter_href->{gatk_calculategenotypeposteriors_support_set}." ";  #Supporting data set
	print $FILEHANDLE "-V ".$outfile_path_no_ending.".vcf"." ";  #Infile
	print $FILEHANDLE "-o ".$outfile_path_no_ending."_refined.vcf"." ";  #Outfile
	say $FILEHANDLE "\n";

	## Change name of file to accomodate downstream
	print $FILEHANDLE "mv ";
	print $FILEHANDLE $outfile_path_no_ending."_refined.vcf"." ";
	print $FILEHANDLE $outfile_path_no_ending.".vcf";
	say $FILEHANDLE "\n";
    }

    ## BcfTools norm, Left-align and normalize indels, split multiallelics
    bcftools_norm({FILEHANDLE => $FILEHANDLE,
		   reference_path_ref => \$active_parameter_href->{human_genome_reference},
		   infile_path => $outfile_path_no_ending.".vcf",
		   outfile_path => $outfile_path_no_ending."_normalized.vcf",
		   multiallelic => "-",
		  });

    ## Change name of file to accomodate downstream
    say $FILEHANDLE "\n";
    print $FILEHANDLE "mv ";
    print $FILEHANDLE $outfile_path_no_ending."_normalized.vcf"." ";
    print $FILEHANDLE $outfile_path_no_ending.".vcf";
    say $FILEHANDLE "\n";

    ## Produce a bcf compressed and index from vcf
    if ($active_parameter_href->{gatk_variantrecalibration_bcf_file}) {

	vcf_to_bcf({infile => $outfile_path_no_ending,
		    FILEHANDLE => $FILEHANDLE,
		   });

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => $outfile_path_no_ending.".bcf*",
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
	say $FILEHANDLE "wait", "\n";
    }

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    my @outfiles = ($outfile_path_no_ending.".vcf*", $intermediary_file_path_noending.".intervals.tranches.pdf");
    foreach my $outfile (@outfiles) {

	migrate_file_from_temp({temp_path => $outfile,
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
    }
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "pedigree_check",  #Disabled pedigreeCheck to not include relationship test is qccollect
			outdirectory => $outfamily_directory,
			outfile_ending => $outfile_no_ending.".vcf",
			outdata_type => "infile_dependent"
		       });
	$sample_info_href->{vcf_file}{ready_vcf}{path} = catfile($outfamily_directory, $outfile_no_ending.".vcf");

	if ($active_parameter_href->{gatk_variantrecalibration_bcf_file} eq 1) {

	    $sample_info_href->{bcf_file}{path} = catfile($outfamily_directory, $outfile_no_ending.".bcf");
	}

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub gatk_concatenate_genotypegvcfs {

##gatk_concatenate_genotypegvcfs

##Function : Concatenate GVCFs produced after gatk_genotypegvcfs done per contig.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $core_number = $active_parameter_href->{core_processor_number};

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => catfile(lc($$outaligner_dir_ref), "gatk"),
					     call_type => $call_type,
					     core_number => $core_number,
					     process_time => 10,
					     temp_directory => $$temp_directory_ref
					    });

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, "gatk");
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, "gatk");

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{pgatk_genotypegvcfs}{file_tag};
    my $outfile_tag = $file_info_href->{$$family_id_ref}{pgatk_genotypegvcfs}{file_tag};

    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};
    my $core_counter = 1;
    while ( my ($contig_index, $contig) = each(@{ $file_info_href->{contigs} }) ) {

	print_wait({counter_ref => \$contig_index,
		    core_number_ref => \$core_number,
		    core_counter_ref => \$core_counter,
		    FILEHANDLE => $FILEHANDLE,
		   });

	## Copy file(s) to temporary directory
	migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			      path => catfile($infamily_directory, $$family_id_ref.$infile_tag.$call_type."_".$contig.".vcf*"),
			      temp_directory => $$temp_directory_ref
			     });
    }
    say $FILEHANDLE "wait", "\n";

    ## Writes sbatch code to supplied filehandle to concatenate variants in vcf format. Each array element is combined with the infilePre and Postfix.
    concatenate_variants({active_parameter_href => $active_parameter_href,
			  FILEHANDLE => $FILEHANDLE,
			  elements_ref => \@{ $file_info_href->{contigs} },
			  infile_prefix => catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_"),
			  infile_postfix => ".vcf",
			  outfile => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".vcf"),
			 });

    ## Produce a bcf compressed and index from vcf
    if ($active_parameter_href->{gatk_concatenate_genotypegvcfs_bcf_file}) {

	if ( ($consensus_analysis_type eq "wes") || ($consensus_analysis_type eq "rapid") ) {  #Exome/rapid analysis

	    say $FILEHANDLE "###Remove extra reference samples","\n";

	    say $FILEHANDLE "##GATK SelectVariants","\n";

	    ## Writes java core commands to filehandle.
	    java_core({FILEHANDLE => $FILEHANDLE,
		       memory_allocation => "Xmx2g",
		       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		       java_temporary_directory => $$temp_directory_ref,
		       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
		      });

	    print $FILEHANDLE "-T SelectVariants ";  #Type of analysis to run
	    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
	    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	    print $FILEHANDLE "-V: ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".vcf")." ";  #InFile
	    print $FILEHANDLE "-o ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_incnonvariantloci.vcf")." ";  #OutFile

	    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

		print $FILEHANDLE "-sn ".$sample_id." ";  #Include genotypes from this sample
	    }
	    say $FILEHANDLE "\n";

	    ## Move to original filename
	    print $FILEHANDLE "mv ";
	    print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_incnonvariantloci.vcf")." ";
	    say $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".vcf"), "\n";
	}

	vcf_to_bcf({infile => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type),
		    FILEHANDLE => $FILEHANDLE,
		   });

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".bcf*"),
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
	say $FILEHANDLE "wait", "\n";
    }

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".vcf*"),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	if ($active_parameter_href->{gatk_concatenate_genotypegvcfs_bcf_file} eq 1) {

	    $sample_info_href->{gbcf_file}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.".bcf");
	}

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub gatk_genotypegvcfs {

##gatk_genotypegvcfs

##Function : GATK GenoTypeGVCFs.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $family_id_ref, $outaligner_dir_ref, $call_type, $program_name
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $family_id_ref              => The family_id {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $program_name               => The program name

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $sbatch_script_tracker=0;
    my $core_number = 4;  #gatk genotype is most safely processed in single thread mode, , but we need some java heap allocation
    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};

    my $process_time = 10;

    if ($active_parameter_href->{gatk_genotypegvcfs_all_sites} eq 1) {

	$process_time = 50;  #Including all sites requires longer processing time
    }

    ## Assign directories
    my $outfamily_file_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref);  #For ".fam" file

    ## Create .fam file to be used in variant calling analyses
    create_fam_file({parameter_href => $parameter_href,
		     active_parameter_href => $active_parameter_href,
		     sample_info_href => $sample_info_href,
		     FILEHANDLE => $FILEHANDLE,
		     fam_file_path => catfile($outfamily_file_directory, $$family_id_ref.".fam"),
		    });

    ## Split per contig
    foreach my $contig (@{ $file_info_href->{contigs} }) {

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
						 job_id_href => $job_id_href,
						 FILEHANDLE => $FILEHANDLE,
						 directory_id => $$family_id_ref,
						 program_name => $program_name,
						 program_directory => catfile(lc($$outaligner_dir_ref), "gatk"),
						 call_type => $call_type,
						 core_number => $core_number,
						 process_time => $process_time,
						 temp_directory => $$temp_directory_ref,
						 sleep => 1,  #Let process sleep randomly for 0-60 seconds to avoid race condition
						});

	## Assign directories
	my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, "gatk");
	$parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

	## Assign file_tags
	my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};

	## Collect infiles for all sample_ids to enable migration to temporary directory
	foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	    ## Add merged infile name after merging all BAM files per sample_id
	    my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

	    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, $$outaligner_dir_ref, "gatk");
	    my $infile_tag = $file_info_href->{$sample_id}{pgatk_haplotypecaller}{file_tag};

	    ## Copy file(s) to temporary directory
	    say $FILEHANDLE "## Copy file(s) to temporary directory";
	    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
				  path => catfile($insample_directory, $infile.$infile_tag."_".$contig.".vcf*"),
				  temp_directory => $$temp_directory_ref
				 });
	    say $FILEHANDLE "wait", "\n";
	}

	## GATK GenoTypeGVCFs
	say $FILEHANDLE "## GATK GenoTypeGVCFs";

	## Writes java core commands to filehandle.
	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx24g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $$temp_directory_ref,
		   java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
		  });

	print $FILEHANDLE "-T GenotypeGVCFs ";  #Type of analysis to run
	print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
	print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	print $FILEHANDLE "-D ".$active_parameter_href->{gatk_haplotypecaller_snp_known_set}." ";  #Known SNPs to use for annotation SNPs

	## Check if "--pedigree" and "--pedigreeValidationType" should be included in analysis
	gatk_pedigree_flag({active_parameter_href => $active_parameter_href,
			    FILEHANDLE => $FILEHANDLE,
			    outfamily_file_directory => $outfamily_file_directory,
			    program_name => $program_name,
			   });

	if ($active_parameter_href->{gatk_genotypegvcfs_all_sites} eq 1) {

	    print $FILEHANDLE "-allSites ";  #Include loci found to be non-variant after genotyping
	}

	print $FILEHANDLE "-L ".$contig." ";  #Per contig

	if ( ($consensus_analysis_type eq "wes") || ($consensus_analysis_type eq "rapid") ) {

	    print $FILEHANDLE "-V ".$active_parameter_href->{gatk_genotypegvcfs_ref_gvcf}." ";
	}

	foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	    ## Add merged infile name after merging all BAM files per sample_id
	    my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias
	    my $infile_tag = $file_info_href->{$sample_id}{pgatk_haplotypecaller}{file_tag};

	    print $FILEHANDLE "-V ".catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".vcf")." ";  #InFile
	}
	say $FILEHANDLE "-o ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.".vcf"), "\n";  #OutFile

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.".vcf*"),
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
	say $FILEHANDLE "wait", "\n";

	close($FILEHANDLE);

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    ## Collect QC metadata info for later use
	    $sample_info_href->{vcf_file}{ready_vcf}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.".vcf");

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			dependencies => "sample_id_dependency_step_in_parallel",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name,
			sbatch_script_tracker => $sbatch_script_tracker
		       });
	}
	$sbatch_script_tracker++; #Tracks nr of sbatch scripts
    }
}


sub rcoverageplots {

##rcoverageplots

##Function : Generates sbatch scripts for R scripts: 1. covplots_genome.R 2. covplots_exome.R; on files generated from calculateCoverage genomecoveragebed.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $lane_href, $infile_lane_no_ending_href, $job_id_href, $sample_id, $outaligner_dir, $program_name
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $lane_href                  => The lane info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id                  => The sample_id
##         : $outaligner_dir             => The outaligner_dir used in the analysis
##         : $program_name               => The program name

    my $parameter_href = $_[0];
    my $active_parameter_href = $_[1];
    my $sample_info_href = $_[2];
    my $file_info_href = $_[3];
    my $lane_href = $_[4];
    my $infile_lane_no_ending_href = $_[5];
    my $job_id_href = $_[6];
    my $sample_id = $_[7];
    my $outaligner_dir = $_[8];
    my $program_name = $_[9];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $sample_id,
					     program_name => $program_name,
					     program_directory => catfile(lc($outaligner_dir), "coveragereport"),
					     temp_directory => $active_parameter_href->{temp_directory}
					    });

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, $outaligner_dir, "coveragereport");
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, $outaligner_dir, "coveragereport");

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$sample_id}{pgenomecoveragebed}{file_tag};
    my $outfile_tag = $file_info_href->{$sample_id}{pgatk_baserecalibration}{file_tag};

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

    if ( defined($active_parameter_href->{pgenomecoveragebed}) && ($active_parameter_href->{pgenomecoveragebed} > 0) ) {

	print $FILEHANDLE "Rscript ";
	print $FILEHANDLE catfile($active_parameter_href->{script_dir}, "covplots_genome.R")."  ";
	print $FILEHANDLE catfile($insample_directory, $infile.$infile_tag)." ";  #InFile
	print $FILEHANDLE $infile." ";  #Sample name
	print $FILEHANDLE $active_parameter_href->{genomecoveragebed_max_coverage}." ";  #X-axis max scale
	say $FILEHANDLE $outsample_directory, " &", "\n";  #OutFile
    }
    say $FILEHANDLE "wait", "\n";
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $sample_id,
		    dependencies => "case_dependency_dead_end",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
    return;
}


sub genomecoveragebed {

##genomecoveragebed

##Function : Calculates coverage on BAM files.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, family_id_ref, $temp_directory_ref, $outaligner_dir_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id_ref
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}


    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $file_name;

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref, "coveragereport");

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{pgatk_baserecalibration}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    my $core_number=1;

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					  job_id_href => $job_id_href,
					  FILEHANDLE => $FILEHANDLE,
					  directory_id => $$sample_id_ref,
					  program_name => $program_name,
					  program_directory => catfile(lc($$outaligner_dir_ref), "coveragereport"),
					  core_number => $core_number,
					  process_time => 16,
					  temp_directory => $$temp_directory_ref,
					 });

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($insample_directory, $infile.$infile_tag.".b*"),
			  temp_directory => $$temp_directory_ref,
			 });
    say $FILEHANDLE "wait", "\n";

    ## GenomeCoverageBed
    say $FILEHANDLE "## Calculate coverage metrics on alignment";
    print $FILEHANDLE "genomeCoverageBed ";
    print $FILEHANDLE "-max ".$active_parameter_href->{genomecoveragebed_max_coverage}." ";  #Combine all positions with a depth >= max into a single bin in the histogram.
    print $FILEHANDLE "-ibam ".catfile($$temp_directory_ref, $infile.$infile_tag.".bam")." ";  #InFile
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $infile.$outfile_tag)." ", "\n";  #OutFile

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $infile.$outfile_tag),
			    file_path => $outsample_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
    return;
}


sub picardtools_calculatehsmetrics {

##picardtools_calculatehsmetrics

##Function : Calculates coverage on exonic part of BAM files.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, family_id_ref, $temp_directory_ref, $outaligner_dir_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $file_name;

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref, "coveragereport");

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{pgatk_baserecalibration}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    ## Alias exome_target_bed endings
    my $infile_list_ending_ref = \$file_info_href->{exome_target_bed}[0];
    my $padded_infile_list_ending_ref = \$file_info_href->{exome_target_bed}[1];
    my $padded_interval_list_ending_ref = \$file_info_href->{exome_target_bed}[2];

    my $core_number=2;

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					  job_id_href => $job_id_href,
					  FILEHANDLE => $FILEHANDLE,
					  directory_id => $$sample_id_ref,
					  program_name => $program_name,
					  program_directory => catfile(lc($$outaligner_dir_ref), "coveragereport"),
					  core_number => $core_number,
					  process_time => 16,
					  temp_directory => $$temp_directory_ref,
					 });

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($insample_directory, $infile.$infile_tag.".b*"),
			  temp_directory => $$temp_directory_ref,
			 });
    say $FILEHANDLE "wait", "\n";

    ## CalculateHsMetrics
    say $FILEHANDLE "## Calculate capture metrics on alignment";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx4g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $$temp_directory_ref,
	       java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
	      });

    print $FILEHANDLE "CalculateHsMetrics ";
    print $FILEHANDLE "INPUT=".catfile($$temp_directory_ref, $infile.$infile_tag.".bam")." ";  #InFile
    print $FILEHANDLE "OUTPUT=".catfile($$temp_directory_ref, $infile.$outfile_tag)." ";  #OutFile
    print $FILEHANDLE "REFERENCE_SEQUENCE=".$active_parameter_href->{human_genome_reference}." ";  #Reference file

    ## Get exome_target_bed file for specfic sample_id and add file_ending from file_infoHash if supplied
    my $exome_target_bed_file = get_exom_target_bed_file({active_parameter_href => $active_parameter_href,
							  sample_id_ref => $sample_id_ref,
							 });


    print $FILEHANDLE "BAIT_INTERVALS=".$exome_target_bed_file.$$padded_infile_list_ending_ref." ";  #Capture kit padded target infile_list file
    say $FILEHANDLE "TARGET_INTERVALS=".$exome_target_bed_file.$$infile_list_ending_ref, "\n";  #Capture kit target infile_list file

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $infile.$outfile_tag),
			    file_path => $outsample_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			sample_id => $$sample_id_ref,
			program_name => "calculatehsmetrics",
			infile => $infile,
			outdirectory => $outsample_directory,
			outfile_ending => $outfile_tag,
			outdata_type => "infile_dependent"
		       });
    }
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub picardtools_collectmultiplemetrics {

##picardtools_collectmultiplemetrics

##Function : Calculates coverage and alignment metrics on BAM files.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, family_id_ref, $temp_directory_ref, $outaligner_dir_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $file_name;

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref, "coveragereport");

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{pgatk_baserecalibration}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{pgatk_baserecalibration}{file_tag};

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    my $core_number = 1;

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					  job_id_href => $job_id_href,
					  FILEHANDLE => $FILEHANDLE,
					  directory_id => $$sample_id_ref,
					  program_name => $program_name,
					  program_directory => catfile(lc($$outaligner_dir_ref), "coveragereport"),
					  core_number => $core_number,
					  process_time => 16,
					  temp_directory => $$temp_directory_ref,
					 });

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($insample_directory, $infile.$infile_tag.".b*"),
			  temp_directory => $$temp_directory_ref,
			 });
    say $FILEHANDLE "wait", "\n";

    ## CollectMultipleMetrics
    say $FILEHANDLE "## Collecting multiple metrics on alignment";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx4g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $$temp_directory_ref,
	       java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
	      });

    print $FILEHANDLE "CollectMultipleMetrics ";
    print $FILEHANDLE "INPUT=".catfile($$temp_directory_ref, $infile.$infile_tag.".bam")." ";  #InFile
    print $FILEHANDLE "OUTPUT=".catfile($$temp_directory_ref, $infile.$outfile_tag)." ";  #OutFile
    say $FILEHANDLE "R=".$active_parameter_href->{human_genome_reference}, "\n";  #Reference file

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    my @outfiles = ($infile.$outfile_tag.".alignment_summary_metrics",
		    $infile.$outfile_tag.".quality*",
		    $infile.$outfile_tag.".insert*",
	);
    foreach my $outfile (@outfiles) {

	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $outfile),
				file_path => $outsample_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
    }
    say $FILEHANDLE "wait", "\n";

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			sample_id => $$sample_id_ref,
			program_name => "collectmultiplemetrics",
			infile => $infile,
			outdirectory => $outsample_directory,
			outfile_ending => $outfile_tag.".alignment_summary_metrics",
			outdata_type => "infile_dependent"
		       });
	sample_info_qc({sample_info_href => $sample_info_href,
			sample_id => $$sample_id_ref,
			program_name => "collectmultiplemetricsinsertsize",
			infile => $infile,
			outdirectory => $outsample_directory,
			outfile_ending => $outfile_tag.".insert_size_metrics",
			outdata_type => "infile_dependent"
		       });
    }
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub chanjo_sexcheck {

##chanjo_sexcheck

##Function : Predict gender from BAM files.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, family_id_ref, $temp_directory_ref, $outaligner_dir_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $file_name;

    ## Assign directories
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref);
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref, "coveragereport");

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{pgatk_baserecalibration}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					  job_id_href => $job_id_href,
					  FILEHANDLE => $FILEHANDLE,
					  directory_id => $$sample_id_ref,
					  program_name => $program_name,
					  program_directory => catfile(lc($$outaligner_dir_ref), "coveragereport"),
					  process_time => 2,
					 });

    ## chanjo_sexcheck
    say $FILEHANDLE "## Predicting sex from alignment";
    print $FILEHANDLE "chanjo ";  #Program
    print $FILEHANDLE "--log-level DEBUG ";
    print $FILEHANDLE "--log-file ".catfile($outsample_directory, $infile.$infile_tag."_chanjo_sexcheck.log")." ";
    print $FILEHANDLE "sex ";  #Sub command

    ## Set chromosome prefix if required
    if (any {$_ eq "chrX"} @{ $file_info_href->{contigs_size_ordered} }) {  #If element is part of array

	print $FILEHANDLE "--prefix chr ";
    }
    print $FILEHANDLE catfile($insample_directory, $infile.$infile_tag.".bam")." ";  #InFile
    say $FILEHANDLE "> ".catfile($outsample_directory, $infile.$outfile_tag), "\n";  #OutFile

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			sample_id => $$sample_id_ref,
			program_name => "chanjo_sexcheck",
			infile => $infile,
			outdirectory => $outsample_directory,
			outfile_ending => $outfile_tag,
			outdata_type => "infile_dependent"
		       });
	sample_info_qc({sample_info_href => $sample_info_href,
			sample_id => $$sample_id_ref,
			program_name => "chanjo",
			infile => $infile,
			outdirectory => $outsample_directory,
			outfile_ending => $infile_tag."_chanjo_sexcheck.log",
			outdata_type => "infile_dependent"
		       });
    }
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub sambamba_depth {

##sambamba_depth

##Function : Generate coverage bed outfile for each individual.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, family_id_ref, $temp_directory_ref, $outaligner_dir_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $file_name;
    my $core_number = 2;

    ## Assign directories
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref);
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref, "coveragereport");

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{pgatk_baserecalibration}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					  job_id_href => $job_id_href,
					  FILEHANDLE => $FILEHANDLE,
					  directory_id => $$sample_id_ref,
					  program_name => $program_name,
					  program_directory => catfile(lc($$outaligner_dir_ref), "coveragereport"),
					  core_number => $core_number,
					  process_time => 10,
					  temp_directory => $$temp_directory_ref,
					 });

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($insample_directory, $infile.$infile_tag.".b*"),
			  temp_directory => $$temp_directory_ref
			 });
    say $FILEHANDLE "wait", "\n";

    ## sambamba_depth
    say $FILEHANDLE "## Annotating bed from alignment";
    print $FILEHANDLE "sambamba ";  #Program
    print $FILEHANDLE "depth ";  #Sub command
    print $FILEHANDLE "region "; #Mode
    print $FILEHANDLE "--regions ".$active_parameter_href->{sambamba_depth_bed}." ";  #Region to calculate coverage on
    print $FILEHANDLE "--fix-mate-overlaps ";
    print $FILEHANDLE "--min-base-quality ".$active_parameter_href->{sambamba_depth_base_quality}." ";  #The minimum base quality to include in analysis
    print $FILEHANDLE q?--filter '?;
    print $FILEHANDLE "mapping_quality >= ".$active_parameter_href->{sambamba_depth_mapping_quality}." ";  #The minimum mapping quality to include in analysis

    if ($active_parameter_href->{sambamba_depth_noduplicates}) {  #Do not include duplicates in coverage calculation

	print $FILEHANDLE "and not duplicate ";
    }
    if ($active_parameter_href->{sambamba_depth_quality_control}) {  #Do not include failed quality control reads in coverage calculation

	print $FILEHANDLE "and not failed_quality_control";
    }

    print $FILEHANDLE q?' ?;

    foreach my $cutoff (@{ $active_parameter_href->{sambamba_depth_cutoffs} }) {

	print $FILEHANDLE "--cov-threshold ".$cutoff." ";  #The cutoff is used for the completeness calculation
    }

    print $FILEHANDLE catfile($$temp_directory_ref, $infile.$infile_tag.".bam")." ";  #InFile
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $infile.$outfile_tag.".bed"). "\n";  #OutFile

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $infile.$outfile_tag.".bed"),
			    file_path => $outsample_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	$sample_info_href->{sample}{$$sample_id_ref}{program}{$program_name}{$infile}{bed}{path} = catfile($outsample_directory, $infile.$outfile_tag.".bed");
    }

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency_add_to_case",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub sv_rankvariant {

##sv_rankvariant

##Function : Annotate and score SV variants depending on mendelian inheritance, frequency and phenotype etc.
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $program_info_path, $file_name, $FILEHANDLE, family_id_ref, $temp_directory_ref, $reference_dir_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $family_id_ref              => The family_id_ref {REF}
##         : $call_type                  => The variant call type
##         : $program_name               => The program name
##         : $file_name                  => File name
##         : $FILEHANDLE                 => Sbatch filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $reference_dir_ref          => MIP reference directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $reference_dir_ref = $arg_href->{reference_dir_ref} //= \$arg_href->{active_parameter_href}{reference_dir};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	reference_dir_ref => { default => \$$, strict_type => 1, store => \$reference_dir_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "SV", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $xargs_file_name;
    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};
    my $time = 20;

    ## Set the number of cores
    my $core_number = $active_parameter_href->{core_processor_number};
    my $genmod_core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
						     core_number => 16
						    });

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$family_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref)),
								 core_number => $core_number,
								 process_time => 10,
								 temp_directory => $$temp_directory_ref
								});

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_file_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref);

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{psv_vcfparser}{file_tag};
    my $infile_ending_stub = $$family_id_ref.$infile_tag.$call_type;
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};
    my $outfile_ending_stub = $$family_id_ref.$outfile_tag.$call_type;

    my $vcfparser_analysis_type = "";
    my @contigs_size_ordered = @{ $file_info_href->{contigs_size_ordered} };  #Set default
    my @contigs = @{ $file_info_href->{contigs} };  #Set default for handling subset of contigs

    ### If no males or other remove contig Y from all downstream analysis
    my @contig_arrays = (\@contigs_size_ordered, \@contigs);
    
    foreach my $array_ref (@contig_arrays) {
	
	## Removes contig_names from contigs array if no male or other found
	remove_contigs({active_parameter_href => $active_parameter_href,
			contigs_ref => $array_ref,
			contig_names_ref => ["Y"],
		       });
    }

    my $family_file = catfile($outfamily_file_directory, $$family_id_ref.".fam");

    ## Create .fam file to be used in variant calling analyses
    create_fam_file({parameter_href => $parameter_href,
		     active_parameter_href => $active_parameter_href,
		     sample_info_href => $sample_info_href,
		     FILEHANDLE => $FILEHANDLE,
		     fam_file_path => $family_file,
		    });

    for (my $vcfparser_outfile_counter=0;$vcfparser_outfile_counter<$active_parameter_href->{vcfparser_outfile_count};$vcfparser_outfile_counter++) {

	if ($vcfparser_outfile_counter == 1) {

	    $vcfparser_analysis_type = ".selected";  #SelectFile variants
	    @contigs_size_ordered = @{ $file_info_href->{sorted_select_file_contigs} };  #Selectfile contigs
	    @contigs = @{ $file_info_href->{select_file_contigs} };
	}

	if ( ($consensus_analysis_type eq "wgs") || ($consensus_analysis_type eq "mixed") ) {  #Transfer contig files

	    ## Copy file(s) to temporary directory
	    say $FILEHANDLE "## Copy file(s) to temporary directory";
	    $xargs_file_counter = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
							      XARGSFILEHANDLE => $XARGSFILEHANDLE,
							      contigs_ref => \@contigs_size_ordered,
							      file_name => $file_name,
							      program_info_path => $program_info_path,
							      core_number => $core_number,
							      xargs_file_counter => $xargs_file_counter,
							      infile => $$family_id_ref.$infile_tag.$call_type,
							      file_ending => $vcfparser_analysis_type.".vcf*",
							      indirectory => $infamily_directory,
							      temp_directory => $active_parameter_href->{temp_directory},
							     });
	}
	else {

	    ## Copy file(s) to temporary directory
	    say $FILEHANDLE "## Copy file(s) to temporary directory";
	    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
				  path => catfile($infamily_directory, $$family_id_ref.$infile_tag.$call_type.$vcfparser_analysis_type.".vcf"),
				  temp_directory => $$temp_directory_ref
				 });
	    say $FILEHANDLE "wait", "\n";

	    ## Clear trap for signal(s)
	    clear_trap({FILEHANDLE => $FILEHANDLE,
		       });
	}

	my $genmod_module = "";  #Track which genmod modules has been processed

	## Check affected/unaffected status
	if ( (defined($parameter_href->{dynamic_parameter}{unaffected})) && (@{ $parameter_href->{dynamic_parameter}{unaffected} } eq @{ $active_parameter_href->{sample_ids} }) ) {  #Only unaffected

	    if (! $vcfparser_outfile_counter) {

		$log->warn("Only unaffected sample(s) in pedigree - skipping genmod 'models', 'score' and 'compound'");
	    }
	}

	## Genmod
	say $FILEHANDLE "## Genmod";
	
	## Create file commands for xargs
	($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
								 XARGSFILEHANDLE => $XARGSFILEHANDLE,
								 file_name => $file_name,
								 program_info_path => $program_info_path,
								 core_number => $genmod_core_number,
								 xargs_file_counter => $xargs_file_counter,
								 first_command => "genmod",
								});
	
	## Process per contig
	foreach my $contig (@contigs_size_ordered) {

	    my $genmod_file_ending_stub = $infile_ending_stub;
	    my $genmod_xargs_file_name = $xargs_file_name;
	    my $genmod_indata = catfile($$temp_directory_ref, $genmod_file_ending_stub.$vcfparser_analysis_type.".vcf")." ";  #InFile
	    
	    if ( ($consensus_analysis_type eq "wgs") || ($consensus_analysis_type eq "mixed") ) {  #Update endings with contig info
		
		$genmod_file_ending_stub = $infile_ending_stub."_".$contig;
		$genmod_xargs_file_name = $xargs_file_name.".".$contig;
		$genmod_indata = catfile($$temp_directory_ref, $genmod_file_ending_stub.$vcfparser_analysis_type.".vcf")." ";  #InFile
	    }
	    $genmod_module = "";  #Restart for next contig
	    
	    ## Genmod Annotate
	    $genmod_module = "_annotate";
	    
	    print $XARGSFILEHANDLE "-v ";  #Increase output verbosity
	    print $XARGSFILEHANDLE "annotate ";  #Annotate vcf variants
	    print $XARGSFILEHANDLE "--temp_dir ".$$temp_directory_ref." ";  #Temporary directory
	    
	    if ($active_parameter_href->{sv_genmod_annotate_regions}) {
		
		print $XARGSFILEHANDLE "--regions ";  #Use predefined annotation file distributed with genmod
		}
	    if ( (defined($parameter_href->{dynamic_parameter}{unaffected})) && (@{ $parameter_href->{dynamic_parameter}{unaffected} } eq @{ $active_parameter_href->{sample_ids} }) ) {  #Only unaffected
		
		## Write to outputFile - last genmod module
		print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $genmod_file_ending_stub.$vcfparser_analysis_type.$genmod_module.".vcf")." ";  #OutFile
		print $XARGSFILEHANDLE "2> ".$genmod_xargs_file_name.$genmod_module.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		say $XARGSFILEHANDLE $genmod_indata;  #Infile
	    }
	    else {

		## Write to outputstream
		print $XARGSFILEHANDLE "-o ".catfile(dirname(devnull()), "stdout")." ";  #OutFile
		print $XARGSFILEHANDLE "2> ".$genmod_xargs_file_name.$genmod_module.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		print $XARGSFILEHANDLE $genmod_indata;  #InStream or Infile
		print $XARGSFILEHANDLE "| ";  #Pipe
		    
		$genmod_indata = "- ";  #Preparation for next module
		
		## Genmod Models
		$genmod_module .= "_models";
		print $XARGSFILEHANDLE "genmod ";
		print $XARGSFILEHANDLE "-v ";  #Increase output verbosity
		print $XARGSFILEHANDLE "models ";  #Annotate genetic models for vcf variants
		print $XARGSFILEHANDLE "--temp_dir ".$$temp_directory_ref." ";  #Temporary directory
		print $XARGSFILEHANDLE "--family_file ".$family_file." ";  #Pedigree file
		print $XARGSFILEHANDLE "--family_type ".$active_parameter_href->{sv_genmod_models_family_type}." ";  #Family type
		
		if (defined($active_parameter_href->{sv_genmod_models_reduced_penetrance_file})) {
			
		    print $XARGSFILEHANDLE "--reduced_penetrance ".$active_parameter_href->{sv_genmod_models_reduced_penetrance_file}." ";  #Use list of genes that have been shown to display reduced penetrance
		}
		print $XARGSFILEHANDLE "--processes 4 ";  #Define how many processes that should be use for annotation
		
		if ( ($active_parameter_href->{psv_varianteffectpredictor} > 0)
		    && (! $active_parameter_href->{sv_genmod_annotate_regions}) ) {  #Use VEP annotations in compound models
			
			print $XARGSFILEHANDLE "--vep ";
		}
		if ($active_parameter_href->{sv_genmod_models_whole_gene}) {
		    
		    print $XARGSFILEHANDLE "--whole_gene ";
		}
		
		print $XARGSFILEHANDLE "-o ".catfile(dirname(devnull()), "stdout")." ";  #OutFile
		print $XARGSFILEHANDLE $genmod_indata;  #InFile
		print $XARGSFILEHANDLE "2> ".$genmod_xargs_file_name.$genmod_module.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		print $XARGSFILEHANDLE "| ";  #Pipe
		$genmod_indata = "- ";  #Preparation for next module
		    
		## Genmod Score
		$genmod_module .= "_score";
		    
		print $XARGSFILEHANDLE "genmod ";
		print $XARGSFILEHANDLE "-v ";  #Increase output verbosity
		print $XARGSFILEHANDLE "score ";  #Score variants in a vcf file using Weighted sums
		print $XARGSFILEHANDLE "--family_file ".$family_file." ";  #Pedigree file
		print $XARGSFILEHANDLE "--family_type ".$active_parameter_href->{sv_genmod_models_family_type}." ";  #Family type
		print $XARGSFILEHANDLE "--rank_results ";  #Add a info field that shows how the different categories contribute to the rank score
		    
		if (defined($active_parameter_href->{rank_model_file})) {

		    print $XARGSFILEHANDLE "--score_config ".$active_parameter_href->{sv_rank_model_file}." ";  #Rank model config.ini file
		}

		## Write to outputstream
		print $XARGSFILEHANDLE "-o ".catfile(dirname(devnull()), "stdout")." ";  #OutFile
		print $XARGSFILEHANDLE "2> ".$genmod_xargs_file_name.$genmod_module.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		print $XARGSFILEHANDLE $genmod_indata;  #InStream or Infile
		print $XARGSFILEHANDLE "| ";  #Pipe

		##Genmod Compound
		$genmod_module .= "_compound";
		
		print $XARGSFILEHANDLE "genmod ";
		print $XARGSFILEHANDLE "-v ";  #Increase output verbosity
		print $XARGSFILEHANDLE "compound ";  #Adjust score for compound variants in a vcf file
		print $XARGSFILEHANDLE "--temp_dir ".$$temp_directory_ref." ";  #Temporary directory
		
		if ( ($active_parameter_href->{psv_varianteffectpredictor} > 0)
		     && (! $active_parameter_href->{sv_genmod_annotate_regions}) ) {  #Use VEP annotations in compound models
		    
		    print $XARGSFILEHANDLE "--vep ";
		}

		print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $genmod_file_ending_stub.$vcfparser_analysis_type.$genmod_module.".vcf")." ";  #OutFile
		print $XARGSFILEHANDLE "2> ".$genmod_xargs_file_name.$genmod_module.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		
		say $XARGSFILEHANDLE $genmod_indata;  #InStream or Infile
	    }

	    if ( ($consensus_analysis_type eq "wes") || ($consensus_analysis_type eq "rapid") ) {  #Update endings with contig info
		
		last;  #Only perform once for exome samples to avoid risking contigs lacking variants throwing errors
	    }
	}

	my $concatenate_ending = "";
	if ( ($consensus_analysis_type eq "wgs") || ($consensus_analysis_type eq "mixed") ) {
	    
	    $concatenate_ending = "_cat";
	    
	    ## Writes sbatch code to supplied filehandle to concatenate variants in vcf format. Each array element is combined with the infilePre and Postfix.
	    concatenate_variants({active_parameter_href => $active_parameter_href,
				  FILEHANDLE => $FILEHANDLE,
				  elements_ref => \@contigs,
				  infile_prefix => catfile($$temp_directory_ref, $infile_ending_stub."_"),
				  infile_postfix => $vcfparser_analysis_type.$genmod_module.".vcf",
				  outfile => catfile($$temp_directory_ref, $infile_ending_stub.$vcfparser_analysis_type.$concatenate_ending.".vcf"),
				 });
	}
	else {

	    $concatenate_ending = $genmod_module;
	}

	## Writes sbatch code to supplied filehandle to sort variants in vcf format
	sort_vcf({active_parameter_href => $active_parameter_href,
		  FILEHANDLE => $FILEHANDLE,
		  sequence_dict_file => catfile($$reference_dir_ref, $file_info_href->{human_genome_reference_name_no_ending}.".dict"),
		  infile => catfile($$temp_directory_ref, $infile_ending_stub.$vcfparser_analysis_type.$concatenate_ending.".vcf"),
		  outfile => catfile($$temp_directory_ref, $outfile_ending_stub.$vcfparser_analysis_type.".vcf"),
		 });

	print $FILEHANDLE "\n";

	if ($consensus_analysis_type eq "wes") {

	    ## Enable trap for signal(s) and function
	    enable_trap({FILEHANDLE => $FILEHANDLE,
			});
	}

	if ($active_parameter_href->{sv_rankvariant_binary_file}) {

	    ## Compress or decompress original file or stream to outfile (if supplied)
	    bgzip({FILEHANDLE => $FILEHANDLE,
		   infile_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf"),
		   outfile_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf.gz"),
		  });
	    say $FILEHANDLE "\n";

	    ## Index file using tabix
	    tabix({FILEHANDLE => $FILEHANDLE,
		   infile_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf.gz"),
		  });
	    say $FILEHANDLE "\n";
	}

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf*"),
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
	say $FILEHANDLE "wait", "\n";


	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    if ($vcfparser_outfile_counter == 1) {

		$sample_info_href->{sv_vcf_file}{clinical}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf");
		$sample_info_href->{program}{sv_rankvariant}{clinical}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf");   #Save clinical candidate list path

		if ($active_parameter_href->{sv_rankvariant_binary_file}) {

		    $sample_info_href->{sv_vcf_binary_file}{clinical}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf.gz");
		}
	    }
	    else {

		$sample_info_href->{sv_vcf_file}{research}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf");
		$sample_info_href->{program}{sv_rankvariant}{research}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf");   #Save research candidate list path

		if ($active_parameter_href->{sv_rankvariant_binary_file}) {

		    $sample_info_href->{sv_vcf_binary_file}{research}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf.gz");
		}
	    }
	}
    }
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	if (defined($active_parameter_href->{sv_rank_model_file})) {  #Add to SampleInfo

	    if ($active_parameter_href->{sv_rank_model_file}=~/v(\d+\.\d+.\d+|\d+\.\d+)/) {

		$sample_info_href->{program}{sv_rankvariant}{rank_model}{version} = $1;
	    }
	    $sample_info_href->{program}{sv_rankvariant}{rank_model}{file} = basename($active_parameter_href->{sv_rank_model_file});
	    $sample_info_href->{program}{sv_rankvariant}{rank_model}{path} = $active_parameter_href->{sv_rank_model_file};

	}
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "sv_genmod",
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.$outfile_tag.$call_type.$vcfparser_analysis_type.".vcf",
			outdata_type => "static"
		       });
	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub sv_vcfparser {

##sv_vcfparser

##Function : sv_vcfparser performs parsing of varianteffectpredictor annotated variants
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $file_name, $program_info_path, $FILEHANDLE, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $FILEHANDLE                 => Sbatch filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "SV", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $time = 20;
    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $xargs_file_name;
    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$family_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref)),
								 call_type => $call_type,
								 temp_directory => $$temp_directory_ref,
								});

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{psv_varianteffectpredictor}{file_tag};
    my $infile_ending_stub = $$family_id_ref.$infile_tag.$call_type;
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};
    my $outfile_ending_stub = $$family_id_ref.$outfile_tag.$call_type;

    my @contigs = @{ $file_info_href->{contigs_size_ordered} };  #Set default

    ### If no males or other remove contig Y from all downstream analysis
    ## Removes contig_names from contigs array if no male or other found
    remove_contigs({active_parameter_href => $active_parameter_href,
		    contigs_ref => \@contigs,
		    contig_names_ref => ["Y"],
		   });

    if ( ($consensus_analysis_type eq "wgs") || ($consensus_analysis_type eq "mixed") ) {  #Transfer contig files

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@contigs,
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      infile => $infile_ending_stub,
									      indirectory => $infamily_directory,
									      temp_directory => $$temp_directory_ref,
									     });
    }
    else {

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			      path => catfile($infamily_directory, $$family_id_ref.$infile_tag.$call_type.".vcf"),
			      temp_directory => $$temp_directory_ref
			     });
	say $FILEHANDLE "wait", "\n";
    }

    ## vcfparser
    say $FILEHANDLE "## vcfparser";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "perl",
							    });

    foreach my $contig (@contigs) {

	my $vcfparser_infile_ending_stub = $infile_ending_stub;
	my $vcfparser_outfile_ending_stub = $outfile_ending_stub;
	my $vcfparser_xargs_file_name = $xargs_file_name;

	if ( ($consensus_analysis_type eq "wgs") || ($consensus_analysis_type eq "mixed") ) {  #Update endings with contig info

	    $vcfparser_infile_ending_stub = $infile_ending_stub."_".$contig;
	    $vcfparser_outfile_ending_stub = $outfile_ending_stub."_".$contig;
	    $vcfparser_xargs_file_name = $xargs_file_name.".".$contig;
	}
	print $XARGSFILEHANDLE catfile($active_parameter_href->{script_dir}, "vcfparser.pl")." ";  #Parses the VEP output to tab-sep format
	print $XARGSFILEHANDLE catfile($$temp_directory_ref, $vcfparser_infile_ending_stub.".vcf")." ";  #Infile

	if ($active_parameter_href->{psv_varianteffectpredictor} > 0) {

	    print $XARGSFILEHANDLE "--parse_vep ".$active_parameter_href->{sv_vcfparser_vep_transcripts}." ";  #Parse VEP transcript specific entries
	}
	if ($active_parameter_href->{sv_vcfparser_per_gene}) {
	    
	    print $XARGSFILEHANDLE "--per_gene ".$active_parameter_href->{sv_vcfparser_per_gene}." ";  #Keep only most severe consequence per gene
	}
	if ($contig =~ /MT|M/) {

	    print $XARGSFILEHANDLE "--padding 10 ";  #Special case for mitochondrial contig annotation
	}
	if ($active_parameter_href->{sv_vcfparser_range_feature_file}) {

	    print $XARGSFILEHANDLE "-rf ".$active_parameter_href->{sv_vcfparser_range_feature_file}." ";  #List of genes to analyse separately

	    if ( ($active_parameter_href->{sv_vcfparser_range_feature_annotation_columns})
		  && (@{ $active_parameter_href->{sv_vcfparser_range_feature_annotation_columns} }) ) {

		print $XARGSFILEHANDLE "-rf_ac ";  #Range annotation columns
		print $XARGSFILEHANDLE join(',', @{ $active_parameter_href->{sv_vcfparser_range_feature_annotation_columns} })." ";
	    }
	}
	if ($active_parameter_href->{sv_vcfparser_select_file}) {

	    if (! check_entry_hash_of_array({hash_ref => $file_info_href,
					     key => "select_file_contigs",
					     element => $contig,
					    })
		) {

		print $XARGSFILEHANDLE "-sf ".catfile($active_parameter_href->{sv_vcfparser_select_file})." ";  #List of genes to analyse separately
		print $XARGSFILEHANDLE "-sf_mc ".$active_parameter_href->{sv_vcfparser_select_file_matching_column}." ";  #Column of HGNC Symbol in SelectFile (-sf)

		if ( ($active_parameter_href->{sv_vcfparser_select_feature_annotation_columns})
		     && (@{ $active_parameter_href->{sv_vcfparser_select_feature_annotation_columns} })) {

		    print $XARGSFILEHANDLE "-sf_ac ";  #Select annotation columns
		    print $XARGSFILEHANDLE join(',', @{ $active_parameter_href->{sv_vcfparser_select_feature_annotation_columns} })." ";
		}
		print $XARGSFILEHANDLE "-sof ".catfile($$temp_directory_ref, $vcfparser_outfile_ending_stub.".selected.vcf")." ";
	    }
	}
	print $XARGSFILEHANDLE "> ".catfile($$temp_directory_ref, $vcfparser_outfile_ending_stub.".vcf")." ";  #outfile
	say $XARGSFILEHANDLE "2> ".$vcfparser_xargs_file_name.".stderr.txt ";  #Redirect xargs output to program specific stderr file

	if ( ($consensus_analysis_type eq "wes") || ($consensus_analysis_type eq "rapid") ) {  #Update endings with contig info

	    last;  #Only perform once for exome samples to avoid risking contigs lacking variants throwing errors
	}
    }

    my $outfile_ending = $outfile_ending_stub;

    if ( ($consensus_analysis_type eq "wgs") || ($consensus_analysis_type eq "mixed") ) {  #Update endings with contig info

	$outfile_ending .= "_".$contigs[0];

	## QC Data File(s)
	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $outfile_ending.".vcf"),
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
	say $FILEHANDLE "wait", "\n";
    }

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Clear old vcfparser entry if present
	if (defined($sample_info_href->{$program_name})) {

	    delete($sample_info_href->{$program_name});
	}
	if ($active_parameter_href->{sv_vcfparser_range_feature_file}) {

	    ## Collect databases(s) from a potentially merged select_file and adds them to sample_info
	    collect_gene_panels({sample_info_href => $sample_info_href,
				 family_id_ref => $family_id_ref,
				 program_name_ref => \$program_name,
				 aggregate_gene_panel_file => $active_parameter_href->{sv_vcfparser_range_feature_file},
				 aggregate_gene_panels_key => "range_file",
				});

	    if ($active_parameter_href->{sv_vcfparser_range_feature_file}=~/v(\d+\.\d+.\d+|\d+\.\d+)/) {

		$sample_info_href->{$program_name}{range_file}{version} = $1;
	    }
	    $sample_info_href->{$program_name}{range_file}{path} = $active_parameter_href->{sv_vcfparser_range_feature_file};
	}
	if ($active_parameter_href->{sv_vcfparser_select_file}) {

	    ## Collect databases(s) from a potentially merged select_file and adds them to sample_info
	    collect_gene_panels({sample_info_href => $sample_info_href,
				 family_id_ref => $family_id_ref,
				 program_name_ref => \$program_name,
				 aggregate_gene_panel_file => catfile($active_parameter_href->{sv_vcfparser_select_file}),
				 aggregate_gene_panels_key => "select_file",
				});

	    if ($active_parameter_href->{sv_vcfparser_select_file}=~/v(\d+\.\d+.\d+|\d+\.\d+)/) {

		$sample_info_href->{$program_name}{select_file}{version} = $1;
	    }
	    $sample_info_href->{$program_name}{select_file}{path} = catfile($active_parameter_href->{sv_vcfparser_select_file});
	}

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => $program_name,
			outdirectory => $outfamily_directory,
			outfile_ending => $outfile_ending.".vcf",
			outdata_type => "static"
		       });
    }

    close($XARGSFILEHANDLE);

    my $vcfparser_analysis_type = "";

    for (my $vcfparser_outfile_counter=0;$vcfparser_outfile_counter<$active_parameter_href->{vcfparser_outfile_count};$vcfparser_outfile_counter++) {

	if ($vcfparser_outfile_counter == 1) {

	    $vcfparser_analysis_type = ".selected";  #SelectFile variants
	    @contigs = @{ $file_info_href->{sorted_select_file_contigs} };
	}

	if ( ($consensus_analysis_type eq "wgs") || ($consensus_analysis_type eq "mixed") ) {

	    ## Copies file from temporary directory.
	    say $FILEHANDLE "## Copy file(s) from temporary directory";
	    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
										  XARGSFILEHANDLE => $XARGSFILEHANDLE,
										  contigs_ref => \@contigs,
										  file_name =>$file_name,
										  program_info_path => $program_info_path,
										  core_number => $core_number,
										  xargs_file_counter => $xargs_file_counter,
										  outfile => $outfile_ending_stub,
										  file_ending => $vcfparser_analysis_type.".vcf*",
										  outdirectory => $outfamily_directory,
										  temp_directory => $$temp_directory_ref,
										 });
	}
	else {

	    ## Copies file from temporary directory.
	    say $FILEHANDLE "## Copy file from temporary directory";
	    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $outfile_ending_stub.$vcfparser_analysis_type.".vcf*"),
				    file_path => $outfamily_directory,
				    FILEHANDLE => $FILEHANDLE,
				   });
	    say $FILEHANDLE "wait", "\n";
	}

	## Adds the most complete vcf file to sample_info
	add_most_complete_vcf({active_parameter_href => $active_parameter_href,
			       sample_info_href => $sample_info_href,
			       program_name => $program_name,
			       path => catfile($outfamily_directory, $outfile_ending_stub.$vcfparser_analysis_type.".vcf"),
			       vcfparser_outfile_counter => $vcfparser_outfile_counter,
			      });
    }
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub sv_varianteffectpredictor {

##sv_varianteffectpredictor

##Function : SV varianteffectpredictor performs annotation of SV variants.
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $program_info_path, $file_name, $FILEHANDLE, $stderr_path, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $FILEHANDLE                 => Sbatch filehandle to write to
##         : $stderr_path                 => The stderr path of the block script
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;
    my $stderr_path;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "SV", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $time = 20;
    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $xargs_file_name;
    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};
    my $fork_number = 4;  #varianteffectpredictor forks

    my @contigs = @{ $file_info_href->{contigs_size_ordered} };  #Set default
    
    ### If no males or other remove contig Y from all downstream analysis
    ## Removes contig_names from contigs array if no male or other found
    remove_contigs({active_parameter_href => $active_parameter_href,
		    contigs_ref => \@contigs,
		    contig_names_ref => ["Y"],
		   });

    ## Set the number of cores to allocate per sbatch job.
    my $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					      core_number => scalar(@contigs),
					     });
    $core_number = floor($core_number / $fork_number);  #Adjust for the number of forks

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$family_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref)),
								 call_type => $call_type,
								 core_number => $active_parameter_href->{core_processor_number},
								 process_time => 10,
								 temp_directory => $$temp_directory_ref
								});
    $stderr_path = $program_info_path.".stderr.txt";

    my ($volume, $directory, $stderr_file) = File::Spec->splitpath($stderr_path);  #Split to enable submission to &sample_info_qc later

    ## Assign directories
    my $infamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$family_id_ref}{psv_combinevariantcallsets}{file_tag};
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};
    my $outfile_ending_stub = $$family_id_ref.$outfile_tag.$call_type;

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($infamily_directory, $$family_id_ref.$infile_tag.$call_type.".vcf*"),
			  temp_directory => $$temp_directory_ref
			 });
    say $FILEHANDLE "wait", "\n";

    ## Fix SV with no length as these will fail in the annotation with VEP
    my $perl_fix_sv_nolengths = q?perl -nae 'my %info; my $start; my $end; my $alt; my @data; ?;  #Set up variables
    $perl_fix_sv_nolengths .= q?@data=split("\t", $_); ?;  #Split line
    $perl_fix_sv_nolengths .= q?$start = $data[1]; $start++; ?;  #Add $start position
    $perl_fix_sv_nolengths .= q?$alt=$data[4]; ?;  #Add $alt allele
    $perl_fix_sv_nolengths .= q?foreach my $bit (split /\;/, $data[7]) { my ($key, $value) = split /\=/, $bit; $info{$key} = $value; } ?;  #Add INFO field to %data using $key->$value
    $perl_fix_sv_nolengths .= q?if(defined($info{END})) { $end = $info{END}; } ?;  #Add $end position
    $perl_fix_sv_nolengths .= q?if($alt=~ /\<|\[|\]|\>/) { $alt=~ s/\<|\>//g; $alt=~ s/\:.+//g; if($start >= $end && $alt=~ /del/i) {} else {print $_} } ?;  #If SV, strip SV type entry and check if no length, then do not print variant else print
    $perl_fix_sv_nolengths .= q?else {print $_}' ?;  #All other line - print

    print $FILEHANDLE $perl_fix_sv_nolengths." ";
    print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type.".vcf")." ";
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_fixedsvlength.vcf")." ", "\n";

    ## varianteffectpredictor
    say $FILEHANDLE "## varianteffectpredictor";

    my $assembly_version = $file_info_href->{human_genome_reference_source}.$file_info_href->{human_genome_reference_version};

    ## Alias genome source and version to be compatible with VEP
    alias_assembly_version({assembly_version_ref => \$assembly_version
			   });

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "perl",
							    });

    foreach my $contig (@contigs) {

	my $vep_outfile_ending_stub = $outfile_ending_stub;
	my $vep_xargs_file_name = $xargs_file_name;

	if ( ($consensus_analysis_type eq "wgs") || ($consensus_analysis_type eq "mixed") ) {  #Update endings with contig info

	    $vep_outfile_ending_stub = $outfile_ending_stub."_".$contig;
	    $vep_xargs_file_name = $xargs_file_name.".".$contig;
	}

	print $XARGSFILEHANDLE catfile($active_parameter_href->{vep_directory_path}, "variant_effect_predictor.pl")." ";  #VEP script
	print $XARGSFILEHANDLE "--assembly ".$assembly_version." ";
	print $XARGSFILEHANDLE "--dir_cache ".$active_parameter_href->{vep_directory_cache}." ";  #Specify the cache directory to use
	print $XARGSFILEHANDLE "--cache ";  #Enables use of the cache.

	if ($active_parameter_href->{vep_reference}) {  #Use reference file for analysis with vep

	    print $XARGSFILEHANDLE "--fasta ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	}

	print $XARGSFILEHANDLE "--force_overwrite ";  #Force the overwrite of the existing file
	print $XARGSFILEHANDLE "--format vcf ";  #Input is in the VCF format
	print $XARGSFILEHANDLE "--vcf ";  #Writes output in VCF format.
	print $XARGSFILEHANDLE "--no_progress ";  #Do not show progress in stderr
	print $XARGSFILEHANDLE "--fork ".$fork_number." ";  #Enable forking, using the specified number of forks.
	print $XARGSFILEHANDLE "--buffer_size 100 ";  #Sets the internal buffer size, corresponding to the number of variations that are read in to memory simultaneously
	print $XARGSFILEHANDLE "--offline ";  #Use installed assembly

	if ( ($consensus_analysis_type eq "wgs") || ($consensus_analysis_type eq "mixed") ) {  #Add contig info

	    print $XARGSFILEHANDLE "--chr ".$contig." ";
	}

	##VEPPlugins
	foreach my $plugin (@{ $active_parameter_href->{sv_vep_plugins} }) {

	    if ($plugin eq "LoF") {

		print $XARGSFILEHANDLE "--plugin ".$plugin.",human_ancestor_fa:".catfile($active_parameter_href->{vep_directory_cache}, "human_ancestor.fa,filter_position:0.05")." ";
	    }
	    elsif ($plugin eq "UpDownDistance") {  #Special case for mitochondrial contig annotation

		if ($contig =~ /MT|M/) {

		    print $XARGSFILEHANDLE "--plugin UpDownDistance,10,10 ";
		}
	    }
	    else {

		print $XARGSFILEHANDLE "--plugin ".$plugin." ";
	    }
	}

	##VEPFeatures
	foreach my $vep_feature (@{ $active_parameter_href->{sv_vep_features} }) {

	    print $XARGSFILEHANDLE "--".$vep_feature." ";  #Add VEP features to the output.

	    if ( ($contig =~ /MT|M/) && ($vep_feature eq "refseq") ) {  #Special case for mitochondrial contig annotation

		print $XARGSFILEHANDLE "--all_refseq ";
	    }
	    if ( ($vep_feature eq "sift") || ($vep_feature eq "polyphen") )  {  #Protein predictions

		print $XARGSFILEHANDLE "p ";  #Add prediction term
	    }
	}

	print $XARGSFILEHANDLE "-i ".catfile($$temp_directory_ref, $$family_id_ref.$infile_tag.$call_type."_fixedsvlength.vcf")." ";  #InFile (family vcf)
	print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $vep_outfile_ending_stub.".vcf")." ";  #OutFile
	print $XARGSFILEHANDLE "1> ".$vep_xargs_file_name.".stdout.txt ";  #Redirect xargs output to program specific stdout file
	say $XARGSFILEHANDLE "2> ".$vep_xargs_file_name.".stderr.txt ";  #Redirect xargs output to program specific stderr file

	if ( ($consensus_analysis_type eq "wes") || ($consensus_analysis_type eq "rapid") ) {  #Update endings with contig info

	    last;  #Only perform once for exome samples to avoid risking contigs lacking variants throwing errors
	}
    }

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	my $outfile_ending = $outfile_ending_stub;

	if ( ($consensus_analysis_type eq "wgs") || ($consensus_analysis_type eq "mixed") ) {  #Update endings with contig info

	    $outfile_ending .= "_".$contigs[0];
	}

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => $program_name."summary",
			outdirectory => $outfamily_directory,
			outfile_ending => $outfile_ending.".vcf_summary.html",
			outdata_type => "static"
		       });

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => $program_name,
			outdirectory => $outfamily_directory,
			outfile_ending => $outfile_ending.".vcf",
			outdata_type => "static"
		       });
    }

    ## QC Data File(s)
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $outfile_ending_stub."*.vcf_s*"),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    close($XARGSFILEHANDLE);

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $outfile_ending_stub."*.vcf*"),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Submitt job
	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub sv_combinevariantcallsets {

##sv_combinevariantcallsets

##Function : CombineVariants to combine all structural variants call from different callers.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, family_id_ref, $temp_directory_ref, $reference_dir_ref, $outaligner_dir_ref, $call_type
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $reference_dir_ref          => MIP reference directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $reference_dir_ref = $arg_href->{reference_dir_ref} //= \$arg_href->{active_parameter_href}{reference_dir};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	reference_dir_ref => { default => \$$, strict_type => 1, store => \$reference_dir_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "SV", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my @structural_variant_callers;  #Stores callers that have been executed
    my @parallel_chains;  #Stores the parallel chains that jobIds should be inherited from

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$family_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref)),
								 call_type => $call_type,
								 process_time => 2,
								 temp_directory => $$temp_directory_ref,
								});
    my ($volume, $directory, $stderr_file) = File::Spec->splitpath($program_info_path.".stderr.txt");  #Split to enable submission to &sample_info_qc later

    ## Assign directories
    my $outfamily_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};

    ## Collect infiles for all sample_ids to enable migration to temporary directory
    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	## Add merged infile name after merging all BAM files per sample_id
	my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

	foreach my $structural_variant_caller (@{ $parameter_href->{dynamic_parameter}{structural_variant_callers} }) {

	    if ( ($active_parameter_href->{$structural_variant_caller} > 0) && ($structural_variant_caller !~/pmanta|pdelly_reformat/) ) {  #Expect vcf. Special case: manta and delly are processed by joint calling and per family

		my $program_outdirectory_name = $parameter_href->{$structural_variant_caller}{outdir_name};
		my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, $$outaligner_dir_ref, $program_outdirectory_name);
		my $infile_tag = $file_info_href->{$sample_id}{$structural_variant_caller}{file_tag};

		if (! ( any {$_ eq $parameter_href->{$structural_variant_caller}{chain}} @parallel_chains ) ) { #If element is not part of array

		    push(@parallel_chains, $parameter_href->{$structural_variant_caller}{chain});
		}

		## Copy file(s) to temporary directory
		say $FILEHANDLE "## Copy file(s) to temporary directory";
		migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
				      path => catfile($insample_directory, $infile.$infile_tag.".vcf*"),
				      temp_directory => $$temp_directory_ref
				     });

		say $FILEHANDLE "wait", "\n";

		## Compress or decompress original file or stream to outfile (if supplied)
		bgzip({FILEHANDLE => $FILEHANDLE,
		       infile_path => catfile($$temp_directory_ref, $infile.$infile_tag.".vcf"),
		       outfile_path => catfile($$temp_directory_ref, $infile.$infile_tag.".vcf.gz"),
		      });
		print $FILEHANDLE "\n";

		## Index file using tabix
		tabix({FILEHANDLE => $FILEHANDLE,
		       infile_path => catfile($$temp_directory_ref, $infile.$infile_tag.".vcf.gz"),
		      });
		say $FILEHANDLE "\n";
	    }
	}
    }

    ## Merge all structural variant caller's vcf files per sample_id
    say $FILEHANDLE "## Merge all structural variant caller's vcf files per sample_id";
    foreach my $structural_variant_caller (@{ $parameter_href->{dynamic_parameter}{structural_variant_callers} }) {

	if ($active_parameter_href->{$structural_variant_caller} > 0 && ($structural_variant_caller !~/pmanta|pdelly_reformat/) ) {  #Expect vcf. Special case: manta is processed by joint calling and per family

	    print $FILEHANDLE "bcftools merge ";

	    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {  #Collapse all structural variant calls to one vcf file per variant caller and sample_id

		## Add merged infile name after merging all BAM files per sample_id
		my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

		my $program_outdirectory_name = $parameter_href->{$structural_variant_caller}{outdir_name};
		my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, $$outaligner_dir_ref, $program_outdirectory_name);
		my $infile_tag = $file_info_href->{$sample_id}{$structural_variant_caller}{file_tag};

		print $FILEHANDLE catfile($$temp_directory_ref, $infile.$infile_tag.".vcf.gz")." ";  #InFile
	    }

	    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref."_".$structural_variant_caller.".vcf"), "\n";  #OutFile

	    ## Compress or decompress original file or stream to outfile (if supplied)
	    bgzip({FILEHANDLE => $FILEHANDLE,
		   infile_path => catfile($$temp_directory_ref, $$family_id_ref."_".$structural_variant_caller.".vcf"),
		   outfile_path => catfile($$temp_directory_ref, $$family_id_ref."_".$structural_variant_caller.".vcf.gz"),
		  });
	    say $FILEHANDLE "\n";

	    ## Index file using tabix
	    tabix({FILEHANDLE => $FILEHANDLE,
		   infile_path => catfile($$temp_directory_ref, $$family_id_ref."_".$structural_variant_caller.".vcf.gz"),
		  });
	    say $FILEHANDLE "\n";
	}
    }

    ## Add joint calling per family callers like Manta and Delly
    foreach my $structural_variant_caller (@{ $parameter_href->{dynamic_parameter}{structural_variant_callers} }) {

	if ($active_parameter_href->{$structural_variant_caller} > 0  && ($structural_variant_caller =~/pmanta|pdelly_reformat/) ) {  #Expect vcf. Special case: manta and delly are processed by joint calling and per family

	    my $program_outdirectory_name = $parameter_href->{$structural_variant_caller}{outdir_name};
	    my $infamily_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, $program_outdirectory_name);
	    my $infile_tag = $file_info_href->{$$family_id_ref}{$structural_variant_caller}{file_tag};

	    if (! ( any {$_ eq $parameter_href->{$structural_variant_caller}{chain}} @parallel_chains ) ) { #If element is not part of array

		push(@parallel_chains, $parameter_href->{$structural_variant_caller}{chain});
	    }

	    ## Copy file(s) to temporary directory
	    say $FILEHANDLE "## Copy file(s) to temporary directory";
	    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
				  path => catfile($infamily_directory, $$family_id_ref.$infile_tag."_".$call_type.".vcf*"),
				  temp_directory => $$temp_directory_ref
				 });

	    say $FILEHANDLE "wait", "\n";

	    ## Compress or decompress original file or stream to outfile (if supplied)
	    bgzip({FILEHANDLE => $FILEHANDLE,
		   infile_path => catfile($$temp_directory_ref, $$family_id_ref.$infile_tag."_".$call_type.".vcf"),
		   outfile_path => catfile($$temp_directory_ref, $$family_id_ref."_".$structural_variant_caller.".vcf.gz"),
		  });
	    print $FILEHANDLE "\n";

	    ## Index file using tabix
	    tabix({FILEHANDLE => $FILEHANDLE,
		   infile_path => catfile($$temp_directory_ref, $$family_id_ref."_".$structural_variant_caller.".vcf.gz"),
		  });
	    say $FILEHANDLE "\n";
	}
    }

    ## Concatenate structural variant caller's family vcf files
    say $FILEHANDLE "## Concatenate structural variant caller's family vcf files";
    print $FILEHANDLE "bcftools concat ";
    print $FILEHANDLE "-a ";  #First coordinate of the next file can precede last record of the current file

    foreach my $structural_variant_caller (@{ $parameter_href->{dynamic_parameter}{structural_variant_callers} }) {

	if ($active_parameter_href->{$structural_variant_caller} > 0) {  #Expect vcf

	    print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref."_".$structural_variant_caller.".vcf.gz")." ";
	}
    }
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref."_".$call_type.".vcf"), "\n";

    ## Writes sbatch code to supplied filehandle to sort variants in vcf format
    sort_vcf({active_parameter_href => $active_parameter_href,
	      FILEHANDLE => $FILEHANDLE,
	      sequence_dict_file => catfile($$reference_dir_ref, $file_info_href->{human_genome_reference_name_no_ending}.".dict"),
	      infile => catfile($$temp_directory_ref, $$family_id_ref."_".$call_type.".vcf")." ",
	      outfile => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_sorted.vcf")." ",
	     });

    print $FILEHANDLE "\n";

    my $alt_file_ending = "";  #Alternative ending
    if ($active_parameter_href->{sv_vt_decompose} > 0) {

	$alt_file_ending .= "_vt";

	## Split multiallelic variants
	say $FILEHANDLE "## Split multiallelic variants";
	print $FILEHANDLE "vt decompose ";
	print $FILEHANDLE "-s ";
	print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_sorted.vcf")." ";
	say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$alt_file_ending.".vcf"), "\n";
    }

    ## Remove FILTER ne PASS
    if ($active_parameter_href->{sv_bcftools_view_filter} > 0) {

	say $FILEHANDLE "## Remove FILTER ne PASS";
	print $FILEHANDLE "bcftools view ";
	print $FILEHANDLE "-f PASS ";
	print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$alt_file_ending.".vcf")." ";

	$alt_file_ending .= "_filt";

	say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$alt_file_ending.".vcf"), "\n";
    }

    ## Remove common variants
    if ($active_parameter_href->{sv_genmod_filter} > 0) {

	say $FILEHANDLE "## Remove common variants";
	print $FILEHANDLE "genmod ";  #Program
	print $FILEHANDLE "-v ";  #Increase output verbosity
	print $FILEHANDLE "annotate ";  #Command
	print $FILEHANDLE "--temp_dir ".$$temp_directory_ref." ";  #Temporary directory
	print $FILEHANDLE "--thousand-g ".$active_parameter_href->{sv_genmod_filter_1000g}." ";  #1000G reference
	print $FILEHANDLE "-o ".catfile(dirname(devnull()), "stdout")." ";  #OutStream
	print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$alt_file_ending.".vcf")." ";
	print $FILEHANDLE "| ";

	$alt_file_ending .= "_genmod_filter";  #Update ending

	print $FILEHANDLE "genmod ";  #Program
	print $FILEHANDLE "-v ";  #Increase output verbosity
	print $FILEHANDLE "filter ";  #Command
	print $FILEHANDLE "-t ".$active_parameter_href->{sv_genmod_filter_threshold}." ";  #Threshold for filtering variants
	print $FILEHANDLE "- ";  #InStream
	say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$alt_file_ending.".vcf"), "\n";  #OutFile
    }

    ## Annotate 1000G structural variants
    if ($active_parameter_href->{sv_vcfanno} > 0) {

	say $FILEHANDLE "## Annotate 1000G structural variants";
	print $FILEHANDLE "vcfanno ";  #Program
	print $FILEHANDLE "-lua ".$active_parameter_href->{sv_vcfanno_lua}." ";  #Increase output verbosity
	print $FILEHANDLE "-ends ";  #Annotate the start and end as well as the interval itself
	print $FILEHANDLE $active_parameter_href->{sv_vcfanno_config}." ";  #Config
	print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$alt_file_ending.".vcf")." ";
	print $FILEHANDLE "| ";
	print $FILEHANDLE q?perl -nae 'if($_=~/^#/) {print $_} else {$F[7]=~s/\[||\]//g; print join("\t", @F), "\n"}' ?;  #Remove "[" and "]" from INFO as it breaks vcf format

	$alt_file_ending .= "_vcfanno";  #Update ending

	say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$alt_file_ending.".vcf"), "\n";

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    sample_info_qc({sample_info_href => $sample_info_href,
			    program_name => "sv_combinevariantcallsets",
			    outdirectory => $directory,
			    outfile_ending => $stderr_file,
			    outdata_type => "info_directory"
			   });
	}

	say $FILEHANDLE "## Add header for 1000G annotation of structural variants";
	print $FILEHANDLE "bcftools annotate ";
	print $FILEHANDLE "--header-lines ".$active_parameter_href->{sv_vcfannotation_header_lines_file}." ";
	print $FILEHANDLE catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$alt_file_ending.".vcf")." ";

	$alt_file_ending .= "_bcftools_annotate";  #Update ending

	say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$alt_file_ending.".vcf"), "\n";

    }

    if ($alt_file_ending ne "") {  #Then we have something to rename

	## Writes sbatch code to supplied filehandle to sort variants in vcf format
	sort_vcf({active_parameter_href => $active_parameter_href,
		  FILEHANDLE => $FILEHANDLE,
		  sequence_dict_file => catfile($$reference_dir_ref, $file_info_href->{human_genome_reference_name_no_ending}.".dict"),
		  infile => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.$alt_file_ending.".vcf"),
		  outfile => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".vcf"),
		 });

	print $FILEHANDLE "\n";
    }

    if ($active_parameter_href->{sv_combinevariantcallsets_bcf_file}) {

	vcf_to_bcf({infile => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type),
		    FILEHANDLE => $FILEHANDLE,
		   });

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".bcf*"),
				file_path => $outfamily_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
    }

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".vcf"),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	$sample_info_href->{sv_vcf_file}{ready_vcf}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.".vcf");

	if ($active_parameter_href->{sv_combinevariantcallsets_bcf_file}) {

	    $sample_info_href->{sv_bcf_file}{path} = catfile($outfamily_directory, $$family_id_ref.$outfile_tag.$call_type.".bcf");
	}

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "chain_and_parallel_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name,
		    parallel_chains_ref => \@parallel_chains,
		   });
    }
}

sub cnvnator {

##cnvnator

##Function : Call structural variants using cnvnator
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, $program_info_path, family_id_ref, $temp_directory_ref, $reference_dir_ref, $outaligner_dir_ref, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $reference_dir_ref          => MIP reference directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $reference_dir_ref = $arg_href->{reference_dir_ref} //= \$arg_href->{active_parameter_href}{reference_dir};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	reference_dir_ref => { default => \$$, strict_type => 1, store => \$reference_dir_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $program_outdirectory_name = $parameter_href->{"p".$program_name}{outdir_name};

    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 30;
    my $xargs_file_name;

    $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$sample_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref), lc($program_outdirectory_name)),
								 core_number => $core_number,
								 process_time => $time,
								 temp_directory => $$temp_directory_ref
								});

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref, $program_outdirectory_name);
    $parameter_href->{"p".$program_name}{$$sample_id_ref}{indirectory} = $outsample_directory; #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{pgatk_baserecalibration}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    my $root_file;
    my $phenotype_info = $sample_info_href->{sample}{$$sample_id_ref}{phenotype}; #Alias

    my $perl_vcf_fix = q&perl -nae 'chomp($_); if($_=~/^##/) {print $_, "\n"} elsif($_=~/^#CHROM/) {print q?##FORMAT=<ID=GT,Number=1,Type=String,Description="Genotype">?, "\n"; print $_."\t".FORMAT."\t&.$$sample_id_ref.q&", "\n"} else {print $_."\tGT\t&;
    if ($phenotype_info eq 2) {  #Affected

	$perl_vcf_fix .= q&1/1"&;
    }
    if ($phenotype_info ne 2) {  #Unaffected

	$perl_vcf_fix .= q&0/1"&;
    }
    $perl_vcf_fix .= q&, "\n"}' &;

    my $perl_add_contigs = q?perl -nae '{print "##contig=<ID=".$F[0].",length=".$F[1].">", "\n"}'?;

    ## Add contigs to vcfheader
    print $FILEHANDLE $perl_add_contigs." ";
    print $FILEHANDLE $active_parameter_href->{human_genome_reference}.".fai "; #Reference fai file
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, "contig_header.txt")." ";

    my $core_counter = 1;
    ## Create by cnvnator required "chr.fa" files
    say $FILEHANDLE "## Create by cnvnator required 'chr.fa' files";
    while ( my ($contig_index, $contig) = each(@{ $file_info_href->{contigs} }) ) {

	print_wait({counter_ref => \$contig_index,
		    core_number_ref => \$core_number,
		    core_counter_ref => \$core_counter,
		    FILEHANDLE => $FILEHANDLE,
		   });

	print $FILEHANDLE "samtools faidx ";
	print $FILEHANDLE $active_parameter_href->{human_genome_reference}." ";
	print $FILEHANDLE $contig." ";
	say $FILEHANDLE "> ".catfile($$temp_directory_ref, $contig.".fa")." &";
    }
    say $FILEHANDLE "wait", "\n";

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									  XARGSFILEHANDLE => $XARGSFILEHANDLE,
									  contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									  file_name =>$file_name,
									  program_info_path => $program_info_path,
									  core_number => $core_number,
									  xargs_file_counter => $xargs_file_counter,
									  infile => $infile.$infile_tag,
									  indirectory => $insample_directory,
									  file_ending => ".b*",
									  temp_directory => $$temp_directory_ref,
									 });

    ## cnvnator
    say $FILEHANDLE "## cnvnator";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "cnvnator",
							    });

    ## Process per contig
    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE "-chrom ".$contig." ";  #chromosome name
	print $XARGSFILEHANDLE "-unique ";  #To have correct q0 field for CNV calls

	$root_file = catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".root");  #Output ROOT file

	print $XARGSFILEHANDLE "-root ".$root_file." ";
	print $XARGSFILEHANDLE "-tree ".catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";  #InFile
	print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$contig.".stdout.txt ";  #Redirect xargs output to program specific stdout file
	print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	print $XARGSFILEHANDLE "; ";

	cnvnator_his({root_file => $root_file,
		      contig_ref => \$contig,
		      cnv_bin_size_ref => \$active_parameter_href->{cnv_bin_size},
		      chromosome_reference => catfile($$temp_directory_ref, $contig.".fa"),
		      FILEHANDLE => $XARGSFILEHANDLE,
		      stdout_file => $xargs_file_name.".".$contig.".stdout.txt",
		      stderr_file => $xargs_file_name.".".$contig.".stderr.txt",
		     });
	cnvnator_stat({root_file => $root_file,
		       contig_ref => \$contig,
		       cnv_bin_size_ref => \$active_parameter_href->{cnv_bin_size},
		       FILEHANDLE => $XARGSFILEHANDLE,
		       stdout_file => $xargs_file_name.".".$contig.".stdout.txt",
		       stderr_file => $xargs_file_name.".".$contig.".stderr.txt",
		      });
	cnvnator_partition({root_file => $root_file,
			    contig_ref => \$contig,
			    cnv_bin_size_ref => \$active_parameter_href->{cnv_bin_size},
			    FILEHANDLE => $XARGSFILEHANDLE,
			    stdout_file => $xargs_file_name.".".$contig.".stdout.txt",
			    stderr_file => $xargs_file_name.".".$contig.".stderr.txt",
			   });
	cnvnator_calling({root_file => $root_file,
			  contig_ref => \$contig,
			  cnv_bin_size_ref => \$active_parameter_href->{cnv_bin_size},
			  chromosome_reference => $$reference_dir_ref,
			  FILEHANDLE => $XARGSFILEHANDLE,
			  stderr_file => $xargs_file_name.".".$contig.".stderr.txt",
			  outfile => catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig.".vcf"), #OutFile
			 });
	print $XARGSFILEHANDLE "\n";
    }

    ## Writes sbatch code to supplied filehandle to concatenate variants in vcf format. Each array element is combined with the infilePre and Postfix.
    concatenate_variants({active_parameter_href => $active_parameter_href,
			  FILEHANDLE => $FILEHANDLE,
			  elements_ref => \@{ $file_info_href->{contigs} },
			  infile_prefix => catfile($$temp_directory_ref, $infile.$outfile_tag."_"),
			  infile_postfix => ".vcf",
			  outfile => catfile($$temp_directory_ref, $infile.$outfile_tag."_concat.vcf"),
			 });

    ## Fix GT FORMAT in header and Sample_id and GT and Genotype call
    print $FILEHANDLE $perl_vcf_fix." ";
    print $FILEHANDLE catfile($$temp_directory_ref, $infile.$outfile_tag."_concat.vcf")." ";
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $infile.$outfile_tag."_concat_fix.vcf")." ";

    ##Add contigs to header
    print $FILEHANDLE "bcftools annotate ";
    print $FILEHANDLE "-h ".catfile($$temp_directory_ref, "contig_header.txt")." ";
    print $FILEHANDLE catfile($$temp_directory_ref, $infile.$outfile_tag."_concat_fix.vcf")." ";
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $infile.$outfile_tag.".vcf")." ";

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $infile.$outfile_tag.".vcf*"),
			    file_path => $outsample_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "cnvnator",
			outdirectory => $outsample_directory,
			outfile_ending => $infile.$outfile_tag.".vcf",
			outdata_type => "static"
		       });
	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name,
		   });
    }
}


sub delly_reformat {

##delly_reformat

##Function : Merge, regenotype, and filter using delly
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $program_info_path, family_id_ref, $temp_directory_ref, $reference_dir_ref, $outaligner_dir_ref, $xargs_file_counter, $call_type
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $reference_dir_ref          => MIP reference directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $xargs_file_counter         => The xargs file counter
##         : $call_type                  => The variant call type

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $reference_dir_ref = $arg_href->{reference_dir_ref} //= \$arg_href->{active_parameter_href}{reference_dir};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $xargs_file_counter;
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	reference_dir_ref => { default => \$$, strict_type => 1, store => \$reference_dir_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
	call_type => { default => "SV", strict_type => 1, store => \$call_type},
    };
    
    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $program_outdirectory_name = $parameter_href->{"p".$program_name}{outdir_name};
    
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 30;
    my $xargs_file_name;
    
    $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    
    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$family_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref), lc($program_outdirectory_name)),
								 core_number => $core_number,
								 process_time => $time,
								 temp_directory => $$temp_directory_ref
								});

    ## Assign directories
    my $outfamily_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, lc($$outaligner_dir_ref), lc($program_outdirectory_name));
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream
	
    ## Assign file_tags
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};
    my $outfile_no_ending = $$family_id_ref.$outfile_tag."_".$call_type;
    my $outfile_path_no_ending = catfile($$temp_directory_ref, $outfile_no_ending);
 
    
    ## Removes an element from array and return new array while leaving orginal elements_ref untouched
    my @contigs = remove_element({elements_ref => \@{ $file_info_href->{contigs_size_ordered} },
				  remove_contigs_ref => ["MT", "M"],
				  contig_switch => 1,
				 });

    ## Removes contigs from supplied contigs_ref
    remove_array_element({contigs_ref => \@contigs,
			  remove_contigs_ref => ["Y"],  #Skip contig Y throughout since sometimes there are no variants particularly for INS
			 });

    ## Collect infiles for all sample_ids to enable migration to temporary directory        
    my @infile_tag_keys = ("pgatk_baserecalibration", "pdelly_call");
    while ( my ($sample_id_index, $sample_id) = each (@{ $active_parameter_href->{sample_ids} }) ) {

	## Assign directories
	my $insample_directory_bam = catdir($active_parameter_href->{outdata_dir}, $sample_id, $$outaligner_dir_ref);
	my $insample_directory_bcf = catdir($active_parameter_href->{outdata_dir}, $sample_id, $$outaligner_dir_ref, $parameter_href->{pdelly_call}{outdir_name});

	foreach my $infile_tag_key (@infile_tag_keys) {
	
	    ## Assign file_tags
	    my $infile_tag = $file_info_href->{$sample_id}{$infile_tag_key}{file_tag};

	    ## Add merged infile name after merging all BAM files per sample_id
	    my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias
	    
	    if ($infile_tag_key eq "pdelly_call") {  #BCFs
		
	      SV_TYPE:
		foreach my $sv_type (@{ $active_parameter_href->{delly_types} }) { 
		    
		    my $file_ending = "_".$sv_type.".b*";
		    
		    if ($sv_type ne "TRA") {
			
			## Copy file(s) to temporary directory
			say $FILEHANDLE "## Copy file(s) to temporary directory";
			($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
											      XARGSFILEHANDLE => $XARGSFILEHANDLE,
											      contigs_ref => \@contigs,
											      file_name =>$file_name,
											      program_info_path => $program_info_path,
											      core_number => ($core_number - 1),  #Compensate for cp of entire BAM (INS, TRA), see above
											      xargs_file_counter => $xargs_file_counter,
											      infile => $infile.$infile_tag,
											      indirectory => $insample_directory_bcf,
											      file_ending => $file_ending,
											      temp_directory => $$temp_directory_ref,
											     });
		    }
		    else {
			
			say $FILEHANDLE "## Copy file(s) to temporary directory";
			migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
					      path => catfile($insample_directory_bcf, $infile.$infile_tag.$file_ending),
					      temp_directory => $active_parameter_href->{temp_directory}
					     });
		    }
		}
	    }
	    else {  #BAMs
		
		my $file_ending = ".b*";

		## Copy file(s) to temporary directory
		say $FILEHANDLE "## Copy file(s) to temporary directory";
		migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
				      path => catfile($insample_directory_bam, $infile.$infile_tag.$file_ending),
				      temp_directory => $active_parameter_href->{temp_directory}
				     });

		## Copy file(s) to temporary directory
		say $FILEHANDLE "## Copy file(s) to temporary directory";
		($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
										      XARGSFILEHANDLE => $XARGSFILEHANDLE,
										      contigs_ref => \@contigs,
										      file_name =>$file_name,
										      program_info_path => $program_info_path,
										      core_number => ($core_number - 1),  #Compensate for cp of entire BAM TRA, see above
										      xargs_file_counter => $xargs_file_counter,
										      infile => $infile.$infile_tag,
										      indirectory => $insample_directory_bam,
										      file_ending => $file_ending,
										      temp_directory => $$temp_directory_ref,
										     });
	    }
	    say $FILEHANDLE "wait", "\n";
	}
    }


    ### Delly merge
    say $FILEHANDLE "## delly merge \n";

    say $FILEHANDLE "## Fix locale bug using old centosOS and Boost library";
    say $FILEHANDLE q?LC_ALL="C"; export LC_ALL ?, "\n\n";
    
    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "delly merge",
							    });
  SV_TYPE:
    foreach my $sv_type (@{ $active_parameter_href->{delly_types} }) {  

	
	
	if ($sv_type ne "TRA") {
	    
	  CONTIG:
	    foreach my $contig (@contigs) {
		
		print $XARGSFILEHANDLE "-t ".$sv_type." ";  #The SV to call
		print $XARGSFILEHANDLE "-m 0 ";  #Min. SV size
		print $XARGSFILEHANDLE "-n 100000000 "; #Max. SV size
		print $XARGSFILEHANDLE "-o ".$outfile_path_no_ending."_".$contig."_".$sv_type.".bcf ";

	      SAMPLE_ID:
		foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {
		    
		    ## Assign file_tags
		    my $infile_tag = $file_info_href->{$sample_id}{pdelly_call}{file_tag};
		    
		    ## Add merged infile name after merging all BAM files per sample_id
		    my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

		    print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig."_".$sv_type.".bcf")." ";
		}
		print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$contig.".".$sv_type.".stdout.txt ";  #Redirect xargs output to program specific stdout file
		say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".".$sv_type.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    }
	}
	else {
	    
	    print $XARGSFILEHANDLE "-t ".$sv_type." ";  #The SV to call
	    print $XARGSFILEHANDLE "-m 0 ";  #min. SV size
	    print $XARGSFILEHANDLE "-n 100000000 "; #Max. SV size
	    print $XARGSFILEHANDLE "-o ".$outfile_path_no_ending."_".$sv_type.".bcf ";

	  SAMPLE_ID:
	    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

		## Assign file_tags
		my $infile_tag = $file_info_href->{$sample_id}{pdelly_call}{file_tag};
		
		## Add merged infile name after merging all BAM files per sample_id
		my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

		print $XARGSFILEHANDLE  catfile($$temp_directory_ref, $infile.$infile_tag."_".$sv_type.".bcf")." ";
	    }
	    print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$sv_type.".stdout.txt ";  #Redirect xargs output to program specific stdout file
	    say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$sv_type.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	}
    }


    ## Delly call regenotype
    say $FILEHANDLE "## delly call regenotype";

  SAMPLE_ID:
    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	## Assign file_tags
	my $infile_tag = $file_info_href->{$sample_id}{pgatk_baserecalibration}{file_tag};

	## Add merged infile name after merging all BAM files per sample_id
	my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

	my $bam_sample_file_path_no_ending = catfile($$temp_directory_ref, $infile.$infile_tag);
	my $bcf_sample_file_path_no_ending = catfile($$temp_directory_ref, $infile.$outfile_tag);
	
	## Create file commands for xargs
	($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
								 XARGSFILEHANDLE => $XARGSFILEHANDLE,
								 file_name => $file_name,
								 program_info_path => $program_info_path,
								 core_number => $core_number,
								 xargs_file_counter => $xargs_file_counter,
								 first_command => "delly call",
								});
      SV_TYPE:
	foreach my $sv_type (@{ $active_parameter_href->{delly_types} }) {  

	    if ($sv_type ne "TRA") {

	      CONTIG:
		foreach my $contig (@contigs) {

		    print $XARGSFILEHANDLE "-t ".$sv_type." ";  #The SV to call
		    print $XARGSFILEHANDLE "-g ".$active_parameter_href->{human_genome_reference}." "; #Reference file
		    print $XARGSFILEHANDLE "-v ".$outfile_path_no_ending."_".$contig."_".$sv_type.".bcf ";
		    print $XARGSFILEHANDLE "-x ".$active_parameter_href->{delly_exclude_file}." ";  #to exclude telomere and centromere regions
		    print $XARGSFILEHANDLE "-o ".$bcf_sample_file_path_no_ending."_".$contig."_".$sv_type."_geno.bcf ";
		    print $XARGSFILEHANDLE $bam_sample_file_path_no_ending."_".$contig.".bam ";  #InFile
		    print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$contig.".".$sv_type.".stdout.txt ";  #Redirect xargs output to program specific stdout file
		    say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".".$sv_type.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		}
	    }
	    else {
		
		print $XARGSFILEHANDLE "-t ".$sv_type." ";  #The SV to call
		print $XARGSFILEHANDLE "-g ".$active_parameter_href->{human_genome_reference}." "; #Reference file
		print $XARGSFILEHANDLE "-v ".$outfile_path_no_ending."_".$sv_type.".bcf ";
		print $XARGSFILEHANDLE "-x ".$active_parameter_href->{delly_exclude_file}." ";  #to exclude telomere and centromere regions
		print $XARGSFILEHANDLE "-o ".$bcf_sample_file_path_no_ending."_".$sv_type."_geno.bcf ";
		print $XARGSFILEHANDLE $bam_sample_file_path_no_ending.".bam ";  #InFile
		print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$sv_type.".stdout.txt ";  #Redirect xargs output to program specific stdout file
		say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$sv_type.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    }
	}
    }


    ### Merge calls
    say $FILEHANDLE "## bcftools merge";
      
    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "bcftools merge",
							    });
  SV_TYPE:
    foreach my $sv_type (@{ $active_parameter_href->{delly_types} }) {  
	
	if ($sv_type ne "TRA") {
	    
	  CONTIG:
	    foreach my $contig (@contigs) {
		
		print $XARGSFILEHANDLE "-O b ";
		print $XARGSFILEHANDLE "-o ".$outfile_path_no_ending."_".$contig."_".$sv_type."_geno_merged.bcf ";
		
	      SAMPLE_ID:
		foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {
		    
		    ## Add merged infile name after merging all BAM files per sample_id
		    my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias
		    
		    print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig."_".$sv_type."_geno.bcf")." ";  #Infile
		}
		print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$contig.".".$sv_type.".stdout.txt ";  #Redirect xargs output to program specific stdout file
		say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".".$sv_type.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    }
	}
	else {
	    
	    print $XARGSFILEHANDLE "-O b ";
	    print $XARGSFILEHANDLE "-o ".$outfile_path_no_ending."_".$sv_type."_geno_merged.bcf ";
	    
	  SAMPLE_ID:
	    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {
		
		## Add merged infile name after merging all BAM files per sample_id
		my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

		print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile.$outfile_tag."_".$sv_type."_geno.bcf")." ";  #Infile
	    }
	    print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$sv_type.".stdout.txt ";  #Redirect xargs output to program specific stdout file
	    say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$sv_type.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	}
    }

    ### Merge calls
    say $FILEHANDLE "## Index bcf";
      
    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "bcftools index",
							    });
  SV_TYPE:
    foreach my $sv_type (@{ $active_parameter_href->{delly_types} }) {  
	
	if ($sv_type ne "TRA") {
	    
	  CONTIG:
	    foreach my $contig (@contigs) {

		print $XARGSFILEHANDLE $outfile_path_no_ending."_".$contig."_".$sv_type."_geno_merged.bcf ";
		print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$contig.".".$sv_type.".stdout.txt ";  #Redirect xargs output to program specific stdout file
		say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".".$sv_type.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    }
	}
	else {
	    
	    print $XARGSFILEHANDLE $outfile_path_no_ending."_".$sv_type."_geno_merged.bcf ";
	    print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$sv_type.".stdout.txt ";  #Redirect xargs output to program specific stdout file
	    say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$sv_type.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	}
    }


    ### Filter calls
    say $FILEHANDLE "## Delly filter";
      
    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "delly filter",
							    });
  SV_TYPE:
    foreach my $sv_type (@{ $active_parameter_href->{delly_types} }) {  
	
	if ($sv_type ne "TRA") {
	    
	  CONTIG:
	    foreach my $contig (@contigs) {
		
		print $XARGSFILEHANDLE "-t ".$sv_type." ";  #The SV to call
		print $XARGSFILEHANDLE "-f germline ";  #Filter mode
		print $XARGSFILEHANDLE "-o ".$outfile_path_no_ending."_".$contig."_".$sv_type."_geno_merged_filtered.bcf ";
		print $XARGSFILEHANDLE $outfile_path_no_ending."_".$contig."_".$sv_type."_geno_merged.bcf ";
		print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$contig.".".$sv_type.".stdout.txt ";  #Redirect xargs output to program specific stdout file
		say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".".$sv_type.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    }
	}
	else {
	    
	    print $XARGSFILEHANDLE "-t ".$sv_type." ";  #The SV to call
	    print $XARGSFILEHANDLE "-f germline ";  #Filter mode
	    print $XARGSFILEHANDLE "-o ".$outfile_path_no_ending."_".$sv_type."_geno_merged_filtered.bcf ";
	    print $XARGSFILEHANDLE $outfile_path_no_ending."_".$sv_type."_geno_merged.bcf ";
	    print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$sv_type.".stdout.txt ";  #Redirect xargs output to program specific stdout file
	    say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$sv_type.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	}
    }

    ### Concatenate SV types
    say $FILEHANDLE "## bcftools concat - merge all SV types and contigs";

    print $FILEHANDLE "bcftools concat ";
    print $FILEHANDLE "--allow-overlaps "; #First coordinate of the next file can precede last record of the current file
    print $FILEHANDLE "-O v ";  #uncompressed VCF
    print $FILEHANDLE "-o ".$outfile_path_no_ending."_concat.vcf ";
    
  SV_TYPE:
    foreach my $sv_type (@{ $active_parameter_href->{delly_types} }) {
	
	if($sv_type ne "TRA") {
	    
	  CONTIG:
	    foreach my $contig (@contigs) {
		
		print $FILEHANDLE $outfile_path_no_ending."_".$contig."_".$sv_type."_geno_merged_filtered.bcf "; 
	    }   
	}
	else {

	    print $FILEHANDLE $outfile_path_no_ending."_".$sv_type."_geno_merged.bcf ";
	}
    }
    say $FILEHANDLE "\n";

    ## Writes sbatch code to supplied filehandle to sort variants in vcf format
    sort_vcf({active_parameter_href => $active_parameter_href,
	      FILEHANDLE => $FILEHANDLE,
	      sequence_dict_file => catfile($$reference_dir_ref, $file_info_href->{human_genome_reference_name_no_ending}.".dict"),
	      infile => $outfile_path_no_ending."_concat.vcf",
	      outfile => $outfile_path_no_ending.".vcf",
	     });

    ## Copies file from temporary directory.
    say $FILEHANDLE "\n## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => $outfile_path_no_ending.".vcf",
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "delly",
			outdirectory => $outfamily_directory,
			outfile_ending => $outfile_no_ending."vcf",
			outdata_type => "static"
		       });
    }
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name,
		   });
    }
}


sub delly_call {

##delly_call

##Function : Call structural variants using delly
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, $program_info_path, family_id_ref, $temp_directory_ref, $reference_dir_ref, $outaligner_dir_ref, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $reference_dir_ref          => MIP reference directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $reference_dir_ref = $arg_href->{reference_dir_ref} //= \$arg_href->{active_parameter_href}{reference_dir};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	reference_dir_ref => { default => \$$, strict_type => 1, store => \$reference_dir_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $program_outdirectory_name = $parameter_href->{"p".$program_name}{outdir_name};

    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 30;
    my $xargs_file_name;

    $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$sample_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref), lc($program_outdirectory_name)),
								 core_number => $core_number,
								 process_time => $time,
								 temp_directory => $$temp_directory_ref
								});

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref, $program_outdirectory_name);
    $parameter_href->{"p".$program_name}{$$sample_id_ref}{indirectory} = $outsample_directory; #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{pgatk_baserecalibration}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Removes an element from array and return new array while leaving orginal elements_ref untouched
    my @contigs = remove_element({elements_ref => \@{ $file_info_href->{contigs_size_ordered} },
				  remove_contigs_ref => ["MT", "M"],  
				  contig_switch => 1,
				 });

    ## Removes contigs from supplied contigs_ref
    remove_array_element({contigs_ref => \@contigs,
			  remove_contigs_ref => ["Y"],  #Skip contig Y throughout since sometimes there are no variants particularly for INS
			 });

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    ## Required for processing complete file (INS, TRA)
    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($insample_directory, $infile.$infile_tag.".b*"),
			  temp_directory => $active_parameter_href->{temp_directory}
			 });

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									  XARGSFILEHANDLE => $XARGSFILEHANDLE,
									  contigs_ref => \@contigs,
									  file_name =>$file_name,
									  program_info_path => $program_info_path,
									  core_number => ($core_number - 1),  #Compensate for cp of entire BAM (INS, TRA), see above
									  xargs_file_counter => $xargs_file_counter,
									  infile => $infile.$infile_tag,
									  indirectory => $insample_directory,
									  file_ending => ".b*",
									  temp_directory => $$temp_directory_ref,
									 });
    say $FILEHANDLE "wait", "\n";

    ## delly
    say $FILEHANDLE "## delly";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "delly call",
							    });

    foreach my $sv_type (@{ $active_parameter_href->{delly_types} }) {

	if ($sv_type ne "TRA") {

	    ## Process per contig
	    foreach my $contig (@contigs) {
		
		print $XARGSFILEHANDLE "-t ".$sv_type." ";  #The SV to call
		print $XARGSFILEHANDLE "-x ".$active_parameter_href->{delly_exclude_file}." ";  #to exclude telomere and centromere regions
		print $XARGSFILEHANDLE "-g ".$active_parameter_href->{human_genome_reference}." "; #Reference file
		print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig."_".$sv_type.".bcf")." ";
		print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";  #InFile
		print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$contig.".".$sv_type.".stdout.txt ";  #Redirect xargs output to program specific stdout file
		say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".".$sv_type.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    }
	}
	else {

	    print $XARGSFILEHANDLE "-t ".$sv_type." ";  #The SV to call
	    print $XARGSFILEHANDLE "-g ".$active_parameter_href->{human_genome_reference}." "; #Reference file
	    print $XARGSFILEHANDLE "-x ".$active_parameter_href->{delly_exclude_file}." ";  #to exclude telomere and centromere regions
	    print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $infile.$outfile_tag."_".$sv_type.".bcf")." ";
	    print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile.$infile_tag.".bam")." ";  #InFile
	    print $XARGSFILEHANDLE "1> ".$xargs_file_name.".".$sv_type.".stdout.txt ";  #Redirect xargs output to program specific stdout file
	    say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$sv_type.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	}
    }


    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $infile.$outfile_tag."*.bcf*"),
			    file_path => $outsample_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name,
		   });
    }
}


sub manta {

##manta

##Function : Joint analysis of structural variation
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "SV", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};
    my $program_outdirectory_name = $parameter_href->{"p".$program_name}{outdir_name};
    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 30;

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => catfile(lc($$outaligner_dir_ref), lc($program_outdirectory_name)),
					     process_time => $time,
					     core_number => $core_number,
					     temp_directory => $$temp_directory_ref,
					    });

    ## Assign directories
    my $outfamily_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, lc($$outaligner_dir_ref), lc($program_outdirectory_name));
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};

    my $core_counter = 1;
    ## Collect infiles for all sample_ids to enable migration to temporary directory
    while ( my ($sample_id_index, $sample_id) = each (@{ $active_parameter_href->{sample_ids} }) ) {

	print_wait({counter_ref => \$sample_id_index,
		    core_number_ref => \$core_number,
		    core_counter_ref => \$core_counter,
		    FILEHANDLE => $FILEHANDLE,
		   });

	## Assign directories
	my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, $$outaligner_dir_ref);

	## Assign file_tags
	my $infile_tag = $file_info_href->{$sample_id}{pgatk_baserecalibration}{file_tag};

	## Add merged infile name after merging all BAM files per sample_id
	my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			      path => catfile($insample_directory, $infile.$infile_tag.".b*"),
			      temp_directory => $$temp_directory_ref,
			     });
    }
    say $FILEHANDLE "wait", "\n";

    ## manta
    say $FILEHANDLE "## Manta";
    print $FILEHANDLE "configManta.py ";

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	## Assign file_tags
	my $infile_tag = $file_info_href->{$sample_id}{pgatk_baserecalibration}{file_tag};

	## Add merged infile name after merging all BAM files per sample_id
	my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

	print $FILEHANDLE "--bam ".catfile($$temp_directory_ref, $infile.$infile_tag.".bam")." ";  #Infile
    }
    print $FILEHANDLE "--referenceFasta ".$active_parameter_href->{human_genome_reference}." ";  #Reference file

    if ($consensus_analysis_type ne "wgs") {

	print $FILEHANDLE "--exome ";
    }
    say $FILEHANDLE "--runDir ".$$temp_directory_ref, "\n";

    say $FILEHANDLE "## Manta workflow";
    print $FILEHANDLE catfile($$temp_directory_ref, "runWorkflow.py")." ";
    say $FILEHANDLE "--mode local ", "\n";

    print $FILEHANDLE "gzip ";
    print $FILEHANDLE "-d ";
    print $FILEHANDLE "-c ";
    print $FILEHANDLE catfile($$temp_directory_ref, "results", "variants", "diploidSV.vcf.gz")." ";
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag."_".$call_type.".vcf"), "\n";

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag."_".$call_type.".vcf*"),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "manta",
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.$outfile_tag."_".$call_type.".vcf",
			outdata_type => "static"
		       });
    }
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name,
		   });
    }
}


sub findtranslocations {

##findtranslocations

##Function : Call structural variants using findtranslocations
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, family_id_ref, $temp_directory_ref, $reference_dir_ref, $outaligner_dir_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $reference_dir_ref          => MIP reference directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $reference_dir_ref = $arg_href->{reference_dir_ref} //= \$arg_href->{active_parameter_href}{reference_dir};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	reference_dir_ref => { default => \$$, strict_type => 1, store => \$reference_dir_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = 2;
    my $program_outdirectory_name = $parameter_href->{"p".$program_name}{outdir_name};

    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 30;
    my $xargs_file_name;

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$sample_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref), lc($program_outdirectory_name)),
								 core_number => $core_number,
								 process_time => $time,
								 temp_directory => $$temp_directory_ref
								});

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref, $program_outdirectory_name);
    $parameter_href->{"p".$program_name}{$$sample_id_ref}{indirectory} = $outsample_directory; #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{pgatk_baserecalibration}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    my @findtranslocations_types = ("intra", "inter");
    my $perl_vcf_fix = q&perl -nae 'chomp($_); if($_=~/^##/) {print $_, "\n"} elsif($_=~/^#CHROM/) {print q?##FORMAT=<ID=GT,Number=1,Type=String,Description="Genotype">?, "\n"; print $_."\t".FORMAT."\t&.$$sample_id_ref.q&", "\n"} else {print $_."\tGT\t1/1", "\n"}' &;
    my $perl_add_contigs = q?perl -nae '{print "##contig=<ID=".$F[0].",length=".$F[1].">", "\n"}'?;

    ## Add contigs to vcfheader
    print $FILEHANDLE $perl_add_contigs." ";
    print $FILEHANDLE $active_parameter_href->{human_genome_reference}.".fai "; #Reference fai file
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, "contig_header.txt")." ";

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			  path => catfile($insample_directory, $infile.$infile_tag.".b*"),
			  temp_directory => $active_parameter_href->{temp_directory}
			 });
    say $FILEHANDLE "wait", "\n";

    ## Findtranslocations
    say $FILEHANDLE "## FindTranslocations";
    print $FILEHANDLE "FindTranslocations ";
    print $FILEHANDLE "--sv ";
    print $FILEHANDLE "--auto ";
    print $FILEHANDLE "--bam ".catfile($$temp_directory_ref, $infile.$infile_tag.".bam")." ";  #Infile
    print $FILEHANDLE "--bai ".catfile($$temp_directory_ref, $infile.$infile_tag.".bai")." ";  #Infile index
    print $FILEHANDLE "--minimum-supporting-pairs ".$active_parameter_href->{findtranslocations_minimum_supporting_pairs}." ";
    say $FILEHANDLE "--output ".catfile($$temp_directory_ref, $infile.$outfile_tag)." ";

    foreach my $sv_type (@findtranslocations_types) {

	## Fix GT FORMAT in header and Sample_id and GT and Genotype call
	print $FILEHANDLE $perl_vcf_fix." ";
	print $FILEHANDLE catfile($$temp_directory_ref, $infile.$outfile_tag."_".$sv_type."_chr_events.vcf")." ";
	say $FILEHANDLE "> ".catfile($$temp_directory_ref, $infile.$outfile_tag."_".$sv_type."_glfixed.vcf")." ";

	##Add contigs to header
	print $FILEHANDLE "bcftools annotate ";
	print $FILEHANDLE "-h ".catfile($$temp_directory_ref, "contig_header.txt")." ";
	print $FILEHANDLE catfile($$temp_directory_ref, $infile.$outfile_tag."_".$sv_type."_glfixed.vcf")." ";
	say $FILEHANDLE "> ".catfile($$temp_directory_ref, $infile.$outfile_tag."_".$sv_type."_glfixed_contig_header.vcf")." ";
    }

    ## Writes sbatch code to supplied filehandle to concatenate variants in vcf format. Each array element is combined with the infilePre and Postfix.
    concatenate_variants({active_parameter_href => $active_parameter_href,
			  FILEHANDLE => $FILEHANDLE,
			  elements_ref => \@findtranslocations_types,
			  infile_prefix => catfile($$temp_directory_ref, $infile.$outfile_tag."_"),
			  infile_postfix => "_glfixed_contig_header.vcf",
			  outfile => catfile($$temp_directory_ref, $infile.$outfile_tag."_glfixed_contig_header_concat.vcf"),
			 });

    ## Writes sbatch code to supplied filehandle to sort variants in vcf format
    sort_vcf({active_parameter_href => $active_parameter_href,
	      file_info_href => $file_info_href,
	      FILEHANDLE => $FILEHANDLE,
	      sequence_dict_file => catfile($$reference_dir_ref, $file_info_href->{human_genome_reference_name_no_ending}.".dict"),
	      infile => catfile($$temp_directory_ref, $infile.$outfile_tag."_glfixed_contig_header_concat.vcf"),
	      outfile => catfile($$temp_directory_ref, $infile.$outfile_tag.".vcf")." ",
	     });

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $infile.$outfile_tag.".vcf*"),
			    file_path => $outsample_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "findtranslocations",
			outdirectory => $outsample_directory,
			outfile_ending => $infile.$outfile_tag.".vcf",
			outdata_type => "static"
		       });
	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name,
		   });
    }
}


sub samtools_mpileup {

##samtools_mpileup

##Function : samtools_mpileup
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $xargs_file_counter          => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $program_outdirectory_name = $parameter_href->{"p".$program_name}{outdir_name};
    my $time = 30;
    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $xargs_file_name;

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$family_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref), $program_outdirectory_name),
								 core_number => $core_number,
								 process_time => $time,
								 temp_directory => $$temp_directory_ref
								});

    $core_number = floor($active_parameter_href->{node_ram_memory} / 4);  #Division by X according to the java heap
    $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					   core_number => $core_number
					  });  #To not exceed maximum

    ## Assign directories
    my $outfamily_file_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, $program_outdirectory_name);  #For ".fam" file
    my $outfamily_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, $program_outdirectory_name);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};

    ## Create .fam file to be used in variant calling analyses
    create_fam_file({parameter_href => $parameter_href,
		     active_parameter_href => $active_parameter_href,
		     sample_info_href => $sample_info_href,
		     FILEHANDLE => $FILEHANDLE,
		     fam_file_path => catfile($outfamily_file_directory, $$family_id_ref.".fam"),
		     include_header => 0,
		    });

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {  #Collect infiles for all sample_ids

	my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, $$outaligner_dir_ref);
	my $infile_tag = $file_info_href->{$sample_id}{pgatk_baserecalibration}{file_tag};

	## Add merged infile name after merging all BAM files per sample_id
	my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      infile => $infile.$infile_tag,
									      indirectory => $insample_directory,
									      file_ending => ".b*",
									      temp_directory => $$temp_directory_ref,
									     });
    }

    ## SamTools mpileup
    say $FILEHANDLE "## SamTools mpileup";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "samtools",
							    });

    ## Split per contig
    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE "mpileup ";  #Type of analysis to run
	print $XARGSFILEHANDLE "-g ";  #Generate genotype likelihoods in BCF format
	print $XARGSFILEHANDLE "-C 50 ";  #Adjust mapping quality
	print $XARGSFILEHANDLE "-p ";  #Apply -m and -F per-sample for increased sensitivity
	print $XARGSFILEHANDLE "-t DV,AD "; #Optional tags to output; Allelic depth
	print $XARGSFILEHANDLE "-f ".$active_parameter_href->{human_genome_reference}." ";  #Reference file

	foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {  #Collect infiles for all sample_ids

	    my $infile_tag = $file_info_href->{$sample_id}{pgatk_baserecalibration}{file_tag};

	    ## Add merged infile name after merging all BAM files per sample_id
	    my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

	    print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";  #InFile
	}

	print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	print $XARGSFILEHANDLE "| ";  #Pipe
	print $XARGSFILEHANDLE "bcftools ";
	print $XARGSFILEHANDLE "call ";  #SNP/indel variant calling from VCF/BCF.
	print $XARGSFILEHANDLE "--format-fields GQ ";  #Comma-separated list of FORMAT fields to output for each sample
	print $XARGSFILEHANDLE "-v ";  #Output variant sites only
	print $XARGSFILEHANDLE "-m ";  #Alternative model for multiallelic and rare-variant calling

	if ($parameter_href->{dynamic_parameter}{trio}) {

	    print $XARGSFILEHANDLE "--samples-file ".catfile($outfamily_file_directory, $$family_id_ref.".fam")." ";
	    print $XARGSFILEHANDLE "--constrain trio ";
	}
	print $XARGSFILEHANDLE "2>> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	print $XARGSFILEHANDLE "| ";  #Pipe
	print $XARGSFILEHANDLE "bcftools ";
	print $XARGSFILEHANDLE "filter ";  #SNP/indel variant calling filtering.
	print $XARGSFILEHANDLE "-sLowQual ";  #Filter on lowQual
	print $XARGSFILEHANDLE "-g3 ";  #Filter SNPs within <int> base pairs of an indel
	print $XARGSFILEHANDLE "-G10 ";  #Filter clusters of indels separated by <int> or fewer base pairs allowing only one to pass
	print $XARGSFILEHANDLE q?-e \'%QUAL<10 || (RPB<0.1 && %QUAL<15) || (AC<2 && %QUAL<15) || %MAX(DV)<=3 || %MAX(DV)/%MAX(DP)<=0.25\' ?;  #exclude sites for which the expression is true
	print $XARGSFILEHANDLE "2>> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file

	if ($active_parameter_href->{replace_iupac}) {

	    ## Replace the IUPAC code in alternative allels with N for input stream and writes to stream
	    replace_iupac({stderr_path => $xargs_file_name.".".$contig.".stderr.txt",
			   FILEHANDLE => $XARGSFILEHANDLE
			  });
	}

	print $XARGSFILEHANDLE "| ";  #Pipe

	## BcfTools norm, Left-align and normalize indels, split multiallelics
	bcftools_norm({FILEHANDLE => $XARGSFILEHANDLE,
		       reference_path_ref => \$active_parameter_href->{human_genome_reference},
		       outfile_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.".vcf"),
		       multiallelic => "-",
		       stderr_file_path => catfile($xargs_file_name.".".$contig.".stderr.txt"),
		      });
    }

    ## Writes sbatch code to supplied filehandle to concatenate variants in vcf format. Each array element is combined with the infilePre and Postfix.
    concatenate_variants({active_parameter_href => $active_parameter_href,
			  FILEHANDLE => $FILEHANDLE,
			  elements_ref => \@{ $file_info_href->{contigs} },
			  infile_prefix => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_"),
			  infile_postfix => ".vcf",
			  outfile => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".vcf"),
			 });

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".vcf*"),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect samtools version in qccollect
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "samtools",
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.$outfile_tag.$call_type.".vcf",
			outdata_type => "static"
		       });
	## Locating samtools_mpileup file
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "samtools_mpileup",
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.$outfile_tag.$call_type.".vcf",
			outdata_type => "static"
		       });
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "bcftools",
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.$outfile_tag.$call_type.".vcf",
			outdata_type => "static"
		       });

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name,
		   });
    }
}

sub freebayes {

##freebayes

##Function : Call snv/small indels usig freebayes
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $program_outdirectory_name = $parameter_href->{"p".$program_name}{outdir_name};
    my $time = 30;
    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $xargs_file_name;

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$family_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref), $program_outdirectory_name),
								 core_number => $core_number,
								 process_time => $time,
								 temp_directory => $$temp_directory_ref
								});

    $core_number = floor($active_parameter_href->{node_ram_memory} / 4);  #Division by X according to the java heap
    $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					   core_number => $core_number,
					  });  #To not exceed maximum

    ## Assign directories
    my $outfamily_file_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, $program_outdirectory_name);  #For ".fam" file
    my $outfamily_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, $$outaligner_dir_ref, $program_outdirectory_name);
    $parameter_href->{"p".$program_name}{indirectory} = $outfamily_directory;  #Used downstream

    ## Assign file_tags
    my $outfile_tag = $file_info_href->{$$family_id_ref}{"p".$program_name}{file_tag};

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, $$outaligner_dir_ref);
	my $infile_tag = $file_info_href->{$sample_id}{pgatk_baserecalibration}{file_tag};

	## Add merged infile name after merging all BAM files per sample_id
	my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      infile => $infile.$infile_tag,
									      indirectory => $insample_directory,
									      file_ending => ".b*",
									      temp_directory => $$temp_directory_ref,
									     });
    }

    ## Freebayes
    say $FILEHANDLE "## Freebayes";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "freebayes",
							    });

    ## Split per contig
    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE "--standard-filters "; #Equivalent to -m 30 -q 20 -R 0 -S 0
	print $XARGSFILEHANDLE "--genotype-qualities ";  #Calculate the marginal probability of genotypes and report as GQ
	print $XARGSFILEHANDLE "--fasta-reference ".$active_parameter_href->{human_genome_reference}." ";  #Reference file

	foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	    my $infile_tag = $file_info_href->{$sample_id}{pgatk_baserecalibration}{file_tag};

	    ## Add merged infile name after merging all BAM files per sample_id
	    my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

	    print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";  #InFile
	}

	print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	print $XARGSFILEHANDLE "| ";  #Pipe
	print $XARGSFILEHANDLE "bcftools ";
	print $XARGSFILEHANDLE "filter ";  #SNP/indel variant calling filtering.
	print $XARGSFILEHANDLE "-sLowQual ";  #Filter on lowQual
	print $XARGSFILEHANDLE "-g3 ";  #Filter SNPs within <int> base pairs of an indel
	print $XARGSFILEHANDLE "-G10 ";  #Filter clusters of indels separated by <int> or fewer base pairs allowing only one to pass
	print $XARGSFILEHANDLE q?-e \'%QUAL<10 || (AC<2 && %QUAL<15)\' ?;  #exclude sites for which the expression is true
	print $XARGSFILEHANDLE "2>> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file

	if ($active_parameter_href->{replace_iupac}) {

	    ## Replace the IUPAC code in alternative allels with N for input stream and writes to stream
	    replace_iupac({stderr_path => $xargs_file_name.".".$contig.".stderr.txt",
			   FILEHANDLE => $XARGSFILEHANDLE
			  });
	}
	print $XARGSFILEHANDLE "| ";  #Pipe

	## BcfTools norm, Left-align and normalize indels, split multiallelics
	bcftools_norm({FILEHANDLE => $XARGSFILEHANDLE,
		       reference_path_ref => \$active_parameter_href->{human_genome_reference},
		       outfile_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_".$contig.".vcf"),
		       multiallelic => "-",
		       stderr_file_path => catfile($xargs_file_name.".".$contig.".stderr.txt"),
		      });
    }

    ## Writes sbatch code to supplied filehandle to concatenate variants in vcf format. Each array element is combined with the infilePre and Postfix.
    concatenate_variants({active_parameter_href => $active_parameter_href,
			  FILEHANDLE => $FILEHANDLE,
			  elements_ref => \@{ $file_info_href->{contigs} },
			  infile_prefix => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type."_"),
			  infile_postfix => ".vcf",
			  outfile => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".vcf"),
			 });

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $$family_id_ref.$outfile_tag.$call_type.".vcf*"),
			    file_path => $outfamily_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "freebayes",
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.$outfile_tag.$call_type.".vcf",
			outdata_type => "static"
		       });
	sample_info_qc({sample_info_href => $sample_info_href,
			program_name => "bcftools",
			outdirectory => $outfamily_directory,
			outfile_ending => $$family_id_ref.$outfile_tag.$call_type.".vcf",
			outdata_type => "static"
		       });

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name,
		   });
    }
}


sub gatk_haplotypecaller {

##gatk_haplotypecaller

##Function : gatk_haplotypecaller.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $analysis_type_ref = \$active_parameter_href->{analysis_type}{$$sample_id_ref};
    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 30;
    my $xargs_file_name;

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$sample_id_ref,
								 program_name => $program_name,
								 program_directory => catfile(lc($$outaligner_dir_ref), "gatk"),
								 core_number => $core_number,
								 process_time => $time,
								 temp_directory => $$temp_directory_ref
								});

    $core_number = floor($active_parameter_href->{node_ram_memory} / 4);  #Division by X according to the java heap
    $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					   core_number => $core_number,
					  });  #To not exceed maximum

    ## Assign directories
    my $outfamily_file_directory = catdir($active_parameter_href->{outdata_dir}, $$family_id_ref);  #For ".fam" file
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref, "gatk");
    $parameter_href->{"p".$program_name}{$$sample_id_ref}{indirectory} = $outsample_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{pgatk_baserecalibration}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Create .fam file to be used in variant calling analyses
    create_fam_file({parameter_href => $parameter_href,
		     active_parameter_href => $active_parameter_href,
		     sample_info_href => $sample_info_href,
		     FILEHANDLE => $FILEHANDLE,
		     fam_file_path => catfile($outfamily_file_directory, $$family_id_ref.".fam"),
		    });

    ## Get exome_target_bed file for specfic sample_id and add file_ending from file_infoHash if supplied
    my $exome_target_bed_file = get_exom_target_bed_file({active_parameter_href => $active_parameter_href,
							  sample_id_ref => $sample_id_ref,
							  file_ending_ref => \$file_info_href->{exome_target_bed}[2],
							 });
    if ( ($$analysis_type_ref eq "wes") || ($$analysis_type_ref eq "rapid") ) { #Exome/rapid analysis

	## Generate contig specific interval_list
	generate_contig_specific_target_bed_file({active_parameter_href => $active_parameter_href,
						  file_info_href => $file_info_href,
						  FILEHANDLE => $FILEHANDLE,
						  exome_target_bed_file_ref => \$exome_target_bed_file,
						 });

	$exome_target_bed_file = basename($exome_target_bed_file);  #Reroute to only filename
    }

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    ## Copy file(s) to temporary directory
    say $FILEHANDLE "## Copy file(s) to temporary directory";
    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									  XARGSFILEHANDLE => $XARGSFILEHANDLE,
									  contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									  file_name =>$file_name,
									  program_info_path => $program_info_path,
									  core_number => $core_number,
									  xargs_file_counter => $xargs_file_counter,
									  infile => $infile.$infile_tag,
									  indirectory => $insample_directory,
									  file_ending => ".b*",
									  temp_directory => $$temp_directory_ref,
									 });

    ## GATK HaplotypeCaller
    say $FILEHANDLE "## GATK HaplotypeCaller";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "java",
							     memory_allocation => "Xmx8g",
							     java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
							     java_temporary_directory => $$temp_directory_ref,
							     java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
							    });

    ## Split per contig
    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE "-T HaplotypeCaller ";  #Type of analysis to run
	print $XARGSFILEHANDLE "-l INFO ";  #Set the minimum level of logging
	print $XARGSFILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	print $XARGSFILEHANDLE "-D ".$active_parameter_href->{gatk_haplotypecaller_snp_known_set}." ";  #Known SNPs to use for annotation SNPs
	print $XARGSFILEHANDLE "-stand_call_conf 10.0 ";  #The minimum phred-scaled confidence threshold at which variants should be called

	## Check if "--pedigree" and "--pedigreeValidationType" should be included in analysis
	gatk_pedigree_flag({active_parameter_href => $active_parameter_href,
			    FILEHANDLE => $XARGSFILEHANDLE,
			    outfamily_file_directory => $outfamily_file_directory,
			    program_name => $program_name,
			   });

	## Filter
	if ($active_parameter_href->{gatk_haplotypecaller_soft_clipped_bases}) { #Do not analyze soft clipped bases in the reads

	    print $XARGSFILEHANDLE "--dontUseSoftClippedBases ";  #Do not analyze soft clipped bases in the reads
	}
	if ( ($$analysis_type_ref eq "wgs") && ($active_parameter_href->{gatk_haplotypecaller_pcr_indel_model} ne 0) ) {

	    print $XARGSFILEHANDLE "--pcr_indel_model ".$active_parameter_href->{gatk_haplotypecaller_pcr_indel_model}." ";  #Assume that we run pcr-free sequencing (true for Rapid WGS and X-ten)
	}

	## Annotations to apply to variant calls
	print $XARGSFILEHANDLE "--annotation ".join(" --annotation ", (@{ $active_parameter_href->{gatk_haplotypecaller_annotation} }) )." ";

	if (scalar(@{ $active_parameter{sample_ids} }) >= 10) {

	    print $XARGSFILEHANDLE "--annotation InbreedingCoeff ";  #Likelihood-based test for the inbreeding among samples (Only meningful with at least 10 founder samples)
	}
	print $XARGSFILEHANDLE "--emitRefConfidence GVCF ";  #Mode for emitting experimental reference confidence scores. GVCF generates block summarized version of the BP_RESOLUTION data
	print $XARGSFILEHANDLE "--variant_index_type LINEAR ";
	print $XARGSFILEHANDLE "--variant_index_parameter 128000 ";

	if ( ($$analysis_type_ref eq "wes") || ( $$analysis_type_ref eq "rapid") ) { #Exome/rapid analysis

	    print $XARGSFILEHANDLE "-L ".catfile($$temp_directory_ref, $contig."_".$exome_target_bed_file)." "; #Limit to targets kit target file
	}
	else {  #wgs

	    print $XARGSFILEHANDLE "-L ".$contig." ";  #Per contig
	}

	print $XARGSFILEHANDLE "-I ".catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";  #InFile
	print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig.".vcf")." ";  #OutFile
	say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
    }

    ## Copies file from temporary directory. Per contig
    say $FILEHANDLE "## Copy file from temporary directory";
    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									  XARGSFILEHANDLE => $XARGSFILEHANDLE,
									  contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									  file_name =>$file_name,
									  program_info_path => $program_info_path,
									  core_number => $core_number,
									  xargs_file_counter => $xargs_file_counter,
									  outfile => $infile.$outfile_tag,
									  outdirectory => $outsample_directory,
									  temp_directory => $$temp_directory_ref,
									  file_ending => ".vcf*",
									 });
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub gatk_baserecalibration {

##gatk_baserecalibration

##Function : GATK baserecalibrator/printreads to recalibrate bases before variant calling. Both BaseRecalibrator/PrintReads will be executed within the same sbatch script.
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, $program_info_path, $file_name, $FILEHANDLE, family_id_ref, $temp_directory_ref, $reference_dir_ref, $outaligner_dir_ref, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $FILEHANDLE                 => Filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $reference_dir_ref          => MIP reference directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $reference_dir_ref = $arg_href->{reference_dir_ref} //= \$arg_href->{active_parameter_href}{reference_dir};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;
    my $program_info_path;
    my $file_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => { strict_type => 1, store => \$file_name},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	reference_dir_ref => { default => \$$, strict_type => 1, store => \$reference_dir_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $analysis_type_ref = \$active_parameter_href->{analysis_type}{$$sample_id_ref};
    my $gatk_temporary_directory = catfile($$temp_directory_ref, "gatk", "intermediary");

    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 20;
    my $xargs_file_name;

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$sample_id_ref,
								  program_name => $program_name,
								  program_directory => catfile(lc($$outaligner_dir_ref)),
								  core_number => $core_number,
								  process_time => 50,
								  temp_directory => $gatk_temporary_directory,
								 });
    }
    else {

	## Create GATK intermediary directory
	say $FILEHANDLE "## Create GATK intermediary directory";
	say $FILEHANDLE "mkdir -p ".$gatk_temporary_directory;
    }

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $intermediary_sample_directory = $gatk_temporary_directory;
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{$$sample_id_ref}{indirectory} = $outsample_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{pgatk_realigner}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Alias exome_target_bed endings
    my $infile_list_ending_ref = \$file_info_href->{exome_target_bed}[0];

    ## Get exome_target_bed file for specfic sample_id and add file_ending from file_infoHash if supplied
    my $exome_target_bed_file = get_exom_target_bed_file({active_parameter_href => $active_parameter_href,
							  sample_id_ref => $sample_id_ref,
							  file_ending_ref => \$file_info_href->{exome_target_bed}[0],
							 });
    if ( ($$analysis_type_ref eq "wes") || ($$analysis_type_ref eq "rapid") ) { #Exome/rapid analysis

	## Generate contig specific interval_list
	generate_contig_specific_target_bed_file({active_parameter_href => $active_parameter_href,
						  file_info_href => $file_info_href,
						  FILEHANDLE => $FILEHANDLE,
						  exome_target_bed_file_ref => \$exome_target_bed_file,
						  file_ending => ".intervals",
						 });

	$exome_target_bed_file = basename($exome_target_bed_file).".intervals";  #Add required GATK ending and reroute to only filename
    }

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      infile => $infile.$infile_tag,
									      indirectory => $insample_directory,
									      file_ending => ".b*",
									      temp_directory => $$temp_directory_ref,
									     });
    }

    $core_number = floor($active_parameter_href->{node_ram_memory} / 4);  #Division by X according to the java heap
    $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					   core_number => $core_number
					  });  #To not exceed maximum

    ## GATK BaseRecalibrator
    say $FILEHANDLE "## GATK BaseRecalibrator";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "java",
							     memory_allocation => "Xmx4g",
							     java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
							     java_temporary_directory => $$temp_directory_ref,
							     java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
							    });

    ## Process per contig
    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE "-T BaseRecalibrator ";  #Type of analysis to run
	print $XARGSFILEHANDLE "-l INFO ";  #Set the minimum level of logging
	print $XARGSFILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	print $XARGSFILEHANDLE "-cov ".join(" -cov ", (@{ $active_parameter_href->{gatk_baserecalibration_covariates} }) )." ";  #Covariates to be used in the recalibration
	print $XARGSFILEHANDLE "-knownSites ".join(" -knownSites ", map { catfile($$reference_dir_ref, $_) } (@{ $active_parameter_href->{gatk_baserecalibration_known_sites} }) )." ";
	print $XARGSFILEHANDLE "-nct ".$active_parameter_href->{core_processor_number}." ";  #How many CPU threads should be allocated per data thread to running this analysis
	print $XARGSFILEHANDLE "-dcov ".$active_parameter_href->{gatk_downsample_to_coverage}." ";  #Coverage to downsample to at any given locus

	if ($active_parameter_href->{gatk_disable_auto_index_and_file_lock}) {

	    print $XARGSFILEHANDLE "--disable_auto_index_creation_and_locking_when_reading_rods ";  #Disables index auto-creation and related file locking when reading vcfs
	}
	if ( ($$analysis_type_ref eq "wes") || ($$analysis_type_ref eq "rapid") ) { #Exome/rapid analysis

	    print $XARGSFILEHANDLE "-L ".catfile($$temp_directory_ref, $contig."_".$exome_target_bed_file)." "; #Limit to targets kit target file
	}
	else {  #wgs

	    print $XARGSFILEHANDLE "-L ".$contig." ";  #Per contig
	}

	print $XARGSFILEHANDLE "-I ".catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";  #InFile
	print $XARGSFILEHANDLE "-o ".catfile($intermediary_sample_directory, $infile.$infile_tag."_".$contig.".grp")." ";  #Recalibration table file
	say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
    }

    ## GATK PrintReads
    say $FILEHANDLE "## GATK PrintReads";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "java",
							     memory_allocation => "Xmx4g",
							     java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
							     java_temporary_directory => $$temp_directory_ref,
							     java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
							    });

    ## Process per contig
    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE "-T PrintReads ";  #Type of analysis to run
	print $XARGSFILEHANDLE "-l INFO ";  #Set the minimum level of logging"
	print $XARGSFILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	print $XARGSFILEHANDLE "-nct ".$active_parameter_href->{core_processor_number}." ";  #How many CPU threads should be allocated per data thread to running this analysis
	print $XARGSFILEHANDLE "-dcov ".$active_parameter_href->{gatk_downsample_to_coverage}." ";  #Coverage to downsample to at any given locus

	if ($active_parameter_href->{gatk_disable_auto_index_and_file_lock}) {

	    print $XARGSFILEHANDLE "--disable_auto_index_creation_and_locking_when_reading_rods ";  #Disables index auto-creation and related file locking when reading vcfs
	}

	print $XARGSFILEHANDLE "-BQSR ".catfile($intermediary_sample_directory, $infile.$infile_tag."_".$contig.".grp")." ";  #Recalibration table file

	##Extra read filters
	if ($active_parameter_href->{gatk_baserecalibration_over_clipped_read}) {

	    print $XARGSFILEHANDLE "-rf OverclippedRead ";  #Filter out reads that are over-soft-clipped
	}
	foreach my $level (@{ $active_parameter_href->{gatk_baserecalibration_static_quantized_quals} }) {

	    print $XARGSFILEHANDLE "--static_quantized_quals ".$level." ";  #Use discrete levels of quality base recalibration
	}
	if ($active_parameter_href->{gatk_baserecalibration_disable_indel_qual}) {

	    print $XARGSFILEHANDLE "--disable_indel_quals  ";  #Do not recalibrate indel base quality (should be done for Pacbio reads)
	}
	if ( ($$analysis_type_ref eq "wes") || ($$analysis_type_ref eq "rapid") ) { #Exome/rapid analysis

	    print $XARGSFILEHANDLE "-L ".catfile($$temp_directory_ref, $contig."_".$exome_target_bed_file)." "; #Limit to targets kit target file
	}
	else {  #wgs

	    print $XARGSFILEHANDLE "-L ".$contig." ";  #Per contig
	}

	print $XARGSFILEHANDLE "-I ".catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";  #InFile per contig
	print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig.".bam")." ";  #OutFile
	say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
    }

    ## Copies file from temporary directory. Per contig for variant callers.
    say $FILEHANDLE "## Copy file from temporary directory";
    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									  XARGSFILEHANDLE => $XARGSFILEHANDLE,
									  contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									  file_name =>$file_name,
									  program_info_path => $program_info_path,
									  core_number => $core_number,
									  xargs_file_counter => $xargs_file_counter,
									  outfile => $infile.$outfile_tag,
									  outdirectory => $outsample_directory,
									  temp_directory => $$temp_directory_ref,
									  file_ending => ".b*",
									 });

    if ($$reduce_io_ref) {  #Run as block sbatch script

	## Remove file at temporary Directory
	remove_contig_file_at_temp_directory({files_ref => \@{ $file_info_href->{contigs_size_ordered} },
					      FILEHANDLE => $FILEHANDLE,
					      core_number => $core_number,
					      file_name => $infile.$infile_tag,
					      file_ending => ".b*",
					      temp_directory => $$temp_directory_ref,
					     });
    }

    ## Concatenates BAMs
    gather_bam_files({active_parameter_href => $active_parameter_href,
		      elements_ref => \@{ $file_info_href->{contigs} },
		      FILEHANDLE => $FILEHANDLE,
		      infile => $infile.$outfile_tag,
		      create_index => "FALSE",
		     });

    ## Create BAM index (temporary fix to accomodate Pilup.Js bug)
    print $FILEHANDLE "\nsamtools index ";
    say $FILEHANDLE catfile($$temp_directory_ref, $infile.$outfile_tag.".bam")."\n";

    ## Copies file from temporary directory.
    say $FILEHANDLE "## Copy file from temporary directory";
    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $infile.$outfile_tag.".b*"),
			    file_path => $outsample_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    ## Remove Concatenated BAM file at temporary Directory
    remove_file({file_ref => \catfile($$temp_directory_ref, $infile.$outfile_tag.".b*"),
		 FILEHANDLE => $FILEHANDLE,
		});
    
    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	$sample_info_href->{sample}{$$sample_id_ref}{most_complete_bam}{path} = catfile($outsample_directory, $infile.$outfile_tag.".bam");
    }

    close($XARGSFILEHANDLE);

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub gatk_realigner {

##gatk_realigner

##Function : GATK ReAlignerTargetCreator/IndelRealigner to rearrange reads around INDELs. Both ReAlignerTargetCreator and IndelRealigner will be executed within the same sbatch script.
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id, $program_name, $program_info_path, $file_name, $FILEHANDLE, family_id_ref, $temp_directory_ref, $reference_dir_ref, $outaligner_dir_ref, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $FILEHANDLE                 => Filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $reference_dir_ref          => MIP reference directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $reference_dir_ref = $arg_href->{reference_dir_ref} //= \$arg_href->{active_parameter_href}{reference_dir};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;
    my $program_info_path;
    my $file_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => { strict_type => 1, store => \$file_name},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	reference_dir_ref => { default => \$$, strict_type => 1, store => \$reference_dir_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $analysis_type_ref = \$active_parameter_href->{analysis_type}{$$sample_id_ref};
    my $gatk_temporary_directory = catfile($$temp_directory_ref, "gatk", "intermediary");

    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 20;
    my $xargs_file_name;

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$sample_id_ref,
								  program_name => $program_name,
								  program_directory => catfile(lc($$outaligner_dir_ref)),
								  core_number => $core_number,
								  process_time => 40,
								  temp_directory => $gatk_temporary_directory
								 });
    }
    else {

	## Create GATK intermediary directory
	say $FILEHANDLE "## Create GATK intermediary directory";
	say $FILEHANDLE "mkdir -p ".$gatk_temporary_directory;
    }

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $intermediary_sample_directory = $gatk_temporary_directory;
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{$$sample_id_ref}{indirectory} = $outsample_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{psambamba_markduplicates}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Get exome_target_bed file for specfic sample_id and add file_ending from file_infoHash if supplied
    my $exome_target_bed_file = get_exom_target_bed_file({active_parameter_href => $active_parameter_href,
							  sample_id_ref => $sample_id_ref,
							  file_ending_ref => \$file_info_href->{exome_target_bed}[2],
							 });

    if ( ($$analysis_type_ref eq "wes") || ($$analysis_type_ref eq "rapid") ) { #Exome/rapid analysis

	## Generate contig specific interval_list
	generate_contig_specific_target_bed_file({active_parameter_href => $active_parameter_href,
						  file_info_href => $file_info_href,
						  FILEHANDLE => $FILEHANDLE,
						  exome_target_bed_file_ref => \$exome_target_bed_file,
						 });
	$exome_target_bed_file = basename($exome_target_bed_file);  #Reroute to only filename
    }

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      infile => $infile.$infile_tag,
									      indirectory => $insample_directory,
									      file_ending => ".b*",
									      temp_directory => $$temp_directory_ref,
									     });
    }

    ## GATK ReAlignerTargetCreator
    say $FILEHANDLE "## GATK ReAlignerTargetCreator";

    $core_number = floor($active_parameter_href->{node_ram_memory} / 4);  #Division by 4 since the java heap is 4GB
    $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					   core_number => $core_number
					  });  #To not exceed maximum

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "java",
							     memory_allocation => "Xmx4g",
							     java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
							     java_temporary_directory => $$temp_directory_ref,
							     java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
							    });

    ## Process per contig
    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE "-T RealignerTargetCreator ";  #Type of analysis to run
	print $XARGSFILEHANDLE "-l INFO ";  #Set the minimum level of logging
	print $XARGSFILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	print $XARGSFILEHANDLE "-known ".join(" -known ", map { catfile($$reference_dir_ref, $_) } (@{ $active_parameter_href->{gatk_realigner_indel_known_sites} }) )." ";  #Input VCF file(s) with known indels
	print $XARGSFILEHANDLE "-dcov ".$active_parameter_href->{gatk_downsample_to_coverage}." ";  #Coverage to downsample to at any given locus

	if ($active_parameter_href->{gatk_disable_auto_index_and_file_lock}) {

	    print $XARGSFILEHANDLE "--disable_auto_index_creation_and_locking_when_reading_rods ";  #Disables index auto-creation and related file locking when reading vcfs
	}
	if ( ($$analysis_type_ref eq "wes") || ($$analysis_type_ref eq "rapid") ) { #Exome/rapid analysis

	    print $XARGSFILEHANDLE "-L ".catfile($$temp_directory_ref, $contig."_".$exome_target_bed_file)." "; #Limit to targets kit target file
	}
	else {  #wgs

	    print $XARGSFILEHANDLE "-L ".$contig." ";  #Per contig
	}
	print $XARGSFILEHANDLE "-I ".catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";  #InFile
	print $XARGSFILEHANDLE "-o ".catfile($intermediary_sample_directory, $infile.$outfile_tag."_".$contig.".intervals")." ";  #Interval outfile
	say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
    }

    ## GATK IndelRealigner
    say $FILEHANDLE "## GATK IndelRealigner";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "java",
							     memory_allocation => "Xmx4g",
							     java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
							     java_temporary_directory => $$temp_directory_ref,
							     java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
							    });

    ## Process per contig
    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE "-T IndelRealigner ";
	print $XARGSFILEHANDLE "-l INFO ";
	print $XARGSFILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file
	print $XARGSFILEHANDLE "-known ".join(" -known ", map { catfile($$reference_dir_ref, $_) } (@{ $active_parameter_href->{gatk_realigner_indel_known_sites} }) )." ";  #Input VCF file(s) with known indels
	print $XARGSFILEHANDLE "-dcov ".$active_parameter_href->{gatk_downsample_to_coverage}." ";  #Coverage to downsample to at any given locus
	print $XARGSFILEHANDLE "--consensusDeterminationModel USE_READS ";  #Additionally uses indels already present in the original alignments of the reads
	print $XARGSFILEHANDLE "-targetIntervals ".catfile($intermediary_sample_directory, $infile.$outfile_tag."_".$contig.".intervals")." ";

	if ($active_parameter_href->{gatk_disable_auto_index_and_file_lock}) {

	    print $XARGSFILEHANDLE "--disable_auto_index_creation_and_locking_when_reading_rods ";  #Disables index auto-creation and related file locking when reading vcfs
	}
	if ( ($$analysis_type_ref eq "wes") || ($$analysis_type_ref eq "rapid") ) { #Exome/rapid analysis

	    print $XARGSFILEHANDLE "-L ".catfile($$temp_directory_ref, $contig."_".$exome_target_bed_file)." "; #Limit to targets kit target file
	}
	else {  #wgs

	    print $XARGSFILEHANDLE "-L ".$contig." ";  #Per contig
	}

	print $XARGSFILEHANDLE "-I ".catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";  #InFile per contig
	print $XARGSFILEHANDLE "-o ".catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig.".bam")." ";  #OutFile
	say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
    }

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Copies file from temporary directory. Per contig
	say $FILEHANDLE "## Copy file from temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      outfile => $infile.$outfile_tag,
									      outdirectory => $outsample_directory,
									      temp_directory => $$temp_directory_ref,
									      file_ending => ".b*",
									     });

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    $sample_info_href->{sample}{$$sample_id_ref}{most_complete_bam}{path} = catfile($outsample_directory, $infile.$outfile_tag.".bam");
	}
    }
    else {

	## Remove file at temporary Directory
	remove_contig_file_at_temp_directory({files_ref => \@{ $file_info_href->{contigs_size_ordered} },
					      FILEHANDLE => $FILEHANDLE,
					      core_number => $core_number,
					      file_name => $infile.$infile_tag,
					      file_ending => ".b*",
					      temp_directory => $$temp_directory_ref,
					     });
    }

    close($XARGSFILEHANDLE);

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	close($FILEHANDLE);

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			sample_id => $$sample_id_ref,
			dependencies => "case_dependency",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name
		       });
	}
    }
    else {

	return $xargs_file_counter;  #Track the number of created xargs scripts per module for Block algorithm
    }
}


sub picardtools_markduplicates {

##picardtools_markduplicates

##Function : Mark duplicated reads using Picardtools markduplicates in files generated from alignment (sorted, merged).
##Returns  : "$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $lane_href, $job_id_href, $sample_id_ref, $program_name, $program_info_path, $file_name, $FILEHANDLE, $family_id_ref, temp_directory_ref, outaligner_dir_ref, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $lane_href                  => The lane info hash {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $FILEHANDLE                 => Filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $lane_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;
    my $program_info_path;
    my $file_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	lane_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$lane_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => { strict_type => 1, store => \$file_name},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $lanes = join("",@{ $lane_href->{$$sample_id_ref} });  #Extract lanes

    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 20;
    my $xargs_file_name;

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    }

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{$$sample_id_ref}{indirectory} = $outsample_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{ppicardtools_mergesamfiles}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    ## Sums all mapped and duplicate reads and takes fraction of before finishing
    my $regexp = q?perl -nae'my %feature; while (<>) { if($_=~/duplicates/ && $_=~/^(\d+)/) {$feature{dup} = $feature{dup} + $1} if($_=~/\d+\smapped/ && $_=~/^(\d+)/) {$feature{map} = $feature{map} + $1} } print "Read Mapped: ".$feature{map}."\nDuplicates: ".$feature{dup}."\n"."Fraction Duplicates: ".$feature{dup}/$feature{map}, "\n"; last;'?;

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$sample_id_ref,
								  program_name => $program_name,
								  program_directory => lc($$outaligner_dir_ref),
								  core_number => $core_number,
								  process_time => $time,
								  temp_directory => $$temp_directory_ref
								 });

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      infile => $infile.$infile_tag,
									      indirectory => $insample_directory,
									      file_ending => ".b*",
									      temp_directory => $$temp_directory_ref,
									     });
    }

    ## Marking Duplicates
    say $FILEHANDLE "## Marking duplicates";

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "java",
							     memory_allocation => "Xmx4g",
							     java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
							     java_temporary_directory => $$temp_directory_ref,
							     java_jar =>  $active_parameter_href->{picardtools_path}."/picard.jar",
							    });
    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE "MarkDuplicates ";
	print $XARGSFILEHANDLE "METRICS_FILE=".catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig.".metric")." ";  #MetricFile
	print $XARGSFILEHANDLE "CREATE_INDEX=TRUE ";  #Create a BAM index when writing a coordinate-sorted BAM file.
	print $XARGSFILEHANDLE "INPUT=".catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";;  #InFile
	print $XARGSFILEHANDLE "OUTPUT=".catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig.".bam")." ";  #OutFile
	print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	print $XARGSFILEHANDLE "; ";

	## Process BAM with sambamba flagstat to produce metric file for downstream analysis
	sambamba_flagstat({infile_path => catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig.".bam"),
			   outfile_path => catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig."_metric"),
			   stderr_file_path => $xargs_file_name.".".$contig.".stderr.txt",
			   FILEHANDLE => $XARGSFILEHANDLE,
			  });
    }

    ## Concatenate all metric files
    print $FILEHANDLE "cat ";
    print $FILEHANDLE catfile($$temp_directory_ref, $infile.$outfile_tag."_*_metric")." ";
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $infile.$outfile_tag."_metric_all")." ", "\n";  #Metric file for all files

    ## Sum metric over concatenated file
    print $FILEHANDLE $regexp." ";
    print $FILEHANDLE catfile($$temp_directory_ref, $infile.$outfile_tag."_metric_all")." ";
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $infile.$outfile_tag."_metric")." ", "\n";  #Sum of all original metric files


    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $infile.$outfile_tag."_metric"),
			    file_path => $outsample_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			sample_id => $$sample_id_ref,
			program_name => "markduplicates",
			infile => $infile,
			outdirectory => $outsample_directory,
			outfile_ending => $outfile_tag."_metric",
			outdata_type => "infile_dependent"
		       });
	$sample_info_href->{sample}{$$sample_id_ref}{program}{markduplicates}{$infile}{processed_by} = $program_name;  #markduplicates can be processed by either picardtools_markduplicates or Sambamba markduplicates

	if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	    $sample_info_href->{sample}{$$sample_id_ref}{most_complete_bam}{path} = catfile($outsample_directory, $infile.$outfile_tag."_".$file_info_href->{contigs_size_ordered}[0].".bam");
	}
    }

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Copies file from temporary directory. Per contig
	say $FILEHANDLE "## Copy file from temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      outfile => $infile.$outfile_tag,
									      outdirectory => $outsample_directory,
									      temp_directory => $$temp_directory_ref,
									      file_ending => ".b*",
									     });
    }
    else {

	## Remove file at temporary Directory
	remove_contig_file_at_temp_directory({files_ref => \@{ $file_info_href->{contigs_size_ordered} },
					      FILEHANDLE => $FILEHANDLE,
					      core_number => $core_number,
					      file_name => $infile.$infile_tag,
					      file_ending => ".b*",
					      temp_directory => $$temp_directory_ref,
					     });
    }

    close($XARGSFILEHANDLE);

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	close($FILEHANDLE);

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			sample_id => $$sample_id_ref,
			dependencies => "case_dependency",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name
		       });
	}
    }
    else {

	return $xargs_file_counter;  #Track the number of created xargs scripts per module for Block algorithm
    }
}


sub sambamba_markduplicates {

##sambamba_markduplicates

##Function : Mark duplicated reads using Sambamba markduplicates in files generated from alignment (sorted, merged).
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $lane_href, $job_id_href, $sample_id_ref, $program_name, $program_info_path, $file_name,, $FILEHANDLE, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $lane_href                  => The lane info hash {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $FILEHANDLE                 => Filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $lane_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;
    my $program_info_path;
    my $file_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	lane_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$lane_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => { strict_type => 1, store => \$file_name},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $lanes = join("",@{ $lane_href->{$$sample_id_ref} });  #Extract lanes

    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 20;
    my $xargs_file_name;

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    }

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{$$sample_id_ref}{indirectory} = $outsample_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{ppicardtools_mergesamfiles}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Add merged infile name after merging all BAM files per sample_id
    my $infile = $file_info_href->{$$sample_id_ref}{merge_infile};  #Alias

    ## Sums all mapped and duplicate reads and takes fraction of before finishing
    my $regexp = q?perl -nae'my %feature; while (<>) { if($_=~/duplicates/ && $_=~/^(\d+)/) {$feature{dup} = $feature{dup} + $1} if($_=~/\d+\smapped/ && $_=~/^(\d+)/) {$feature{map} = $feature{map} + $1} } print "Read Mapped: ".$feature{map}."\nDuplicates: ".$feature{dup}."\n"."Fraction Duplicates: ".$feature{dup}/$feature{map}, "\n"; last;'?;

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$sample_id_ref,
								  program_name => $program_name,
								  program_directory => lc($$outaligner_dir_ref),
								  core_number => $core_number,
								  process_time => $time,
								  temp_directory => $$temp_directory_ref
								 });

	## Copy file(s) to temporary directory
	say $FILEHANDLE "## Copy file(s) to temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      infile => $infile.$infile_tag,
									      indirectory => $insample_directory,
									      file_ending => ".b*",
									      temp_directory => $$temp_directory_ref,
									     });
    }

    ## Marking Duplicates
    say $FILEHANDLE "## Marking Duplicates";

    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => "sambamba ",  #Program
							    });

    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	print $XARGSFILEHANDLE "markdup ";
	print $XARGSFILEHANDLE "--tmpdir=".$active_parameter_href->{temp_directory}." ";  #Directory for storing intermediate files
	print $XARGSFILEHANDLE "--show-progress ";  #Show progressbar in STDERR
	print $XARGSFILEHANDLE "--hash-table-size=".$active_parameter_href->{sambamba_markdup_hash_table_size}." ";  #Size of hash table for finding read pairs
	print $XARGSFILEHANDLE "--overflow-list-size=".$active_parameter_href->{sambamba_markdup_overflow_list_size}." ";  #Size of the overflow list
	print $XARGSFILEHANDLE "--io-buffer-size=".$active_parameter_href->{sambamba_markdup_io_buffer_size}." "; #Two buffers of BUFFER_SIZE *megabytes* each are used for reading and writing BAM during the second pass
	print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";;  #InFile
	print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig.".bam")." ";  #OutFile
	print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	print $XARGSFILEHANDLE "; ";

	## Process BAM with sambamba flagstat to produce metric file for downstream analysis
	sambamba_flagstat({infile_path => catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig.".bam"),
			   outfile_path => catfile($$temp_directory_ref, $infile.$outfile_tag."_".$contig."_metric"),
			   stderr_file_path => $xargs_file_name.".".$contig.".stderr.txt",
			   FILEHANDLE => $XARGSFILEHANDLE,
			  });
    }

    ## Concatenate all metric files
    print $FILEHANDLE "cat ";
    print $FILEHANDLE catfile($$temp_directory_ref, $infile.$outfile_tag."_*_metric")." ";
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $infile.$outfile_tag."_metric_all")." ", "\n";  #Metric file for all files

    ## Sum metric over concatenated file
    print $FILEHANDLE $regexp." ";
    print $FILEHANDLE catfile($$temp_directory_ref, $infile.$outfile_tag."_metric_all")." ";
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, $infile.$outfile_tag."_metric")." ", "\n";  #Sum of all original metric files


    migrate_file_from_temp({temp_path => catfile($$temp_directory_ref, $infile.$outfile_tag."_metric"),
			    file_path => $outsample_directory,
			    FILEHANDLE => $FILEHANDLE,
			   });
    say $FILEHANDLE "wait", "\n";

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	## Collect QC metadata info for later use
	sample_info_qc({sample_info_href => $sample_info_href,
			sample_id => $$sample_id_ref,
			program_name => "markduplicates",
			infile => $infile,
			outdirectory => $outsample_directory,
			outfile_ending => $outfile_tag."_metric",
			outdata_type => "infile_dependent"
		       });
	$sample_info_href->{sample}{$$sample_id_ref}{program}{markduplicates}{$infile}{processed_by} = $program_name;  #markduplicates can be processed by either picardtools markduplicates or sambamba markduplicates

	if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	    $sample_info_href->{sample}{$$sample_id_ref}{most_complete_bam}{path} = catfile($outsample_directory, $infile.$outfile_tag."_".$file_info_href->{contigs_size_ordered}[0].".bam");
	}
    }

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	## Copies file from temporary directory. Per contig
	say $FILEHANDLE "## Copy file from temporary directory";
	($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      file_name =>$file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      outfile => $infile.$outfile_tag,
									      outdirectory => $outsample_directory,
									      temp_directory => $$temp_directory_ref,
									      file_ending => ".b*",
									     });
    }
    else {

	## Remove file at temporary Directory
	remove_contig_file_at_temp_directory({files_ref => \@{ $file_info_href->{contigs_size_ordered} },
					      FILEHANDLE => $FILEHANDLE,
					      core_number => $core_number,
					      file_name => $infile.$infile_tag,
					      file_ending => ".b*",
					      temp_directory => $$temp_directory_ref,
					     });
    }

    close($XARGSFILEHANDLE);

    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	close($FILEHANDLE);

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			sample_id => $$sample_id_ref,
			dependencies => "case_dependency",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name
		       });
	}
    }
    else {

	return $xargs_file_counter;  #Track the number of created xargs scripts per module for Block algorithm
    }
}


sub picardtools_mergesamfiles {

##picardtools_mergesamfiles

##Function : Merges all bam files using Picardtools mergesamfiles within each sampleid and files generated previously (option if provided with '-picardtools_mergesamfiles_previous_bams'). The merged files have to be sorted before attempting to merge.
##Returns  : "|$xargs_file_counter"
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $lane_href, $job_id_href, $sample_id_ref, $program_name, $program_info_path, $file_name,, $FILEHANDLE, $family_id_ref, $outaligner_dir_ref, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $lane_href                  => The lane info hash {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name
##         : $program_info_path          => The program info path
##         : $file_name                  => File name
##         : $FILEHANDLE                 => Filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $lane_href;
    my $sample_id_ref;
    my $program_name;
    my $program_info_path;
    my $file_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	lane_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$lane_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	file_name => { strict_type => 1, store => \$file_name},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $reduce_io_ref = \$active_parameter_href->{reduce_io};
    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};
    my $lanes = join("",@{ $lane_href->{$$sample_id_ref} });  #Extract lanes

    my $XARGSFILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $xargs_file_name;

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$sample_id_ref,
								  program_name => $program_name,
								  program_directory => lc($$outaligner_dir_ref),
								  core_number => $core_number,
								  process_time => 20,
								  temp_directory => $$temp_directory_ref
								 });
    }

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{$$sample_id_ref}{indirectory} = $outsample_directory;  #Used downstream

    ## Assign file_tags
    my $infile_tag;

    if ($consensus_analysis_type ne "rapid") {

	$infile_tag = $file_info_href->{$$sample_id_ref}{ $parameter_href->{active_aligner} }{file_tag};
    }
    else {  #Rapid mode used

	$infile_tag = $file_info_href->{$$sample_id_ref}{ppicardtools_mergerapidreads}{file_tag};
    }
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{ppicardtools_mergesamfiles}{file_tag};

    ## Copies files from source to temporary folder. Loop over files specified by $files_ref and collects files from $extract_files_ref.
    migrate_files_to_temp({active_parameter_href => $active_parameter_href,
			   files_ref => \@{ $infile_lane_no_ending_href->{$$sample_id_ref} },
			   extract_files_ref => \@{ $infile_lane_no_ending_href->{$$sample_id_ref} },
			   FILEHANDLE => $FILEHANDLE,
			   insample_directory => $insample_directory,
			   core_number => $core_number,
			   file_ending => $infile_tag.".b*"
			  });

    foreach my $infile ( @{ $infile_lane_no_ending_href->{$$sample_id_ref} } ) {

	## Split BAMs using Samtools
	say $FILEHANDLE "## Split alignment files per contig";
	($xargs_file_counter, $xargs_file_name) = split_bam_sambamba({active_parameter_href => $active_parameter_href,
								      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
								      FILEHANDLE => $FILEHANDLE,
								      XARGSFILEHANDLE => $XARGSFILEHANDLE,
								      file_name => $file_name,
								      program_info_path => $program_info_path,
								      core_number => $core_number,
								      xargs_file_counter => $xargs_file_counter,
								      temp_directory_ref => $temp_directory_ref,
								      infile => $infile.$infile_tag
								     });
    }

    if (scalar( @{ $infile_lane_no_ending_href->{$$sample_id_ref} }) > 1) {

	## picardtools_mergesamfiles
	say $FILEHANDLE "## Merging alignment files";

	$core_number = floor($active_parameter_href->{node_ram_memory} / 4);  #Division by X according to java Heap size
	$core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					       core_number => $core_number,
					      });  #To not exceed maximum

	## Create file commands for xargs
	($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
								 XARGSFILEHANDLE => $XARGSFILEHANDLE,
								 file_name => $file_name,
								 program_info_path => $program_info_path,
								 core_number => $core_number,
								 first_command => "java",
								 xargs_file_counter => $xargs_file_counter,
								 memory_allocation => "Xmx4g",
								 java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
								 java_temporary_directory => $$temp_directory_ref,
								 java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
								});

	## Split per contig
	foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	  INFILES:
	    while (my ($index, $infile) = each( @{ $infile_lane_no_ending_href->{$$sample_id_ref} } ) ) {

		if(! $index) { #First round of loop

		    print $XARGSFILEHANDLE "MergeSamFiles ";
		    print $XARGSFILEHANDLE "USE_THREADING=TRUE "; #Create a background thread to encode, compress and write to disk the output file
		    print $XARGSFILEHANDLE "CREATE_INDEX=TRUE ";  #Create a BAM index when writing a coordinate-sorted BAM file.
		    print $XARGSFILEHANDLE "OUTPUT=".catfile($$temp_directory_ref, $$sample_id_ref."_lanes_".$lanes.$outfile_tag."_".$contig.".bam")." ";  #OutFile
		}
		print $XARGSFILEHANDLE "INPUT=".catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";  #InFile
	    }
	    say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	}
    }
    else {  #only 1 infile - rename sample instead of merge to streamline handling of filenames downstream

	## Rename samples
	say $FILEHANDLE "## Renaming sample instead of merge to streamline handling of filenames downstream";

	## Create file commands for xargs
	($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
								 XARGSFILEHANDLE => $XARGSFILEHANDLE,
								 file_name => $file_name,
								 program_info_path => $program_info_path,
								 core_number => $core_number,
								 first_command => "mv",
								 xargs_file_counter => $xargs_file_counter,
								});

	## Split per contig
	foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

	  INFILES:
	    foreach my $infile (@{ $infile_lane_no_ending_href->{$$sample_id_ref} }) {

		print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";  #InFile
		print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$sample_id_ref."_lanes_".$lanes.$outfile_tag."_".$contig.".bam")." ";  #OutFile
		print $XARGSFILEHANDLE "; ";
		print $XARGSFILEHANDLE "samtools index ";
		print $XARGSFILEHANDLE catfile($$temp_directory_ref, $$sample_id_ref."_lanes_".$lanes.$outfile_tag."_".$contig.".bam")." ";
	    }
	    print $XARGSFILEHANDLE "\n";
	}
    }

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

	    $sample_info_href->{sample}{$$sample_id_ref}{most_complete_bam}{path} = catfile($outsample_directory, $$sample_id_ref."_lanes_".$lanes.$outfile_tag.".bam");
	}
    }

    ## Merge previously merged files with merged files generated this run
    if ( ($file_info_href->{$$sample_id_ref}{picardtools_mergesamfiles_previous_bams})
	 && (scalar( @{ $infile_lane_no_ending_href->{$$sample_id_ref} }) > 1) ) {

      PREVIOUS_FILES_TO_MERGE:
	foreach my $merge_file (@{ $active_parameter_href->{picardtools_mergesamfiles_previous_bams} }) {

	    if ($merge_file =~ /$$sample_id_ref/) {  #Look for sample_id in previously generated file to be merged with current run to be able to merge correct files within sample_id
		
		## Copy file(s) to temporary directory
		say $FILEHANDLE "## Copy file(s) to temporary directory";
		my $picardtools_mergesamfiles_previous_bams_file = migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
											 path => $merge_file,
											 temp_directory => $$temp_directory_ref
											});
		say $FILEHANDLE "wait", "\n";

		if ($merge_file =~ /lane(\d+)|s_(\d+)/) {  #Look for lanes_ or lane\d in previously generated file to be merged with current run to be able to extract previous lanes

		    my $merge_lanes; if($1) {$merge_lanes = $1;} else {$merge_lanes = $2;}  #Make sure to always supply lanes from previous regexp

		    ## Removes ".file_ending" in filename.FILENDING(.gz)
		    my $picardtools_mergesamfiles_previous_bams_file_noending = remove_file_ending({file_name_ref => \$picardtools_mergesamfiles_previous_bams_file,
												    file_ending => ".bam",
												   });

		    ## Split BAMs using Samtools
		    say $FILEHANDLE "## Split alignment files per contig";
		    ($xargs_file_counter, $xargs_file_name) = split_bam_sambamba({active_parameter_href => $active_parameter_href,
										  contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
										  FILEHANDLE => $FILEHANDLE,
										  XARGSFILEHANDLE => $XARGSFILEHANDLE,
										  file_name => $file_name,
										  program_info_path => $program_info_path,
										  core_number => $core_number,
										  xargs_file_counter => $xargs_file_counter,
										  temp_directory_ref => $temp_directory_ref,
										  infile => $picardtools_mergesamfiles_previous_bams_file_noending
										 });

		    ## picardtools_mergesamfiles
		    say $FILEHANDLE "## Merging alignment files";

		    $core_number = floor($active_parameter_href->{node_ram_memory} / 4);  #Division by X according to java Heap size
		    $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
							   core_number => $core_number,
							  });  #To not exceed maximum

		    ## Create file commands for xargs
		    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
									     XARGSFILEHANDLE => $XARGSFILEHANDLE,
									     file_name => $file_name,
									     program_info_path => $program_info_path,
									     core_number => $core_number,
									     xargs_file_counter => $xargs_file_counter,
									     first_command => "java",
									     memory_allocation => "Xmx4g",
									     java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
									     java_temporary_directory => $$temp_directory_ref,
									     java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
									    });

		    ## Split per contig
		    foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

			print $XARGSFILEHANDLE "MergeSamFiles ";
			print $XARGSFILEHANDLE "USE_THREADING=TRUE "; #Create a background thread to encode, compress and write to disk the output file
			print $XARGSFILEHANDLE "CREATE_INDEX=TRUE ";  #Create a BAM index when writing a coordinate-sorted BAM file.
			print $XARGSFILEHANDLE "OUTPUT=".catfile($$temp_directory_ref, $$sample_id_ref."_lanes_".$merge_lanes.$lanes.$outfile_tag."_".$contig.".bam")." ";  #OutFile
			print $XARGSFILEHANDLE "INPUT=".catfile($$temp_directory_ref, $$sample_id_ref."_lanes_".$lanes.$outfile_tag."_".$contig.".bam")." ";  #InFile from previous merge
			print $XARGSFILEHANDLE "INPUT=".catfile($$temp_directory_ref, $picardtools_mergesamfiles_previous_bams_file_noending."_".$contig.".bam")." ";  #$merge_lanes contains lane info on previous merge, $infile_lane_no_ending{$$sample_id_ref}[0] uses @RG for very first .bam file to include read group for subsequent merges. Complete path.
			say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		    }

		    if ( ! $$reduce_io_ref) {

			## Copies file from temporary directory. Per contig
			say $FILEHANDLE "## Copy file from temporary directory";
			($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
											      XARGSFILEHANDLE => $XARGSFILEHANDLE,
											      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
											      file_name =>$file_name,
											      program_info_path => $program_info_path,
											      core_number => $core_number,
											      xargs_file_counter => $xargs_file_counter,
											      outfile => $$sample_id_ref."_lanes_".$merge_lanes.$lanes.$outfile_tag,
											      outdirectory => $outsample_directory,
											      temp_directory => $$temp_directory_ref,
											      file_ending => ".b*",
											     });
		    }
		    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

			if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

			    $sample_info_href->{sample}{$$sample_id_ref}{most_complete_bam}{path} = catfile($outsample_directory, $$sample_id_ref."_lanes_".$merge_lanes.$lanes.$outfile_tag.".bam");
			}
		    }
		}
	    }
	}
    }

    ## Merge files previously merged to single file with single file generated this run
    elsif ($file_info_href->{$$sample_id_ref}{picardtools_mergesamfiles_previous_bams}) {

      PREVIOUS_FILES_TO_MERGE:
	foreach my $merge_file (@{ $active_parameter_href->{picardtools_mergesamfiles_previous_bams} }) {

	    ## Copy file(s) to temporary directory
	    say $FILEHANDLE "## Copy file(s) to temporary directory";
	    my $picardtools_mergesamfiles_previous_bams_file = migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
										     path => $merge_file,
										     temp_directory => $$temp_directory_ref
										    });
	    say $FILEHANDLE "wait", "\n";

	    if ($merge_file =~ /lane(\d+)|s_(\d+)/) {  #Look for lanes_ or lane\d in previously generated file to be merged with current run to be able to extract previous lanes

		my $merge_lanes; if($1) {$merge_lanes = $1;} else {$merge_lanes = $2;}  #Make sure to always supply lanes from previous regexp
		my $infile = $infile_lane_no_ending_href->{$$sample_id_ref}[0];  #Can only be 1 element in array due to previous if statement

		## picardtools_mergesamfiles
		say $FILEHANDLE "## Merging alignment files";

		$core_number = floor($active_parameter_href->{node_ram_memory} / 4);  #Division by X according to java Heap size
		$core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
						       core_number => $core_number,
						      });  #To not exceed maximum

		## Removes ".file_ending" in filename.FILENDING(.gz)
		my $picardtools_mergesamfiles_previous_bams_file_noending = remove_file_ending({file_name_ref => \$picardtools_mergesamfiles_previous_bams_file,
												file_ending => ".bam",
											       });

		## Split BAMs using Samtools
		say $FILEHANDLE "## Split alignment files per contig";
		($xargs_file_counter, $xargs_file_name) = split_bam_sambamba({active_parameter_href => $active_parameter_href,
									      contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
									      FILEHANDLE => $FILEHANDLE,
									      XARGSFILEHANDLE => $XARGSFILEHANDLE,
									      file_name => $file_name,
									      program_info_path => $program_info_path,
									      core_number => $core_number,
									      xargs_file_counter => $xargs_file_counter,
									      temp_directory_ref => $temp_directory_ref,
									      infile => $picardtools_mergesamfiles_previous_bams_file_noending
									     });

		## Create file commands for xargs
		($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
									 XARGSFILEHANDLE => $XARGSFILEHANDLE,
									 file_name => $file_name,
									 program_info_path => $program_info_path,
									 core_number => $core_number,
									 xargs_file_counter => $xargs_file_counter,
									 first_command => "java",
									 memory_allocation => "Xmx4g",
									 java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
									 java_temporary_directory => $$temp_directory_ref,
									 java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
									});

		## Split per contig
		foreach my $contig (@{ $file_info_href->{contigs_size_ordered} }) {

		    print $XARGSFILEHANDLE "MergeSamFiles ";
		    print $XARGSFILEHANDLE "USE_THREADING=TRUE "; #Create a background thread to encode, compress and write to disk the output file
		    print $XARGSFILEHANDLE "CREATE_INDEX=TRUE ";  #create a BAM index when writing a coordinate-sorted BAM file.
		    print $XARGSFILEHANDLE "OUTPUT=".catfile($$temp_directory_ref, $$sample_id_ref."_lanes_".$merge_lanes.$lanes.$outfile_tag."_".$contig.".bam")." ";  #OutFile
		    print $XARGSFILEHANDLE "INPUT=".catfile($$temp_directory_ref, $infile.$infile_tag."_".$contig.".bam")." ";  #InFile
		    print $XARGSFILEHANDLE "INPUT=".catfile($$temp_directory_ref, $picardtools_mergesamfiles_previous_bams_file_noending."_".$contig.".bam")." ";  #$merge_lanes contains lane info on previous merge, $infile_lane_no_ending{$$sample_id_ref}[0] uses @RG for very first .bam file to include read group for subsequent merges. Complete path.
		    say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
		}

		if ( ! $$reduce_io_ref) {

		    ## Copies file from temporary directory. Per contig
		    say $FILEHANDLE "## Copy file from temporary directory";
		    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
											  XARGSFILEHANDLE => $XARGSFILEHANDLE,
											  contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
											  file_name =>$file_name,
											  program_info_path => $program_info_path,
											  core_number => $core_number,
											  xargs_file_counter => $xargs_file_counter,
											  outfile => $$sample_id_ref."_lanes_".$merge_lanes.$lanes.$outfile_tag,
											  outdirectory => $outsample_directory,
											  temp_directory => $$temp_directory_ref,
											  file_ending => ".b*",
											 });
		}
		if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

		    if ( ! $$reduce_io_ref) {  #Run as individual sbatch script

			$sample_info_href->{sample}{$$sample_id_ref}{most_complete_bam}{path} = catfile($outsample_directory, $$sample_id_ref."_lanes_".$merge_lanes.$lanes.$outfile_tag.".bam");
		    }
		}
	    }
	}
    }
    else {

	if ( ! $$reduce_io_ref) {

	    ## Copies file from temporary directory. Per contig
	    say $FILEHANDLE "## Copy file from temporary directory";
	    ($xargs_file_counter, $xargs_file_name) = xargs_migrate_contig_files({FILEHANDLE => $FILEHANDLE,
										  XARGSFILEHANDLE => $XARGSFILEHANDLE,
										  contigs_ref => \@{ $file_info_href->{contigs_size_ordered} },
										  file_name =>$file_name,
										  program_info_path => $program_info_path,
										  core_number => $core_number,
										  xargs_file_counter => $xargs_file_counter,
										  outfile => $$sample_id_ref."_lanes_".$lanes.$outfile_tag,
										  outdirectory => $outsample_directory,
										  temp_directory => $$temp_directory_ref,
										  file_ending => ".b*",
										 });
	}
    }

    close($XARGSFILEHANDLE);

    ## Add merged infile name after merging all BAM files per sample_id
    add_merged_infile_name({active_parameter_href => $active_parameter_href,
			    file_info_href => $file_info_href,
			    lane_href => $lane_href,
			    infile_lane_no_ending_href => $infile_lane_no_ending_href,
			    sample_id => $$sample_id_ref,
			   });

    if ( ! $$reduce_io_ref) {

	close($FILEHANDLE);

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			sample_id => $$sample_id_ref,
			dependencies => "case_dependency",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name
		       });
	}
    }
    else {

	remove_files_at_temp({active_parameter_href => $active_parameter_href,
			      files_ref => \@{ $infile_lane_no_ending_href->{$$sample_id_ref} },
			      extract_files_ref => \@{ $infile_lane_no_ending_href->{$$sample_id_ref} },
			      FILEHANDLE => $FILEHANDLE,
			      insample_directory => $insample_directory,
			      core_number => $core_number,
			      infile_tag => $infile_tag,
			      file_ending => "*",
			     });
	return $xargs_file_counter;  #Track the number of created xargs scripts per module
    }
}


sub bwa_sampe {

##bwa_sampe

##Function : Perform alignment of BWA Aln index reads using BWA sampe.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_href, $indir_path_href, $infile_lane_no_ending_href, $infile_both_strands_no_ending_href, $job_id_href, $sample_id, $outaligner_dir, $program_name
##         : $parameter_href                     => The parameter hash {REF}
##         : $active_parameter_href              => The active parameters for this analysis hash {REF}
##         : $sample_info_href                   => Info on samples and family hash {REF}
##         : $infile_href                        => The infiles hash {REF}
##         : $indir_path_href                    => The indirectories path(s) hash {REF}
##         : $infile_lane_no_ending_href         => The infile(s) without the ".ending" {REF}
##         : $infile_both_strands_no_ending_href => The infile(s) without the ".ending" and strand info {REF}
##         : $job_id_href                        => The job_id hash {REF}
##         : $sample_id                          => The sample_id
##         : $outaligner_dir                     => The outaligner_dir used in the analysis
##         : $program_name                       => The program name

    my $parameter_href = $_[0];
    my $active_parameter_href = $_[1];
    my $sample_info_href = $_[2];
    my $infile_href = $_[3];
    my $indir_path_href = $_[4];
    my $infile_lane_no_ending_href = $_[5];
    my $infile_both_strands_no_ending_href = $_[6];
    my $job_id_href = $_[7];
    my $sample_id = $_[8];
    my $outaligner_dir = $_[9];
    my $program_name = $_[10];

    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};
    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time=0;
    my $infile_size;
    my $paired_end_tracker = 0;

    while ( my ($infile_no_ending_index, $infile_no_ending) = each (@{ $infile_lane_no_ending_href->{$sample_id} }) ) {  #For all files from BWA aln but process in the same command i.e. both reads per align call

	if ($consensus_analysis_type eq "wgs") {

	    $time = 40;
	}
	else {

	    $time = 20;
	}

	my $core_number = 2;
	my $sequence_run_mode = $sample_info_href->{sample}{$sample_id}{file}{$infile_no_ending}{sequence_run_type};  #Collect paired-end or single-end sequence run mode

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
						 job_id_href => $job_id_href,
						 FILEHANDLE => $FILEHANDLE,
						 directory_id => $sample_id,
						 program_name => $program_name,
						 program_directory => lc($outaligner_dir),
						 core_number => $core_number,
						 process_time => $time,
						 temp_directory => $active_parameter_href->{temp_directory}
						});

	## Assign directories
	my $fastq_insample_directory = $indir_path_href->{$sample_id};
	my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, "bwa");
	my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, "bwa");
	$parameter_href->{"p".$program_name}{$sample_id}{indirectory} = $outsample_directory;  #Used downstream

	my $infile = $infile{$sample_id}[$paired_end_tracker]; #For required .fastq file

	## Copies files from source to temporary folder. Loop over files specified by $files_ref and collects files from $extract_files_ref.
	migrate_files_to_temp({active_parameter_href => $active_parameter_href,
			       files_ref => \@{ $infile_href->{$sample_id} },
			       extract_files_ref => \@{ $infile_href->{$sample_id} },
			       FILEHANDLE => $FILEHANDLE,
			       insample_directory => $fastq_insample_directory,
			       core_number => $core_number
			      });  #Fastq files
	migrate_files_to_temp({active_parameter_href => $active_parameter_href,
			       files_ref => \@{ $infile_both_strands_no_ending_href->{$sample_id} },
			       extract_files_ref => \@{ $infile_both_strands_no_ending_href->{$sample_id} },
			       FILEHANDLE => $FILEHANDLE,
			       insample_directory => $insample_directory,
			       core_number => $core_number,
			       file_ending => ".sai*",
			      });

	## BWA Sampe
	say $FILEHANDLE "## Aligning reads";
	print $FILEHANDLE "bwa sampe ";
	print $FILEHANDLE q?-r "@RG\t?;
	print $FILEHANDLE q?ID:?.$infile_no_ending.q?\t?;
	print $FILEHANDLE q?SM:?.$sample_id.q?\t?;
	print $FILEHANDLE q?PL:?.$active_parameter_href->{platform}.q?" ?;  #Read group header line
	print $FILEHANDLE $active_parameter_href->{human_genome_reference}." ";  #Reference
	print $FILEHANDLE catfile($active_parameter_href->{temp_directory}, $infile_both_strands_no_ending_href->{$sample_id}[$paired_end_tracker].".sai")." ";  #Read 1

	if ( $sequence_run_mode eq "paired_end") {

	    $paired_end_tracker = $paired_end_tracker+1;  #Increment to collect correct read 2 from %infile
	    print $FILEHANDLE catfile($active_parameter_href->{temp_directory}, $infile_both_strands_no_ending_href->{$sample_id}[$paired_end_tracker].".sai")." ";  #Read 2
	}

	print $FILEHANDLE catfile($active_parameter_href->{temp_directory}, $infile)." ";  #Fastq read 1

	if ( $sequence_run_mode eq "paired_end") {

	    print $FILEHANDLE catfile($active_parameter_href->{temp_directory}, $infile_href->{$sample_id}[$paired_end_tracker])." ";  #Fastq read 2
	}

	say $FILEHANDLE "> ".catfile($active_parameter_href->{temp_directory}, $infile_no_ending.".sam"), "\n";  #Outfile (SAM)

	## Convert SAM to BAM using samtools view
	say $FILEHANDLE "## Convert SAM to BAM";
	print $FILEHANDLE "samtools view -bS ".catfile($active_parameter_href->{temp_directory}, $infile_no_ending.".sam")." ";  #Infile (SAM)
	say $FILEHANDLE "> ".catfile($active_parameter_href->{temp_directory}, $infile_no_ending.".bam"), "\n";  #Outfile (BAM)

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	migrate_file_from_temp({temp_path => catfile($active_parameter_href->{temp_directory}, $infile_no_ending.".bam"),
				file_path => $outsample_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
	say $FILEHANDLE "wait", "\n";

	close($FILEHANDLE);

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    $sample_info_href->{sample}{$sample_id}{most_complete_bam}{path} = catfile($outsample_directory, $infile_no_ending.".bam");

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			sample_id => $sample_id,
			dependencies => "sample_id_dependency_step_in_parallel",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name,
			sbatch_script_tracker => $infile_no_ending_index,
		       });
	}
	$paired_end_tracker++;
    }
}


sub bwa_aln {

##bwa_aln

##Function : Generates BWA aln index on fastq files.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_href, $indir_path_href, $infile_lane_no_ending_href, $infile_both_strands_no_ending_href, $job_id_href, $sample_id, $outaligner_dir, $program_name
##         : $parameter_href                     => The parameter hash {REF}
##         : $active_parameter_href              => The active parameters for this analysis hash {REF}
##         : $sample_info_href                   => Info on samples and family hash {REF}
##         : $infile_href                        => The infiles hash {REF}
##         : $indir_path_href                    => The indirectories path(s) hash {REF}
##         : $infile_lane_no_ending_href         => The infile(s) without the ".ending" {REF}
##         : $infile_both_strands_no_ending_href => The infile(s) without the ".ending" and strand info {REF}
##         : $job_id_href                        => The job_id hash {REF}
##         : $sample_id                          => The sample_id
##         : $outaligner_dir                     => The outaligner_dir used in the analysis
##         : $program_name                       => The program name

    my $parameter_href = $_[0];
    my $active_parameter_href = $_[1];
    my $sample_info_href = $_[2];
    my $infile_href = $_[3];
    my $indir_path_href = $_[4];
    my $infile_lane_no_ending_href = $_[5];
    my $infile_both_strands_no_ending_href = $_[6];
    my $job_id_href = $_[7];
    my $sample_id = $_[8];
    my $outaligner_dir = $_[9];
    my $program_name = $_[10];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = ceil(2.5*scalar( @{ $infile_lane_no_ending_href->{$sample_id} }));  #One full lane on Hiseq takes approx. 2,5 h for bwa_aln to process, round up to nearest full hour.
    my $core_number = 0;

    foreach my $infile (@{ $infile_lane_no_ending_href->{$sample_id} }) {  #For all files

	## Adjust the number of cores to be used in the analysis according to sequencing mode requirements.
	adjust_core_number_to_seq_mode({core_number_ref => \$core_number,
					sequence_run_type_ref => \$sample_info_href->{sample}{$sample_id}{file}{$infile}{sequence_run_type},
				       });
    }

    ## Set the number of cores to allocate per sbatch job.
    $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					   core_number => $core_number,
					  });  #Make sure that the number of cores does not exceed maximum after incrementing above

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $sample_id,
					     program_name => $program_name,
					     program_directory => lc($outaligner_dir),
					     core_number => $core_number,
					     process_time => $time,
					     temp_directory => $active_parameter_href->{temp_directory}
					    });

    ## Assign directories
    my $insample_directory =  $indir_path_href->{$sample_id};
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, lc($outaligner_dir));
    $parameter_href->{"p".$program_name}{$sample_id}{indirectory} = $outsample_directory;  #Used downstream

    ## Copies files from source to temporary folder. Loop over files specified by $files_ref and collects files from $extract_files_ref
    migrate_files_to_temp({active_parameter_href => $active_parameter_href,
			   files_ref => \@{ $infile_href->{$sample_id} },
			   extract_files_ref => \@{ $infile_href->{$sample_id} },
			   FILEHANDLE => $FILEHANDLE,
			   insample_directory => $insample_directory,
			   core_number => $core_number,
			  });

    ## BWA Aln
    say $FILEHANDLE "## Creating .sai index";
    my $core_counter = 1;
    while ( my ($infile_counter_index, $infile) = each (@{ $infile_href->{$sample_id} }) ) {

	print_wait({counter_ref => \$infile_counter_index,
		    core_number_ref => \$core_number,
		    core_counter_ref => \$core_counter,
		    FILEHANDLE => $FILEHANDLE,
		   });

	print $FILEHANDLE "bwa aln ";
	print $FILEHANDLE "-k 1 ";  #maximum differences in the seed
	print $FILEHANDLE "-t 4 ";  #number of threads
	print $FILEHANDLE "-n 3 ";  #max diff (int) or missing prob under 0.02 err rate (float)
	print $FILEHANDLE "-q ".$active_parameter_href->{bwa_aln_quality_trimming}." ";  #Quality trimming
	print $FILEHANDLE $active_parameter_href->{human_genome_reference}." ";  #Reference
	print $FILEHANDLE catfile($active_parameter_href->{temp_directory}, $infile)." ";  #InFile
	say $FILEHANDLE "> ".catfile($active_parameter_href->{temp_directory}, $infile_both_strands_no_ending_href->{$sample_id}[$infile_counter_index].".sai")." &\n";  #OutFile
    }
    say $FILEHANDLE "wait", "\n";

    ## Copies files from temporary folder to source. Loop over files specified by $files_ref and collects files from $extract_files_ref.
    migrate_files_from_temp({files_ref => \@{ $infile_both_strands_no_ending_href->{$sample_id} },
			     extract_files_ref => \@{ $infile_both_strands_no_ending_href->{$sample_id} },
			     outsample_directory => $outsample_directory,
			     temp_directory => $active_parameter_href->{temp_directory},
			     core_number => $core_number,
			     file_ending => ".sai",
			     FILEHANDLE => $FILEHANDLE,
			    });

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $sample_id,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}

sub picardtools_mergerapidreads {

##picardtools_mergerapidreads

##Function : Merges all batch read processes to one file using Picardtools mergesamfiles within each sampleid. The read batch proccessed files have to be sorted before attempting to merge.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $sample_id, $program_name, $outaligner_dir_ref, $temp_directory_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $temp_directory_ref         => The temporary directory {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$sample_id_ref,
					     program_name => $program_name,
					     program_directory => lc($$outaligner_dir_ref),
					     core_number => $active_parameter_href->{core_processor_number},
					     process_time => 20,
					    });

    ## Assign directories
    my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);

    ## Assign file_tags
    my $infile_tag = $file_info_href->{$$sample_id_ref}{pbwa_mem}{file_tag};
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    my $core_counter = 1;
    my $core_tracker=0;  #Required to portion out cores and files before wait and to track the MOS_BU outfiles to correct lane

    for (my $infile_counter=0;$infile_counter<scalar( @{ $infile_lane_no_ending_href->{$$sample_id_ref} });$infile_counter++) {  #For all files from

	my $infile = $infile_lane_no_ending_href->{$$sample_id_ref}[$infile_counter];
	my $nr_read_batch_process = $sample_info_href->{sample}{$$sample_id_ref}{$infile_lane_no_ending_href->{$$sample_id_ref}[$infile_counter]}{pbwa_mem}{read_batch_process};

	if ($nr_read_batch_process > 0) {  #Check that we have read batch processes to merge

	    print_wait({counter_ref => \$core_tracker,
			core_number_ref => \$active_parameter_href->{core_processor_number},
			core_counter_ref => \$core_counter,
			FILEHANDLE => $FILEHANDLE,
		       });

	    for (my $read_batch_processes_count=0;$read_batch_processes_count<$nr_read_batch_process;$read_batch_processes_count++) {

		if ($read_batch_processes_count eq 0) {

		    java_core({FILEHANDLE => $FILEHANDLE,
			       memory_allocation => "Xmx4g",
			       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
			       java_temporary_directory => $active_parameter_href->{temp_directory},
			       java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
			      });

		    print $FILEHANDLE "MergeSamFiles ";
		    print $FILEHANDLE "USE_THREADING=TRUE "; #Create a background thread to encode, compress and write to disk the output file
		    print $FILEHANDLE "CREATE_INDEX=TRUE ";  #Create a BAM index when writing a coordinate-sorted BAM file.
		    print $FILEHANDLE "OUTPUT=".catfile($outsample_directory, $infile_lane_no_ending_href->{$$sample_id_ref}[$infile_counter].$outfile_tag.".bam")." ";  #OutFile
		}
		print $FILEHANDLE "INPUT=".catfile($insample_directory, $infile_lane_no_ending_href->{$$sample_id_ref}[$infile_counter]."_".$read_batch_processes_count.$outfile_tag.".bam")." ";  #InFile(s)
	    }
	    say $FILEHANDLE "& ","\n";
	    $core_tracker++;  #Track nr of merge calls for infiles so that wait can be printed at the correct intervals (dependent on $active_parameter_href->{core_processor_number})
	}
	else {  #Still needs to rename file to be included in potential merge of BAM files in next step

	    java_core({FILEHANDLE => $FILEHANDLE,
		       memory_allocation => "Xmx4g",
		       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		       java_temporary_directory => $active_parameter_href->{temp_directory},
		       java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
		      });

	    print $FILEHANDLE "MergeSamFiles ";
	    print $FILEHANDLE "USE_THREADING=TRUE ";  #Create a background thread to encode, compress and write to disk the output file
	    print $FILEHANDLE "CREATE_INDEX=TRUE ";  #Create a BAM index when writing a coordinate-sorted BAM file.
	    print $FILEHANDLE "INPUT=".catfile($insample_directory, $infile_lane_no_ending_href->{$$sample_id_ref}[$infile_counter]."_0".$outfile_tag."_rg.bam")." ";  #InFile
	    say $FILEHANDLE "OUTPUT=".catfile($outsample_directory, $infile_lane_no_ending_href->{$$sample_id_ref}[$infile_counter].$outfile_tag.".bam")." &";  #OutFile
	}
    }
    say $FILEHANDLE "wait", "\n";

    ## Remove Temp Directory
    remove_directory({directory_ref => \$active_parameter_href->{temp_directory},
		      FILEHANDLE => $FILEHANDLE,
		     });
    
    close($FILEHANDLE);
    
    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub bwa_mem {

##bwa_mem

##Function : Performs alignment.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_href, $indir_path_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, $family_id_ref, $outaligner_dir_ref, $temp_directory_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file info hash {REF}
##         : $infile_href                => The infiles hash {REF}
##         : $indir_path_href            => The indirectories path(s) hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $temp_directory_ref         => The temporary directory

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_href;
    my $indir_path_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;
    
    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_href},
	indir_path_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$indir_path_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};
    my $time = 30;
    my $infile_size;
    my $total_sbatch_counter = 0;
    my $paired_end_tracker = 0;  #Too avoid adjusting infile_index in submitting to jobs

    ## Assign directories
    my $insample_directory = $indir_path_href->{$$sample_id_ref};
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{$$sample_id_ref}{indirectory} = $outsample_directory;  #Used downstream
 
    ## Assign file_tags
    my $outfile_tag = $file_info_href->{$$sample_id_ref}{"p".$program_name}{file_tag};

    ## Collect fastq file(s) size and interleaved info
    while ( my ($infile_index, $infile_no_ending) = each(@{ $infile_lane_no_ending_href->{$$sample_id_ref} }) ) {

	## Assign file alias
	my $outfile_path_no_ending = catfile($$temp_directory_ref, $infile_no_ending.$outfile_tag);
	my $sequence_run_mode = $sample_info_href->{sample}{$$sample_id_ref}{file}{$infile_no_ending}{sequence_run_type};  #Collect paired-end or single-end sequence run mode

	my $interleaved_fastq_file = $sample_info_href->{sample}{$$sample_id_ref}{file}{$infile_no_ending}{interleaved};
	my $fastq_file_first = $infile_href->{$$sample_id_ref}[$infile_index];
	my $fastq_file_second;  #Initiate

	## Fastq.gz
	if ($fastq_file_first =~/.fastq.gz$/) {  #Files are already gz and presently the scalar for compression has not been investigated. Therefore no automatic time allocation can be performed.

	    if ($sample_info_href->{sample}{$$sample_id_ref}{file}{$infile_no_ending}{sequence_run_type} eq "paired_end") {  #Second read direction if present
		$fastq_file_second = $infile_href->{$$sample_id_ref}[$infile_index+$infile_index];
                $infile_size = -s catfile($insample_directory, $fastq_file_second);
	    }
	    else {  #Single_end

                $infile_size = -s catfile($insample_directory, $fastq_file_first);
	    }
        }
        else {  #Files are in fastq format

	    if ($sample_info_href->{sample}{$$sample_id_ref}{file}{$infile_no_ending}{sequence_run_type} eq "paired_end") {  #Second read direction if present
		$fastq_file_second = $infile_href->{$$sample_id_ref}[$infile_index+$infile_index];
		$infile_size = -s catfile($insample_directory, $fastq_file_second);  # collect .fastq file size to enable estimation of time required for aligning, +1 for syncing multiple infiles per sample_id. Hence, filesize will be calculated on read2 (should not matter).
	    }
	    else {  #Single_end

                $infile_size = -s catfile($insample_directory, $fastq_file_first);
	    }
        }

	## Parallelize alignment by spliting of alignment processes as the files are read
	if ($consensus_analysis_type eq "rapid") {

	    my $seq_length = $sample_info_href->{sample}{$$sample_id_ref}{file}{$infile_no_ending}{sequence_length};
	    my ($number_nodes, $read_nr_of_lines) = determine_nr_of_rapid_nodes({seq_length => $seq_length,
										 infile_size => $infile_size,
										});

	    for (my $sbatch_counter=0;$sbatch_counter<$number_nodes-1;$sbatch_counter++) {  #Parallization for each file handled

		## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
		my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
									     job_id_href => $job_id_href,
									     FILEHANDLE => $FILEHANDLE,
									     directory_id => $$sample_id_ref,
									     program_name => $program_name,
									     program_directory => lc($$outaligner_dir_ref),
									     core_number => $active_parameter_href->{core_processor_number},
									     process_time => $time,
									     sleep => 1,  #Let process sleep randomly for 0-60 seconds to avoid race condition
									    });
		my ($volume, $directory, $stderr_file) = File::Spec->splitpath($program_info_path.".stderr.txt");  #Split to enable submission to &sample_info_qc later

		my $read_start = $sbatch_counter *  $read_nr_of_lines;  #Constant for gz files
		my $read_stop = $read_start + ceil( $read_nr_of_lines + 1);  #Constant for gz files

		my $infile;

		if ($sequence_run_mode eq "paired_end") {  #Second read direction if present

		    $infile = $fastq_file_second;  #For required .fastq file
                }
                else {  #Single_end

		    $infile = $fastq_file_first;  #For required .fastq file
                }

		## BWA Mem for each read batch
		print $FILEHANDLE "bwa mem ";
		print $FILEHANDLE "-M ";  #Mark shorter split hits as secondary (for Picard compatibility).
		print $FILEHANDLE "-t ".$active_parameter_href->{core_processor_number}." ";  #Number of threads

		if ($interleaved_fastq_file) {

		    print $FILEHANDLE "-p ";  #interleaved fastq mode
		}

		## Read group header line
		print $FILEHANDLE q?-R "@RG\t?;
		print $FILEHANDLE q?ID:?.$infile_no_ending.q?\t?;
		print $FILEHANDLE q?SM:?.$$sample_id_ref.q?\t?;
		print $FILEHANDLE q?PL:?.$active_parameter_href->{platform}.q?" ?;

		print $FILEHANDLE $active_parameter_href->{human_genome_reference}." ";  #Reference
		print $FILEHANDLE "<( ";  #Pipe to BWA Mem (Read 1)
		print $FILEHANDLE "zcat ";  #Decompress Read 1
		print $FILEHANDLE catfile($insample_directory, $infile)." ";  #Read 1
		print $FILEHANDLE "| ";  #Pipe
		print $FILEHANDLE q?perl -ne 'if ( ($.>?.$read_start.q?) && ($.<?.$read_stop.q?) ) {print $_;}' ?;  #Limit to sbatch script interval
		print $FILEHANDLE ") ";  #End Read 1

		if ($sequence_run_mode eq "paired_end") {  #Second read direction if present

		    print $FILEHANDLE "<( ";  #Pipe to BWA Mem (Read 2)
		    print $FILEHANDLE "zcat ";  #Decompress Read 2
		    print $FILEHANDLE catfile($insample_directory, $infile_href->{$$sample_id_ref}[$infile_index+$infile_index+1])." ";  #Read 2
		    print $FILEHANDLE "| ";  #Pipe
		    print $FILEHANDLE q?perl -ne 'if ( ($.>?.$read_start.q?) && ($.<?.$read_stop.q?) ) {print $_;}' ?;  #Limit to sbatch script interval
		    print $FILEHANDLE ") ";  #End Read 2
		}

		print $FILEHANDLE "| ";  #Pipe SAM to BAM conversion of aligned reads
		print $FILEHANDLE "samtools view ";
		print $FILEHANDLE "-S ";  #Input is SAM
		print $FILEHANDLE "-h ";  #Print header for the SAM output
		print $FILEHANDLE "-u ";  #Uncompressed BAM output
		print $FILEHANDLE "- ";  #/dev/stdin
		print $FILEHANDLE "| ";  #Pipe
		print $FILEHANDLE "intersectBed ";  #Limit output to only clinically interesting genes
		print $FILEHANDLE "-abam stdin ";  #The A input file is in BAM format.  Output will be BAM as well.
		print $FILEHANDLE "-b ".$active_parameter_href->{bwa_mem_rapid_db}." ";  #Db file of clinically relevant variants
		say $FILEHANDLE "> ".catfile($outsample_directory, $infile_no_ending."_".$sbatch_counter.".bam"), "\n";  #Outfile (BAM)

		print $FILEHANDLE "samtools sort ";
		print $FILEHANDLE catfile($outsample_directory, $infile_no_ending."_".$sbatch_counter.".bam")." ";  #Infile
		say $FILEHANDLE catfile($outsample_directory, $infile_no_ending."_".$sbatch_counter.$outfile_tag), "\n";  #OutFile

		print $FILEHANDLE "samtools index ";
		say $FILEHANDLE catfile($outsample_directory, $infile_no_ending."_".$sbatch_counter.$outfile_tag.".bam"), "\n";  #OutFile

		close($FILEHANDLE);

		if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

		    submit_job({active_parameter_href => $active_parameter_href,
				sample_info_href => $sample_info_href,
				job_id_href => $job_id_href,
				infile_lane_no_ending_href => $infile_lane_no_ending_href,
				sample_id => $$sample_id_ref,
				dependencies => "sample_id_dependency_step_in_parallel",
				path => $parameter_href->{"p".$program_name}{chain},
				sbatch_file_name => $file_name,
				sbatch_script_tracker => $total_sbatch_counter
			       });
		}
		$total_sbatch_counter++;

                ## Save sbatch Counter to track how many read batch processes we have engaged
		$sample_info_href->{sample}{$$sample_id_ref}{ $infile_no_ending }{pbwa_mem}{read_batch_process} = $sbatch_counter+1;  #Used to be  $sbatch_counter
		$sample_info_href->{sample}{$$sample_id_ref}{pbwa_mem}{sbatch_batch_processes} = $total_sbatch_counter;
	    }
	}
	else {  #Not rapid mode align whole file

	    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
									 job_id_href => $job_id_href,
									 FILEHANDLE => $FILEHANDLE,
									 directory_id => $$sample_id_ref,
									 program_name => $program_name,
									 program_directory => lc($$outaligner_dir_ref),
									 core_number => $active_parameter_href->{core_processor_number},
									 process_time => $time,
									 temp_directory => $$temp_directory_ref,
									 sleep => 1,  #Let process sleep randomly for 0-60 seconds to avoid race condition
									});
	    my ($volume, $directory, $stderr_file) = File::Spec->splitpath($program_info_path.".stderr.txt");  #Split to enable submission to &sample_info_qc later

	    ## Copies file to temporary directory.
	    say $FILEHANDLE "## Copy file(s) to temporary directory";
	    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
				  path => catfile($insample_directory, $infile_href->{$$sample_id_ref}[$paired_end_tracker]),
				  temp_directory => $$temp_directory_ref,
				 });  #Read 1

	    if ($sequence_run_mode eq "paired_end") {  #Second read direction if present

		migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
				      path => catfile($insample_directory, $infile_href->{$$sample_id_ref}[$paired_end_tracker+1]),
				      temp_directory => $$temp_directory_ref,
				     });  #Read 2
	    }
	    say $FILEHANDLE "wait", "\n";

	    ### BWA MEM

	    ##Detect version and source of the human_genome_reference: Source (hg19 or GRCh) and return the correct bwa_mem binary
	    my $bwa_binary = select_bwamem_binary({human_genome_reference_source_ref => \$file_info_href->{human_genome_reference_source},
						   human_genome_reference_version_ref => \$file_info_href->{human_genome_reference_version},
						  });

	    say $FILEHANDLE "## Aligning reads and sorting via Sambamba";

	    print $FILEHANDLE $bwa_binary." ";

	    if ($bwa_binary eq "bwa mem") {  #Prior to ALTs in refrence genome

		print $FILEHANDLE "-M ";  #Mark shorter split hits as secondary (for Picard compatibility).
	    }
	    else {

		if ($active_parameter_href->{bwa_mem_hla}) {

		    print $FILEHANDLE "-H ";  #Apply HLA typing
		}
		print $FILEHANDLE "-o ".catfile($$temp_directory_ref, $infile_no_ending)." ";  #prefix for output files
	    }
	    print $FILEHANDLE "-t ".$active_parameter_href->{core_processor_number}." ";  #Number of threads

	    if ($interleaved_fastq_file) {

		print $FILEHANDLE "-p ";  #interleaved fastq mode
	    }

	    print $FILEHANDLE q?-R "@RG\t?;
	    print $FILEHANDLE q?ID:?.$infile_no_ending.q?\t?;
	    print $FILEHANDLE q?SM:?.$$sample_id_ref.q?\t?;
	    print $FILEHANDLE q?PL:?.$active_parameter_href->{platform}.q?" ?;  #Read group header line
	    print $FILEHANDLE $active_parameter_href->{human_genome_reference}." ";  #Reference
	    print $FILEHANDLE catfile($$temp_directory_ref, $infile_href->{$$sample_id_ref}[$paired_end_tracker])." ";  #Read 1

	    if ($sequence_run_mode eq "paired_end") {  #Second read direction if present

		$paired_end_tracker = $paired_end_tracker+1;  #Increment to collect correct read 2 from %infile
		print $FILEHANDLE catfile($$temp_directory_ref, $infile_href->{$$sample_id_ref}[$paired_end_tracker])." ";  #Read 2
	    }
	    $paired_end_tracker++;

	    if ($bwa_binary eq "bwa mem") {  #Prior to ALTs in refrence genome

		print $FILEHANDLE "| ";  #Pipe SAM to BAM conversion of aligned reads
		print $FILEHANDLE "samtools view ";
		print $FILEHANDLE "-S ";  #Input is SAM
		print $FILEHANDLE "-h ";  #Print header for the SAM output
		print $FILEHANDLE "-u ";  #Uncompressed BAM output
		print $FILEHANDLE "-@ ".$active_parameter_href->{core_processor_number}." ";  #Number of threads
		print $FILEHANDLE "- ";  #/dev/stdin
		print $FILEHANDLE "| ";
	    }
	    else {

		print $FILEHANDLE "| ";
		print $FILEHANDLE "sh ";
		say $FILEHANDLE "\n";
	    }

	    print $FILEHANDLE "sambamba ";  #Program
	    print $FILEHANDLE "sort ";  #Command
	    print $FILEHANDLE "-m ".$active_parameter_href->{bwa_sambamba_sort_memory_limit}." ";  #Memory limit
	    print $FILEHANDLE "--tmpdir=".$$temp_directory_ref." ";  #Directory for storing intermediate files
	    print $FILEHANDLE "--show-progress ";  #Show progressbar in STDERR
	    print $FILEHANDLE "--out=".$outfile_path_no_ending.".bam"." ";  #Outfile

	    if ($bwa_binary eq "bwa mem") {  #Pipe from samtools view

		say $FILEHANDLE catfile(dirname(devnull()),"stdin"),"\n";

		## BAMS, bwa_mem logs etc.
		migrate_file_from_temp({temp_path => $outfile_path_no_ending.".*",
					file_path => $outsample_directory,
					FILEHANDLE => $FILEHANDLE,
				       });
		say $FILEHANDLE "wait", "\n";
	    }
	    else {  #Sort directly from run-bwakit

		say $FILEHANDLE catfile($$temp_directory_ref, $infile_no_ending.".aln.bam"), "\n";

		## Copies file from temporary directory.
		say $FILEHANDLE "## Copy file from temporary directory";
		my @outfiles = ($outfile_path_no_ending.".b*",
				catfile($$temp_directory_ref, $infile_no_ending.".log*"),
				catfile($$temp_directory_ref, $infile_no_ending.".hla*"),
		    );
		foreach my $outfile (@outfiles) {

		    migrate_file_from_temp({temp_path => $outfile,
					    file_path => $outsample_directory,
					    FILEHANDLE => $FILEHANDLE,
					   });
		}
		say $FILEHANDLE "wait", "\n";
	    }

	    if ($active_parameter_href->{bwa_mem_bamstats}) {

		print $FILEHANDLE "samtools stats ";
		print $FILEHANDLE $outfile_path_no_ending.".bam"." ";
		print $FILEHANDLE "| ";
		print $FILEHANDLE q?perl -ne '$raw; $map; chomp($_); print $_, "\n"; if($_=~/raw total sequences:\s+(\d+)/) {$raw = $1;} elsif($_=~/reads mapped:\s+(\d+)/) {$map = $1; $p = ($map / $raw ) * 100; print "percentage mapped reads:\t".$p."\n"}' ?;
		say $FILEHANDLE "> ".$outfile_path_no_ending.".stats"." ", "\n";

		## Copies file from temporary directory.
		say $FILEHANDLE "## Copy file from temporary directory";
		migrate_file_from_temp({temp_path => $outfile_path_no_ending.".stats",
					file_path => $outsample_directory,
					FILEHANDLE => $FILEHANDLE,
				       });
		say $FILEHANDLE "wait", "\n";
	    }

	    if ($active_parameter_href->{bwa_mem_cram}) {

		say $FILEHANDLE "## Create CRAM file from BAM";
		print $FILEHANDLE "sambamba ";  #Program
		print $FILEHANDLE "view ";  #Commmand
		print $FILEHANDLE "-f cram "; #Write output to CRAM-format
		print $FILEHANDLE "-h ";  #print header before reads
		print $FILEHANDLE "-T ".$active_parameter_href->{human_genome_reference}." ";  #Reference
		print $FILEHANDLE "--output-filename ".$outfile_path_no_ending.".cram"." ";
		say $FILEHANDLE $outfile_path_no_ending.".bam", "\n";

		## Copies file from temporary directory.
		say $FILEHANDLE "## Copy file from temporary directory";
		migrate_file_from_temp({temp_path => $outfile_path_no_ending.".cram",
					file_path => $outsample_directory,
					FILEHANDLE => $FILEHANDLE,
				       });
		say $FILEHANDLE "wait", "\n";
	    }

	    close($FILEHANDLE);

	    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

		$sample_info_href->{sample}{$$sample_id_ref}{most_complete_bam}{path} = catfile($outsample_directory, $infile_no_ending.".bam");

		if ($active_parameter_href->{bwa_mem_cram}) {

		    $sample_info_href->{sample}{$$sample_id_ref}{program}{bwa}{$infile_no_ending}{path} = catfile($outsample_directory, $infile_no_ending.$outfile_tag.".cram");  #Required for analysisRunStatus check downstream
		    $sample_info_href->{sample}{$$sample_id_ref}{file}{$infile_no_ending}{cram_file} = catfile($outsample_directory, $infile_no_ending.$outfile_tag.".cram");  #Fastreference to cram file
		}
		if ($active_parameter_href->{bwa_mem_bamstats}) {

		    ## Collect QC metadata info for later use
		    sample_info_qc({sample_info_href => $sample_info_href,
				    sample_id => $$sample_id_ref,
				    program_name => "bamstats",
				    infile => $infile_no_ending,
				    outdirectory => $outsample_directory,
				    outfile_ending => $outfile_tag.".stats",
				    outdata_type => "infile_dependent"
				   });
		}

		if ($bwa_binary eq "bwa mem") {

		    sample_info_qc({sample_info_href => $sample_info_href,
				    sample_id => $$sample_id_ref,
				    program_name => "bwa",
				    infile => $infile_no_ending,
				    outdirectory => $directory,
				    outfile_ending => $stderr_file,
				    outdata_type => "info_directory"
				   });
		}
		else {

		    sample_info_qc({sample_info_href => $sample_info_href,
				    sample_id => $$sample_id_ref,
				    program_name => "Bwa",
				    infile => $infile_no_ending,
				    outdirectory => $outsample_directory,
				    outfile_ending => ".log.bwamem",
				    outdata_type => "infile_dependent"
				   });
		}
		submit_job({active_parameter_href => $active_parameter_href,
			    sample_info_href => $sample_info_href,
			    job_id_href => $job_id_href,
			    infile_lane_no_ending_href => $infile_lane_no_ending_href,
			    sample_id => $$sample_id_ref,
			    dependencies => "sample_id_dependency_step_in_parallel",
			    path => $parameter_href->{"p".$program_name}{chain},
			    sbatch_file_name => $file_name,
			    sbatch_script_tracker => $infile_index
			   });
	    }
	}
    }
}


sub mosaik_aligner {

##mosaik_aligner

##Function : Performs alignment.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_href, $indir_path_href, $infile_lane_no_ending_href, $sample_id, $outaligner_dir, $program_name
##         : $parameter_href              => The parameter hash {REF}
##         : $active_parameter_href       => The active parameters for this analysis hash {REF}
##         : $sample_info_href            => Info on samples and family hash {REF}
##         : $file_info_href              => The file info hash {REF}
##         : $infile_href                 => The infiles hash {REF}
##         : $indir_path_href             => The indirectories path(s) hash {REF}
##         : $infile_lane_no_ending_href  => The infile(s) without the ".ending" {REF}
##         : $sample_id                   => The sample_id
##         : $outaligner_dir              => The outaligner_dir used in the analysis
##         : $program_name                => The program name

    my $parameter_href = $_[0];
    my $active_parameter_href = $_[1];
    my $sample_info_href = $_[2];
    my $file_info_href = $_[3];
    my $infile_href = $_[4];
    my $indir_path_href = $_[5];
    my $infile_lane_no_ending_href = $_[6];
    my $job_id_href = $_[7];
    my $sample_id = $_[8];
    my $outaligner_dir = $_[9];
    my $program_name = $_[10];

    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};
    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $sbatch_script_tracker=0;
    my $time=0;
    my $infile_size;

    for (my $infile_counter=0;$infile_counter<scalar( @{ $infile_lane_no_ending_href->{$sample_id} });$infile_counter++) {  #For all infiles per lane

	if ($consensus_analysis_type eq "wgs") {

	    $time = 80;
	}
	else {

	    $time = 40;
	}

	my $infile = $infile_lane_no_ending_href->{$sample_id}[$infile_counter];

	## Set parameters depending on sequence length
	my $seq_length = $sample_info_href->{sample}{$sample_id}{file}{$infile}{sequence_length};
	my $act_parameter = 35;  #The alignment candidate threshold (length)
	my $bw_parameter = 35;  #Specifies the Smith-Waterman bandwidth.

	if ($seq_length <= 36) {

	    $act_parameter = 20;
	    $bw_parameter = 13;
	}
	if ($seq_length > 36 && $seq_length <= 51) {

	    $act_parameter = 25;
	    $bw_parameter = 21;
	}
	if ($seq_length > 51 && $seq_length <= 76) {

	    $bw_parameter = 29;
	}

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								     job_id_href => $job_id_href,
								     FILEHANDLE => $FILEHANDLE,
								     directory_id => $sample_id,
								     program_name => $program_name,
								     program_directory => lc($outaligner_dir),
								     core_number => $active_parameter_href->{core_processor_number},
								     process_time => $time,
								     temp_directory => $active_parameter_href->{temp_directory}
								    });
	my ($volume, $directory, $stdout_file) = File::Spec->splitpath($program_info_path."stdout.txt");  #Split to enable submission to &sample_info_qc later

	## Assign directories
	my $insample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, $outaligner_dir);
	my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $sample_id, $outaligner_dir);
	$parameter_href->{"p".$program_name}{$sample_id}{indirectory} = $outsample_directory;  #Used downstream
	my $outfile_tag = $file_info_href->{$sample_id}{"p".$program_name}{file_tag};

	## Copies file to temporary directory.
	say $FILEHANDLE "## Copy file to node";
	migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			      path => catfile($insample_directory, $infile.".dat"),
			      temp_directory => $active_parameter_href->{temp_directory}
			     });
	say $FILEHANDLE "wait", "\n";

	## mosaik_aligner
	say $FILEHANDLE "## Create node temporary MOSAIK directory";
	say $FILEHANDLE "mkdir -p ".catfile($active_parameter_href->{temp_directory}, "mosaik_tmp");
	say $FILEHANDLE "export MOSAIK_TMP=".catfile($active_parameter_href->{temp_directory}, "mosaik_tmp"), "\n";

	say $FILEHANDLE "## Generating .bam file from .dat files";
	print $FILEHANDLE "MosaikAligner ";
	print $FILEHANDLE "-ia ".catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{mosaik_align_reference})." ";  #Mosaik Reference
	print $FILEHANDLE "-annse ".catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{mosaik_align_neural_network_se_file})." ";  #NerualNetworkSE

	if ($sample_info_href->{sample}{$sample_id}{file}{ $infile_lane_no_ending_href->{$sample_id}[$infile_counter] }{sequence_run_type} eq "paired_end") {  #Second read direction if present

	    print $FILEHANDLE "-annpe ".catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{mosaik_align_neural_network_pe_file})." ";  #NerualNetwork
	    print $FILEHANDLE "-ls 100 "; #Enable local alignment search for PE reads
	}

	print $FILEHANDLE "-p ".$active_parameter_href->{core_processor_number}." ";  #Nr of cores
	print $FILEHANDLE "-hs 15 ";  #Hash size
	print $FILEHANDLE "-mm 4 ";  #The # of mismatches allowed
	print $FILEHANDLE "-mhp 100 "; #The maximum of positions stored per seed
	print $FILEHANDLE "-act ".$act_parameter." ";  #The alignment candidate threshold (length)
	print $FILEHANDLE "-bw ".$bw_parameter." ";  #Specifies the Smith-Waterman bandwidth.
	print $FILEHANDLE "-j ".catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{mosaik_jump_db_stub})." ";  #JumpDatabase
	print $FILEHANDLE "-in ".catfile($active_parameter_href->{temp_directory}, $infile.".dat")." ";  #Infile
	say $FILEHANDLE "-out ".catfile($active_parameter_href->{temp_directory}, $infile)." ";  #OutFile (mosaik_aligner appends .bam to infile name)

	## BAM to SAM conversion and sorting/indexing. Make sure that the BAM file BIN field is correct (Mosaik v.2.2.3 does according to Picard not set the bin field correctly)
	say $FILEHANDLE "## BAM to SAM";
	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx2g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $active_parameter_href->{temp_directory},
		   java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
		  });

	print $FILEHANDLE "SamFormatConverter ";
	print $FILEHANDLE "VALIDATION_STRINGENCY=SILENT ";  #Disable errors print
	print $FILEHANDLE "INPUT=".catfile($active_parameter_href->{temp_directory}, $infile.".bam")." ";  #InFile
	say $FILEHANDLE "OUTPUT=".catfile($active_parameter_href->{temp_directory}, $infile.".sam")." "; #OutFile

	## SAM to BAM conversion
	say $FILEHANDLE "## SAM to BAM";
	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx2g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $active_parameter_href->{temp_directory},
		   java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
		  });

	print $FILEHANDLE "SamFormatConverter ";
	print $FILEHANDLE "INPUT=".catfile($active_parameter_href->{temp_directory}, $infile.".sam")." ";  #InFile
	say $FILEHANDLE "OUTPUT=".catfile($active_parameter_href->{temp_directory}, $infile.".bam")." ";  #OutFile

	## Sort BAM
	say $FILEHANDLE "## Sort BAM";
	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx4g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $active_parameter_href->{temp_directory},
		   java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
		  });

	print $FILEHANDLE "SortSam ";
	print $FILEHANDLE "SORT_ORDER=coordinate ";  #Sort per contig and coordinate
	print $FILEHANDLE "CREATE_INDEX=TRUE ";  #create a BAM index when writing a coordinate-sorted BAM file.
	print $FILEHANDLE "INPUT=".catfile($active_parameter_href->{temp_directory}, $infile.".bam")." ";  #InFile
	say $FILEHANDLE "OUTPUT=".catfile($active_parameter_href->{temp_directory}, $infile.$outfile_tag.".bam");  #Outfile

	if ($active_parameter_href->{genomic_set} ne "nouser_info") {

	    ## Create Bedtools genome file
	    say $FILEHANDLE "## Create Bedtools genome file";
	    print $FILEHANDLE "cut -f1-2 ".catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{human_genome_reference}.".fai")." ";  #Contig name and length
	    say $FILEHANDLE "> ".catfile($active_parameter_href->{temp_directory}, "bedtools_genome_file.txt")." ";  #Bedtool genome file

	    ## Select alignment mapping to genetic regions
	    say $FILEHANDLE "## Select alignment mapping to genetic regions";
	    print $FILEHANDLE "bedtools intersect ";
	    print $FILEHANDLE "-abam ".catfile($active_parameter_href->{temp_directory}, $infile.$outfile_tag.".bam")." ";
	    print $FILEHANDLE "-b ".catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{genomic_set})." ";
	    print $FILEHANDLE "-wa ";
	    print $FILEHANDLE "-sorted ";
	    print $FILEHANDLE "-g ".catfile($active_parameter_href->{temp_directory}, "bedtools_genome_file.txt")." ";  #Bedtool genome file
	    say $FILEHANDLE "> ".catfile($active_parameter_href->{temp_directory}, $infile.$outfile_tag."_genetic_regions.bam")." ";  #TempFile

	    ## Move to final file name
	    say $FILEHANDLE "## Move to final file name";
	    print $FILEHANDLE "mv ";
	    print $FILEHANDLE catfile($active_parameter_href->{temp_directory}, $infile.$outfile_tag."_genetic_regions.bam")." ";  #TempFile
	    say $FILEHANDLE catfile($active_parameter_href->{temp_directory}, $infile.$outfile_tag.".bam")." ";  #OutFile

	    ## Writes java core commands to filehandle.
	    java_core({FILEHANDLE => $FILEHANDLE,
		       memory_allocation => "Xmx2g",
		       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		       java_temporary_directory => $active_parameter_href->{temp_directory},
		       java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
		      });

	    print $FILEHANDLE "BuildBamIndex ";
	    say $FILEHANDLE "INPUT=".catfile($active_parameter_href->{temp_directory}, $infile.$outfile_tag.".bam")." ";  #OutFile

	    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

		## Collect QC metadata info for later use
		$sample_info_href->{sample}{$sample_id}{most_complete_bam}{path} = catfile($outsample_directory, $infile.$outfile_tag.".bam");
	    }
	}

	## Copies file from temporary directory.
	say $FILEHANDLE "## Copy file from temporary directory";
	my @outfiles = ($infile.$outfile_tag.".b*", $infile.".stat");
	foreach my $outfile (@outfiles) {

	    migrate_file_from_temp({temp_path => catfile($active_parameter_href->{temp_directory}, $outfile),
				    file_path => $outsample_directory,
				    FILEHANDLE => $FILEHANDLE,
				   });
	}
	say $FILEHANDLE "wait", "\n";

	close($FILEHANDLE);

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    ## Collect QC metadata info for later use
	    sample_info_qc({sample_info_href => $sample_info_href,
			    sample_id => $sample_id,
			    program_name => "mosaik_aligner",
			    infile => $infile,
			    outdirectory => $directory,
			    outfile_ending => $stdout_file,
			    outdata_type => "info_directory"
			   });

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			sample_id => $sample_id,
			dependencies => "sample_id_dependency_step_in_parallel",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name,
			sbatch_script_tracker => $sbatch_script_tracker
		       });
	}
	$sbatch_script_tracker++;  #Tracks nr of sbatch scripts
    }
}


sub mosaik_build {

##mosaik_build

##Function : Generates Mosaik hash format on reads using MosaikBuild
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_href, $indir_path_href, $infile_lane_no_ending_href, $lane_href, $job_id_href, $sample_id_ref, $outaligner_dir, $program_name
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_href                => The infiles hash {REF}
##         : $indir_path_href            => The indirectories path(s) hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $lane_href                  => The lane info hash {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $outaligner_dir             => The outaligner_dir used
##         : $program_name               => The program name

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href = $arg_href->{parameter_href};
    my $active_parameter_href = $arg_href->{active_parameter_href};
    my $sample_info_href = $arg_href->{sample_info_href};
    my $infile_href = $arg_href->{infile_href};
    my $indir_path_href = $arg_href->{indir_path_href};
    my $infile_lane_no_ending_href = $arg_href->{infile_lane_no_ending_href};
    my $lane_href = $arg_href->{lane_href};
    my $job_id_href = $arg_href->{job_id_href};
    my $sample_id_ref = $arg_href->{sample_id_ref};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir};
    my $program_name = $arg_href->{program_name};

    my $temp_directory_ref = \$active_parameter_href->{temp_directory};

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 10;

    ## Set the number of cores to allocate per sbatch job.
    my $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					      core_number => scalar( @{ $lane_href->{$$sample_id_ref} } ),
					     });  #Detect the number of cores to use from lanes

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$sample_id_ref,
					     program_name => $program_name,
					     program_directory => lc($$outaligner_dir_ref),
					     core_number => $core_number,
					     process_time => $time,
					     temp_directory => $$temp_directory_ref
					    });

    ## Assign directories
    my $insample_directory = $indir_path_href->{$$sample_id_ref};
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, $$outaligner_dir_ref);
    $parameter_href->{"p".$program_name}{$$sample_id_ref}{indirectory} = $outsample_directory;  ##Used downstream

    my $core_counter = 1;
    my $paired_end_tracker = 0;
    my $st_parameter = $active_parameter_href->{platform};

    ## Copies files from source to temporary folder. Loop over files specified by $files_ref and collects files from $extract_files_ref.
    migrate_files_to_temp({active_parameter_href => $active_parameter_href,
			   sample_info_href => $sample_info_href,
			   files_ref => \@{ $infile_lane_no_ending_href->{$$sample_id_ref} },
			   extract_files_ref => \@{ $infile_href->{$$sample_id_ref} },
			   FILEHANDLE => $FILEHANDLE,
			   insample_directory => $insample_directory,
			   core_number => $core_number,
			   sample_id => $$sample_id_ref
			  });

    ## MosaikBuild
    say $FILEHANDLE "## Generating .dat file from fastq files";
    for (my $infile_counter=0;$infile_counter<scalar( @{ $infile_lane_no_ending_href->{$$sample_id_ref} });$infile_counter++) {  #For all files

	my $sequence_run_mode = $sample_info_href->{sample}{$$sample_id_ref}{file}{ $infile_lane_no_ending_href->{$$sample_id_ref}[$infile_counter] }{sequence_run_type};  #Collect paired-end or single-end sequence run mode
	my $core_tracker=0;  #Required to portion out cores and files before wait and to track the outfiles to correct lane

	print_wait({counter_ref => \$infile_counter,
		    core_number_ref => \$core_number,
		    core_counter_ref => \$core_counter,
		    FILEHANDLE => $FILEHANDLE,
		   });

	print $FILEHANDLE "MosaikBuild ";
	print $FILEHANDLE "-id ".$infile_lane_no_ending_href->{$$sample_id_ref}[$infile_counter]." ";  #Read group ID for BAM Header
	print $FILEHANDLE "-sam ".$$sample_id_ref." ";  #Sample name for BAM Header
	print $FILEHANDLE "-st ".$st_parameter." ";  #Sequencing technology for BAM Header
	print $FILEHANDLE "-mfl ".$active_parameter_href->{mosaik_build_median_frag_length}." ";  #Median Fragment Length
	print $FILEHANDLE "-q ".catfile($$temp_directory_ref, $infile_href->{$$sample_id_ref}[$paired_end_tracker])." ";  #Read 1

	if ( $sequence_run_mode eq "paired_end") {

	    $paired_end_tracker = $paired_end_tracker+1;  #Increment to collect correct read 2 from %infile
	    print $FILEHANDLE "-q2 ".catfile($$temp_directory_ref, $infile_href->{$$sample_id_ref}[$paired_end_tracker])." ";  #Read 2
	}

	$paired_end_tracker++;  #Increment to correctly track both single-end runs and paired-end runs
	say $FILEHANDLE "-out ".catfile($$temp_directory_ref, $infile_lane_no_ending_href->{$$sample_id_ref}[$infile_counter].".dat")." &\n";  #OutFile
    }
    say $FILEHANDLE "wait", "\n";

    ## Copies files from temporary folder to source. Loop over files specified by $files_ref and collects files from $extract_files_ref.
    migrate_files_from_temp({files_ref => \@{ $infile_lane_no_ending_href->{$$sample_id_ref} },
			     extract_files_ref => \@{ $infile_lane_no_ending_href->{$$sample_id_ref} },
			     outsample_directory => $outsample_directory,
			     temp_directory => $$temp_directory_ref,
			     core_number => $core_number,
			     file_ending => ".dat",
			     FILEHANDLE => $FILEHANDLE,
			    });

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub variantannotationblock {

##variantannotationblock

##Function : Run consecutive module
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $annovar_table_href, $program_name, family_id_ref, $outaligner_dir_ref, $call_type, $xargs_file_counter
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $annovar_table_href         => annovar_table_href {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type
##         : $xargs_file_counter         => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $annovar_table_href;
    my $supported_cosmid_reference_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	annovar_table_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$annovar_table_href},
	supported_cosmid_reference_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_cosmid_reference_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 80;

    ## Set the number of cores to allocate per sbatch job.
    my $core_number = $active_parameter_href->{core_processor_number};
    my $xargs_file_name;

    $log->info("\t[Prepareforvariantannotationblock]\n");

    if ($active_parameter_href->{prhocall} > 0) {  #Run rhocall. Done per family

	$log->info("\t[rhocall]\n");
    }
    if ($active_parameter_href->{pvt} > 0) {

	$log->info("\t[Vt]\n");  #Run vt. Done per family

	check_build_human_genome_prerequisites({parameter_href => $parameter_href,
						active_parameter_href => $active_parameter_href,
						sample_info_href => $sample_info_href,
						file_info_href => $file_info_href,
						infile_lane_no_ending_href => $infile_lane_no_ending_href,
						job_id_href => $job_id_href,
						supported_cosmid_reference_href => $supported_cosmid_reference_href,
						program_name => "vt",
					       });
    }
    if ($active_parameter_href->{pvarianteffectpredictor} > 0) {  #Run varianteffectpredictor. Done per family

	$log->info("\t[Varianteffectpredictor]\n");
    }
    if ($active_parameter_href->{pvcfparser} > 0) {  #Run pvcfparser. Done per family

	$log->info("\t[Vcfparser]\n");
    }
    if ($active_parameter_href->{pannovar} > 0) {  #Run annovar. Done per family

	$log->info("\t[Annovar]\n");

	check_build_human_genome_prerequisites({parameter_href => $parameter_href,
						active_parameter_href => $active_parameter_href,
						sample_info_href => $sample_info_href,
						file_info_href => $file_info_href,
						infile_lane_no_ending_href => $infile_lane_no_ending_href,
						job_id_href => $job_id_href,
						supported_cosmid_reference_href => $supported_cosmid_reference_href,
						program_name => "annovar",
					       });

	for (my $table_names_counter=0;$table_names_counter<scalar(@{ $active_parameter_href->{annovar_table_names} });$table_names_counter++) {  #For all specified table names

	    if ($parameter_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{build_file} eq 1) {

		build_annovar_prerequisites({parameter_href => $parameter_href,
					     active_parameter_href => $active_parameter_href,
					     sample_info_href => $sample_info_href,
					     infile_lane_no_ending_href => $infile_lane_no_ending_href,
					     job_id_href => $job_id_href,
					     annovar_table_href => $annovar_table_href,
					     program_name => "annovar",
					    });
		last;  #Will handle all build tables within sbatch script
	    }
	}
    }
    if ($active_parameter_href->{psnpeff} > 0) {  #Run snpEff. Done per family

	$log->info("\t[Snpeff]\n");

	check_build_download_prerequisites({parameter_href => $parameter_href,
					    active_parameter_href => $active_parameter_href,
					    sample_info_href => $sample_info_href,
					    infile_lane_no_ending_href => $infile_lane_no_ending_href,
					    job_id_href => $job_id_href,
					    supported_cosmid_reference_href => $supported_cosmid_reference_href,
					    program_name => "snpeff",
					   });
    }
    if ($active_parameter_href->{prankvariant} > 0) { #Run rankvariant. Done per family

	$log->info("\t[Rankvariant]\n");
    }

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								 job_id_href => $job_id_href,
								 FILEHANDLE => $FILEHANDLE,
								 directory_id => $$family_id_ref,
								 program_name => $program_name,
								 program_directory => lc($$outaligner_dir_ref),
								 core_number => $core_number,
								 process_time => $time,
								});

    ## Copy files for variantannotationblock to enable restart and skip of modules within block
    ($xargs_file_counter, $xargs_file_name) = prepareforvariantannotationblock({parameter_href => $parameter_href,
										active_parameter_href => $active_parameter_href,
										sample_info_href => $sample_info_href,
										file_info_href => $file_info_href,
										infile_lane_no_ending_href => $infile_lane_no_ending_href,
										job_id_href => $job_id_href,
										call_type => $call_type,
										program_name => "vt",
										file_name => $file_name,
										program_info_path => $program_info_path,
										FILEHANDLE => $FILEHANDLE,
										xargs_file_counter => $xargs_file_counter,
										stderr_path => $program_info_path.".stderr.txt",
									       });
    if ($active_parameter_href->{prhocall} > 0) {  #Run vt. Done per family

	($xargs_file_counter, $xargs_file_name) = rhocall({parameter_href => $parameter_href,
							   active_parameter_href => $active_parameter_href,
							   sample_info_href => $sample_info_href,
							   file_info_href => $file_info_href,
							   infile_lane_no_ending_href => $infile_lane_no_ending_href,
							   job_id_href => $job_id_href,
							   call_type => $call_type,
							   program_name => "rhocall",
							   file_name => $file_name,
							   program_info_path => $program_info_path,
							   FILEHANDLE => $FILEHANDLE,
							   xargs_file_counter => $xargs_file_counter,
							   stderr_path => $program_info_path.".stderr.txt",
							  });
    }
    if ($active_parameter_href->{pvt} > 0) {  #Run vt. Done per family

	($xargs_file_counter, $xargs_file_name) = vt({parameter_href => $parameter_href,
						      active_parameter_href => $active_parameter_href,
						      sample_info_href => $sample_info_href,
						      file_info_href => $file_info_href,
						      infile_lane_no_ending_href => $infile_lane_no_ending_href,
						      job_id_href => $job_id_href,
						      call_type => $call_type,
						      program_name => "vt",
						      file_name => $file_name,
						      program_info_path => $program_info_path,
						      FILEHANDLE => $FILEHANDLE,
						      xargs_file_counter => $xargs_file_counter,
						      stderr_path => $program_info_path.".stderr.txt",
						     });
    }
    if ($active_parameter_href->{pvarianteffectpredictor} > 0) {  #Run varianteffectpredictor. Done per family

	($xargs_file_counter, $xargs_file_name) = varianteffectpredictor({parameter_href => $parameter_href,
									  active_parameter_href => $active_parameter_href,
									  sample_info_href => $sample_info_href,
									  file_info_href => $file_info_href,
									  infile_lane_no_ending_href => $infile_lane_no_ending_href,
									  job_id_href => $job_id_href,
									  call_type => $call_type,
									  program_name => "varianteffectpredictor",
									  file_name => $file_name,
									  program_info_path => $program_info_path,
									  FILEHANDLE => $FILEHANDLE,
									  xargs_file_counter => $xargs_file_counter,
									  stderr_path => $program_info_path.".stderr.txt",
									 });
    }
    if ($active_parameter_href->{pvcfparser} > 0) {  #Run vcfparser. Done per family

	($xargs_file_counter, $xargs_file_name) = vcfparser({parameter_href => $parameter_href,
							     active_parameter_href => $active_parameter_href,
							     sample_info_href => $sample_info_href,
							     file_info_href => $file_info_href,
							     infile_lane_no_ending_href => $infile_lane_no_ending_href,
							     job_id_href => $job_id_href,
							     call_type => $call_type,
							     program_name => "vcfparser",
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     FILEHANDLE => $FILEHANDLE,
							     xargs_file_counter => $xargs_file_counter,
							    });
    }
    if ($active_parameter_href->{pannovar} > 0) {  #Run annovar. Done per family

	($xargs_file_counter, $xargs_file_name) = annovar({parameter_href => $parameter_href,
							   active_parameter_href => $active_parameter_href,
							   sample_info_href => $sample_info_href,
							   file_info_href => $file_info_href,
							   infile_lane_no_ending_href => $infile_lane_no_ending_href,
							   job_id_href => $job_id_href,
							   annovar_table_href => $annovar_table_href,
							   call_type => $call_type,
							   program_name => "annovar",
							   file_name => $file_name,
							   program_info_path => $program_info_path,
							   FILEHANDLE => $FILEHANDLE,
							   xargs_file_counter => $xargs_file_counter,
							  });
    }
    if ($active_parameter_href->{psnpeff} > 0) {  #Run snpEff. Done per family

	($xargs_file_counter, $xargs_file_name) = snpeff({parameter_href => $parameter_href,
							  active_parameter_href => $active_parameter_href,
							  sample_info_href => $sample_info_href,
							  file_info_href => $file_info_href,
							  infile_lane_no_ending_href => $infile_lane_no_ending_href,
							  job_id_href => $job_id_href,
							  call_type => $call_type,
							  program_name => "snpeff",
							  file_name => $file_name,
							  program_info_path => $program_info_path,
							  FILEHANDLE => $FILEHANDLE,
							  xargs_file_counter => $xargs_file_counter,
							 });
    }
    if ($active_parameter_href->{prankvariant} > 0) {  #Run rankvariant. Done per family

	($xargs_file_counter, $xargs_file_name) = rankvariant({parameter_href => $parameter_href,
							       active_parameter_href => $active_parameter_href,
							       sample_info_href => $sample_info_href,
							       file_info_href => $file_info_href,
							       infile_lane_no_ending_href => $infile_lane_no_ending_href,
							       job_id_href => $job_id_href,
							       call_type => $call_type,
							       program_name => "rankvariant",
							       file_name => $file_name,
							       program_info_path => $program_info_path,
							       FILEHANDLE => $FILEHANDLE,
							       xargs_file_counter => $xargs_file_counter,
							      });
    }
}


sub bamcalibrationblock {

##bamcalibrationblock

##Function : Run consecutive module
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $lane_href, $job_id_href, $supported_cosmid_reference_href, $outaligner_dir, $program_name
##         : $parameter_href                  => The parameter hash {REF}
##         : $active_parameter_href           => The active parameters for this analysis hash {REF}
##         : $sample_info_href                => Info on samples and family hash {REF}
##         : $file_info_href                  => The file info hash {REF}
##         : $infile_lane_no_ending_href      => The infile(s) without the ".ending" {REF}
##         : $lane_href                       => The lane info hash {REF}
##         : $job_id_href                     => The job_id hash {REF}
##         : $supported_cosmid_reference_href => The supported cosmid references hash {REF}
##         : $outaligner_dir                  => The outaligner_dir used
##         : $program_name                    => The program name

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $lane_href;
    my $job_id_href;
    my $supported_cosmid_reference_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	lane_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$lane_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	supported_cosmid_reference_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_cosmid_reference_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 80;

    ## Set the number of cores to allocate per sbatch job.
    my $core_number = $active_parameter_href->{core_processor_number};

    ##Always run even for single samples to rename them correctly for standardised downstream processing.
    ##Will also split alignment per contig and copy to temporary directory for '-rio 1' block to enable selective removal of block submodules.
    $log->info("\t[Picardtools mergesamfiles]\n");

    if ($active_parameter{ppicardtools_markduplicates} > 0) {  #Picardtools markduplicates

	$log->info("\t[Picardtools markduplicates]\n");
    }
    if ($active_parameter{psambamba_markduplicates} > 0) {  #Sambamba markduplicates

	$log->info("\t[Sambamba markduplicates]\n");
    }
    if ($active_parameter{pgatk_realigner} > 0) {  #Run GATK realignertargetcreator/indelrealigner

	$log->info("\t[GATK realignertargetcreator/indelrealigner]\n");

	check_build_human_genome_prerequisites({parameter_href => $parameter_href,
						active_parameter_href => $active_parameter_href,
						sample_info_href => $sample_info_href,
						file_info_href => $file_info_href,
						infile_lane_no_ending_href => $infile_lane_no_ending_href,
						job_id_href => $job_id_href,
						supported_cosmid_reference_href => $supported_cosmid_reference_href,
						program_name => "gatk_realigner",
					       });
	check_build_download_prerequisites({parameter_href => $parameter_href,
					    active_parameter_href => $active_parameter_href,
					    sample_info_href => $sample_info_href,
					    infile_lane_no_ending_href => $infile_lane_no_ending_href,
					    job_id_href => $job_id_href,
					    supported_cosmid_reference_href => $supported_cosmid_reference_href,
					    program_name => "gatk_realigner",
					   });
    }
    if ($active_parameter{pgatk_baserecalibration} > 0) {  #Run GATK baserecalibrator/printreads

	$log->info("\t[GATK baserecalibrator/printreads]\n");

	check_build_human_genome_prerequisites({parameter_href => $parameter_href,
						active_parameter_href => $active_parameter_href,
						sample_info_href => $sample_info_href,
						file_info_href => $file_info_href,
						infile_lane_no_ending_href => $infile_lane_no_ending_href,
						job_id_href => $job_id_href,
						supported_cosmid_reference_href => $supported_cosmid_reference_href,
						program_name => "gatk_baserecalibration",
					       });

	check_build_download_prerequisites({parameter_href => $parameter_href,
					    active_parameter_href => $active_parameter_href,
					    sample_info_href => $sample_info_href,
					    infile_lane_no_ending_href => $infile_lane_no_ending_href,
					    job_id_href => $job_id_href,
					    supported_cosmid_reference_href => $supported_cosmid_reference_href,
					    program_name => "gatk_baserecalibration",
					   });
    }

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	my $xargs_file_counter = 0;
	my $xargs_file_name;

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	my ($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								     job_id_href => $job_id_href,
								     FILEHANDLE => $FILEHANDLE,
								     directory_id => $sample_id,
								     program_name => $program_name,
								     program_directory => lc($$outaligner_dir_ref),
								     core_number => $core_number,
								     process_time => $time,
								     temp_directory => $$temp_directory_ref
								    });

	##Always run even for single samples to rename them correctly for standardised downstream processing.
	##Will also split alignment per contig and copy to temporary directory for -rio 1 block to enable selective removal of block submodules.
	($xargs_file_counter, $xargs_file_name) = picardtools_mergesamfiles({parameter_href => $parameter_href,
									     active_parameter_href => $active_parameter_href,
									     sample_info_href => $sample_info_href,
									     file_info_href => $file_info_href,
									     infile_lane_no_ending_href => $infile_lane_no_ending_href,
									     lane_href => $lane_href,
									     job_id_href => $job_id_href,
									     sample_id_ref => \$sample_id,
									     program_name => "picardtools_mergesamfiles",
									     file_name => $file_name,
									     program_info_path => $program_info_path,
									     FILEHANDLE => $FILEHANDLE,
									    });

	if ($active_parameter{ppicardtools_markduplicates} > 0) {  #Picardtools markduplicates

	    ($xargs_file_counter, $xargs_file_name) = picardtools_markduplicates({parameter_href => $parameter_href,
										  active_parameter_href => $active_parameter_href,
										  sample_info_href => $sample_info_href,
										  file_info_href => $file_info_href,
										  infile_lane_no_ending_href => $infile_lane_no_ending_href,
										  lane_href => $lane_href,
										  job_id_href => $job_id_href,
										  sample_id_ref => \$sample_id,
										  program_name => "picardtools_markduplicates",
										  file_name => $file_name,
										  program_info_path => $program_info_path,
										  FILEHANDLE => $FILEHANDLE,
										  xargs_file_counter => $xargs_file_counter,
										 });
	}
	if ($active_parameter{psambamba_markduplicates} > 0) {  #Sambamba markduplicates

	    ($xargs_file_counter, $xargs_file_name) = sambamba_markduplicates({parameter_href => $parameter_href,
									       active_parameter_href => $active_parameter_href,
									       sample_info_href => $sample_info_href,
									       file_info_href => $file_info_href,
									       infile_lane_no_ending_href => $infile_lane_no_ending_href,
									       lane_href => $lane_href,
									       job_id_href => $job_id_href,
									       sample_id_ref => \$sample_id,
									       program_name => "sambamba_markduplicates",
									       file_name => $file_name,
									       program_info_path => $program_info_path,
									       FILEHANDLE => $FILEHANDLE,
									       xargs_file_counter => $xargs_file_counter,
									      });
	}
	if ($active_parameter{pgatk_realigner} > 0) {  #Run GATK realignertargetcreator/indelrealigner

	    ($xargs_file_counter, $xargs_file_name) = gatk_realigner({parameter_href => $parameter_href,
								      active_parameter_href => $active_parameter_href,
								      sample_info_href => $sample_info_href,
								      file_info_href => $file_info_href,
								      infile_lane_no_ending_href => $infile_lane_no_ending_href,
								      job_id_href => $job_id_href,
								      sample_id_ref => \$sample_id,
								      program_name => "gatk_realigner",
								      file_name => $file_name,
								      program_info_path => $program_info_path,
								      FILEHANDLE => $FILEHANDLE,
								      xargs_file_counter => $xargs_file_counter,
								     });
	}
	if ($active_parameter{pgatk_baserecalibration} > 0) {  #Run GATK baserecalibrator/printreads

	    ($xargs_file_counter, $xargs_file_name) = gatk_baserecalibration({parameter_href => $parameter_href,
									      active_parameter_href => $active_parameter_href,
									      sample_info_href => $sample_info_href,
									      file_info_href => $file_info_href,
									      infile_lane_no_ending_href => $infile_lane_no_ending_href,
									      job_id_href => $job_id_href,
									      sample_id_ref => \$sample_id,
									      program_name => "gatk_baserecalibration",
									      file_name => $file_name,
									      program_info_path => $program_info_path,
									      FILEHANDLE => $FILEHANDLE,
									      xargs_file_counter => $xargs_file_counter,
									     });
	}
    }
}


sub madeline {

##madeline

##Function : Draw pedigree trees.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_lane_no_ending_href, $job_id_href, $family_id_ref, $program_name
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $family_id_ref              => The family_id_ref {REF}
##         : $program_name               => The program name

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 1;
    my $core_number = 1;

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => lc($program_name),
					     core_number => $core_number,
					     process_time => $time,
					    });

    ## Assign directories
    my $outfamily_directory = catfile($active_parameter_href->{outdata_dir}, $$family_id_ref, lc($program_name));

    say $FILEHANDLE "## Reformat pedigree to madeline format";

    print $FILEHANDLE "ped_parser ";
    print $FILEHANDLE "-t mip ";  #MIP pedigree format
    print $FILEHANDLE "--to_madeline ";  #Print the ped file in madeline format
    print $FILEHANDLE $active_parameter_href->{pedigree_file}." ";  #InFile
    say $FILEHANDLE "-o ".catfile($outfamily_directory, "madeline_pedigree.txt")." ";

    say $FILEHANDLE "## ".$program_name;

    print $FILEHANDLE "madeline2 ";
    print $FILEHANDLE "--color ";
    print $FILEHANDLE "--outputprefix ".catfile($outfamily_directory, $$family_id_ref."_madeline")." ";
    say $FILEHANDLE catfile($outfamily_directory, "madeline_pedigree.txt")." ";

    ## Collect QC metadata info for active program for later use
    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	$sample_info_href->{program}{$program_name}{path} = catfile($outfamily_directory, $$family_id_ref."_madeline.xml");
    }

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "case_dependency_dead_end",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub fastqc {

##fastqc

##Function : Raw sequence quality analysis using FASTQC.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_href, $indir_path_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_href                => The infiles hash {REF}
##         : $indir_path_href            => The indirectories path(s) hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_href;
    my $indir_path_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_href => { defined => 1, default => {}, strict_type => 1, store => \$infile_href},
	indir_path_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$indir_path_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 10;
    my $core_number = 0;

    foreach my $infile (@{ $infile_lane_no_ending_href->{$$sample_id_ref} }) {

	## Adjust the number of cores to be used in the analysis according to sequencing mode requirements.
	adjust_core_number_to_seq_mode({core_number_ref => \$core_number,
					sequence_run_type_ref => \$sample_info_href->{sample}{$$sample_id_ref}{file}{$infile}{sequence_run_type},
				       });
    }

    ## Set the number of cores to allocate per sbatch job.
    $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					   core_number => $core_number,
					  });  #Make sure that the number of cores does not exceed maximum after incrementing above

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$sample_id_ref,
					     program_name => $program_name,
					     program_directory => lc($program_name),
					     core_number => $core_number,
					     process_time => $time,
					     temp_directory => $$temp_directory_ref,
					    });

    ## Assign directories
    my $insample_directory = $indir_path_href->{$$sample_id_ref};
    my $outsample_directory = catdir($active_parameter_href->{outdata_dir}, $$sample_id_ref, lc($program_name));

    ## Copies files from source to temporary folder. Loop over files specified by $files_ref and collects files from $extract_files_ref.
    migrate_files_to_temp({active_parameter_href => $active_parameter_href,
			   sample_info_href => $sample_info_href,
			   files_ref => \@{ $infile_lane_no_ending_href->{$$sample_id_ref} },
			   extract_files_ref => \@{ $infile_href->{$$sample_id_ref} },
			   FILEHANDLE => $FILEHANDLE,
			   insample_directory => $insample_directory,
			   core_number => $core_number,
			   sample_id => $$sample_id_ref
			  });

    say $FILEHANDLE "## ".$program_name;

    my $core_counter = 1;
    while ( my ($index, $infile) = each(@{ $infile_href->{$$sample_id_ref} }) ) {

	print_wait({counter_ref => \$index,
		    core_number_ref => \$core_number,
		    core_counter_ref => \$core_counter,
		    FILEHANDLE => $FILEHANDLE,
		   });

	## Removes ".file_ending" in filename.FILENDING(.gz)
	my $file_at_lane_level = remove_file_ending({file_name_ref => \$infile,
						     file_ending => ".fastq",
						    });

	print $FILEHANDLE "fastqc ";
	print $FILEHANDLE catfile($$temp_directory_ref, $infile)." ";  #InFile
	print $FILEHANDLE "--extract ";  #the zipped output file will be uncompressed in the same directory after it has been created.
	print $FILEHANDLE "-o ".$$temp_directory_ref." ";  #OutFile
	say $FILEHANDLE "&", "\n";

	## Collect QC metadata info for active program for later use
	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    sample_info_qc({sample_info_href => $sample_info_href,
			    sample_id => $$sample_id_ref,
			    program_name => "fastqc",
			    infile => $infile,
			    outdirectory => catfile($outsample_directory, $file_at_lane_level."_fastqc"),
			    outfile_ending => "fastqc_data.txt",
			    outdata_type => "static"
			   });
	}
    }
    say $FILEHANDLE "wait", "\n";

    ## Copies files from temporary folder to source.
    $core_counter = 1;
    while ( my ($index, $infile) = each(@{ $infile_href->{$$sample_id_ref} }) ) {

	print_wait({counter_ref => \$index,
		    core_number_ref => \$core_number,
		    core_counter_ref => \$core_counter,
		    FILEHANDLE => $FILEHANDLE,
		   });

	## Removes ".file_ending" in filename.FILENDING(.gz)
	my $file_at_lane_level = remove_file_ending({file_name_ref => \$infile,
						     file_ending => ".fastq",
						    });

	## Copies files from temporary folder to source
	print $FILEHANDLE "cp -r ";
	print $FILEHANDLE catfile($$temp_directory_ref, $file_at_lane_level."_fastqc")." ";
	print $FILEHANDLE $outsample_directory." ";
	say $FILEHANDLE "&", "\n";
    }
    say $FILEHANDLE "wait", "\n";

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $$sample_id_ref,
		    dependencies => "case_dependency_dead_end",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub gzip_fastq {

##gzip_fastq

##Function : Automatically gzips fastq files.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_href, $indir_path_href, $infile_lane_no_ending_href, $job_id_href, $sample_id, $program_name
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_href                => The infiles hash {REF}
##         : $indir_path_href            => The indirectories path(s) hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id                  => The sample_id
##         : $program_name               => The program name

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_href;
    my $indir_path_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_href},
	indir_path_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$indir_path_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id => { required => 1, defined => 1, strict_type => 1, store => \$sample_id},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = ceil(1.5*scalar( @{ $infile_href->{$sample_id} }));  #One full lane on Hiseq takes approx. 1.5 h for gzip to process, round up to nearest full hour.

    my $core_number = 0;

    foreach my $infile (@{ $infile_lane_no_ending_href->{$sample_id} }) {

	## Adjust the number of cores to be used in the analysis according to sequencing mode requirements.
	adjust_core_number_to_seq_mode({core_number_ref => \$core_number,
					sequence_run_type_ref => \$sample_info_href->{sample}{$sample_id}{file}{$infile}{sequence_run_type},
				       });
    }

    ## Set the number of cores to allocate per sbatch job.
    $core_number = core_number_per_sbatch({active_parameter_href => $active_parameter_href,
					   core_number => $core_number,
					  });  #Make sure that the number of cores does not exceed maximum after incrementing above

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $sample_id,
					     program_name => $program_name,
					     program_directory => lc($program_name),
					     core_number => $core_number,
					     process_time => $time,
					    });

    ## Assign directories
    my $insample_directory = $indir_path_href->{$sample_id};

    my $core_counter = 1;
    my $uncompressed_file_counter = 0;  #Used to print wait at the right times since infiles cannot be used (can be a mixture of .gz and .fast files)

    say $FILEHANDLE "cd ".$indir_path_href->{$sample_id}, "\n";

    foreach my $infile (@{ $infile_href->{$sample_id} }) {

	if ($infile =~/.fastq$/) {  #For files ending with .fastq required since there can be a mixture (also .fastq.gz) within the sample dir

	    if ($uncompressed_file_counter == $core_counter * $active_parameter_href->{core_processor_number}) {  #Using only $active_parameter{core_processor_number} cores

		say $FILEHANDLE "wait", "\n";
		$core_counter=$core_counter+1;
	    }

	    print $FILEHANDLE "gzip ";
	    say $FILEHANDLE catfile($insample_directory, $infile)." &\n";  #InFile
	    $uncompressed_file_counter++;
	    $infile .= ".gz";  #Add ".gz" to original fastq ending, since this will execute before fastQC screen and mosaikBuild.
	}
    }
    say $FILEHANDLE "wait", "\n";

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    sample_id => $sample_id,
		    dependencies => "no_dependency",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub split_fastq_file {

##split_fastq_file

##Function : Split input fastq files into batches of reads, versions and compress. Moves original file to subdirectory.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_href, $indir_path_href, $infile_lane_no_ending_href, $job_id_href, $sample_id_ref, $program_name, sequence_read_batch
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_href                => The infiles hash {REF}
##         : $indir_path_href            => The indirectories path(s) hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $sample_id_ref              => The sample_id {REF}
##         : $program_name               => The program name
##         : $sequence_read_batch        => Number of sequences in each fastq batch

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $sequence_read_batch;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_href;
    my $indir_path_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $sample_id_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_href => { defined => 1, default => {}, strict_type => 1, store => \$infile_href},
	indir_path_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$indir_path_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	sequence_read_batch => { default => 2500000,
				 allow => qr/^\d+$/,
				 strict_type => 1, store => \$sequence_read_batch},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $time = 10;
    my $core_number = 4;

    foreach my $fastq_file (@{ $infile_href->{$$sample_id_ref} }) {

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
						 job_id_href => $job_id_href,
						 FILEHANDLE => $FILEHANDLE,
						 directory_id => $$sample_id_ref,
						 program_name => $program_name,
						 program_directory => lc($program_name),
						 core_number => $core_number,
						 process_time => $time,
						 temp_directory => $$temp_directory_ref,
						});

	## Assign directories
	my $insample_directory = $indir_path_href->{$$sample_id_ref};
	my $outsample_directory = $indir_path_href->{$$sample_id_ref};

	say $FILEHANDLE "## ".$program_name;

	my %fastq_file_info;

	## Detect fastq file info for later rebuild of filename
	if ($fastq_file =~/(\d+)_(\d+)_([^_]+)_([^_]+)_([^_]+)_(\d).fastq/) {

	    %fastq_file_info = (lane => $1,
				date => $2,
				flowcell => $3,
				sample_id => $4,
				index => $5,
				direction => $6,
		);
	}
	## Removes ".file_ending" in filename.FILENDING(.gz)
	my $file_prefix = remove_file_ending({file_name_ref => \$fastq_file,
					      file_ending => ".fastq",
					     })."_splitted_";

	## Copies file to temporary directory.
	migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			      path => catfile($insample_directory, $fastq_file),
			      temp_directory => $$temp_directory_ref,
			     });
	say $FILEHANDLE "wait ";

	## Decompress file and split
	print $FILEHANDLE "unpigz ";
	print $FILEHANDLE "-p ".$core_number." ";  #nr of threads
	print $FILEHANDLE "-c ";  #Write all processed output to stdout
	print $FILEHANDLE catfile($$temp_directory_ref, $fastq_file)." ";  #Infile
	print $FILEHANDLE "| ";  #Pipe
	print $FILEHANDLE "split ";
	print $FILEHANDLE "-l ".($sequence_read_batch * 4)." ";  #put NUMBER lines per output file
	print $FILEHANDLE "- ";  #STDIN
	print $FILEHANDLE "-d ";  #use numeric suffixes instead of alphabetic
	print $FILEHANDLE "-a 4 ";  #use suffixes of length N
	say $FILEHANDLE catfile($$temp_directory_ref, $file_prefix), "\n";

	## Remove original files
	remove_file({file_ref => \catfile($$temp_directory_ref, $fastq_file),
		     FILEHANDLE => $FILEHANDLE,
		    });
	say $FILEHANDLE "\n";

	## Find all splitted files
	say $FILEHANDLE "splitted_files=(".catfile($$temp_directory_ref, "*_splitted_*").")", "\n";

	## Iterate through array using a counter
	say $FILEHANDLE q?for ((file_counter=0; file_counter<${#splitted_files[@]}; file_counter++)); do ?;

	## Rename each element of array to include splitted suffix in FlowCellID
	print $FILEHANDLE "\t".q?mv ${splitted_files[$file_counter]} ?;
	print $FILEHANDLE catfile($$temp_directory_ref, "");
	print $FILEHANDLE $fastq_file_info{lane}."_";
	print $FILEHANDLE $fastq_file_info{date}."_";
	print $FILEHANDLE $fastq_file_info{flowcell}.q?"-SP"$file_counter"?;
	print $FILEHANDLE "_".$fastq_file_info{sample_id}."_";
	print $FILEHANDLE $fastq_file_info{index}."_";
	print $FILEHANDLE $fastq_file_info{direction}.".fastq";
	say $FILEHANDLE q?"?, "\n";

	say $FILEHANDLE "\t".q?echo "${splitted_files[$file_counter]}" ?;
	say $FILEHANDLE "done";

	## Compress file again
	my $splittedFile = catfile($indir_path{$$sample_id_ref}, $file_prefix."*");
	print $FILEHANDLE "pigz ";
	say $FILEHANDLE catfile($$temp_directory_ref, "*.fastq"), "\n";

	## Copies files from temporary folder to source
	print $FILEHANDLE "cp ";
	print $FILEHANDLE catfile($$temp_directory_ref, "*-SP*.fastq.gz")." ";
	say $FILEHANDLE $outsample_directory,"\n";

	## Move original file to not be included in subsequent analysis
	say $FILEHANDLE "mkdir -p ".catfile($insample_directory, "original_fastq_files"), "\n";

	print $FILEHANDLE "mv ";
	print $FILEHANDLE catfile($insample_directory, $fastq_file)." ";
	say $FILEHANDLE catfile($insample_directory, "original_fastq_files", $fastq_file), "\n";

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			sample_id => $$sample_id_ref,
			dependencies => "case_dependency_dead_end",
			path => $parameter_href->{"p".$program_name}{chain},
			sbatch_file_name => $file_name
		       });
	}
    }
    close($FILEHANDLE);
}


sub build_annovar_prerequisites {

##build_annovar_prerequisites

##Function : Creates the annovarPreRequisites.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $infile_lane_no_ending_href, $job_id_href, $annovar_table_href, $program_name, family_id_ref, $temp_directory_ref, $outaligner_dir_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $annovar_table_href         => annovar_table_href {REF}
##         : $program_name               => The program name
##         : $family_id_ref              => The family_id {REF}
##         : $temp_directory_ref         => The temporary directory {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}


    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $annovar_table_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	annovar_table_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$annovar_table_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    $parameter_href->{annovar_build_reference}{build_file} = 0;  #Ensure that this subrutine is only executed once
    my $annovar_temporary_directory = catfile($active_parameter_href->{annovar_path}, "humandb", "Db_temporary");  #Temporary download directory

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => lc($$outaligner_dir_ref),
					     process_time => 3,
					     temp_directory => $$temp_directory_ref
					    });

    $log->warn("Will try to create required annovar database files before executing ".$program_name."\n");

    say $FILEHANDLE "## Make temporary download directory\n";
    say $FILEHANDLE "mkdir -p ".$annovar_temporary_directory."; ", "\n";

    say $FILEHANDLE "## Downloading annovar Db files", "\n";

    for (my $table_names_counter=0;$table_names_counter<scalar(@{ $active_parameter_href->{annovar_table_names} });$table_names_counter++) {  #For all specified table names

	if ($parameter_href->{$active_parameter_href->{annovar_table_names}[$table_names_counter]}{build_file} eq 1) {

	    print $FILEHANDLE "perl ".catfile($active_parameter_href->{annovar_path}, "annotate_variation.pl")." ";  #annovar script
	    print $FILEHANDLE "-buildver ".$active_parameter_href->{annovar_genome_build_version}." ";  #GenomeBuild version
	    print $FILEHANDLE "-downdb ".$annovar_table_href->{$active_parameter_href->{annovar_table_names}[$table_names_counter]}{download}." ";  #Db to download

	    if (defined($annovar_table_href->{$active_parameter_href->{annovar_table_names}[$table_names_counter]}{ucsc_alias})) {

		print $FILEHANDLE "-webfrom ucsc ";  #Download from ucsc
	    }
	    else {

		print $FILEHANDLE "-webfrom annovar ";  #Download from annovar
	    }
	    say $FILEHANDLE catfile($annovar_temporary_directory)." ", "\n";  #annovar/humandb directory is assumed

	    if ($active_parameter_href->{annovar_table_names}[$table_names_counter] =~/ensGene|refGene/) {  #Special case for MT download

		print $FILEHANDLE "perl ".catfile($active_parameter_href->{annovar_path}, "annotate_variation.pl")." ";  #annovar script
		print $FILEHANDLE "-buildver GRCh37_MT ";  #GenomeBuild version
		print $FILEHANDLE "-downdb ensGene ";  #Db to download
		print $FILEHANDLE "-webfrom annovar ";  #Download from annovar
		say $FILEHANDLE catfile($annovar_temporary_directory), "\n";  #annovar/humandb directory is assumed
	    }

	    ### Check file existance and move created file if lacking
	    my $intended_file_path;
	    my $temporary_file_path;

	    if (defined($annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{file})) {

		for (my $files_counter=0;$files_counter<scalar(@{ $annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{file} });$files_counter++) {  #All annovar_table file(s), some tables have multiple files downloaded from the same call

		    $intended_file_path = catfile($active_parameter_href->{annovar_path}, "humandb", $annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{file}[$files_counter]);
		    $temporary_file_path = catfile($annovar_temporary_directory, $annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{file}[$files_counter]);

		    ## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
		    print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
						     intended_file_path_ref => \$intended_file_path,
						     temporary_file_path_ref => \$temporary_file_path,
						    });

		    if (defined($annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{index_file})) {

			$intended_file_path = catfile($active_parameter_href->{annovar_path}, "humandb", $annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{file}[$files_counter].".idx");
			$temporary_file_path = catfile($annovar_temporary_directory, $annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{file}[$files_counter].".idx");

			## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
			print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
							 intended_file_path_ref => \$intended_file_path,
							 temporary_file_path_ref => \$temporary_file_path,
							});
		    }
		}
	    }
	    elsif ((defined($annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{ucsc_alias}))){

		$intended_file_path = catfile($active_parameter_href->{annovar_path}, "humandb", $active_parameter_href->{annovar_genome_build_version}."_".$annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{ucsc_alias}.".txt");
		$temporary_file_path = catfile($annovar_temporary_directory, $active_parameter_href->{annovar_genome_build_version}."_".$annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{ucsc_alias}.".txt");

		## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
		print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
						 intended_file_path_ref => \$intended_file_path,
						 temporary_file_path_ref => \$temporary_file_path,
						});

		if (defined($annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{index_file})) {

		    $intended_file_path = catfile($active_parameter_href->{annovar_path}, "humandb", $active_parameter_href->{annovar_genome_build_version}."_".$annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{ucsc_alias}.".txt.idx");
		    $temporary_file_path = catfile($annovar_temporary_directory, $active_parameter_href->{annovar_genome_build_version}."_".$annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{ucsc_alias}.".txt.idx");

		    ## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
		    print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
						     intended_file_path_ref => \$intended_file_path,
						     temporary_file_path_ref => \$temporary_file_path,
						    });
		}
	    }
	    else {

		$intended_file_path = catfile($active_parameter_href->{annovar_path}, "humandb", $active_parameter_href->{annovar_genome_build_version}."_".$active_parameter_href->{annovar_table_names}[$table_names_counter].".txt");
		$temporary_file_path = catfile($annovar_temporary_directory, $active_parameter_href->{annovar_genome_build_version}."_".$active_parameter_href->{annovar_table_names}[$table_names_counter].".txt");

		## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
		print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
						 intended_file_path_ref => \$intended_file_path,
						 temporary_file_path_ref => \$temporary_file_path,
						});

		if (defined($annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{index_file})) {

		    $intended_file_path = catfile($active_parameter_href->{annovar_path}, "humandb", $active_parameter_href->{annovar_genome_build_version}."_".$active_parameter_href->{annovar_table_names}[$table_names_counter].".txt.idx");
		    $temporary_file_path = catfile($annovar_temporary_directory, $active_parameter_href->{annovar_genome_build_version}."_".$active_parameter_href->{annovar_table_names}[$table_names_counter].".txt.idx");

		    ## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
		    print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
						     intended_file_path_ref => \$intended_file_path,
						     temporary_file_path_ref => \$temporary_file_path,
						    });
		}
	    }
	}
        $parameter_href->{$active_parameter_href->{annovar_table_names}[$table_names_counter]}{build_file} = 0;
    }

    say $FILEHANDLE "rm -rf $annovar_temporary_directory;", "\n";  #Cleaning up temp directory
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "no_dependency_add_to_case",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub build_downloadable_prerequisites {

##build_downloadable_prerequisites

##Function : Creates the downloadable resources.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_lane_no_ending_href, $job_id_href, supported_cosmid_reference_href, $program_name, $family_id_ref, $outaligner_dir_ref
##         : $parameter_href                  => The parameter hash {REF}
##         : $active_parameter_href           => The active parameters for this analysis hash {REF}
##         : $sample_info_href                => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href      => The infile(s) without the ".ending" {REF}
##         : $job_id_href                     => The job_id hash {REF}
##         : $supported_cosmid_reference_href => The supported cosmid references hash {REF}
##         : $program_name                    => The program name
##         : $family_id_ref                   => Family ID {REF}
##         : $outaligner_dir_ref              => The outaligner_dir used in the analysis

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $supported_cosmid_reference_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	supported_cosmid_reference_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_cosmid_reference_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => lc($$outaligner_dir_ref),
					     process_time => 4,
					    });

    say $FILEHANDLE "cd $active_parameter_href->{reference_dir}", "\n";  #Move to reference directory

    ## Locates and sets the cosmid directory to download to
    my $cosmid_resource_directory = check_cosmid_yaml({active_parameter_href => $active_parameter_href,
						      });

    for my $parameter_name (keys %$supported_cosmid_reference_href) {

	if (! check_entry_hash_of_array({hash_ref => $parameter_href->{$parameter_name},
					 key => "associated_program",
					 element => "p".$program_name,
					})
	    ) {  #If the cosmid supported parameter is associated with the MIP program

	    if ($parameter_href->{$parameter_name}{build_file} eq 1) {

		download_reference({parameter_href => $parameter_href,
				    active_parameter_href => $active_parameter_href,
				    sample_info_href => $sample_info_href,
				    infile_lane_no_ending_href => $infile_lane_no_ending_href,
				    job_id_href => $job_id_href,
				    supported_cosmid_reference_href => $supported_cosmid_reference_href,
				    cosmid_resource_directory_ref => \$cosmid_resource_directory,
				    program_ref => \$program_name,
				    FILEHANDLE => $FILEHANDLE,
				    parameter_name => $parameter_name,
				   });
	    }
	}
    }

    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "no_dependency_add_to_case",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub build_ptchs_metric_prerequisites {

##build_ptchs_metric_prerequisites

##Function : Creates the target "infiles_list" "padded.infile_list" and interval_list files.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $FILEHANDLE, $family_id_ref, $outaligner_dir_ref, temp_directory_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => The program name
##         : $FILEHANDLE                 => Filehandle to write to
##         : $family_id_ref              => Family ID {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $temp_directory_ref         => The temporary directory

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;
    my $FILEHANDLE;  #Decides if a new sbatch script will be generated or handled by supplied FILEHANDLE

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $file_name;

    unless(defined($FILEHANDLE)) {  #No supplied FILEHANDLE i.e. create new sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					      job_id_href => $job_id_href,
					      FILEHANDLE => $FILEHANDLE,
					      directory_id => $$family_id_ref,
					      program_name => $program_name,
					      program_directory => lc($$outaligner_dir_ref),
					     });
    }

    my $random_integer = int(rand(10000));  #Generate a random integer between 0-10,000.

    ## Alias exome_target_bed endings
    my $infile_list_ending_ref = \$file_info_href->{exome_target_bed}[0];
    my $padded_infile_list_ending_ref = \$file_info_href->{exome_target_bed}[1];
    my $padded_interval_list_ending_ref = \$file_info_href->{exome_target_bed}[2];

    foreach my $exome_target_bed_file (keys $active_parameter_href->{exome_target_bed}) {

	$log->warn("Will try to create required ".$exome_target_bed_file." associated file(s) before executing ".$program_name."\n");

	my $exome_target_bed_file_random = $exome_target_bed_file."_".$random_integer;  #Add random integer

	say $FILEHANDLE "## CreateSequenceDictionary from reference";

	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx2g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $$temp_directory_ref,
		   java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
		  });

	print $FILEHANDLE "CreateSequenceDictionary ";
	print $FILEHANDLE "R=".$active_parameter_href->{human_genome_reference}." ";  #Reference genome
	say $FILEHANDLE "OUTPUT=".$exome_target_bed_file_random.".dict", "\n";  #Output sequence dictionnary

	say $FILEHANDLE "## Add target file to headers from sequenceDictionary";
	print $FILEHANDLE "cat ";  #Concatenate
	print $FILEHANDLE $exome_target_bed_file_random.".dict"." ";  #Sequence dictionnary
	print $FILEHANDLE $exome_target_bed_file." ";  #Bed file
	print $FILEHANDLE "> ";  #Write to
	say $FILEHANDLE $exome_target_bed_file_random.".dict_body", "\n";  #Add bed body to dictionnary

	say $FILEHANDLE "#Remove target annotations, 'track', 'browse' and keep only 5 columns";
	print $FILEHANDLE q?perl  -nae 'if ($_=~/@/) {print $_;} elsif ($_=~/^track/) {} elsif ($_=~/^browser/) {} else {print @F[0], "\t", (@F[1] + 1), "\t", @F[2], "\t", "+", "\t", "-", "\n";}' ?;
	print $FILEHANDLE $exome_target_bed_file_random.".dict_body"." ";  #Infile
	print $FILEHANDLE "> ";  #Write to
	say $FILEHANDLE $exome_target_bed_file_random.".dict_body_col_5.interval_list", "\n";  #Remove unnecessary info and reformat

	say $FILEHANDLE "## Create".$$infile_list_ending_ref;
	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx2g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $$temp_directory_ref,
		   java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
		  });

	print $FILEHANDLE "IntervalListTools ";
	print $FILEHANDLE "INPUT=".$exome_target_bed_file_random.".dict_body_col_5.interval_list"." ";
	say $FILEHANDLE "OUTPUT=".$exome_target_bed_file_random.".dict_body_col_5_".$$infile_list_ending_ref, "\n";

	my $intended_file_path = $exome_target_bed_file.$$infile_list_ending_ref;
	my $temporary_file_path = $exome_target_bed_file_random.".dict_body_col_5_".$$infile_list_ending_ref;

	## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
	print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
					 intended_file_path_ref => \$intended_file_path,
					 temporary_file_path_ref => \$temporary_file_path,
					});

	say $FILEHANDLE "#Create".$$padded_infile_list_ending_ref;
	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx2g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $active_parameter_href->{temp_directory},
		   java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
		  });

	print $FILEHANDLE "IntervalListTools ";
	print $FILEHANDLE "PADDING=100 ";  #Add 100 nt on both sides of bed entry
	print $FILEHANDLE "INPUT=".$exome_target_bed_file_random.".dict_body_col_5.interval_list"." ";
	say $FILEHANDLE "OUTPUT=".$exome_target_bed_file_random.".dict_body_col_5".$$padded_infile_list_ending_ref, "\n";

	$intended_file_path = $exome_target_bed_file.$$padded_infile_list_ending_ref;
	$temporary_file_path = $exome_target_bed_file_random.".dict_body_col_5".$$padded_infile_list_ending_ref;

	## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
	print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
					 intended_file_path_ref => \$intended_file_path,
					 temporary_file_path_ref => \$temporary_file_path,
					});

	say $FILEHANDLE "#Create ".$$padded_interval_list_ending_ref." by softlinking";

	##Softlink '.interval_list' to padded .infile_list", "\n";
	print $FILEHANDLE "ln -f -s ";  #Softlink
	print $FILEHANDLE $exome_target_bed_file.$$padded_infile_list_ending_ref." ";  #Origin file
	print $FILEHANDLE $exome_target_bed_file.$$padded_interval_list_ending_ref;  #interval_list file

	say $FILEHANDLE "\n";

	## Remove temporary files
	say $FILEHANDLE "#Remove temporary files";

	my @temp_files = ($exome_target_bed_file_random.".dict_body_col_5.interval_list",
			  $exome_target_bed_file_random.".dict_body",
			  $exome_target_bed_file_random.".dict",
	    );
	foreach my $file (@temp_files) {
	    
	    remove_file({file_ref => \$file,
			 FILEHANDLE => $FILEHANDLE,
			});
	    say $FILEHANDLE "\n";
	}
    }
    unless(defined($FILEHANDLE)) { #Unless FILEHANDLE was supplied close filehandle and submit

	close($FILEHANDLE);

	if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			dependencies => "no_dependency_add_to_case",
			path => "MIP",
			sbatch_file_name => $file_name
		       });
	}
    }
}

sub build_bwa_prerequisites {

##build_bwa_prerequisites

##Function : Creates the BwaPreRequisites using active_parameters{'human_genome_reference'} as reference.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $supported_cosmid_reference_href, $bwa_build_reference_file_endings_ref, $program_name, $FILEHANDLE, family_id_ref, $temp_directory_ref, $outaligner_dir_ref, $human_genome_reference_ref
##         : $parameter_href                       => The parameter hash {REF}
##         : $active_parameter_href                => The active parameters for this analysis hash {REF}
##         : $sample_info_href                     => Info on samples and family hash {REF}
##         : $file_info_href                       => The file_info hash {REF}
##         : $infile_lane_no_ending_href           => The infile(s) without the ".ending" {REF}
##         : $job_id_href                          => The job_id hash {REF}
##         : $supported_cosmid_reference_href      => The supported cosmid references hash {REF}
##         : $bwa_build_reference_file_endings_ref => The bwa reference associated file endings {REF}
##         : $family_id_ref                        => Family ID {REF}
##         : $outaligner_dir_ref                   => The outaligner_dir used in the analysis
##         : $program_name                         => The program name
##         : $family_id_ref                        => The family_id {REF}
##         : $temp_directory_ref                   => The temporary directory {REF}
##         : $outaligner_dir_ref                   => The outaligner_dir used in the analysis {REF}
##         : $human_genome_reference_ref           => Human genome reference {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $human_genome_reference_ref = $arg_href->{'human_genome_reference_ref'} //= \$arg_href->{'active_parameter_href'}{'human_genome_reference'},

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $supported_cosmid_reference_href;
    my $bwa_build_reference_file_endings_ref;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	supported_cosmid_reference_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_cosmid_reference_href},
	bwa_build_reference_file_endings_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$bwa_build_reference_file_endings_ref},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	human_genome_reference_ref => { default => \$$, strict_type => 1, store => \$human_genome_reference_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $random_integer = int(rand(10000));  #Generate a random integer between 0-10,000.

    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $$family_id_ref,
					     program_name => $program_name,
					     program_directory => lc($$outaligner_dir_ref),
					     process_time => 3,
					    });

    build_human_genome_prerequisites({parameter_href => $parameter_href,
				      active_parameter_href => $active_parameter_href,
				      sample_info_href => $sample_info_href,
				      file_info_href => $file_info_href,
				      infile_lane_no_ending_href => $infile_lane_no_ending_href,
				      job_id_href => $job_id_href,
				      supported_cosmid_reference_href => $supported_cosmid_reference_href,
				      program => $program_name,
				      FILEHANDLE => $FILEHANDLE,
				      random_integer => $random_integer,
				     });

    if ($parameter_href->{bwa_build_reference}{build_file} eq 1) {

	$log->warn("Will try to create required ".$$human_genome_reference_ref." index files before executing ".$program_name."\n");

	say $FILEHANDLE "## Building BWA index";
	print $FILEHANDLE "bwa index ";  #Index sequences in the FASTA format
	print $FILEHANDLE "-p ".$$human_genome_reference_ref."_".$random_integer." "; #Prefix of the index
	print $FILEHANDLE "-a bwtsw ";  #BWT construction algorithm
	say $FILEHANDLE $$human_genome_reference_ref, "\n";  #The FASTA reference sequences file

	foreach my $file (@$bwa_build_reference_file_endings_ref) {

	    my $intended_file_path = $$human_genome_reference_ref.$file;
	    my $temporary_file_path = $$human_genome_reference_ref."_".$random_integer.$file;

	    ## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
	    print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
					     intended_file_path_ref => \$intended_file_path,
					     temporary_file_path_ref => \$temporary_file_path,
					    });
	}
	$parameter_href->{bwa_build_reference}{build_file} = 0;  #Ensure that this subrutine is only executed once
    }
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "no_dependency_add_to_case",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub build_mosaikaligner_prerequisites {

##build_mosaikaligner_prerequisites

##Function : Creates the mosaikAlign prerequisites using active_parameters{'human_genome_reference'} as reference.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $supported_cosmid_reference_href, $mosaik_jump_db_stub_file_endings_ref, $human_genome_reference_source_ref, $human_genome_reference_version_ref, $family_id, $outaligner_dir, $program_name
##         : $parameter_href                       => The parameter hash {REF}
##         : $active_parameter_href                => The active parameters for this analysis hash {REF}
##         : $sample_info_href                     => Info on samples and family hash {REF}
##         : $file_info_href                       => The file_info hash {REF}
##         : $infile_lane_no_ending_href           => The infile(s) without the ".ending" {REF}
##         : $job_id_href                          => The job_id hash {REF}
##         : $supported_cosmid_reference_href      => The supported cosmid references hash {REF}
##         : $mosaik_jump_db_stub_file_endings_ref => The mosaikJump database file endings
##         : $human_genome_reference_source_ref    => The human genome source {REF}
##         : $human_genome_reference_version_ref   => The human genome build version {REF}
##         : $family_id                            => Family ID
##         : $outaligner_dir                       => AlignerOutDir used in the analysis
##         : $program_name                         => Program name

    my $parameter_href = $_[0];
    my $active_parameter_href = $_[1];
    my $sample_info_href = $_[2];
    my $file_info_href = $_[3];
    my $infile_lane_no_ending_href = $_[4];
    my $job_id_href = $_[5];
    my $supported_cosmid_reference_href = $_[6];
    my $mosaik_jump_db_stub_file_endings_ref = $_[7];
    my $human_genome_reference_source_ref = $_[8];
    my $human_genome_reference_version_ref = $_[9];
    my $family_id = $_[10];
    my $outaligner_dir = $_[11];
    my $program_name = $_[12];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
    my $random_integer = int(rand(10000));  #Generate a random integer between 0-10,000.
    
    ## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header.
    my ($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					     job_id_href => $job_id_href,
					     FILEHANDLE => $FILEHANDLE,
					     directory_id => $family_id,
					     program_name => $program_name,
					     program_directory => lc($outaligner_dir),
					     core_number => 4,
					     process_time => 2,
					    });

    ## Creates the humanGenomePreRequisites using active_parameters{human_genome_reference} as reference.
    build_human_genome_prerequisites({parameter_href => $parameter_href,
				      active_parameter_href => $active_parameter_href,
				      sample_info_href => $sample_info_href,
				      file_info_href => $file_info_href,
				      infile_lane_no_ending_href => $infile_lane_no_ending_href,
				      job_id_href => $job_id_href,
				      supported_cosmid_reference_href => $supported_cosmid_reference_href,
				      family_id_ref => \$family_id,
				      outaligner_dir_ref => \$outaligner_dir,
				      program => $program_name,
				      FILEHANDLE => $FILEHANDLE,
				      random_integer => $random_integer,
				     });

    if ($parameter_href->{mosaik_align_reference}{build_file} eq 1) {  ##Begin auto_build of MosaikAlignReference

	$log->warn("Will try to create required ".$active_parameter_href->{mosaik_align_reference}." before executing ".$program_name."\n");

	say $FILEHANDLE "#Building MosaikAligner Reference";
	print $FILEHANDLE "MosaikBuild ";
	print $FILEHANDLE "-fr ".catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{human_genome_reference})." ";  #The FASTA reference sequences file
	print $FILEHANDLE "-sn homo_sapiens ";  #Species name
	print $FILEHANDLE "-ga ".$$human_genome_reference_source_ref.$$human_genome_reference_version_ref." ";  #The genome assembly ID
	say $FILEHANDLE "-oa ".catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{mosaik_align_reference}."_".$random_integer), "\n";  #Temporary outfile

	my $intended_file_path = catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{mosaik_align_reference});
	my $temporary_file_path = catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{mosaik_align_reference}."_".$random_integer);

	## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
	print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
					 intended_file_path_ref => \$intended_file_path,
					 temporary_file_path_ref => \$temporary_file_path,
					});
    }
    if ($parameter_href->{mosaik_jump_db_stub}{build_file} eq 1) {  ##Begin auto_build of MosaikJump Database

	$log->warn("Will try to create required ".$active_parameter_href->{mosaik_jump_db_stub}." before executing ".$program_name."\n");

	say $FILEHANDLE "#Building MosaikAligner JumpDatabase";
	say $FILEHANDLE "mkdir -p ".catfile("scratch", "mosaik_tmp");
	say $FILEHANDLE "export MOSAIK_TMP=".catfile("scratch", "mosaik_tmp"), "\n";

	print $FILEHANDLE "MosaikJump ";
	print $FILEHANDLE "-ia ".catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{mosaik_align_reference})." ";  #The input reference file
	print $FILEHANDLE "-hs 15 ";  #The hash size
	print $FILEHANDLE "-mem 24 ";  #The amount memory used when sorting hashes
	say $FILEHANDLE "-out ".catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{mosaik_jump_db_stub}."_".$random_integer), "\n";  #Mosaik JumpDbStub for the output filenames

	for (my $file_endings_counter=0;$file_endings_counter<scalar(@$mosaik_jump_db_stub_file_endings_ref);$file_endings_counter++) {  #All MosaikJumpDb assocaiated files

	    my $intended_file_path = catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{mosaik_jump_db_stub}.$mosaik_jump_db_stub_file_endings_ref->[$file_endings_counter]);
	    my $temporary_file_path = catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{mosaik_jump_db_stub}."_".$random_integer.$mosaik_jump_db_stub_file_endings_ref->[$file_endings_counter]);

	    ## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
	    print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
					     intended_file_path_ref => \$intended_file_path,
					     temporary_file_path_ref => \$temporary_file_path,
					    });
	}

	say $FILEHANDLE "rm -rf ".catfile("scratch", "mosaik_tmp"), "\n";  #Cleaning up temp directory
    }
    close($FILEHANDLE);

    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	submit_job({active_parameter_href => $active_parameter_href,
		    sample_info_href => $sample_info_href,
		    job_id_href => $job_id_href,
		    infile_lane_no_ending_href => $infile_lane_no_ending_href,
		    dependencies => "no_dependency_add_to_case",
		    path => $parameter_href->{"p".$program_name}{chain},
		    sbatch_file_name => $file_name
		   });
    }
}


sub check_build_human_genome_prerequisites {

##check_build_human_genome_prerequisites

##Function : Checks if the HumanGenomePreRequisites needs to be built
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $supported_cosmid_reference_href, $program_name
##         : $parameter_href                  => The parameter hash {REF}
##         : $active_parameter_href           => The active parameters for this analysis hash {REF}
##         : $sample_info_href                => Info on samples and family hash {REF}
##         : $file_info_href                  => The file_info hash {REF}
##         : $infile_lane_no_ending_href      => The infile(s) without the ".ending" {REF}
##         : $job_id_href                     => The job_id hash {REF}
##         : $supported_cosmid_reference_href => The supported cosmid references hash {REF}
##         : $program_name                    => Program name

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $supported_cosmid_reference_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	supported_cosmid_reference_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_cosmid_reference_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    foreach my $file_ending (@{ $file_info_href->{human_genome_reference_file_endings} }) {  #Files assocaiated with human genome reference

	if ( ($parameter_href->{"human_genome_reference".$file_ending}{build_file} eq 1) || ($file_info_href->{human_genome_compressed} eq "compressed") ) {

	    if ( ($active_parameter_href->{"p".$program_name} == 1) && ($active_parameter_href->{dry_run_all} != 1)) {

		## Creates the humanGenomePreRequisites using active_parameters{human_genome_reference} as reference.
		build_human_genome_prerequisites({parameter_href => $parameter_href,
						  active_parameter_href => $active_parameter_href,
						  sample_info_href => $sample_info_href,
						  file_info_href => $file_info_href,
						  infile_lane_no_ending_href => $infile_lane_no_ending_href,
						  job_id_href => $job_id_href,
						  supported_cosmid_reference_href => $supported_cosmid_reference_href,
						  family_id_ref => \$active_parameter_href->{family_id},
						  outaligner_dir_ref => \$active_parameter_href->{outaligner_dir},
						  program => $program_name,
						 });
		last;#Will handle all metafiles build within sbatch script
	    }
	}
    }
}


sub check_build_ptchs_metric_prerequisites {

##check_build_ptchs_metric_prerequisites

##Function : Check if PicardtoolsHSMetricsPrequisites needs to be built
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $program_name, $FILEHANDLE, $family_id_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The associated reference file endings {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $program_name               => Program name
##         : $FILEHANDLE                 => Filehandle to write to
##         : $family_id_ref              => The family_id_ref {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $program_name;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ($parameter_href->{exome_target_bed}{build_file} eq 1) {

	build_ptchs_metric_prerequisites({parameter_href => $parameter_href,
					  active_parameter_href => $active_parameter_href,
					  sample_info_href => $sample_info_href,
					  file_info_href => $file_info_href,
					  infile_lane_no_ending_href => $infile_lane_no_ending_href,
					  job_id_href => $job_id_href,
					  program_name => $program_name,
					  FILEHANDLE => $FILEHANDLE,
					 });

	$parameter_href->{exome_target_bed}{build_file} = 0;  #Only build once for all modules and files
    }
}


sub download_reference {

##download_reference

##Function : Downloads reference(s) using the database download manager Cosmid.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_lane_no_ending_href, $job_id_href, $supported_cosmid_reference_href, $cosmid_resource_directory_ref, $program_ref, $FILEHANDLE, $parameter_name, $cosmid_resource_directory_ref
##         : $parameter_href                  => The parameter hash {REF}
##         : $active_parameter_href           => The active parameters for this analysis hash {REF}
##         : $sample_info_href                => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href      => The infile(s) without the ".ending" {REF}
##         : $job_id_href                     => The job_id hash {REF}
##         : $supported_cosmid_reference_href => The supported cosmid references hash {REF}
##         : $cosmid_resource_directory_ref   => Cosmid directory {REF}
##         : $program_ref                     => Program under evaluation {REF}
##         : $FILEHANDLE                      => Filehandle to write to
##         : $parameter_name                  => Parameter to use for download

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $supported_cosmid_reference_href;
    my $cosmid_resource_directory_ref;
    my $program_ref;
    my $FILEHANDLE;
    my $parameter_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	supported_cosmid_reference_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_cosmid_reference_href},
 	cosmid_resource_directory_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$cosmid_resource_directory_ref},
	program_ref => { required => 1, defined => 1,  default => \$$, strict_type => 1, store => \$program_ref},
	FILEHANDLE => { required => 1, store => \$FILEHANDLE},
	parameter_name => { required => 1, defined => 1, strict_type => 1, store => \$parameter_name},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my @vt_references = ("indels", "mills", "dbsnp", "hapmap", "dbsnpex", "1000g_snps");  #Should be decomposed and normalzed using vt out of downloadable references using Cosmid

    if ($parameter_href->{$parameter_name}{build_file} eq 1) {  #Reference need to be built a.k.a downloaded

	## Use $parameter instead of $active_parameter to cater for annotation files that are arrays and not supplied as flag => value
	if (defined($active_parameter_href->{$parameter_name})) {

	    $log->warn("Will try to download ".$active_parameter_href->{$parameter_name}." before executing ".$$program_ref."\n");
	}
	else {

	    $log->warn("Will try to download ".$parameter_name." before executing ".$$program_ref."\n");
	}

	print $FILEHANDLE "cosmid ";  #Database download manager
	print $FILEHANDLE "clone ";  #Clone resource
	print $FILEHANDLE $supported_cosmid_reference_href->{$parameter_name}{cosmid_name};  #The actual reference

	unless ($supported_cosmid_reference_href->{$parameter_name}{version} eq "latest") {  #Version to download

	    print $FILEHANDLE "#".$supported_cosmid_reference_href->{$parameter_name}{version},
	}
	say $FILEHANDLE "\n";

	## Check if reference comes decompressed or not
	if ($supported_cosmid_reference_href->{$parameter_name}{compressed_switch} eq "compressed") {

	    ## Clear trap for signal(s)
	    clear_trap({FILEHANDLE => $FILEHANDLE,
		       });

	    print $FILEHANDLE "gzip ";
	    print $FILEHANDLE "-d ";  #Decompress
	    say $FILEHANDLE catfile($$cosmid_resource_directory_ref, $supported_cosmid_reference_href->{$parameter_name}{cosmid_name}, "*.gz"), "\n";

	    ## Enable trap for signal(s) and function
	    enable_trap({FILEHANDLE => $FILEHANDLE,
			});
	}

	my $temporary_file_path = catfile($$cosmid_resource_directory_ref, $supported_cosmid_reference_href->{$parameter_name}{cosmid_name}, "*");

	if ( ( any {$_ eq $supported_cosmid_reference_href->{$parameter_name}{cosmid_name}} @vt_references ) ) {  #If element is part of array

	    ## Split multi allelic records into single records and normalize
	    vt_core({active_parameter_href => $active_parameter_href,
		     sample_info_href => $sample_info_href,
		     infile_lane_no_ending_href => $infile_lane_no_ending_href,
		     job_id_href => $job_id_href,
		     FILEHANDLE => $FILEHANDLE,
		     infile_path => catfile($$cosmid_resource_directory_ref, $supported_cosmid_reference_href->{$parameter_name}{cosmid_name}, "*"),
		     outfile_path => catfile($$cosmid_resource_directory_ref, $supported_cosmid_reference_href->{$parameter_name}{cosmid_name}, $active_parameter_href->{$parameter_name}),
		     decompose => $active_parameter_href->{vt_decompose},
		     normalize => $active_parameter_href->{vt_normalize},
		    });
	    $temporary_file_path = catfile($$cosmid_resource_directory_ref, $supported_cosmid_reference_href->{$parameter_name}{cosmid_name}, $active_parameter_href->{$parameter_name});
	}

	my $intended_file_path;
	## Use $parameter instead of $active_parameter to cater for annotation files that are arrays and not supplied as flag => value
	if (defined($active_parameter_href->{$parameter_name})) {

	    $intended_file_path = catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{$parameter_name});
	}
	else {

	    $intended_file_path = catfile($active_parameter_href->{reference_dir}, $parameter_name);
	}

	## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
	print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
					 intended_file_path_ref => \$intended_file_path,
					 temporary_file_path_ref => \$temporary_file_path,
					});

	## Remove temporary Cosmid resources directory
	print $FILEHANDLE "rm -rf ";
	say $FILEHANDLE catfile($$cosmid_resource_directory_ref, $supported_cosmid_reference_href->{$parameter_name}{cosmid_name}, ";"), "\n";

	## Clear trap for signal(s)
	clear_trap({FILEHANDLE => $FILEHANDLE,
		   });

	## Remove temporary Cosmid ".cosmid.yaml" file
	remove_file({file_ref => \catfile($$cosmid_resource_directory_ref, ".cosmid.yaml"),
		     FILEHANDLE => $FILEHANDLE,
		    });
	say $FILEHANDLE "\n";

	## Enable trap for signal(s) and function
	enable_trap({FILEHANDLE => $FILEHANDLE,
		    });

	for my $supported_parameter_name (keys %$supported_cosmid_reference_href) {

	    if ($supported_cosmid_reference_href->{$supported_parameter_name}{cosmid_name} eq $supported_cosmid_reference_href->{$parameter_name}{cosmid_name}) {  #Reset to 0 for all supported_cosmid_reference that are shared between modules

		$parameter_href->{$supported_parameter_name}{build_file} = 0;  #Only need to download once per analysis call
	    }
	}
    }
}


sub build_human_genome_prerequisites {

##build_human_genome_prerequisites

##Function : Creates the human genome prerequisites using active_parameters{human_genome_reference} as reference.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $infile_lane_no_ending_href, $job_id_href, $supported_cosmid_reference_href, $program, $FILEHANDLE, $random_integer, $family_id_ref, $reference_dir_ref, $outaligner_dir_ref, $human_genome_reference_ref
##         : $parameter_href                  => The parameter hash {REF}
##         : $active_parameter_href           => The active parameters for this analysis hash {REF}
##         : $sample_info_href                => Info on samples and family hash {REF}
##         : $file_info_href                  => The file_info hash {REF}
##         : $infile_lane_no_ending_href      => The infile(s) without the ".ending" {REF}
##         : $job_id_href                     => The job_id hash {REF}
##         : $supported_cosmid_reference_href => The supported cosmid references hash {REF}
##         : $program                         => The program under evaluation
##         : $FILEHANDLE                      => Filehandle to write to. A new sbatch script will be generated if $FILEHANDLE is lacking, else write to exising $FILEHANDLE {Optional}
##         : $random_integer                  => The random integer to create temporary file name
##         : $family_id_ref                   => Family ID {REF}
##         : $reference_dir_ref               => MIP reference directory
##         : $outaligner_dir_ref              => The outaligner_dir used in the analysis
##         : $human_genome_reference_ref      => Human genome reference {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $reference_dir_ref = $arg_href->{reference_dir_ref} //= \$arg_href->{active_parameter_href}{reference_dir};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $human_genome_reference_ref = $arg_href->{'human_genome_reference_ref'} //= \$arg_href->{'active_parameter_href'}{'human_genome_reference'},

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $supported_cosmid_reference_href;
    my $program;
    my $FILEHANDLE;
    my $random_integer;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	supported_cosmid_reference_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_cosmid_reference_href},
	program => { required => 1, defined => 1, strict_type => 1, store => \$program},
	FILEHANDLE => { store => \$FILEHANDLE},
	random_integer => { strict_type => 1, store => \$random_integer},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	reference_dir_ref => { default => \$$, strict_type => 1, store => \$reference_dir_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	human_genome_reference_ref => { default => \$$, strict_type => 1, store => \$human_genome_reference_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $file_name;

    unless(defined($FILEHANDLE)) {  #No supplied FILEHANDLE i.e. create new sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
	$random_integer = int(rand(10000));  #Generate a random integer between 0-10,000.

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name) = program_prerequisites({active_parameter_href => $active_parameter_href,
					      job_id_href => $job_id_href,
					      FILEHANDLE => $FILEHANDLE,
					      directory_id => $$family_id_ref,
					      program_name => $program,
					      program_directory => lc($$outaligner_dir_ref),
					     });
    }

    say $FILEHANDLE "cd $$reference_dir_ref", "\n";  #Move to reference directory

    ## Locates and sets the cosmid directory to download to
    my $cosmid_resource_directory = check_cosmid_yaml({active_parameter_href => $active_parameter_href,
						      });

    download_reference({parameter_href => $parameter_href,
			active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			job_id_href => $job_id_href,
			supported_cosmid_reference_href => $supported_cosmid_reference_href,
			cosmid_resource_directory_ref => \$cosmid_resource_directory,
			program_ref => \$program,
			FILEHANDLE => $FILEHANDLE,
			parameter_name => "human_genome_reference",
		       });

    ## Check for compressed files
    if ($file_info_href->{human_genome_compressed} eq "compressed") {

	$log->warn("Will try to decompres ".$$human_genome_reference_ref." before executing ".$program."\n");

	## Clear trap for signal(s)
	clear_trap({FILEHANDLE => $FILEHANDLE,
		   });

	print $FILEHANDLE "gzip ";
	print $FILEHANDLE "-d ";  #Decompress
	say $FILEHANDLE $$human_genome_reference_ref, "\n";

	## Enable trap for signal(s) and function
	enable_trap({FILEHANDLE => $FILEHANDLE,
		    });

	$$human_genome_reference_ref =~ s/.fasta.gz/.fasta/g;  #Replace the .fasta.gz ending with .fasta since this will execute before the analysis, hence changing the original file name ending from ".fastq" to ".fastq.gz".
	$log->info("Set human_genome_reference to: ".$$human_genome_reference_ref, "\n");
	$file_info_href->{human_genome_compressedRef} = "uncompressed";
    }

    check_build_ptchs_metric_prerequisites({parameter_href => $parameter_href,
					    active_parameter_href => $active_parameter_href,
					    sample_info_href => $sample_info_href,
					    file_info_href => $file_info_href,
					    infile_lane_no_ending_href => $infile_lane_no_ending_href,
					    job_id_href => $job_id_href,
					    program_name => $program,
					    FILEHANDLE => $FILEHANDLE,
					   });

    foreach my $file_ending (@{ $file_info_href->{human_genome_reference_file_endings} }) {

	if ($parameter_href->{"human_genome_reference".$file_ending}{build_file} eq 1) {

	    if ($file_ending eq ".dict") {

		$log->warn("Will try to create ".$file_ending." file for ".$$human_genome_reference_ref." before executing ".$program."\n");

		my $filename_no_ending = catfile($$reference_dir_ref, $file_info_href->{human_genome_reference_name_no_ending});

		say $FILEHANDLE "#CreateSequenceDictionary from reference";
		java_core({FILEHANDLE => $FILEHANDLE,
			   memory_allocation => "Xmx2g",
			   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
			   java_temporary_directory => $active_parameter_href->{temp_directory},
			   java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
			  });

		print $FILEHANDLE "CreateSequenceDictionary ";
		print $FILEHANDLE "R=".$$human_genome_reference_ref." ";  #Reference genome
		say $FILEHANDLE "OUTPUT=".$filename_no_ending."_".$random_integer.$file_ending, "\n";  #Output sequence dictionnary

		my $intended_file_path = $filename_no_ending.$file_ending;
		my $temporary_file_path = $filename_no_ending."_".$random_integer.$file_ending;

		## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
		print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
						 intended_file_path_ref => \$intended_file_path,
						 temporary_file_path_ref => \$temporary_file_path,
						});		
	    }
	    if ($file_ending eq ".fai") {

		$log->warn("Will try to create ".$file_ending." file for ".$$human_genome_reference_ref." before executing ".$program."\n");

		my $human_genome_reference_temp_file = $$human_genome_reference_ref."_".$random_integer;

		say $FILEHANDLE "## Fai file from reference";
		print $FILEHANDLE "ln -s ";  #Softlink
		print $FILEHANDLE $$human_genome_reference_ref." ";  #Reference genome
		say $FILEHANDLE $human_genome_reference_temp_file, "\n";  #Softlink to reference genome

		print $FILEHANDLE "samtools faidx ";#index/extract FASTA
		say $FILEHANDLE $human_genome_reference_temp_file, "\n";  #Softlink to reference genome

		my $intended_file_path = $$human_genome_reference_ref.$file_ending;
		my $temporary_file_path = $human_genome_reference_temp_file.$file_ending;

		## Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
		print_check_exist_and_move_file({FILEHANDLE => $FILEHANDLE,
						 intended_file_path_ref => \$intended_file_path,
						 temporary_file_path_ref => \$temporary_file_path,
						});

		## Remove softLink
		remove_file({file_ref => \$human_genome_reference_temp_file,
			     FILEHANDLE => $FILEHANDLE,
			    });
		say $FILEHANDLE "\n";  #Softlink to reference genome
	    }
	    $parameter_href->{"human_genome_reference".$file_ending}{build_file} = 0;  #Only create once
	}
    }
    unless(defined($FILEHANDLE)) { #Unless FILEHANDLE was supplied close it and submit

	close($FILEHANDLE);

	if ( ($active_parameter_href->{"p".$program} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			job_id_href => $job_id_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			dependencies => "no_dependency_add_to_case",
			path => "MIP",
			sbatch_file_name => $file_name
		       });
	}
    }
}


sub check_cosmid_installation {

##check_cosmid_installation

##Function : Check that a Cosmid installation exists
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $parameter_name_ref
##         : $parameter_href                  => The parameter hash {REF}
##         : $active_parameter_href           => The active parameters for this analysis hash {REF}
##         : $supported_cosmid_reference_href => Suported Cosmid references {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $supported_cosmid_reference_href;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	supported_cosmid_reference_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_cosmid_reference_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $ret;

    for my $parameter_name (keys %$supported_cosmid_reference_href) {

	if ($parameter_href->{$parameter_name}{build_file} eq 1) {

	    $log->info("Checking your Cosmid installation in preparation for download of ".$active_parameter_href->{$parameter_name}."\n");

	    $ret = `which cosmid;`;

	    if ($ret eq "") {

		$log->fatal("MIP uses cosmid to download ".$active_parameter_href->{$parameter_name}." and MIP could not find a cosmid installation in your environment ","\n");
		exit 1;
	    }
	    else {  #Test ok

		$log->info("Found installation in ".$ret);
	    }
	    last;  #Only need to check once per analysis run
	}
    }
}


sub read_plink_pedigree_file {

##read_plink_pedigree_file

##Function : Reads family_id_pedigree file in PLINK format. Checks for pedigree data for allowed entries and correct format. Add data to sample_info depending on user info.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $supported_capture_kit_href, $file_path, $family_id_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The associated reference file endings {REF}
##         : $supported_capture_kit_href => The supported capture kits hash {REF}
##         : $file_path                  => Pedigree file path
##         : $family_id_ref              => Family_id {RF}
###FORMAT: famliyID\tsample_id\tfather\tmother\tsex(1=male; 2=female; other=unknown)\tphenotype(-9 missing, 0 missing, 1 unaffected, 2 affected)..n

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $supported_capture_kit_href;
    my $file_path;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	supported_capture_kit_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_capture_kit_href},
	file_path => { required => 1, defined => 1, strict_type => 1, store => \$file_path},
	family_id_ref => { default => \$$, strict_type => 1},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my %exom_target_bed_test_file_tracker;  #Use to collect which sample_ids have used a certain capture_kit
    my @pedigree_file_elements = ("family_id", "sample_id", "father", "mother", "sex", "phenotype");
    my @pedigree_sample_ids;
    my $family_id;
    my $sample_id;

    my %user_supply_switch = get_user_supplied_info({parameter_href => $parameter_href,
						     active_parameter_href => $active_parameter_href,
						    });

    ## Defines which entries are allowed and links them to my.
    my %plink_pedigree = define_plink_pedigree();  #Holds allowed entries and positions to be checked for Plink pedigree files

    open(my $PEDF, "<", $file_path) or $log->logdie("Can't open '".$file_path."': ".$!."\n");

    while (<$PEDF>) {

	chomp $_;  #Remove newline

	if ( ($. == 1) && ($_ =~/^\#/) ) {  #Header present add to @pedigree_file_elements with header info for non mandatory headers

	    my @headers = split("\t", $'); #');
	    @headers = splice(@headers, 6, scalar(@headers));  #Remove mandatory headers
	    push(@pedigree_file_elements, @headers);
	    next;
	}
	if (m/^\s+$/) {  # Avoid blank lines

	    next;
	}
	if (m/^\#/) {  # Avoid "#"

	    next;
        }
	if ($_ =~/(\S+)/) {

	    my @line_info = split("\t",$_);  #Loads pedigree file info

	    ##Need to parse family_id and sample_id separately since these have not been set yet
	    if ($line_info[0] =~/\S+/) {  #Family_id

		$family_id = $line_info[0];

		if ($family_id ne $active_parameter_href->{family_id}) {

		    $log->fatal("File: ".$file_path." at line ".$.." pedigree Family_id: '".$family_id."' and supplied family_id: '".$active_parameter_href->{family_id}."' does not match\n");
		    exit 1;
		}
	    }
	    else {

		$log->fatal("File: ".$file_path." at line ".$.." cannot find family_id in column 1\n");
		exit 1;
	    }
	    if ($line_info[1] =~/\S+/) { #Sample_id

		$sample_id = $line_info[1];

		if (! $user_supply_switch{sample_ids}) {

		    push(@{ $active_parameter_href->{sample_ids} }, $line_info[1]);  #Save sample_id info
		}
		else {  #Save sample_ids in pedigree to check that user supplied info and sample_id in pedigree match

		    push(@pedigree_sample_ids, $line_info[1]); #Save pedigree sample_id info
		}
	    }
	    else {

		$log->fatal("File: ".$file_path." at line ".$.." cannot find Sample_id in column 2\n");
		exit 1;
	    }
	    for (my $sample_elements_counter=0;$sample_elements_counter<scalar(@pedigree_file_elements);$sample_elements_counter++) {  #All pedigree_file_elements

		my $pedigree_header_ref = \$pedigree_file_elements[$sample_elements_counter];  #Alias

		if ( defined($line_info[$sample_elements_counter]) && ($line_info[$sample_elements_counter] =~/\S+/) ) {  #Check that we have an non blank entry

		    ## Test element for being part of hash of array at supplied key.
		    if (check_entry_hash_of_array({hash_ref => \%plink_pedigree,
						   key => $sample_elements_counter,
						   element => $line_info[$sample_elements_counter],
						  })
			) {

			$log->fatal("Found illegal element: '".$line_info[$sample_elements_counter]."' in column '".$sample_elements_counter."' in pedigree file: '".$file_path."' at line '".$.."'\n");
			$log->fatal("Please correct the entry before analysis.\n");
			$log->fatal("\nMIP: Aborting run.\n\n");
			exit 1;
		    }

		    my @element_fields = split(";", $line_info[$sample_elements_counter]);  #Split element (if required)

		    if ($sample_elements_counter < 6) {  #Mandatory elements known to be key->value

			$sample_info_href->{sample}{$sample_id}{$$pedigree_header_ref} = $line_info[$sample_elements_counter];

			if ($$pedigree_header_ref =~/phenotype/i) {

			    detect_phenotype({parameter_href => $parameter_href,
					      phenotype => $line_info[$sample_elements_counter],
					      sample_id_ref => \$sample_id,
					     });
			}
		    }
		    else {  #Other elements treat as lists

			## Detects if there are elements in array_query_ref that are not present in scalarQueryRef or array_to_check_ref. If unique adds the unique element to array_to_check_ref.
			check_unique_array_element({array_to_check_ref => \@{ $sample_info_href->{sample}{$sample_id}{$$pedigree_header_ref} },
						    query_ref => \@element_fields,
						   });  #Check if there are any new info and add it to sample_info if so.
		    }
		    if ($sample_info_href->{sample}{$sample_id}{capture_kit} && $$pedigree_header_ref eq "capture_kit") {  #Add latest capture kit for each individual

			my $capture_kit = $sample_info_href->{sample}{$sample_id}{$$pedigree_header_ref}[-1];  #Use only the last capture kit since it should be the most interesting


			## Return a capture kit depending on user info
			my $exome_target_bed_file = add_capture_kit({file_info_href => $file_info_href,
								     supported_capture_kit_href => $supported_capture_kit_href,
								     capture_kit => $capture_kit,
								     user_supplied_parameter_switch => $user_supply_switch{exome_target_bed},
								    });
			if($exome_target_bed_file) {

			    push(@{ $exom_target_bed_test_file_tracker{$exome_target_bed_file} }, $sample_id);

			}
		    }

		    if ($sample_info_href->{sample}{$sample_id}{sequence_type} && $$pedigree_header_ref eq "sequence_type") {  #Add analysis_type

			if (! $user_supply_switch{analysis_type}) {

			    my $analysis_type = $sample_info_href->{sample}{$sample_id}{$$pedigree_header_ref}[-1];  #Use only the last capture kit since it should be the most interesting
			    $active_parameter_href->{analysis_type}{$sample_id} = $analysis_type;
			}
		    }
		}
		else {  #No entry in pedigre file element

		    if ($sample_elements_counter < 6) {  #Only check mandatory elements

			$log->fatal($$pedigree_header_ref, "\t File: ".$file_path." at line ".$.."\tcannot find '".$$pedigree_header_ref."' entry in column ".$sample_elements_counter, "\n");
			exit 1;
		    }
		}
	    }
	}
    }
    if (! $user_supply_switch{sample_ids}) {

	@{ $active_parameter_href->{sample_ids} } = sort(@{ $active_parameter_href->{sample_ids} });  #Lexiographical sort to determine the correct order of ids indata
    }
    else { #Check that CLI supplied sample_id exists in pedigree

	## Prepare CLI supplied sample_ids if comma sep
	my $values_ref = \@{ $parameter_href->{sample_ids}{value} };
	my $element_separator_ref = \$parameter_href->{sample_ids}{element_separator};
	my @temp_sample_ids = split($$element_separator_ref, join($$element_separator_ref, @$values_ref) );

	foreach my $sample_id (@temp_sample_ids) {

	    if (! ( any {$_ eq $sample_id} @pedigree_sample_ids ) ) {  #If element is not part of array

		$log->fatal("Provided sample_id: ".$sample_id." is not present in pedigree file: ".$file_path, "\n");
		exit 1;
	    }
	}
    }
    if(%exom_target_bed_test_file_tracker) {  #We have read capture kits from pedigree and need to transfer to active_parameters

	foreach my $exome_target_bed_file (keys %exom_target_bed_test_file_tracker) {

	    $active_parameter_href->{exome_target_bed}{$exome_target_bed_file} = join(",", @{ $exom_target_bed_test_file_tracker{$exome_target_bed_file} });
	}
    }
    $log->info("Read pedigree file: ".$file_path, "\n");
    close($PEDF);
}


sub read_yaml_pedigree_file {

##read_yaml_pedigree_file

##Function : Reads family_id_pedigree file in YAML format. Checks for pedigree data for allowed entries and correct format. Add data to sample_info depending on user info.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $supported_capture_kit_href, $pedigree_href, $file_path, $family_id_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The associated reference file endings {REF}
##         : $supported_capture_kit_href => The supported capture kits hash {REF}
##         : $pedigree_href              => Pedigree hash {REF}
##         : $file_path                  => Pedigree file path
##         : $family_id_ref              => Family_id {RF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $supported_capture_kit_href;
    my $pedigree_href;
    my $file_path;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	supported_capture_kit_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_capture_kit_href},
	pedigree_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$pedigree_href},
	file_path => { required => 1, defined => 1, strict_type => 1, store => \$file_path},
	family_id_ref => { default => \$$, strict_type => 1},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    ## Defines which values are allowed
    my %allowed_values = (sex => ["male", "female", "unknown"],
			  phenotype => ["affected", "unaffected", "unknown"],
	);

    my %exom_target_bed_test_file_tracker;  #Use to collect which sample_ids have used a certain capture_kit
    my @pedigree_sample_ids;
    my $family_id = $pedigree_href->{family};
    my @mandatory_family_keys = ("family", "samples");
    my @mandatory_sample_keys = ("sample_id", "father", "mother", "sex", "phenotype");
    my @user_input_sample_ids;

    ### Check input

    my %user_supply_switch = get_user_supplied_info({parameter_href => $parameter_href,
						     active_parameter_href => $active_parameter_href,
						    });

    if ($user_supply_switch{sample_ids} != 0) {

	## Prepare CLI supplied sample_ids if comma sep
	my $values_ref = \@{ $parameter_href->{sample_ids}{value} };
	my $element_separator_ref = \$parameter_href->{sample_ids}{element_separator};
	@user_input_sample_ids = split($$element_separator_ref, join($$element_separator_ref, @$values_ref) );
    }

    ## Check that we find mandatory family keys
    foreach my $key (@mandatory_family_keys) {

	if(! $pedigree_href->{$key}) {

	    $log->fatal("File: ".$file_path." cannot find mandatory key: ".$key." in file\n");
	    exit 1;
	}
    }

    ## Check that supplied cmd and YAML pedigree family_id match
    if ($pedigree_href->{family} ne $active_parameter_href->{family_id}) {

	$log->fatal("File: ".$file_path." for  pedigree family_id: '".$pedigree_href->{family}."' and supplied family: '".$active_parameter_href->{family_id}."' does not match\n");
	exit 1;
    }

    ## Check sample keys and values
    foreach my $pedigree_sample_href (@{ $pedigree_href->{samples} }) {

	## Check that we find mandatory family keys
	foreach my $key (@mandatory_sample_keys) {

	    if(! defined($pedigree_sample_href->{$key})) {

		$log->fatal("File: ".$file_path." cannot find mandatory key: ".$key." in file\n");
		exit 1;
	    }
	    elsif ($allowed_values{$key}){  #Check allowed values

		if (! ( any {$_ eq $pedigree_sample_href->{$key}} @{ $allowed_values{$key} } ) ) { #If element is not part of array

		    $log->fatal("File: ".$file_path." found illegal value: ".$pedigree_sample_href->{$key}." allowed values are '".join("' '", @{ $allowed_values{$key} }),"'\n");
		    $log->fatal("Please correct the entry before analysis.\n");
		    $log->fatal("\nMIP: Aborting run.\n\n");
		    exit 1;
		}
	    }
	}
    }

    ### Add values family level info
    foreach my $key (keys %$pedigree_href) {

	unless ($key eq "samples") {

	    $sample_info_href->{$key} = $pedigree_href->{$key};
	}
    }

    ### Add values sample level info
    foreach my $pedigree_sample_href (@{ $pedigree_href->{samples} }) {

	## Sample_id
	my $sample_id = $pedigree_sample_href->{sample_id};  #Alias
	push(@pedigree_sample_ids, $sample_id); #Save pedigree sample_id info

	if ($user_supply_switch{sample_ids} == 0) {

	    push(@{ $active_parameter_href->{sample_ids} }, $sample_id);  #Save sample_id info

	    ## Reformat pedigree keys to plink format and collect sample info to various hashes
	    get_pedigree_sample_info({parameter_href => $parameter_href,
				      active_parameter_href => $active_parameter_href,
				      sample_info_href => $sample_info_href,
				      file_info_href => $file_info_href,
				      supported_capture_kit_href => $supported_capture_kit_href,
				      exom_target_bed_test_file_tracker_href => \%exom_target_bed_test_file_tracker,
				      pedigree_sample_href => $pedigree_sample_href,
				      user_supply_switch_href => \%user_supply_switch,
				      sample_id => $sample_id,
				     });
	}
	else {  #Save sample_ids in pedigree to check that user supplied info and sample_id in pedigree match

	    if (any {$_ eq $sample_id} @user_input_sample_ids) {  #Update sample_id info

		push(@{ $active_parameter_href->{sample_ids} }, $sample_id);  #Save sample_id info

		## Reformat pedigree keys to plink format and collect sample info to various hashes
		get_pedigree_sample_info({parameter_href => $parameter_href,
					  active_parameter_href => $active_parameter_href,
					  sample_info_href => $sample_info_href,
					  file_info_href => $file_info_href,
					  supported_capture_kit_href => $supported_capture_kit_href,
					  exom_target_bed_test_file_tracker_href => \%exom_target_bed_test_file_tracker,
					  pedigree_sample_href => $pedigree_sample_href,
					  user_supply_switch_href => \%user_supply_switch,
					  sample_id => $sample_id,
					 });
	    }
	}
    }

    ##Check that founder_ids are included in the pedigree info and the analysis run
    check_founder_id({pedigree_href => $pedigree_href,
		      pedigree_sample_ids_ref => \@{ $active_parameter_href->{sample_ids} },
		     });

    if (! $user_supply_switch{sample_ids}) {

	@{ $active_parameter_href->{sample_ids} } = sort(@{ $active_parameter_href->{sample_ids} });  #Lexiographical sort to determine the correct order of ids indata
    }
    else { #Check that CLI supplied sample_id exists in pedigree

	foreach my $sample_id (@user_input_sample_ids) {

	    if (! ( any {$_ eq $sample_id} @pedigree_sample_ids ) ) {  #If element is not part of array

		$log->fatal("File: ".$file_path." provided sample_id: ".$sample_id." is not present in file", "\n");
		exit 1;
	    }
	}
	
    }
    if(%exom_target_bed_test_file_tracker) {  #We have read capture kits from pedigree and need to transfer to active_parameters

	foreach my $exome_target_bed_file (keys %exom_target_bed_test_file_tracker) {

	    $active_parameter_href->{exome_target_bed}{$exome_target_bed_file} = join(",", @{ $exom_target_bed_test_file_tracker{$exome_target_bed_file} });
	}
    }
}


sub define_plink_pedigree {

##define_plink_pedigree

##Function : Defines which entries are allowed and links them to position.
##Returns  : "%plink_pedigree"
##Arguments:
##         :

    my %plink_pedigree;

    $plink_pedigree{4} = [1, 2, "other"];  #Sex allowed entries
    $plink_pedigree{5} = [-9, 0, 1, 2];  #Phenotype allowed entries

    return %plink_pedigree
}


sub add_to_job_id {

##add_to_job_id

##Function : Adds all previous jobIds per familyChainKey and chain_key to job_ids string used to set the dependency in SLURM.
##Returns  : "$job_ids"
##Arguments: $job_id_href, $family_id_chain_key, $chain_key
##         : $job_id_href         => The info on jobIds hash {REF}
##         : $family_id_chain_key => Family ID chain hash key
##         : $chain_key           => The current chain hash key

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $job_id_href;
    my $family_id_chain_key;
    my $chain_key;

    my $tmpl = {
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	family_id_chain_key => { required => 1, defined => 1, strict_type => 1, store => \$family_id_chain_key},
	chain_key => { required => 1, defined => 1, strict_type => 1, store => \$chain_key},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $job_id_string = "";  #JobID string to submit to batch system
    my $chain_job_id_href = $job_id_href->{$family_id_chain_key}{$chain_key};  #Alias

    if ($chain_job_id_href) {

	while ( my ($job_index, $job_id) = each (@{ $chain_job_id_href }) ) {

	    if ( (! $job_index) && (scalar( @{ $chain_job_id_href }) == 1) ) {  #Only 1 previous job_id

		$job_id_string .= ":".$job_id;  #First and last job_id start with ":" and end without ":"
	    }
	    elsif (! $job_index) {  #First job_id

		$job_id_string .= ":".$job_id.":";  #First job_id start with :
	    }
	    elsif ($job_index eq (scalar( @{ $chain_job_id_href }) -1) ) {  #Last job_id

		$job_id_string .= $job_id;  #Last job_id finish without :
	    }
	    else {  #JobIDs in the middle

		$job_id_string .= $job_id.":";
	    }
	}
    }
    return $job_id_string;
}


sub push_to_job_id {

##push_to_job_id

##Function : Saves job_id to the correct hash array depending on chaintype.
##Returns  : ""
##Arguments: $active_parameter_href, $sample_info_href, $job_id_href, $infile_lane_no_ending_href, $family_id_chain_key, $sample_id_chain_key, $sample_id, $path, $chain_key_type, $family_id_ref
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $job_id_href                => The info on jobIds hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $family_id_chain_key        => Family ID chain hash key
##         : $sample_id_chain_key        => Sample ID chain hash key
##         : $sample_id                  => Sample ID
##         : $family_id_ref              => Family id {REF}
##         : $path                       => Trunk or branch
##         : $chain_key_type             => "parallel", "merged" or "family_merged"

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $parallel_chains_ref;
    my $family_id_chain_key;
    my $sample_id_chain_key;
    my $sample_id;
    my $path;
    my $chain_key_type;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	parallel_chains_ref => { default => [], strict_type => 1, store => \$parallel_chains_ref},
	family_id_chain_key => { required => 1, defined => 1, strict_type => 1, store => \$family_id_chain_key},
	sample_id_chain_key => { required => 1, defined => 1, strict_type => 1, store => \$sample_id_chain_key},
	sample_id => { strict_type => 1, store => \$sample_id},
	path => { required => 1, defined => 1, strict_type => 1, store => \$path},
	chain_key_type => { required => 1, defined => 1,
			    allow => ["parallel", "merged", "family_merged"],
			    strict_type => 1, store => \$chain_key_type},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Detect if all samples has the same sequencing type and return consensus if reached
    my $consensus_analysis_type = detect_overall_analysis_type({analysis_type_hef => \%{ $active_parameter_href->{analysis_type} },
							       });
    my $chain_key;

    if ($chain_key_type eq "parallel") {  #Push parallel jobs

	if ( ($consensus_analysis_type eq "rapid") && ($sample_info_href->{sample}{$sample_id}{pbwa_mem}{sbatch_batch_processes}) ) {  #Rapid run

	    for (my $sbatch_counter=0;$sbatch_counter<$sample_info_href->{sample}{$sample_id}{pbwa_mem}{sbatch_batch_processes};$sbatch_counter++) {  #Iterate over sbatch processes instead of infile(s)

		$chain_key = $sample_id."_".$chain_key_type."_".$path.$sbatch_counter;  #Set key

		if ($job_id_href->{$family_id_chain_key}{$chain_key}) {  #Job exists

		    for (my $job_counter=0;$job_counter<scalar( @{ $job_id_href->{$family_id_chain_key}{$chain_key} });$job_counter++) {  #All previous jobs i.e. jobs in this case equals to infiles in number

			push ( @{ $job_id_href->{$family_id_chain_key}{$sample_id_chain_key} }, $job_id_href->{$family_id_chain_key}{$chain_key}[$job_counter]);  #Add job_id to hash
		    }
		}
	    }
	    $sample_info_href->{sample}{$sample_id}{pbwa_mem}{sbatch_batch_processes} = ();
	}
	else {

	  INFILES:
	    while ( my ($infile_index) = each($infile_lane_no_ending_href->{$sample_id}) ) {  #All infiles

		$chain_key = $sample_id."_".$chain_key_type."_".$path.$infile_index;  #Set key

		if ($job_id_href->{$family_id_chain_key}{$chain_key}) {  #Job exists

		  JOB_IDS:
		    while (my ($job_index) = each($job_id_href->{$family_id_chain_key}{$chain_key}) ) {  #All previous jobs i.e. jobs in this case equals to infiles in number

			push ( @{ $job_id_href->{$family_id_chain_key}{$sample_id_chain_key} }, $job_id_href->{$family_id_chain_key}{$chain_key}[$job_index]);  #Add job_id to hash
		    }
		}
	    }
	}
    }
    elsif ( ($chain_key_type eq "merged") || ($chain_key_type eq "family_merged")  ) {  #Push merged jobs

	$chain_key = $family_id_chain_key."_".$sample_id_chain_key;  #Set key

	if ($job_id_href->{$family_id_chain_key}{$chain_key}) {  #Job exists
	    
	  JOB_IDS:
	    while (my ($job_index) = each($job_id_href->{$family_id_chain_key}{$chain_key}) ) {  #All previous jobs i.e. jobs in this case equals to infiles in number

		if ($chain_key_type eq "family_merged") {  #Use $family_id_chain_key instead of $sample_id_chain_key

		    push ( @{ $job_id_href->{$family_id_chain_key}{$family_id_chain_key} }, $job_id_href->{$family_id_chain_key}{$chain_key}[$job_index]);  #Add job_id hash
		}
		else {
		    push ( @{ $job_id_href->{$family_id_chain_key}{$sample_id_chain_key} }, $job_id_href->{$family_id_chain_key}{$chain_key}[$job_index]);  #Add job_id to hash
		}
	    }
	}
    }
}


sub submit_job {

##submit_job

##Function : Submits all job_ids to SLURM using SLURM dependencies. The trunk is the "MAIN path" and any subsequent splits into  branches "other paths" later is handled by adding relevant previous job_ids to the new paths key in job_id{family_path_key} hash. The subroutine supports parallel job within each step and submission which do not leave any dependencies. Currently any path downstream of MAIN inherits the relevant previous jobIds, but it is possible to merge back to MAIN for splited paths downstream.
##Returns  : ""
##Arguments: $active_parameter_href, $sample_info_href, $infile_lane_no_ending_href, $job_id_href, $parallel_chains_ref, $sample_id, $dependencies, $path, $sbatch_file_name, $sbatch_script_tracker, $family_id_ref, $job_dependency_type
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The info on jobIds hash {REF}
##         : $parallel_chains_ref        => The info on parallel chains array {REF}
##         : $sample_id                  => Sample id
##         : $dependencies               => Job dependencies
##         : $path                       => Trunk or Branch part of chainkey
##         : $sbatch_file_name           => Sbatch filename to submit
##         : $sbatch_script_tracker      => Track the number of parallel processes (e.g. sbatch scripts for a module)
##         : $family_id_ref              => Family id {REF}
##         : $job_dependency_type        => Job dependency type

###Dependencies

##-1 = Not dependent on earlier scripts, and are self cul-de-scs (no_dependency_dead_end).
##0 = Not dependent on earlier scripts (no_dependency).
##1 = Dependent on earlier scripts within sample_id_path or family_id_path (case_dependency).
##2 = Dependent on earlier scripts within sample_id_path or family_id_path, but are self cul-de-scs (case_dependency_dead_end).
##3 = Dependent on earlier scripts and executed in parallel within step (sample_id_dependency_step_in_parallel)
##4 = Dependent on earlier scripts and parallel scripts and executed in parallel within step (sample_id_and_parallel_dependency_step_in_parallel)
##5 = Dependent on earlier scripts both family_id and sample_id and adds to both family_id and sample_id jobs (case_dependency_add_to_case)
##6 = Not dependent on earlier scripts and adds to sample_id jobs and family_id jobs, but sbatch is processed at family level i.e. affects all sample_id jobs e.g. building a reference (no_dependency_add_to_case)
##7 = Dependent on all earlier scripts in selected chains for family_id jobs i.e. wait for chains jobs before launching (chain_and_parallel_dependency)

###Chain
##ALL = Dependent on all earlier scripts in all chains, sampleId and family_id jobs i.e. wait for all before launching

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $job_dependency_type = $arg_href->{job_dependency_type} //= "afterok";

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $parallel_chains_ref;
    my $sample_id;
    my $dependencies;
    my $path;
    my $sbatch_file_name;
    my $sbatch_script_tracker;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	parallel_chains_ref => { default => [], strict_type => 1, store => \$parallel_chains_ref},
	sample_id => { strict_type => 1, store => \$sample_id},
	dependencies => { required => 1, defined => 1,
			  allow => ["no_dependency_dead_end",
				    "no_dependency",
				    "case_dependency",
				    "case_dependency_dead_end",
				    "sample_id_dependency_step_in_parallel",
				    "sample_id_and_parallel_dependency_step_in_parallel",
				    "case_dependency_add_to_case",
				    "no_dependency_add_to_case",
				    "chain_and_parallel_dependency",
			      ],
			  strict_type => 1, store => \$dependencies},
	path => { required => 1, defined => 1, strict_type => 1, store => \$path},
	sbatch_file_name => { required => 1, defined => 1, strict_type => 1, store => \$sbatch_file_name},
	sbatch_script_tracker => { allow => qr/^\d+$/,
				   strict_type => 1, store => \$sbatch_script_tracker},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	job_dependency_type => { allow => ["afterany", "afterok"],
				 strict_type => 1, store => \$job_dependency_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $sample_id_chain_key;
    my $sample_id_parallel_chain_key;
    my $family_id_parallel_chain_key;

    if (defined($sample_id)) {

	$sample_id_chain_key = $sample_id."_".$path;  #Sample chainkey
    }
    if ( (defined($sbatch_script_tracker)) ) {

	$family_id_parallel_chain_key = $$family_id_ref."_parallel_".$path.$sbatch_script_tracker;  #Family parallel chainkey

	if (defined($sample_id)) {

	    $sample_id_parallel_chain_key = $sample_id."_parallel_".$path.$sbatch_script_tracker;  #Sample parallel chainkey
	}
    }
    my $job_ids = "";  #Create string with all previous job_ids
    my $family_id_chain_key = $$family_id_ref."_".$path;  #Family chainkey
    my $job_id;  #The job_id that is returned from submission

    if ($dependencies eq "no_dependency_dead_end") {  #Initiate chain - No dependencies, lonely program "sapling"

	## Sumit jobs to sbatch
	$job_id = submit_jobs_to_sbatch({sbatch_file_name => $sbatch_file_name,
					});
    }
    if ($dependencies eq "no_dependency_add_to_case") {  #Initiate chain - No dependencies, adds to all sample_id(s) and family_id

	## Sumit jobs to sbatch
	$job_id = submit_jobs_to_sbatch({sbatch_file_name => $sbatch_file_name,
					});

	foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {
	    
	    my $sample_id_chain_key =  $sample_id."_".$path;
	    push ( @{ $job_id_href->{$family_id_chain_key}{$sample_id_chain_key} }, $job_id);  #Add job_id to hash
	    
	    ## Saves job_id to the correct hash array depending on chaintype
	    push_to_job_id({active_parameter_href => $active_parameter_href,
			    sample_info_href => $sample_info_href,
			    infile_lane_no_ending_href => $infile_lane_no_ending_href,
			    job_id_href => $job_id_href,
			    family_id_chain_key => $family_id_chain_key,
			    sample_id_chain_key => $sample_id_chain_key,
			    path => $path,
			    chain_key_type => "family_merged",
			   });
	}
    }
    elsif ($dependencies eq "no_dependency") {  #Initiate chain - No dependencies, initiate Trunk (Main or other)

	## Sumit jobs to sbatch
	$job_id = submit_jobs_to_sbatch({sbatch_file_name => $sbatch_file_name,
					});

	push ( @{ $job_id_href->{$family_id_chain_key}{$sample_id_chain_key} }, $job_id);  #Add job_id to hash
    }
    else {  #Dependent on earlier scripts and/or parallel. JobIDs that do not leave dependencies do not get pushed to job_id hash

	if (defined($sample_id)) {  #Check jobs within sample_id (exception if dependencies = 5)

	    if ($dependencies eq "case_dependency_add_to_case") {  #Add family_id_sample_id jobs to current sample_id chain

		## Saves job_id to the correct hash array depending on chaintype
		push_to_job_id({active_parameter_href => $active_parameter_href,
				sample_info_href => $sample_info_href,
				infile_lane_no_ending_href => $infile_lane_no_ending_href,
				job_id_href => $job_id_href,
				family_id_chain_key => $family_id_chain_key,
				sample_id_chain_key => $sample_id_chain_key,
				sample_id => $sample_id,
				path => $path,
				chain_key_type => "merged",
			       });
	    }
	    if ( ($dependencies eq "case_dependency") || ($dependencies eq "case_dependency_dead_end") ) {  #Not parallel jobs, but check if last job submission was parallel

		## Saves job_id to the correct hash array depending on chaintype
		push_to_job_id({active_parameter_href => $active_parameter_href,
				sample_info_href => $sample_info_href,
				infile_lane_no_ending_href => $infile_lane_no_ending_href,
				job_id_href => $job_id_href,
				family_id_chain_key => $family_id_chain_key,
				sample_id_chain_key => $sample_id_chain_key,
				sample_id => $sample_id,
				path => $path,
				chain_key_type => "parallel",
			       });
	    }
	    if ( (defined($path)) && ($path eq "MAIN") ) {

		if ( ($dependencies eq "sample_id_and_parallel_dependency_step_in_parallel")
		     || ($dependencies eq "sample_id_dependency_step_in_parallel") ) {  #Parallel jobs

		    ## Add to job_id string
		    $job_ids = add_to_job_id({job_id_href => $job_id_href,
					      family_id_chain_key => $family_id_chain_key,
					      chain_key => $sample_id_parallel_chain_key,
					     });

		    if ($job_id_href->{$family_id_chain_key}{$sample_id_chain_key}) {  #Check for previous single jobs - required to initiate broken chain with correct dependencies

			## Add to job_id string
			$job_ids .= add_to_job_id({job_id_href => $job_id_href,
						   family_id_chain_key => $family_id_chain_key,
						   chain_key => $sample_id_chain_key,
						  });
		    }

		}
		else {  #Previous job was a single job

		    ## Add to job_id string
		    $job_ids = add_to_job_id({job_id_href => $job_id_href,
					      family_id_chain_key => $family_id_chain_key,
					      chain_key => $sample_id_chain_key,
					     });
		}
	    }
	    if ( (defined($path)) && ($path ne "MAIN") ) {  #Check for any previous job_ids within path current PATH. Branch.

		if ($job_id_href->{$family_id_chain_key}{$sample_id_chain_key}) {  #Second or later in branch chain

		    ## Add to job_id string
		    $job_ids = add_to_job_id({job_id_href => $job_id_href,
					      family_id_chain_key => $family_id_chain_key,
					      chain_key => $sample_id_chain_key,
					     });
		}
		elsif ($job_id_href->{$$family_id_ref."_MAIN"}{$sample_id."_MAIN"}) {  #Inherit from potential MAIN. Trunk

		    ## Add to job_id string
		    $job_ids = add_to_job_id({job_id_href => $job_id_href,
					      family_id_chain_key => $$family_id_ref."_MAIN",
					      chain_key => $sample_id."_MAIN",
					     });
		}
	    }
	    if ( (defined($path)) && ($path eq "ALL") ) {  #Inherit from all previous jobs

		## Add to job_id string
		$job_ids = add_to_job_id({job_id_href => $job_id_href,
					  family_id_chain_key => "ALL",
					  chain_key => "ALL",
					 });
	    }
	    if ($job_ids) {  #Previous jobs for chainkey exists

		## Sumit jobs to sbatch
		$job_id = submit_jobs_to_sbatch({sbatch_file_name => $sbatch_file_name,
						 job_dependency_type => $job_dependency_type,
						 job_ids => $job_ids,
						});
	    }
	    else {  #No previous jobs

		## Sumit jobs to sbatch
		$job_id = submit_jobs_to_sbatch({sbatch_file_name => $sbatch_file_name,
						});
	    }
	    if ($dependencies eq "case_dependency") {  #Ordinary job push to array

		@{ $job_id_href->{$family_id_chain_key}{$sample_id_chain_key} } = ();  #Clear latest family_id/sample_id chain submission

		##Clear all latest parallel jobs within chainkey
		while (my ($infile_index) = each($infile_lane_no_ending_href->{$sample_id}) ) {

		    my $sample_id_parallel_chain_key = $sample_id."_parallel_".$path.$infile_index;  #Create key

		    if ($job_id_href->{$family_id_chain_key}{$sample_id_parallel_chain_key}) {  #Parallel job exists

			@{ $job_id_href->{$family_id_chain_key}{$sample_id_parallel_chain_key} } = ();  #Clear latest family_id/sample_id chain submission
                    }
		}
		push ( @{ $job_id_href->{$family_id_chain_key}{$sample_id_chain_key} }, $job_id);  #Add job_id to hash
	    }
	    if ( ($dependencies eq "sample_id_dependency_step_in_parallel")
		 || ($dependencies eq "sample_id_and_parallel_dependency_step_in_parallel") ) {  #Parallel job wait to push to array until all parallel jobs are finished within step

		push ( @{ $job_id_href->{$family_id_chain_key}{$sample_id_parallel_chain_key} }, $job_id);  #Add job_id to hash
	    }
	    if ($dependencies eq "case_dependency_add_to_case") {  #Job dependent on both family_id and sample_id push to array

		@{ $job_id_href->{$family_id_chain_key}{$family_id_chain_key."_".$sample_id_chain_key} } = ();  #Clear latest family_id_sample_id chainkey
		@{ $job_id_href->{$family_id_chain_key}{$sample_id_chain_key} } = ();  #Clear latest sample_id chainkey
		push ( @{ $job_id_href->{$family_id_chain_key}{$family_id_chain_key."_".$sample_id_chain_key} }, $job_id);  #Add job_id to hash
	    }

	    ## Keeps the job_id string dependecy within reasonable limits
	    if ( (defined($job_id_href->{ALL}{ALL})) && (scalar(@{ $job_id_href->{ALL}{ALL} } >= 100)) ) {

		shift( @{ $job_id_href->{ALL}{ALL} });  #Remove oldest job_id.
	    }
	    ## Job dependent on all jobs
	    push ( @{ $job_id_href->{ALL}{ALL} }, $job_id);  #Add job_id to hash
	}
	else {  #AFTER merging to family_id

	    if ($dependencies eq "case_dependency_add_to_case") {  #Add family_id_sample_id jobs to current family_id chain

		foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

		    my $sample_id_chain_key = $sample_id."_".$path;  #Current chain

		    ## Saves job_id to the correct hash array depending on chaintype
		    push_to_job_id({active_parameter_href => $active_parameter_href,
				    sample_info_href => $sample_info_href,
				    infile_lane_no_ending_href => $infile_lane_no_ending_href,
				    job_id_href => $job_id_href,
				    family_id_chain_key => $family_id_chain_key,
				    sample_id_chain_key => $sample_id_chain_key,
				    path => $path,
				    chain_key_type => "family_merged",
				   });
		}
	    }
	    if ( ($dependencies eq "case_dependency") || ($dependencies eq "case_dependency_dead_end") ) {  #Not parallel jobs, but check if last job submission was parallel

		if (defined($job_id_href->{$family_id_chain_key})) {

		    foreach my $family_id_parallel_chain_key (keys $job_id_href->{$family_id_chain_key}) {

			## Add to job_id string
			$job_ids .= add_to_job_id({job_id_href => $job_id_href,
						   family_id_chain_key => $family_id_chain_key,
						   chain_key => $family_id_parallel_chain_key,
						  });
		    }
		}
	    }
	    if ( (defined($path)) && ($path eq "MAIN") && ($job_id_href->{$family_id_chain_key}{$family_id_chain_key}) ) {  #Check for any previous job_ids within path MAIN. Test for previous must be done to allow initiating from broken chain. Trunk and not first in chain

		if ( ($dependencies eq "sample_id_and_parallel_dependency_step_in_parallel")
		     || ($dependencies eq "sample_id_dependency_step_in_parallel") ) {  #Parallel jobs

		    ## Add to job_id string
		    $job_ids = add_to_job_id({job_id_href => $job_id_href,
					      family_id_chain_key => $family_id_chain_key,
					      chain_key => $family_id_parallel_chain_key,
					     });
		}
		else {  #Previous job was a single job

		    ## Add to job_id string
		    $job_ids = add_to_job_id({job_id_href => $job_id_href,
					      family_id_chain_key => $family_id_chain_key,
					      chain_key => $family_id_chain_key,
					     });
		}
		if ($dependencies eq "chain_and_parallel_dependency") {  #Add jobs from other parallel chains that have branched of from MAIN i.e. merge branch back again

		    foreach my $parallel_chain (@$parallel_chains_ref) {

			## Add to job_id string
			$job_ids .= add_to_job_id({job_id_href => $job_id_href,
						   family_id_chain_key => $$family_id_ref."_".$parallel_chain,
						   chain_key => $$family_id_ref."_".$parallel_chain,
						  });
		    }
		}
	    }
	    elsif ((defined($path)) && $path eq "MAIN") {  #First family_id MAIN chain

		##Add all previous jobId(s) from sample_id chainkey(s)
		foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

		    my $sample_id_chain_key = $sample_id."_".$path;

		    if ($job_id_href->{$family_id_chain_key}{$sample_id_chain_key}) {

			## Add to job_id string
			$job_ids .= add_to_job_id({job_id_href => $job_id_href,
						   family_id_chain_key => $family_id_chain_key,
						   chain_key => $sample_id_chain_key,
						  });

		    }
		    while (my ($infile_index) = each($infile_lane_no_ending_href->{$sample_id}) ) {

			my $sample_id_parallel_chain_key = $sample_id."_parallel_".$path.$infile_index;  #Create key

			if ($job_id_href->{$family_id_chain_key}{$sample_id_parallel_chain_key}) {  #Parallel job exists

			    ## Add to job_id string
			    $job_ids .= add_to_job_id({job_id_href => $job_id_href,
						       family_id_chain_key => $family_id_chain_key,
						       chain_key => $sample_id_parallel_chain_key,
						      });
			}
		    }
		}
	    }
	    if ((defined($path)) && $path ne "MAIN" ) {  #Check for any previous job_ids within path current PATH. Branch

		if ($job_id_href->{$family_id_chain_key}{$family_id_chain_key}) {  #Second or later in branch chain

		    ## Add to job_id string
		    $job_ids = add_to_job_id({job_id_href => $job_id_href,
					      family_id_chain_key => $family_id_chain_key,
					      chain_key => $family_id_chain_key,
					     });  #Family chain
		}
		elsif ($dependencies eq "chain_and_parallel_dependency") {  #Add jobs from other parallel chains that have branched of from MAIN i.e. merge branch back again

		    foreach my $parallel_chain (@$parallel_chains_ref) {

			foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

			    ## Add to job_id string
			    $job_ids .= add_to_job_id({job_id_href => $job_id_href,
						       family_id_chain_key => $$family_id_ref."_".$parallel_chain,
						       chain_key => $sample_id."_".$parallel_chain,
						      });
			}

			#Add to job_id string
			$job_ids .= add_to_job_id({job_id_href => $job_id_href,
						   family_id_chain_key => $$family_id_ref."_".$parallel_chain,
						   chain_key => $$family_id_ref."_".$parallel_chain,
						  });
		    }
		}
		elsif ($job_id_href->{$$family_id_ref."_MAIN"}{$$family_id_ref."_MAIN"}) {  #Inherit from potential MAIN. Trunk

		    ## Add to job_id string
		    $job_ids = add_to_job_id({job_id_href => $job_id_href,
					      family_id_chain_key => $$family_id_ref."_MAIN",
					      chain_key => $$family_id_ref."_MAIN",
					     });
		}
		else {  #First job in new path and first family_id MAIN chain

		    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

			my $family_id_chain_key = $$family_id_ref."_MAIN";
			my $sample_id_chain_key = $sample_id."_MAIN";

			if ($job_id_href->{$family_id_chain_key}{$sample_id_chain_key}) {

			    ## Add to job_id string
			    $job_ids .= add_to_job_id({job_id_href => $job_id_href,
						       family_id_chain_key => $family_id_chain_key,
						       chain_key => $sample_id_chain_key,
						      });
			}
		    }
		}
	    }
	    if ( (defined($path)) && ($path eq "ALL") ) {  #Inherit from all previous jobs

		## Add to job_id string
		$job_ids = add_to_job_id({job_id_href => $job_id_href,
					  family_id_chain_key => "ALL",
					  chain_key => "ALL",
					 });
	    }
	    if ($job_ids) {

		## Sumit jobs to sbatch
		$job_id = submit_jobs_to_sbatch({sbatch_file_name => $sbatch_file_name,
						 job_dependency_type => $job_dependency_type,
						 job_ids => $job_ids,
						});
	    }
	    else {

		## Sumit jobs to sbatch
		$job_id = submit_jobs_to_sbatch({sbatch_file_name => $sbatch_file_name,
						});
	    }
	    if ( ($dependencies eq "case_dependency") || ($dependencies eq "chain_and_parallel_dependency") ) {  #Ordinary job push to array

		@{ $job_id_href->{$family_id_chain_key}{$family_id_chain_key} } = ();  #Clear latest family_id/sample_id chain submission

		##Clear all latest parallel jobs within chainkey
		foreach my $chain_key (keys $job_id_href->{$family_id_chain_key}) {

		    @{ $job_id_href->{$family_id_chain_key}{$chain_key} } = ();  #Clear latest family_id/sample_id chain submission
		}
		push ( @{ $job_id_href->{$family_id_chain_key}{$family_id_chain_key} }, $job_id);  #Add job_id to hash
	    }
	    if ( ($dependencies eq "sample_id_dependency_step_in_parallel")
		 || ($dependencies eq "sample_id_and_parallel_dependency_step_in_parallel") ) {  #Parallel job wait to push to array until all parallel jobs are finished within step

		push ( @{ $job_id_href->{$family_id_chain_key}{$family_id_parallel_chain_key} }, $job_id);  #Add job_id to hash.
	    }
	    if ($dependencies eq "case_dependency_add_to_case") {  #Job dependent on both family_id and sample_id push to array

		foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

		    my $sample_id_chain_key = $sample_id."_".$path;  #Current chain
		    @{ $job_id_href->{$family_id_chain_key}{$family_id_chain_key."_".$sample_id_chain_key} } = ();
		    @{ $job_id_href->{$family_id_chain_key}{$family_id_chain_key} } = ();  #Clear latest sample_id chainkey
		    push ( @{ $job_id_href->{$family_id_chain_key}{$family_id_chain_key."_".$sample_id_chain_key} }, $job_id);
		}
	    }

	    ## Keeps the job_id string dependecy within reasonable limits
	    if ( (defined($job_id_href->{ALL}{ALL})) && (scalar(@{ $job_id_href->{ALL}{ALL} } >= 100)) ) {

		shift( @{ $job_id_href->{ALL}{ALL} });  #Remove oldest job_id.
	    }
	    ## Job dependent on all jobs
	    push( @{ $job_id_href->{ALL}{ALL} }, $job_id);  #Add job_id to hash
	}
    }

    $log->info("Sbatch script submitted, job id: $job_id\n");
    $log->info("To check status of job, please run \'squeue -j $job_id\'\n");
    $log->info("To cancel job, please run \'scancel $job_id\'\n");

    push( @{ $job_id_href->{PAN}{PAN} }, $job_id);  #Add job_id to hash for sacct processing downstream
}


sub submit_jobs_to_sbatch {

##submit_sbatch_to_sbatch

##Function : Sumit jobs to sbatch
##Returns  : "$job_id"
##Arguments: $sbatch_file_name, $job_dependency_type, $job_ids
##         : sbatch_file_name     => Sbatch file to submit
##         : $job_dependency_type => Job dependency type
##         : $job_ids             => Job ids string

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $sbatch_file_name;
    my $job_dependency_type;
    my $job_ids;

    my $tmpl = { 
	sbatch_file_name => { required => 1, defined => 1, strict_type => 1, store => \$sbatch_file_name},
	job_dependency_type => { strict_type => 1, store => \$job_dependency_type},
	job_ids => { strict_type => 1, store => \$job_ids},
    };
    
   
    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $job_ids_return;
    my $job_id;

    if($job_ids) {  #Current submission should use dependencies

	$job_ids_return = `sbatch --dependency=$job_dependency_type$job_ids $sbatch_file_name`;  #Supply with dependency of previous jobs that this one is dependent on
	($job_id) = ($job_ids_return =~ /Submitted batch job (\d+)/);  #Just submitted job_id
	
    }
    else {  #No dependencies

	$job_ids_return = `sbatch $sbatch_file_name`;  #No jobs have been run: submit
	($job_id) = ($job_ids_return =~ /Submitted batch job (\d+)/);  #Just submitted job_id
    }
    if ($job_ids_return !~/\d+/) {  #Catch errors since, propper sbatch submission should only return numbers
	
	$log->fatal($job_ids_return."\n");
	$log->fatal("MIP: Aborting run.\n");
	exit 1;
    }
    return $job_id;
}


sub core_number_per_sbatch {

##core_number_per_sbatch

##Function : Set the number of cores to allocate per sbatch job.
##Returns  : "$core_number"
##Arguments: $active_parameter_href, $core_number
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $core_number           => The number of cores to allocate

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $core_number;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	core_number => { required => 1, defined => 1, strict_type => 1, store => \$core_number},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ($core_number > $active_parameter_href->{core_processor_number}) {  #Set number of cores depending on how many lanes to process

	$core_number = $active_parameter_href->{core_processor_number};  #Set to max on cluster
    }
    return $core_number;
}


sub collect_infiles {

##collect_infiles

##Function : Collects the ".fastq(.gz)" files from the supplied infiles directory. Checks if any files exist.
##Returns  : ""
##Arguments: $active_parameter_href, $indir_path_href, $infile_href
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $indir_path_href       => The indirectories path(s) hash {REF}
##         : $infile_href           => The infiles hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $indir_path_href;
    my $infile_href;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	indir_path_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$indir_path_href},
	infile_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    $log->info("Reads from platform:\n");

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {  #Collects inputfiles govern by sample_ids

	## Return the key if the hash value and query match
	my $infile_directory_ref = \get_matching_values_key({active_parameter_href => $active_parameter_href,
							     query_value_ref => \$sample_id,
							     parameter_name => "infile_dirs",
							    });


	my @infiles;

	## Collect all fastq files in supplied indirectories
	my $rule = Path::Iterator::Rule->new;
	$rule->skip_subdirs( "original_fastq_files" );  #Ignore if original fastq files sub directory
	$rule->name("*.fastq*");  #Only look for fastq or fastq.gz files
	my $it = $rule->iter( $$infile_directory_ref );

	while ( my $file = $it->() ) {  #Iterate over directory

	    my ($volume, $directory, $fastq_file) = File::Spec->splitpath($file);
	    push(@infiles, $fastq_file);
	}
	chomp(@infiles);   #Remove newline from every entry in array

	if (!@infiles) {  #No "*.fastq*" infiles

	    $log->fatal("Could not find any '.fastq' files in supplied infiles directory ".$$infile_directory_ref, "\n");
	    exit 1;
	}
	foreach my $infile (@infiles) {  #Check that inFileDirs/infile contains sample_id in filename

	    unless ( $infile =~/$sample_id/) {

		$log->fatal("Could not detect sample_id: ".$sample_id." in supplied infile: ".$$infile_directory_ref."/".$infile, "\n");
		$log->fatal("Check that: '--sample_ids' and '--inFileDirs' contain the same sample_id and that the filename of the infile contains the sample_id.", "\n");
		exit 1;
	    }
	}
	$log->info("Sample id: ".$sample_id."\n");
	$log->info("\tInputfiles:\n");

	## Log each file from platform
	foreach my $file (@infiles) {

	    $log->info("\t\t", $file, "\n");  #Indent for visability
	}
	$indir_path_href->{$sample_id} = $$infile_directory_ref;   #Catch inputdir path
	$infile_href->{$sample_id}  = [@infiles];  #Reload files into hash
    }
}


sub infiles_reformat {

##infiles_reformat

##Function : Reformat files for MIP output, which have not yet been created into, correct format so that a sbatch script can be generated with the correct filenames.
##Returns  : "$uncompressed_file_counter"
##Arguments: $active_parameter_href, $sample_info_href, $file_info_href, $infile_href, $indir_path_href, $infile_lane_no_ending_href, $infile_both_strands_no_ending_href, $lane_href, $job_id_href, $program_name, $outaligner_dir_ref
##         : $active_parameter_href              => The active parameters for this analysis hash {REF}
##         : $sample_info_href                   => Info on samples and family hash {REF}
##         : $file_info_href                     => The file_info hash {REF}
##         : $infile_href                        => The infiles hash {REF}
##         : $indir_path_href                    => The indirectories path(s) hash {REF}
##         : $infile_lane_no_ending_href         => The infile(s) without the ".ending" {REF}
##         : $infile_both_strands_no_ending_href => The infile(s) without the ".ending" and strand info {REF}
##         : $lane_href                          => The lane info hash {REF}
##         : $job_id_href                        => The job_id hash {REF}
##         : $program_name                       => The program name {REF}
##         : $outaligner_dir_ref                 => The outaligner_dir used in the analysis {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_href;
    my $indir_path_href;
    my $infile_lane_no_ending_href;
    my $infile_both_strands_no_ending_href;
    my $lane_href;
    my $job_id_href;
    my $program_name;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_href},
	indir_path_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$indir_path_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	infile_both_strands_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_both_strands_no_ending_href},
	lane_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$lane_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	outaligner_dir_ref => { default => \$$, strict_type => 1},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $uncompressed_file_counter = 0;  #Used to decide later if any inputfiles needs to be compressed before starting analysis

    for my $sample_id (keys %$infile_href) {  #For every sample_id

        my $lane_tracker=0;  #Needed to be able to track when lanes are finished

	while (my ($file_index, $file_name) = each(@ { $infile_href->{$sample_id} }) ) {

	    ## Check if a file is gzipped.
	    my $compressed_switch = check_gzipped({file_name_ref => \$file_name,
						  });
	    my $read_file_command = "zcat";

	    if (! $compressed_switch) { #Not compressed

		$uncompressed_file_counter = "uncompressed";  #File needs compression before starting analysis. Note: All files are rechecked downstream and uncompressed ones are gzipped automatically
		$read_file_command = "cat";
	    }

            if ($file_name =~/(\d+)_(\d+)_([^_]+)_([^_]+)_([^_]+)_(\d).fastq/) {  #Parse 'new' no "index" format $1=lane, $2=date, $3=Flow-cell, $4=Sample_id, $5=index,$6=direction

		## Check that the sample_id provided and sample_id in infile name match.
		check_sample_id_match({active_parameter_href => $active_parameter_href,
				       infile_href => $infile_href,
				       sample_id => $sample_id,
				       infile_sample_id => $4,  #$4 = Sample_id from filename
				       file_index => $file_index,
				      });

		## Adds information derived from infile name to sample_info hash. Tracks the number of lanes sequenced and checks unique array elementents.
		add_infile_info({active_parameter_href => $active_parameter_href,
				 sample_info_href => $sample_info_href,
				 file_info_href => $file_info_href,
				 lane_href => $lane_href,
				 infile_href => $infile_href,
				 indir_path_href => $indir_path_href,
				 infile_lane_no_ending_href => $infile_lane_no_ending_href,
				 infile_both_strands_no_ending_href => $infile_both_strands_no_ending_href,
				 lane => $1,
				 date => $2,
				 flowcell => $3,
				 sample_id => $4,
				 index => $5,
				 direction => $6,
				 lane_tracker_ref => \$lane_tracker,
				 file_index => $file_index,
				 compressed_switch => $compressed_switch,
				});
	    }
	    else {  #No regexp match i.e. file does not follow filename convention

		$log->warn("Could not detect MIP file name convention for file: ".$file_name.". \n");
		$log->warn("Will try to find mandatory information in fastq header.", "\n");

		##Check that file name at least contains sample_id
		if ($file_name !~/$sample_id/) {

		    $log->fatal("Please check that the file name contains the sample_id.", "\n");
		}

		## Get run info from fastq file header
		my @fastq_info_headers = get_run_info({directory => $indir_path_href->{$sample_id},
						       read_file_command => $read_file_command,
						       file => $file_name,
						      });

		## Adds information derived from infile name to sample_info hash. Tracks the number of lanes sequenced and checks unique array elementents.
		add_infile_info({active_parameter_href => $active_parameter_href,
				 sample_info_href => $sample_info_href,
				 file_info_href => $file_info_href,
				 lane_href => $lane_href,
				 infile_href => $infile_href,
				 indir_path_href => $indir_path_href,
				 infile_lane_no_ending_href => $infile_lane_no_ending_href,
				 infile_both_strands_no_ending_href => $infile_both_strands_no_ending_href,
				 lane => $fastq_info_headers[3],
				 date => "000101",  #fastq format does not contain a date of the run, so fake it with constant impossible date
				 flowcell => $fastq_info_headers[2],
				 sample_id => $sample_id,
				 index => $fastq_info_headers[5],
				 direction => $fastq_info_headers[4],
				 lane_tracker_ref => \$lane_tracker,
				 file_index => $file_index,
				 compressed_switch => $compressed_switch,
				});

		$log->info("Found following information from fastq header: lane=".$fastq_info_headers[3]." flow-cell=".$fastq_info_headers[2]." index=".$fastq_info_headers[5]." direction=".$fastq_info_headers[4], "\n");
		$log->warn("Will add fake date '20010101' to follow file convention since this is not recorded in fastq header\n");
	    }
        }
    }
    return $uncompressed_file_counter;
}


sub check_sample_id_match {

##check_sample_id_match

##Function : Check that the sample_id provided and sample_id in infile name match.
##Returns  : ""
##Arguments: $active_parameter_href, $infile_href, $sample_id, $infile_sample_id, $file_index
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $infile_href           => The infiles hash {REF}
##         : $sample_id             => Sample id from user
##         : $infile_sample_id      => Sample_id collect with regexp from infile
##         : $file_index            => Counts the number of infiles

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $infile_href;
    my $sample_id;
    my $infile_sample_id;
    my $file_index;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	infile_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_href},
	sample_id => { required => 1, defined => 1, strict_type => 1, store => \$sample_id},
	infile_sample_id => { required => 1, defined => 1, strict_type => 1, store => \$infile_sample_id},
	file_index => { required => 1, defined => 1, strict_type => 1, store => \$file_index},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my %seen = ($infile_sample_id => 1);  #Add input as first increment

    foreach my $sample_id_supplied (@{ $active_parameter_href->{sample_ids} }) {

	$seen{$sample_id_supplied}++;
    }
    unless ($seen{$infile_sample_id} > 1) {

	$log->fatal($sample_id." supplied and sample_id ".$infile_sample_id." found in file : ".$infile_href->{$sample_id}[$file_index]." does not match. Please rename file to match sample_id: ".$sample_id."\n");
	exit 1;
    }
}

sub get_run_info {

##get_run_info

##Function : Get run info from fastq file header
##Returns  : ""
##Arguments: $directory, $read_file, $file
##         : $directory       => Directory of file
##         : $read_file_command => Command used to read file
##         : $file            => File to parse

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $directory;
    my $read_file_command;
    my $file;

    my $tmpl = {
	directory => { required => 1, defined => 1, strict_type => 1, store => \$directory},
	read_file_command => { required => 1, defined => 1, strict_type => 1, store => \$read_file_command},
	file => { required => 1, defined => 1, strict_type => 1, store => \$file},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $fastq_header_regexp = q?perl -nae 'chomp($_); if($_=~/^(@\w+):(\w+):(\w+):(\w+)\S+\s(\w+):\w+:\w+:(\w+)/) {print $1." ".$2." ".$3." ".$4." ".$5." ".$6."\n";} if($.=1) {last;}' ?;

    my $pwd = cwd();  #Save current direcory
    chdir($directory);  #Move to sample_id infile directory

    my $fastq_info_headers = `$read_file_command $file | $fastq_header_regexp;`;  #Collect fastq header info
    my @fastq_info_headers = split(" ", $fastq_info_headers);

    chdir($pwd);  #Move back to original directory

    unless (scalar(@fastq_info_headers) eq 6) {

	$log->fatal("Could not detect reuired sample sequencing run info from fastq file header - PLease proved MIP file in MIP file convention format to proceed\n");
	exit 1;
    }

    return @fastq_info_headers;
}


sub add_infile_info {

##add_infile_info

##Function : Adds information derived from infile name to sample_info hash. Tracks the number of lanes sequenced and checks unique array elementents.
##Returns  : ""
##Arguments: $active_parameter_href, $sample_info_href, $file_info_href, $infile_href, $infile_lane_no_ending_href, $infile_both_strands_no_ending_href, $indir_path_href, $lane_href, $lane, $date, $flowcell, $sample_id, $index, $direction, $lane_tracker_ref, $file_index, $compressed_switch
##         : $active_parameter_href              => The active parameters for this analysis hash {REF}
##         : $sample_info_href                   => Info on samples and family hash {REF}
##         : $file_info_href                     => The file_info hash {REF}
##         : $infile_href                        => The infiles hash {REF}
##         : $infile_lane_no_ending_href         => The infile(s) without the ".ending" {REF}
##         : $infile_both_strands_no_ending_href => The infile(s) without the ".ending" and strand info {REF}
##         : $indir_path_href                    => The indirectories path(s) hash {REF}
##         : $lane_href                          => The lane info hash {REF}
##         : $lane                               => Flow-cell lane
##         : $date                               => Flow-cell sequencing date
##         : $flowcell                           => Flow-cell id
##         : $sample_id                          => Sample id
##         : $index                              => The DNA library preparation molecular barcode
##         : $direction                          => Sequencing read direction
##         : $lane_tracker_ref                   => Counts the number of lanes sequenced {REF}
##         : $file_index                         => Index of file
##         : $compressed_switch                  => ".fastq.gz" or ".fastq" info governs zcat or cat downstream

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $infile_href;
    my $indir_path_href;
    my $infile_lane_no_ending_href;
    my $infile_both_strands_no_ending_href;
    my $lane_href;
    my $lane_tracker_ref;
    my $sample_id;
    my $lane;
    my $date;
    my $flowcell;
    my $index;
    my $direction;
    my $file_index;
    my $compressed_switch;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_href},
	indir_path_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$indir_path_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	infile_both_strands_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_both_strands_no_ending_href},
	lane_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$lane_href},
	sample_id => { required => 1, defined => 1, strict_type => 1, store => \$sample_id},
	lane => { required => 1, defined => 1,
		  allow => qr/^\d+$/,
		  strict_type => 1, store => \$lane},
	lane_tracker_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$lane_tracker_ref},
	date => { required => 1, defined => 1, strict_type => 1, store => \$date},
	flowcell => { required => 1, defined => 1, strict_type => 1, store => \$flowcell},
	index => { required => 1, defined => 1, strict_type => 1, store => \$index},
	direction => { required => 1, defined => 1,
		       allow => [1, 2],
		       strict_type => 1, store => \$direction},
	file_index => { required => 1, defined => 1,
			allow => qr/^\d+$/,
			strict_type => 1, store => \$file_index},
	compressed_switch => { required => 1, defined => 1,
			       allow => [0, 1],
			       strict_type => 1, store => \$compressed_switch},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $read_file;
    my $file_at_lane_level_ref;
    my $file_at_direction_level_ref;

    my $parsed_date = Time::Piece->strptime($date, "%y%m%d");
    $parsed_date = $parsed_date->ymd;

    if ($compressed_switch) {

	$read_file = "zcat";  #Read file in compressed format
    }
    else {

	$read_file = "cat";  #Read file in uncompressed format
    }

    if ($direction == 1) {  #Read 1

	push( @{ $lane_href->{$sample_id} }, $lane);  #Lane
	$infile_lane_no_ending_href->{$sample_id}[$$lane_tracker_ref] = $sample_id.".".$date."_".$flowcell."_".$index.".lane".$lane;  #Save new format (sample_id_date_flow-cell_index_lane) in hash with samplid as keys and inputfiles in array. Note: These files have not been created yet and there is one entry into hash for both strands and .ending is removed (.fastq).

	$file_at_lane_level_ref = \$infile_lane_no_ending_href->{$sample_id}[$$lane_tracker_ref];  #Alias
	$sample_info_href->{sample}{$sample_id}{file}{$$file_at_lane_level_ref}{sequence_run_type} = "single_end";  #Single_end until proven otherwise

	## Collect read length from an infile
	$sample_info_href->{sample}{$sample_id}{file}{$$file_at_lane_level_ref}{sequence_length} = collect_read_length({directory => $indir_path_href->{$sample_id},
															read_file_command => $read_file,
															file => $infile_href->{$sample_id}[$file_index],
														       });

	## Check if fastq file is interleaved
	$sample_info_href->{sample}{$sample_id}{file}{$$file_at_lane_level_ref}{interleaved} = detect_interleaved({directory => $indir_path_href->{$sample_id},
														   read_file_command => $read_file,
														   file => $infile_href->{$sample_id}[$file_index],
														  });

	## Detect "regexp" in string
	$file_info_href->{undetermined_in_file_name}{ $infile_lane_no_ending_href->{$sample_id}[$$lane_tracker_ref] } = check_string({string => $flowcell,
																      regexp => "Undetermined",
																     });
	$$lane_tracker_ref++;
    }
    if ($direction == 2) {  #2nd read direction

	$file_at_lane_level_ref = \$infile_lane_no_ending_href->{$sample_id}[$$lane_tracker_ref-1];  #Alias
	$sample_info_href->{sample}{$sample_id}{file}{$$file_at_lane_level_ref}{sequence_run_type} = "paired_end";  #$lane_tracker -1 since it gets incremented after direction eq 1.
    }

    $infile_both_strands_no_ending_href->{$sample_id}[$file_index] = $sample_id.".".$date."_".$flowcell."_".$index.".lane".$lane."_".$direction;  #Save new format in hash with samplid as keys and inputfiles in array. Note: These files have not been created yet and there is one entry per strand and .ending is removed (.fastq).

    $file_at_direction_level_ref = \$infile_both_strands_no_ending_href->{$sample_id}[$file_index];  #Alias
    $sample_info_href->{sample}{$sample_id}{file}{$$file_at_lane_level_ref}{read_direction_file}{$$file_at_direction_level_ref}{original_file_name} = $infile_href->{$sample_id}[$file_index];  #Original file_name

    $sample_info_href->{sample}{$sample_id}{file}{$$file_at_lane_level_ref}{read_direction_file}{$$file_at_direction_level_ref}{original_file_name_noending} = $lane."_".$date."_".$flowcell."_".$sample_id."_".$index."_".$direction;  #Original file_name, but no ending

    $sample_info_href->{sample}{$sample_id}{file}{$$file_at_lane_level_ref}{read_direction_file}{$$file_at_direction_level_ref}{lane} = $lane;  #Save sample lane

    $sample_info_href->{sample}{$sample_id}{file}{$$file_at_lane_level_ref}{read_direction_file}{$$file_at_direction_level_ref}{date} = $parsed_date;  #Save Sequence run date

    $sample_info_href->{sample}{$sample_id}{file}{$$file_at_lane_level_ref}{read_direction_file}{$$file_at_direction_level_ref}{flowcell} = $flowcell;  #Save Sequence flow-cell

    $sample_info_href->{sample}{$sample_id}{file}{$$file_at_lane_level_ref}{read_direction_file}{$$file_at_direction_level_ref}{sample_barcode} = $index;  #Save sample barcode

    $sample_info_href->{sample}{$sample_id}{file}{$$file_at_lane_level_ref}{read_direction_file}{$$file_at_direction_level_ref}{run_barcode} = $date."_".$flowcell."_".$lane."_".$index;  #Save run barcode

    $sample_info_href->{sample}{$sample_id}{file}{$$file_at_lane_level_ref}{read_direction_file}{$$file_at_direction_level_ref}{read_direction} = $direction;
}


sub detect_interleaved {

##detect_interleaved

##Function : Detect if fastq file is interleaved
##Returns  : "1(=interleaved)"
##Arguments: $directory, $read_file, $file
##         : $directory         => Directory of file
##         : $read_file_command => Command used to read file
##         : $file              => File to parse

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $directory;
    my $read_file_command;
    my $file;

    my $tmpl = {
	directory => { required => 1, defined => 1, strict_type => 1, store => \$directory},
	read_file_command => { required => 1, defined => 1, strict_type => 1, store => \$read_file_command},
	file => { required => 1, defined => 1, strict_type => 1, store => \$file},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $interleaved_regexp = q?perl -nae 'chomp($_); if( ($_=~/^@\S+:\w+:\w+:\w+\S+\s(\w+):\w+:\w+:\w+/) && ($.==5) ) {print $1."\n";last;} elsif ($.==6) {last;}' ?;

    my $pwd = cwd();  #Save current direcory
    chdir($directory);  #Move to sample_id infile directory

    my $fastq_info_headers = `$read_file_command $file | $interleaved_regexp;`;  #Collect interleaved info

    if(! $fastq_info_headers) {

	my $interleaved_regexp = q?perl -nae 'chomp($_); if( ($_=~/^@\w+-\w+:\w+:\w+:\w+:\w+:\w+:\w+\/(\w+)/) && ($.==5) ) {print $1."\n";last;} elsif ($.==6) {last;}' ?;
	$fastq_info_headers = `$read_file_command $file | $interleaved_regexp;`;  #Collect interleaved info
    }

    chdir($pwd);  #Move back to original directory

    unless ($fastq_info_headers=~/[1, 2, 3]/) {

	$log->fatal("Malformed fastq file!\n");
	$log->fatal("Read direction is: ".$fastq_info_headers." allowed entries are '1', '2', '3'. Please check fastq file\n");
	exit 1;
    }
    if ($fastq_info_headers > 1) {

	$log->info("Found interleaved fastq file: ".$file, "\n");
	return 1;
    }
    return;
}


sub check_file_name_exists {

##check_file_name_exists

##Function : Check if a file with with a filename consisting of $file_path_ref.$file_counter.$file_ending_ref exist. If so bumps the version number and return new filename and sbatch version number.
##Returns  : "$file_name, $file_name_tracker"
##Arguments: $file_path_ref, $file_ending_ref
##         : $file_path_ref   => The file path {REF}
##         : $file_ending_ref => The file ending {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $file_path_ref;
    my $file_ending_ref;

    my $tmpl = {
	file_path_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$file_path_ref},
	file_ending_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$file_ending_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $file_name;  #Temp filename
    my $file_name_tracker = 0;  #Nr of sbatch scripts with identical filenames i.e. version number

    for (my $file_counter=0;$file_counter<9999;$file_counter++) {  #Number of possible files with the same name

	$file_name = $$file_path_ref.$file_counter.$$file_ending_ref;  #Filename, filenr and fileending
	$file_name_tracker = $file_counter;  #Nr of sbatch scripts with identical filenames

	unless (-f $file_name) {  #File exists

	    last;  #No file exists
	}
    }
    return ($file_name, $file_name_tracker);
}


sub add_to_active_parameter {

##add_to_active_parameter

##Function : Checks and sets user input or default values to active_parameters.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $supported_capture_kit_href, $broadcasts_ref, $parameter_name, $associated_programs
##         : $parameter_href             => Holds all parameters
##         : $active_parameter_href      => Holds all set parameter for analysis
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $supported_capture_kit_href => The supported capture kits hash {REF}
##         : $broadcasts_ref             => Holds the parameters info for broadcasting later {REF}
##         : $parameter_name             => Parameter name
##         : $associated_programs        => The parameters program(s) {array, REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $supported_capture_kit_href;
    my $broadcasts_ref;
    my $associated_programs_ref;
    my $parameter_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	supported_capture_kit_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_capture_kit_href},
	broadcasts_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$broadcasts_ref},
	associated_programs_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$associated_programs_ref},
	parameter_name => { required => 1, defined => 1, store => \$parameter_name},
	family_id_ref => {default => \$$, strict_type => 1},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $element_separator_ref = \$parameter_href->{$parameter_name}{element_separator};
    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};

    foreach my $associated_program (@$associated_programs_ref) {  #Check all programs that use parameter

	my $parameter_set_switch = 0;

	if (defined($active_parameter_href->{$associated_program}) && ($active_parameter_href->{$associated_program} > 0) ) {  #Only add active programs parameters

	    $parameter_set_switch = 1;

	    ## Input from cmd
	    if ( ($parameter_href->{$parameter_name}{data_type} eq "ARRAY") && (defined($parameter_href->{$parameter_name}{value}[0])) )  {  #Array reference

		my $values_ref = \@{ $parameter_href->{$parameter_name}{value} };
		@{ $active_parameter_href->{$parameter_name} } = split($$element_separator_ref, join($$element_separator_ref, @$values_ref) );
	    }
	    elsif ( ($parameter_href->{$parameter_name}{data_type} eq "HASH") && (keys $parameter_href->{$parameter_name}{value}) ) {  #Hash reference

		$active_parameter_href->{$parameter_name} = $parameter_href->{$parameter_name}{value};
	    }
	    elsif (defined($parameter_href->{$parameter_name}{value}) && (ref($parameter_href->{$parameter_name}{value})!~/ARRAY|HASH/)) {  #Scalar input from cmd

		$active_parameter_href->{$parameter_name} = $parameter_href->{$parameter_name}{value};
	    }
	    else {

		if (defined($active_parameter_href->{$parameter_name})) {  #Input from config file

		}
		elsif (exists($parameter_href->{$parameter_name}{default})) {  #Default exists

		    if ($parameter_href->{$parameter_name}{data_type} eq "ARRAY") {  #Array reference

			push(@{ $active_parameter_href->{$parameter_name} }, @{ $parameter_href->{$parameter_name}{default} });
		    }
		    elsif ($parameter_href->{$parameter_name}{data_type} eq "HASH") {

			## Build default for analysis_type
			if ($parameter_name eq "analysis_type") {

			    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

				$active_parameter_href->{$parameter_name}{$sample_id} = "wgs";
			    }
			}
			## Build default for infile_dirs
			elsif ($parameter_name eq "infile_dirs") {

			    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

				my $path = catfile($active_parameter_href->{cluster_constant_path}, $$family_id_ref, $active_parameter_href->{analysis_type}{$sample_id}, $sample_id, "fastq");
				$active_parameter_href->{$parameter_name}{$path} = $sample_id;
			    }
			}
			else {

			    $active_parameter_href->{$parameter_name} = $parameter_href->{$parameter_name}{default};
			}
		    }
		    else {  #Scalar

			if ($parameter_name eq "bwa_build_reference") {

			    $active_parameter_href->{$parameter_name} = $active_parameter_href->{human_genome_reference};  #Now we now what human genome refrence to build from
			}
			else {

			    $active_parameter_href->{$parameter_name} = $parameter_href->{$parameter_name}{default};
			}
		    }
		}
		else {  ## No default

		    if ( (exists($parameter_href->{$parameter_name}{mandatory})) && ($parameter_href->{$parameter_name}{mandatory} eq "no") ) {  #Not mandatory
		    }
		    else {

			## Special cases where the requirement is depending on other variabels
			if ( ($parameter_name eq "bwa_mem_rapid_db") && ($consensus_analysis_type ne "rapid")) {  #Do nothing since file is not required unless rapid mode is enabled
			}
			elsif ( ($parameter_name eq "gatk_genotypegvcfs_ref_gvcf") && ($consensus_analysis_type =~/wgs/) ) {  #Do nothing since file is not required unless exome or rapid mode is enabled
			}
			elsif ( ($parameter_name eq "vcfparser_range_feature_annotation_columns") && ( $active_parameter_href->{vcfparser_range_feature_file} eq "nouser_info") ) {  #Do nothing since no SelectFile was given
			}
			elsif ( ($parameter_name eq "vcfparser_select_feature_annotation_columns") && ( $active_parameter_href->{vcfparser_select_file} eq "nouser_info") ) {  #Do nothing since no SelectFile was given
			}
			elsif ( ($parameter_name eq "vcfparser_select_file_matching_column") && ( $active_parameter_href->{vcfparser_select_file} eq "nouser_info") ) {  #Do nothing since no SelectFile was given
			}
			elsif ( ($parameter_name eq "rank_model_file") && (!defined($active_parameter_href->{rank_model_file}) ) ) {  #Do nothing since no rank model was given i.e. use rank scripts deafult supplied with distribution
			}
			elsif ( ($parameter_name eq "genmod_models_reduced_penetrance_file") && (!defined($active_parameter_href->{genmod_models_reduced_penetrance_file}) ) ) {  #Do nothing since no reduced penetrance should be performed
			}
			elsif  ($parameter_name eq "exome_target_bed") {

			    ## Return a default capture kit as user supplied no info
			    my $capture_kit = add_capture_kit({file_info_href => $file_info_href,
							       supported_capture_kit_href => $supported_capture_kit_href,
							       capture_kit => "latest",
							      });
			    $active_parameter_href->{$parameter_name}{$capture_kit} = join(",", @{ $active_parameter_href->{sample_ids} });

			    ## Update exome_target_bed files with human_genome_reference_source_ref and human_genome_reference_version_ref
			    update_exome_target_bed({exome_target_bed_file_href => $active_parameter_href->{exome_target_bed},
						     human_genome_reference_source_ref => \$file_info_href->{human_genome_reference_source},
						     human_genome_reference_version_ref => \$file_info_href->{human_genome_reference_version},
						    });
			    $log->warn("Could not detect a supplied capture kit. Will Try to use 'latest' capture kit: ".$capture_kit, "\n");
			}
			else {

			    if (defined($log)) {  #We have a logg object and somewhere to write

				$log->fatal($USAGE, "\n");
				$log->fatal("Supply '-".$parameter_name."' if you want to run ".$associated_program, "\n");
			    }
			    else {

				warn($USAGE, "\n");
				warn("Supply '-".$parameter_name."' if you want to run ".$associated_program, "\n");
			    }
			    exit 1;
			}
		    }
		}
	    }
	}
	if ($parameter_set_switch eq 1) {  #No need to set parameter more than once
	    last;
	}
    }

    ## Parse Human Genome Reference
    if ($parameter_name eq "human_genome_reference") {

	## Update path for supplied reference(s) associated with parameter that should reside in the mip reference directory to full path
	update_mip_reference_path({parameter_href => $parameter_href,
				   active_parameter_href => $active_parameter_href,
				   parameter_name => "human_genome_reference",  #Special case to make sure that complete path is supplied
				  });
	
	## Detect version and source of the human_genome_reference: Source (hg19 or GRCh).
	parse_human_genome_reference({file_info_href => $file_info_href,
				      human_genome_reference_ref => \basename($active_parameter_href->{human_genome_reference}),
				     });

	## Update exome_target_bed files with human_genome_reference_source_ref and human_genome_reference_version_ref
	update_exome_target_bed({exome_target_bed_file_href => $active_parameter_href->{exome_target_bed},
				 human_genome_reference_source_ref => \$file_info_href->{human_genome_reference_source},
				 human_genome_reference_version_ref => \$file_info_href->{human_genome_reference_version},
				});
    }

    ## Parse pedigree file
    if ($parameter_name eq "pedigree_file") {

	## Reads family_id_pedigree file in PLINK|YAML format. Checks for pedigree data for allowed entries and correct format. Add data to sample_info depending on user info.
	if ($active_parameter_href->{pedigree_file} =~/\.yaml$/) {  #Meta data in YAML format

	    ##Loads a YAML file into an arbitrary hash and returns it. Load parameters from previous run from sample_info_file
	    my %pedigree = File::Format::Yaml::load_yaml({yaml_file => $active_parameter_href->{pedigree_file},
							 });
	    $log->info("Loaded: ".$active_parameter_href->{pedigree_file}, "\n");

	    read_yaml_pedigree_file({parameter_href => $parameter_href,
				     active_parameter_href => $active_parameter_href,
				     sample_info_href => $sample_info_href,
				     file_info_href => $file_info_href,
				     supported_capture_kit_href => $supported_capture_kit_href,
				     file_path => $active_parameter_href->{pedigree_file},
				     pedigree_href => \%pedigree,
				    });
	}
	else {  #Expect PLINK pedigree format

	    read_plink_pedigree_file({parameter_href => $parameter_href,
				      active_parameter_href => $active_parameter_href,
				      sample_info_href => $sample_info_href,
				      file_info_href => $file_info_href,
				      supported_capture_kit_href => $supported_capture_kit_href,
				      file_path => $active_parameter_href->{pedigree_file},
				     });
	}
    }

    ## Parameter set
    if (defined($active_parameter_href->{$parameter_name})) {

	my $info = "";  #Hold parameters info

	if (ref($active_parameter_href->{$parameter_name}) eq "ARRAY") {  #Array reference

	    $info = "Set ".$parameter_name." to: ".join($$element_separator_ref, @{ $active_parameter_href->{ $parameter_name } });
	    push(@$broadcasts_ref, $info);  #Add info to broadcasts
	}
	elsif (ref($active_parameter_href->{$parameter_name}) eq "HASH") {

	    $info = "Set ".$parameter_name." to: ".join(",", map { "$_=$active_parameter_href->{$parameter_name}{$_}" } (keys $active_parameter_href->{$parameter_name}));
	    push(@$broadcasts_ref, $info);  #Add info to broadcasts
	}
	else {

	    $info = "Set ".$parameter_name." to: ".$active_parameter_href->{$parameter_name};
	    push(@$broadcasts_ref, $info);  #Add info to broadcasts
	}
    }
}

sub check_parameter_files {

##check_parameter_files

##Function : Checks that files/directories exists and if file_endings need to be built also updates SampleInfoHash information with information from pedigree
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $supported_capture_kit_href, $annovar_table_href, $broadcasts_ref, $annovar_supported_table_names_ref, $associated_programs_ref, $family_id_ref, $parameter_name $parameter_exists_check
##         : $parameter_href                    => Holds all parameters
##         : $active_parameter_href             => Holds all set parameter for analysis
##         : $sample_info_href                  => Info on samples and family hash {REF}
##         : $file_info_href                    => The file_info hash {REF}
##         : $supported_capture_kit_href        => The supported capture kits hash {REF}
##         : $annovar_table_href                => annovar_table_href {REF}
##         : $broadcasts_ref                    => Holds the parameters info for broadcasting later {REF}
##         : $annovar_supported_table_names_ref => The supported annovar reference names array {REF}
##         : $associated_programs_ref           => The parameters program(s) {REF}
##         : $family_id_ref                     => The family_id_ref {REF}
##         : $parameter_name                    => Parameter name
##         : $parameter_exists_check            => Check if intendent file exists in reference directory

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $supported_capture_kit_href;
    my $broadcasts_ref;
    my $annovar_table_href;
    my $annovar_supported_table_names_ref;
    my $associated_programs_ref;
    my $parameter_name;
    my $parameter_exists_check;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	supported_capture_kit_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_capture_kit_href},
	broadcasts_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$broadcasts_ref},
	annovar_table_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$annovar_table_href},
	annovar_supported_table_names_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$annovar_supported_table_names_ref},
	associated_programs_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$associated_programs_ref},
	parameter_name => { required => 1, defined => 1, strict_type => 1, store => \$parameter_name},
	parameter_exists_check => { required => 1, defined => 1, strict_type => 1, store => \$parameter_exists_check},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};

    foreach my $associated_program (@$associated_programs_ref) {  #Check all programs that use parameter

	my $parameter_set_switch = 0;

	if (defined($active_parameter_href->{$associated_program}) && ($active_parameter_href->{$associated_program} > 0) ) {  #Only add active programs parameters

	    $parameter_set_switch = 1;

	    if (exists($parameter_href->{$parameter_name}{reference})) {  #Expect file to be in reference directory
		
		## Update path for supplied reference(s) associated with parameter that should reside in the mip reference directory to full path
		update_mip_reference_path({parameter_href => $parameter_href,
					   active_parameter_href => $active_parameter_href,
					   parameter_name => $parameter_name,
					  });
	    }

	    if (defined($active_parameter_href->{$parameter_name}) ) {  #Check parameter existence
    
		if ($parameter_href->{$parameter_name}{data_type} eq "SCALAR") {
	
		    my $path = catfile($active_parameter_href->{$parameter_name});
		    
		    if ($parameter_name eq "mosaik_jump_db_stub") {

			## Checks files to be built by combining filename stub with fileendings
			check_file_endings_to_build({parameter_href => $parameter_href,
						     active_parameter_href => $active_parameter_href,
						     file_endings_ref => \@{ $file_info_href->{mosaik_jump_db_stub_file_endings} },
						     parameter_name => "mosaik_jump_db_stub",
						     file_name => $active_parameter_href->{mosaik_jump_db_stub},
						    });
		    }
		    elsif ($parameter_name eq "bwa_build_reference") {

			## Checks files to be built by combining filename stub with fileendings
			check_file_endings_to_build({parameter_href => $parameter_href,
						     active_parameter_href => $active_parameter_href,
						     file_endings_ref => \@{ $file_info_href->{bwa_build_reference_file_endings} },
						     parameter_name => "bwa_build_reference",
						     file_name => $active_parameter_href->{human_genome_reference},
						    });
		    }
		    elsif ($parameter_name eq "sample_info_file") {

			if (defined($active_parameter_href->{sample_info_file})) {

			    if (-f $active_parameter_href->{sample_info_file}) {

				if (defined($active_parameter_href->{log_file})) {

				    $log->info("Loaded: ". $active_parameter_href->{sample_info_file}, "\n");
				}

				##Loads a YAML file into an arbitrary hash and returns it. Load parameters from previous run from sample_info_file
				my %temp = File::Format::Yaml::load_yaml({yaml_file => $active_parameter_href->{sample_info_file},
									 });

				## Update sample_info with information from pedigree
				update_sample_info_hash({sample_info_href => $sample_info_href,
							 temp_href => \%temp,
							 family_id_ref => $family_id_ref,
							});
			    }
			}
		    }
		    elsif ( ($parameter_name eq "genomic_set") && ($active_parameter_href->{genomic_set} eq "nouser_info") ) {  #Do nothing since this is not a required feature
		    }
		    elsif ( ($parameter_name eq "bwa_mem_rapid_db") && ($consensus_analysis_type ne "rapid")) {  #Do nothing since file is not required unless rapid mode is enabled
		    }
		    elsif ( ($parameter_name eq "gatk_genotypegvcfs_ref_gvcf") && ($consensus_analysis_type =~/wgs/) ) {  #Do nothing since file is not required unless exome mode is enabled
		    }
		    elsif ( ($parameter_name eq "vcfparser_range_feature_file") && ( $active_parameter_href->{vcfparser_range_feature_file} eq "nouser_info") ) {  #Do nothing since no RangeFile was given
		    }
		    elsif ($parameter_name eq "vcfparser_select_file") {

			if ($active_parameter_href->{vcfparser_select_file} eq "nouser_info") {  #No select_file was given

			    $active_parameter_href->{vcfparser_outfile_count} = 1;  #To track if vcfparser was used with a vcfparser_select_file (=2) or not (=1)
			}
			else {  #To enable addition of select_file to sample_info

			    check_existance({parameter_href => $parameter_href,
					     active_parameter_href => $active_parameter_href,
					     item_name_ref => \$active_parameter_href->{$parameter_name},
					     parameter_name_ref => \$parameter_name,
					     item_type_to_check => $parameter_exists_check,
					    });

			    ## Collects sequences contigs used in select file
			    collect_select_file_contigs({contigs_ref => \@{ $file_info_href->{select_file_contigs} },
							 select_file_path => catfile($active_parameter_href->{vcfparser_select_file}),
							});

			    $active_parameter_href->{vcfparser_outfile_count} = 2;  #To track if vcfparser was used with a vcfparser_select_file (=2) or not (=1)
			}
		    }
		    elsif ( ($parameter_name eq "genmod_models_reduced_penetrance_file") && (!defined($active_parameter_href->{genmod_models_reduced_penetrance_file}) ) ) {  #Do nothing since no reduced penetrance should be performed
		    }
		    elsif ($parameter_name eq "rank_model_file") {

			if (!defined($active_parameter_href->{rank_model_file})) {  #Do nothing since no rank model config file was given. Use default supplied by ranking script
			}
			else {  #To enable addition of rankModel file and version to sample_info

			    check_existance({parameter_href => $parameter_href,
					     active_parameter_href => $active_parameter_href,
					     item_name_ref => \$path,
					     parameter_name_ref => \$parameter_name,
					     item_type_to_check => $parameter_exists_check,
					    });
			}
		    }
		    else {

			check_existance({parameter_href => $parameter_href,
					 active_parameter_href => $active_parameter_href,
					 item_name_ref => \$path,
					 parameter_name_ref => \$parameter_name,
					 item_type_to_check => $parameter_exists_check,
					});

			if ($path =~/\.gz$/) {  #Check for tabix index as well

			    $path .=".tbi";
			    check_existance({parameter_href => $parameter_href,
					     active_parameter_href => $active_parameter_href,
					     item_name_ref => \$path,
					     parameter_name_ref => \$parameter_name,
					     item_type_to_check => $parameter_exists_check,
					    });
			}

			if ($parameter_name eq "human_genome_reference") {

			    ## Check the existance of associated Human genome files
			    check_human_genome_file_endings({parameter_href => $parameter_href,
							     active_parameter_href => $active_parameter_href,
							     file_info_href => $file_info_href,
							     parameter_name_ref => \$parameter_name
							    });
			}
		    }
		}
		if ($parameter_href->{$parameter_name}{data_type} eq "ARRAY") {

		    if ($parameter_name eq "annovar_table_names") {

			## Defines and adds annovar tables parameters to hash
			%{$annovar_table_href} = define_annovar_tables({parameter_href => $parameter_href,
									annovar_supported_table_names_ref => $annovar_supported_table_names_ref,
									annovar_genome_build_version_ref => \$active_parameter{annovar_genome_build_version},
								       });

			## Checks supported annovar Tables and that the supplied supported ones exists
			check_annovar_tables({parameter_href => $parameter_href,
					      active_parameter_href => $active_parameter_href,
					      annovar_table_href => $annovar_table_href,
					      annovar_supported_table_names_ref => $annovar_supported_table_names_ref,
					     });
		    }
		    else {

			foreach my $path (@{ $active_parameter_href->{$parameter_name} }) {

			    check_existance({parameter_href => $parameter_href,
					     active_parameter_href => $active_parameter_href,
					     item_name_ref => \$path,
					     parameter_name_ref => \$parameter_name,
					     item_type_to_check => $parameter_exists_check,
					    });

			    if ($path =~/\.gz$/) {  #Check for tabix index as well

				my $path_index = $path.".tbi";

				check_existance({parameter_href => $parameter_href,
						 active_parameter_href => $active_parameter_href,
						 item_name_ref => \$path_index,
						 parameter_name_ref => \$path_index,
						 item_type_to_check => $parameter_exists_check,
						});
			    }
			}
		    }
		}
		if ($parameter_href->{$parameter_name}{data_type} eq "HASH") {

		    for my $path (keys $active_parameter_href->{$parameter_name}) {

			if ($parameter_name eq "exome_target_bed") {

			    ## Check that supplied target file ends with ".bed" and otherwise exists
			    check_target_bed_file_exist({active_parameter_href => $active_parameter_href,
							 file => $path,
							 parameter_name => $parameter_name,
							});

			    ## Checks files to be built by combining filename stub with fileendings
			    check_file_endings_to_build({parameter_href => $parameter_href,
							 active_parameter_href => $active_parameter_href,
							 file_endings_ref => \@{ $file_info_href->{exome_target_bed} },
							 parameter_name => "exome_target_bed",
							 file_name => $path,
							});
			}
			check_existance({parameter_href => $parameter_href,
					 active_parameter_href => $active_parameter_href,
					 item_name_ref => \$path,
					 parameter_name_ref => \$path,
					 item_type_to_check => $parameter_exists_check,
					});


			if ($path =~/\.gz$/) {  #Check for tabix index as well

			    my $path_index = $path.".tbi";
			    check_existance({parameter_href => $parameter_href,
					     active_parameter_href => $active_parameter_href,
					     item_name_ref => \$path,
					     parameter_name_ref => \$path_index,
					     item_type_to_check => $parameter_exists_check,
					    });
			}
			if ($parameter_name eq "snpsift_annotation_files"){

			    my %snpeff_file = define_snpeff_files({parameter_href => $parameter_href,
								  });
			}
		    }
		}
	    }
	}
	if ($parameter_set_switch eq 1) {  #No need to set parameter more than once
	    last;
	}
    }
}


sub create_file_endings {

##create_file_endings

##Function : Creates the file_tags depending on which modules are used by the user to relevant chain.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $file_info_href, $infile_lane_no_ending_href, $order_parameters_ref, $family_id_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $file_info_href             => Info on files hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $order_parameters_ref       => Order of addition to parameter array {REF}
##         : $family_id_ref              => The family_id {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $order_parameters_ref;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	order_parameters_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$order_parameters_ref},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $consensus_analysis_type = $parameter{dynamic_parameter}{consensus_analysis_type};
    my %temp_file_ending;  #Used to enable seqential build-up of file_tags between modules

    foreach my $order_parameter_element (@$order_parameters_ref) {

	if (defined($active_parameter_href->{$order_parameter_element})) {  #Only active parameters

	    if ( ( any {$_ eq $order_parameter_element} @{ $parameter_href->{dynamic_parameter}{program} } ) ) { #Only process programs

		if ($parameter_href->{$order_parameter_element}{chain} eq "MAIN") {  #MAIN chain

		    if ($parameter_href->{$order_parameter_element}{file_tag} ne "nofile_tag") {  #File_tag exist

			my $file_ending_ref = \$parameter_href->{$order_parameter_element}{file_tag}; #Alias

###MAIN/Per sample_id
			foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

			    if ($active_parameter_href->{$order_parameter_element} > 0) {  #File_ending should be added

				if ($order_parameter_element eq "ppicardtools_mergesamfiles") {  #Special case

				    if (defined($active_parameter_href->{picardtools_mergesamfiles_previous_bams})) {  #Sanity check that we have something to merge and hence to file_tag should be added

					$file_info_href->{$sample_id}{ppicardtools_mergesamfiles}{file_tag} = $temp_file_ending{$sample_id}.$$file_ending_ref;  #Adds from previous entry
				    }
				    else {

					$file_info_href->{$sample_id}{ppicardtools_mergesamfiles}{file_tag} = $temp_file_ending{$sample_id}."";
				    }
				}
				else {

				    if (defined($temp_file_ending{$sample_id})) {

					$file_info_href->{$sample_id}{$order_parameter_element}{file_tag} = $temp_file_ending{$sample_id}.$$file_ending_ref;
				    }
				    else  {  #First module that should add filending

					$file_info_href->{$sample_id}{$order_parameter_element}{file_tag} = $$file_ending_ref;
				    }
				}
			    }
			    else {  #Do not add new module file_tag

				$file_info_href->{$sample_id}{$order_parameter_element}{file_tag} = $temp_file_ending{$sample_id};
			    }
			    $temp_file_ending{$sample_id} = $file_info_href->{$sample_id}{$order_parameter_element}{file_tag};  #To enable sequential build-up of fileending
			}

###MAIN/Per family_id
			if ($active_parameter_href->{$order_parameter_element} > 0) {  #File_ending should be added

			    if ($order_parameter_element eq "ppicardtools_mergesamfiles") {  #Special case - do nothing
			    }
			    elsif ( ($order_parameter_element eq "ppicardtools_mergerapidreads") && ($consensus_analysis_type ne "rapid") ) {  #Special case - do nothing
			    }
			    else {

				if (defined($temp_file_ending{$$family_id_ref})) {

				    $file_info_href->{$$family_id_ref}{$order_parameter_element}{file_tag} = $temp_file_ending{$$family_id_ref}.$$file_ending_ref;
				}
				else  {  #First module that should add filending

				    $file_info_href->{$$family_id_ref}{$order_parameter_element}{file_tag} = $$file_ending_ref;
				}
				$temp_file_ending{$$family_id_ref} = $file_info_href->{$$family_id_ref}{$order_parameter_element}{file_tag};  #To enable sequential build-up of fileending
			    }
			}
			else {  #Do not add new module file_tag

			    $file_info_href->{$$family_id_ref}{$order_parameter_element}{file_tag} = $temp_file_ending{$$family_id_ref};
			}
		    }
		}
		if ($parameter_href->{$order_parameter_element}{chain} ne "MAIN") {  #Other chain(s)

		    my $chain_fork = $parameter_href->{$order_parameter_element}{chain};

		    if ($parameter_href->{$order_parameter_element}{file_tag} ne "nofile_tag") {  #File_tag exist

			my $file_ending_ref = \$parameter_href->{$order_parameter_element}{file_tag};  #Alias

###OTHER/Per sample_id
			foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

			    if ($active_parameter_href->{$order_parameter_element} > 0) {  #File_ending should be added

				unless (defined($temp_file_ending{$chain_fork}{$sample_id})) {

				    $temp_file_ending{$chain_fork}{$sample_id} = $temp_file_ending{$sample_id};  #Inherit current MAIN chain.
				}
				if (defined($temp_file_ending{$chain_fork}{$sample_id})) {

				    $file_info_href->{$sample_id}{$order_parameter_element}{file_tag} = $temp_file_ending{$chain_fork}{$sample_id}.$$file_ending_ref;
				}
				else  {  #First module that should add filending

				    $file_info_href->{$sample_id}{$order_parameter_element}{file_tag} = $$file_ending_ref;
				}
			    }
			    else {  #Do not add new module file_tag

				$file_info_href->{$sample_id}{$order_parameter_element}{file_tag} = $temp_file_ending{$chain_fork}{$sample_id};
			    }
			    $temp_file_ending{$chain_fork}{$sample_id} = $file_info_href->{$sample_id}{$order_parameter_element}{file_tag};  #To enable sequential build-up of fileending
			}
###Other/Per family_id

			if ($active_parameter_href->{$order_parameter_element} > 0) {  #File ending should be added

			    unless (defined($temp_file_ending{$chain_fork}{$$family_id_ref})) {

				$temp_file_ending{$chain_fork}{$$family_id_ref} =  $temp_file_ending{$$family_id_ref};  #Inherit current MAIN chain.
			    }
			    if (defined($temp_file_ending{$chain_fork}{$$family_id_ref})) {

				$file_info_href->{$$family_id_ref}{$order_parameter_element}{file_tag} = $temp_file_ending{$chain_fork}{$$family_id_ref}.$$file_ending_ref;
			    }
			    else  {  #First module that should add filending

				$file_info_href->{$$family_id_ref}{$order_parameter_element}{file_tag} = $$file_ending_ref;
			    }
			    $temp_file_ending{$chain_fork}{$$family_id_ref} = $file_info_href->{$$family_id_ref}{$order_parameter_element}{file_tag};  #To enable sequential build-up of fileending
			}
			else {  #Do not add new module file_tag

			    $file_info_href->{$$family_id_ref}{$order_parameter_element}{file_tag} = $temp_file_ending{$chain_fork}{$$family_id_ref};
			}
		    }
		}
	    }
	}
    }
}


sub program_prerequisites {

##program_prerequisites

##Function : Creates program directories (info & programData & programScript), program script filenames and writes sbatch header.
##Returns  : Path to stdout
##Arguments: $active_parameter_href, $job_id_href, $FILEHANDLE, $directory_id, $program_directory, $program_name, $call_type, $outdata_dir, $outscript_dir, $temp_directory, $email_type, $source_environment_commands_ref, $slurm_quality_of_service, $core_number, $process_time, $error_trap, $pipefail, $sleep
##         : $active_parameter_href           => The active parameters for this analysis hash {REF}
##         : $job_id_href                     => The job_id hash {REF}
##         : $FILEHANDLE                      => FILEHANDLE to write to
##         : $directory_id                    => $samplID|$family_id
##         : $program_directory               => Builds from $directory_id/$outaligner_dir
##         : $program_name                    => Assigns filename to sbatch script
##         : $call_type                       => SNV,INDEL or BOTH
##         : $source_environment_commands_ref => Source environment command {REF}
##         : $outdata_dir                     => The MIP out data directory {Optional}
##         : $outscript_dir                   => The MIP out script directory {Optional}
##         : $temp_directory                  => Temporary directory for program {Optional}
##         : $email_type                      => The email type
##         : $slurm_quality_of_service        => SLURM quality of service priority {Optional}
##         : $core_number                     => The number of cores to allocate {Optional}
##         : $process_time                    => Allowed process time (Hours) {Optional}
##         : $error_trap                      => Error trap switch {Optional}
##         : $pipefail                        => Pipe fail switch {Optional}
##         : $sleep                           => Sleep for X seconds {Optional}

    my ($arg_href) = @_;

    ## Default(s)
    my $outdata_dir = $arg_href->{outdata_dir} //= $arg_href->{active_parameter_href}{outdata_dir};
    my $outscript_dir = $arg_href->{outscript_dir} //= $arg_href->{active_parameter_href}{outscript_dir};
    my $temp_directory = $arg_href->{temp_directory} //= $arg_href->{active_parameter_href}{temp_directory};
    my $email_type = $arg_href->{email_type} //= $arg_href->{active_parameter_href}{email_type};
    my $source_environment_commands_ref = $arg_href->{source_environment_commands_ref} //= $arg_href->{active_parameter_href}{source_environment_commands};
    my $slurm_quality_of_service = $arg_href->{slurm_quality_of_service} //= $arg_href->{active_parameter_href}{slurm_quality_of_service};
    my $core_number;
    my $process_time;
    my $pipefail;
    my $error_trap;
    my $sleep;


    if (defined($arg_href->{call_type})) {

	$arg_href->{call_type} = "_".$arg_href->{call_type};
    }
    $arg_href->{call_type} //= "";

    ## Flatten argument(s)
    my $active_parameter_href;
    my $job_id_href;
    my $FILEHANDLE;
    my $directory_id;
    my $program_directory;
    my $program_name;
    my $call_type;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	FILEHANDLE => { store => \$FILEHANDLE},
	directory_id => { required => 1, defined => 1, strict_type => 1, store => \$directory_id},
	program_directory => { required => 1, defined => 1, strict_type => 1, store => \$program_directory},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	call_type => { strict_type => 1, store => \$call_type},
	outdata_dir => { strict_type => 1 },
	outscript_dir => { strict_type => 1 },
	temp_directory => { strict_type => 1 },
	email_type => { strict_type => 1 },
	source_environment_commands_ref => { default => [], strict_type => 1 },
	core_number => { default => 1,
			 allow => qr/^\d+$/,
			 strict_type => 1, store => \$core_number},
	process_time => { default => 1,
			  allow => qr/^\d+$/,
			  strict_type => 1, store => \$process_time},
	slurm_quality_of_service => { default => "normal",
				      allow => ["low", "high", "normal"],
				      strict_type => 1, store => \$slurm_quality_of_service},
	pipefail => { default => 1,
		      allow => [0, 1],
		      strict_type => 1, store => \$pipefail},
	error_trap  => { default => 1,
			 allow => [0, 1],
			 strict_type => 1, store => \$error_trap},
	sleep => { default => 0,
		   allow => [0, 1],
		   strict_type => 1, store => \$sleep},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    ### Sbatch script names and directory creation

    my $file_name_end = ".sh";
    my $file_name;  #The sbatch script - to be created filename
    my $file_name_tracker;

    my $program_data_directory = catdir($outdata_dir, $directory_id, $program_directory);
    my $file_name_path = catfile($outscript_dir, $directory_id, $program_directory, $program_name."_".$directory_id.$call_type).".";
    my $dry_run_file_name_path = catfile($outscript_dir, $directory_id, $program_directory, "dry_run_".$program_name."_".$directory_id.$call_type).".";
    my $file_info_path = catfile($outdata_dir, $directory_id, $program_directory, "info", $program_name."_".$directory_id.$call_type).".";
    my $dry_run_file_info_path = catfile($outdata_dir, $directory_id, $program_directory, "info", "dry_run_".$program_name."_".$directory_id.$call_type).".";

    ## Create directories
    make_path(catfile($outdata_dir, $directory_id, $program_directory, "info"),  #Creates the outaligner_dir folder and info data file directory
	      $program_data_directory,  #Creates the outaligner_dir folder and if supplied the program data file directory
	      catfile($outscript_dir, $directory_id, $program_directory),  #Creates the outaligner_dir folder script file directory
	);

    ## Set paths depending on dry run or not
    if ( ($active_parameter_href->{"p".$program_name} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	$file_name = $file_name_path;
    }
    elsif ($active_parameter_href->{"p".$program_name} == 2) {  #Dry run single program

	$file_name = $dry_run_file_name_path;
	$file_info_path = $dry_run_file_info_path;
	$log->info("Dry run:\n");
    }
    else {  #Dry run

	$file_name = $dry_run_file_name_path;
	$file_info_path = $dry_run_file_info_path;
	$log->info("Dry run:\n");
    }

    ## Check if a file with with a filename consisting of $file_path_ref.$file_counter.$file_ending_ref exist. If so bumps the version number and return new filename and sbatch version number.
    ($file_name, $file_name_tracker) = check_file_name_exists({file_path_ref => \$file_name,
							       file_ending_ref => \$file_name_end,
							      });

###Info and Log
    $log->info("Creating sbatch script for ".$program_name." and writing script file(s) to: ".$file_name."\n");
    $log->info("Sbatch script ".$program_name." data files will be written to: ".$program_data_directory."\n");

###Sbatch header
    open ($FILEHANDLE, ">",$file_name) or $log->logdie("Can't write to '".$file_name."' :".$!."\n");

    say $FILEHANDLE "#! /bin/bash -l";

    if ($pipefail) {

	say $FILEHANDLE "set -o pipefail";  #Detect errors within pipes
    }
    say $FILEHANDLE "#SBATCH -A ".$active_parameter_href->{project_id};
    say $FILEHANDLE "#SBATCH -n ".$core_number;
    say $FILEHANDLE "#SBATCH -t ".$process_time.":00:00";
    say $FILEHANDLE "#SBATCH --qos=".$slurm_quality_of_service;
    say $FILEHANDLE "#SBATCH -J ".$program_name."_".$directory_id.$call_type;
    say $FILEHANDLE "#SBATCH -e ".$file_info_path.$file_name_tracker.".stderr.txt";
    say $FILEHANDLE "#SBATCH -o ".$file_info_path.$file_name_tracker.".stdout.txt";

    if (exists($active_parameter_href->{email})) {

	if ($email_type =~/B/i) {

	    say $FILEHANDLE "#SBATCH --mail-type=BEGIN";
	}
	if ($email_type =~/E/i) {

	    say $FILEHANDLE "#SBATCH --mail-type=END";
	}
	if ($email_type =~/F/i) {

	    say $FILEHANDLE "#SBATCH --mail-type=FAIL";
	}
	say $FILEHANDLE "#SBATCH --mail-user=".$active_parameter_href->{email}, "\n";
    }

    say $FILEHANDLE q?echo "Running on: $(hostname)"?;
    say $FILEHANDLE q?PROGNAME=$(basename $0)?,"\n";

    if ($sleep) {  #Let the process sleep for a random couple of seconds (0-60) to avoid race conditions in mainly conda sourcing activate

	say $FILEHANDLE "sleep ".int(rand(60));
    }
    if (@$source_environment_commands_ref) {

	say $FILEHANDLE "##Activate environment";
	say $FILEHANDLE join(' ', @$source_environment_commands_ref), "\n";
    }
    if (defined($temp_directory)) {  #Not all programs need a temporary directory

	say $FILEHANDLE "## Create temporary directory";
	say $FILEHANDLE q?temp_directory="?.$temp_directory.q?"?;  #Assign batch variable
	say $FILEHANDLE q?mkdir -p ?.$temp_directory, "\n";

	## Create housekeeping function and trap
	say $FILEHANDLE q?finish() {?, "\n";
	say $FILEHANDLE "\t".q?## Perform sbatch exit housekeeping?;
	say $FILEHANDLE "\t".q?rm -rf ?.$temp_directory;

	## Output SLURM info on each job via sacct command and write to MIP Log file(.status)
	track_progress({job_id_href => $job_id_href,
			FILEHANDLE => $FILEHANDLE,
			log_file_ref => \$active_parameter_href->{log_file},
		       });

	say $FILEHANDLE q?}?;
	say $FILEHANDLE q?trap finish EXIT TERM INT?, "\n";
    }

    if ($error_trap) {

	## Create error handling function and trap
	say $FILEHANDLE q?error() {?, "\n";
	say $FILEHANDLE "\t".q?## Display error message and exit?;
	say $FILEHANDLE "\t".q{ret="$?"};
	say $FILEHANDLE "\t".q?echo "${PROGNAME}: ${1:-"Unknown Error - ExitCode="$ret}" 1>&2?, "\n";
	say $FILEHANDLE "\t".q?exit 1?;

	## Output SLURM info on each job via sacct command and write to MIP Log file(.status)
	track_progress({job_id_href => $job_id_href,
			FILEHANDLE => $FILEHANDLE,
			log_file_ref => \$active_parameter_href->{log_file},
		       });

	say $FILEHANDLE q?}?;
	say $FILEHANDLE q?trap error ERR?, "\n";
    }
    return ($file_name, $file_info_path.$file_name_tracker);  #Return filen name, file path for stdout/stderr for QC check later
}



sub add_merged_infile_name {

##add_merged_infile_name

##Function : Add merged infile name after merging all BAM files per sample_id
##Returns  : ""
##Arguments: $active_parameter_href, $file_info_href, $infile_lane_no_ending_href, $lane_href, $sample_id
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $lane_href                  => The lane info hash {REF}
##         : $sample_id                  => The sample_id

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $file_info_href;
    my $infile_lane_no_ending_href;
    my $lane_href;
    my $sample_id;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	lane_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$lane_href},
	sample_id => { required => 1, defined => 1, strict_type => 1, store => \$sample_id},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $infile;
    my $merge_lanes;  #To pick up merged lanes later
    my $picardtools_mergesamfiles_previous_bams = $file_info_href->{$sample_id}{picardtools_mergesamfiles_previous_bams};  #Alias

    if ( (defined($picardtools_mergesamfiles_previous_bams)) && ($picardtools_mergesamfiles_previous_bams) ) {  # Files merged this round with merged file from previous round

	foreach my $merge_sam_file (@{ $active_parameter_href->{picardtools_mergesamfiles_previous_bams} }) {

	    if ($merge_sam_file =~ /lane(\d+)|s_(\d+)/) {  #Look for lanes_ or lane\d in previously generated file to be merged with current run to be able to extract previous lanes

		##Make sure to always supply lanes from previous regexp
		if($1) {

		    $merge_lanes = $1;
		}
		else {

		    $merge_lanes = $2;
		}
		$infile = $sample_id."_lanes_".$merge_lanes;

		foreach my $lane_id (@ { $lane_href->{$sample_id} }) {

		    $infile .= $lane_id;  #Extract lanes per sample_id
		}
	    }
	}
    }
    else {  #Build infile name again

	$infile = $sample_id."_lanes_";

	foreach my $lane_id (@ { $lane_href->{$sample_id} }) {

	    $infile .= $lane_id;  #Extract lanes per sample_id
	}
    }
    $file_info_href->{$sample_id}{merge_infile} = $infile;
}


sub sample_info_qc {

##sample_info_qc

##Function : Adds outdirectory and outfile to sample_info to track all files that QC metrics are to be extracted from later
##Returns  : ""
##Arguments: $sample_info_href, $program_name, $outdirectory, $outfile_ending, $outdata_type, $sample_id, $infile,
##         : $sample_info_href => Info on samples and family hash {REF}
##         : $program_name     => The program
##         : $outdirectory     => The outdirectory of the QC file
##         : $outfile_ending   => The outfile ending. Actually complete outfile for "static" & "info_directory"
##         : $outdata_type     => Type of data produced by program (info_directory|infile_dependent|static)
##         : $sample_id        => Sample_id for data at sample level {Optional}
##         : $infile           => Infile for data at sample level {Optional}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $sample_info_href;
    my $program_name;
    my $outdirectory;
    my $outfile_ending;
    my $outdata_type;
    my $sample_id;
    my $infile;

    my $tmpl = {
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	outdirectory => { required => 1, defined => 1, strict_type => 1, store => \$outdirectory},
	outfile_ending => { required => 1, defined => 1, strict_type => 1, store => \$outfile_ending},
	outdata_type => { required => 1, defined => 1, strict_type => 1,
			  allow => ["static", "info_directory", "infile_dependent"],
			  store => \$outdata_type},
	infile => { strict_type => 1, store => \$infile},
	sample_id => { strict_type => 1, store => \$sample_id},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    unless (defined($sample_id)) {

	$sample_info_href->{program}{$program_name}{outdirectory} = $outdirectory;  #OutDirectory of QC file
	$sample_info_href->{program}{$program_name}{outfile} = $outfile_ending;
    }
    elsif (defined($infile)) {

	$sample_info_href->{sample}{$sample_id}{program}{$program_name}{$infile}{outdirectory} = $outdirectory;  #OutDirectory of QC file

	if ($outdata_type eq "infile_dependent") {  #Programs which add a filending to infile

	    $sample_info_href->{sample}{$sample_id}{program}{$program_name}{$infile}{outfile} = $infile.$outfile_ending;  #Infile dependent QC outfile
	}
	else {

	    $sample_info_href->{sample}{$sample_id}{program}{$program_name}{$infile}{outfile} = $outfile_ending;  #Static QC outfile or Info stdout file
	}
    }
    else {

	$log->fatal("Please provide infile to enable storing of sample_id data in hash\n");
	exit 1;
    }
}


sub split_target_file {

##split_target_file

##Function : Splits a target file into new contig specific target file
##Returns  : ""
##Arguments: $FILEHANDLE, $indirectory_ref, $outdirectory_ref, $infile_ref, $contig_ref, $file_ending
##         : $FILEHANDLE       => FILEHANDLE to write to
##         : $indirectory_ref  => Indirectory {REF}
##         : $outdirectory_ref => Analysis outdirectory {REF}
##         : $infile_ref       => Target file {REF}
##         : $contig_ref       => The contig to extract {REF}
##         : $file_ending      => File ending to add

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $FILEHANDLE;
    my $indirectory_ref;
    my $outdirectory_ref;
    my $infile_ref;
    my $contig_ref;
    my $file_ending;

    my $tmpl = {
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	indirectory_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$indirectory_ref},
	outdirectory_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$outdirectory_ref},
	infile_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$infile_ref},
	contig_ref => { store => \$contig_ref},
	file_ending => { strict_type => 1, store => \$file_ending},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if (defined($$contig_ref)) {  #The contig to split

	print $FILEHANDLE q?perl -nae 'if($_=~/^\@/) {print $_;} elsif($_=~/^?.$$contig_ref.q?\s+/) {print $_;}' ?;  #Select header and contig
	print $FILEHANDLE catfile($$indirectory_ref, $$infile_ref)." ";  #Infile

	if (defined($file_ending)) {

	    say $FILEHANDLE "> ".catfile($$outdirectory_ref, $$contig_ref."_".$$infile_ref.$file_ending). " &"; #Outfile with supplied file ending
	}
	else {

	    say $FILEHANDLE "> ".catfile($$outdirectory_ref, $$contig_ref."_".$$infile_ref). " &";  #Outfile
	}
    }
}


sub gatk_pedigree_flag {

##gatk_pedigree_flag

##Function : Check if "--pedigree" and "--pedigreeValidationType" should be included in analysis
##Returns  : ""
##Arguments: $active_parameter_href, $FILEHANDLE, $outfamily_file_directory, $pedigree_validation_type, $program_name
##         : $active_parameter_href    => The active parameters for this analysis hash {REF}
##         : $FILEHANDLE               => FILEHANDLE to write to
##         : $outfamily_file_directory => The family data analysis directory
##         : $pedigree_validation_type => The pedigree validation strictness level
##         : $program_name             => The program to use the pedigree file

    my ($arg_href) = @_;

    ## Default(s)
    my $pedigree_validation_type;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $FILEHANDLE;
    my $outfamily_file_directory;
    my $program_name;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	outfamily_file_directory => { required => 1, defined => 1, strict_type => 1, store => \$outfamily_file_directory},
	pedigree_validation_type => { default => "SILENT", strict_type => 1, store => \$pedigree_validation_type},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $fam_file = catfile($outfamily_file_directory, $active_parameter_href->{family_id}.".fam");
    my $parent_counter;
    my $pq_parent_counter = q?perl -ne 'my $parent_counter=0; while (<>) { my @line = split(/\t/, $_); unless ($_=~/^#/) { if ( ($line[2] eq 0) || ($line[3] eq 0) ) { $parent_counter++} } } print $parent_counter; last;'?;
    my $child_counter;
    my $pq_child_counter = q?perl -ne 'my $child_counter=0; while (<>) { my @line = split(/\t/, $_); unless ($_=~/^#/) { if ( ($line[2] ne 0) || ($line[3] ne 0) ) { $child_counter++} } } print $child_counter; last;'?;

    $parent_counter = `$pq_parent_counter $fam_file`;  #Count the number of parents
    $child_counter = `$pq_child_counter $fam_file`;  #Count the number of children

    if ($program_name ne "gatk_phasebytransmission") {

	if ($parent_counter > 0) {  #Parents present

	    print $FILEHANDLE "--pedigreeValidationType ".$pedigree_validation_type." --pedigree ".catfile($outfamily_file_directory, $active_parameter_href->{family_id}.".fam")." ";  #Pedigree files for samples
	}
    }
    else {

	check_pedigree_members({active_parameter_href => $active_parameter_href,
				FILEHANDLE => $FILEHANDLE,
				outfamily_file_directoryRef => \$outfamily_file_directory,
				pedigree_validation_type_ref => \$pedigree_validation_type,
				parent_counter_ref => \$parent_counter,
				child_counter_ref => \$child_counter
			       });  #Special case - GATK PhaseByTransmission needs parent/child or trio
    }
}


sub check_pedigree_members {

##check_pedigree_members

##Function : Detect if the pedigree file contains a valid parent/child or trio
##Returns  : ""
##Arguments: $active_parameter_href, $FILEHANDLE, $outfamily_file_directoryRef, $pedigree_validation_type_ref, $parent_counter_ref, $child_counter_ref
##         : $active_parameter_href        => The active parameters for this analysis hash {REF}
##         : $FILEHANDLE                   => FILEHANDLE to write to
##         : $outfamily_file_directoryRef  => The family data analysis directory {REF}
##         : $pedigree_validation_type_ref => The pedigree validation strictness level {REF}
##         : $parent_counter_ref           => The number of parent(s) {REF}
##         : $child_counter_ref            => The number of children(s) {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $FILEHANDLE;
    my $outfamily_file_directoryRef;
    my $pedigree_validation_type_ref;
    my $parent_counter_ref;
    my $child_counter_ref;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	outfamily_file_directoryRef => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$outfamily_file_directoryRef},
	pedigree_validation_type_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$pedigree_validation_type_ref},
	parent_counter_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$parent_counter_ref},
	child_counter_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$child_counter_ref},

    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    if (scalar(@{ $active_parameter_href->{sample_ids} }) < 4) {  #i.e.1-3 individuals in pedigree

	if ( ($$child_counter_ref == 1) && ($$parent_counter_ref > 0) ) {  #Parent/child or trio

	    print $FILEHANDLE "--pedigreeValidationType ".$$pedigree_validation_type_ref." --pedigree ".catfile($$outfamily_file_directoryRef, $active_parameter_href->{family_id}.".fam")." ";  #Pedigree files for samples
	}
	else {

	    $active_parameter_href->{pgatk_phasebytransmission} = 0;  #Override input since pedigree is not valid for analysis
	    $log->info("Switched GATK PhaseByTransmission to 'no run' mode since MIP did not detect a valid pedigree for this type of analysis.");

	    if ($active_parameter_href->{pgatk_readbackedphasing} > 0) {  #Broadcast

		$log->info("MIP will still try to run GATK ReadBackedPhasing, but with the '-respectPhaseInInput' flag set to false\n");
	    }
	}
    }
    else {

	$active_parameter_href->{pgatk_phasebytransmission} = 0;  #Override input since pedigree is not valid for analysis
	$log->info("Switched GATK PhaseByTransmission to 'no run' mode since MIP did not detect a valid pedigree for this type of analysis.");

	if ($active_parameter_href->{pgatk_readbackedphasing} > 0) {  #Broadcast

	    $log->info("MIP will still try to run GATK ReadBackedPhasing, but with the '-respectPhaseInInput' flag set to false\n");
	}
    }
}


sub write_cmd_mip_log {

##write_cmd_mip_log

##Function : Write CMD to MIP log file
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $order_parameters_ref, $script_ref, $log_file_ref
##         : $parameter_href        => The parameter hash {REF}
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $order_parameters_ref  => Order of addition to parameter array {REF}
##         : $script_ref            => The script that is being executed {REF}
##         : $log_file_ref          => The log file {REF}
##         : $mip_version_ref       => The MIP version

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $order_parameters_ref;
    my $script_ref;
    my $log_file_ref;
    my $mip_version_ref;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	order_parameters_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$order_parameters_ref},
	script_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$script_ref},
	log_file_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$log_file_ref},
	mip_version_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$mip_version_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $cmd_line = $$script_ref." ";

    my @nowrite = ("mip", "bwa_build_reference", "pbamcalibrationblock", "pvariantannotationblock");

    foreach my $order_parameter_element (@$order_parameters_ref) {

	if (defined($active_parameter_href->{$order_parameter_element}) ) {

	    if ( ($order_parameter_element eq "config_file") && ($active_parameter_href->{config_file} eq 0) ) {  #Do not print
	    }
	    else {

		if ( ( any {$_ eq $order_parameter_element} @nowrite ) ) {  #If element is part of array - do nothing
		}
		elsif ( (exists($parameter_href->{$order_parameter_element}{data_type})) && ($parameter_href->{$order_parameter_element}{data_type} eq "ARRAY")) {  #Array reference

		    my $separator = $parameter_href->{$order_parameter_element}{element_separator};
		    $cmd_line .= "-".$order_parameter_element." ".join($separator, @{ $active_parameter_href->{$order_parameter_element} })." ";
		}
		elsif ( (exists($parameter_href->{$order_parameter_element}{data_type})) && ($parameter_href->{$order_parameter_element}{data_type} eq "HASH")) {  #HASH reference

		    $cmd_line .="-".$order_parameter_element." ";  #First key
		    $cmd_line .= join("-".$order_parameter_element." ", map { "$_=$active_parameter_href->{$order_parameter_element}{$_} " } (keys $active_parameter_href->{$order_parameter_element}));
		}
		else {

		    $cmd_line .="-".$order_parameter_element." ".$active_parameter_href->{$order_parameter_element}." ";
		}
	    }
	}
    }
    $log->info($cmd_line,"\n");
    $log->info("MIP Version: ".$$mip_version_ref, "\n");
    $log->info("Script parameters and info from ".$$script_ref." are saved in file: ".$$log_file_ref, "\n");
}


sub check_unique_array_element {

##check_unique_array_element

##Function : Detects if there are items in query_ref that are not present in array_to_check_ref. If unique adds the unique element to array_to_check_ref.
##Returns  : ""
##Arguments: $array_to_check_ref, $array_query_ref
##         : $array_to_check_ref => The arrayref to be queried {REF}
##         : $query_ref          => The query reference can be either array or scalar {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $array_to_check_ref;
    my $query_ref;

    my $tmpl = {
	array_to_check_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$array_to_check_ref},
	query_ref => { required => 1, defined => 1, store => \$query_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $array_query_ref;

    if (ref($query_ref) eq "ARRAY") {  #Array reference

	$array_query_ref = $query_ref;
    }
    if (ref($query_ref) eq "SCALAR") {  #Scalar reference

	push($array_query_ref, $$query_ref);  #Standardize to array
    }

    ##For each array_query_ref element, loop through corresponding array_to_check_ref element(s), add if there are none or an updated/unique entry.
    foreach my $query (@$array_query_ref) {

	if (! ( any {$_ eq $query} @$array_to_check_ref ) ) { #If element is not part of array

	    push( @$array_to_check_ref, $query);  #Go ahead and add
	}
    }
}


sub determine_nr_of_rapid_nodes {

##determine_nr_of_rapid_nodes

##Function : Determines the number of nodes to allocate depending on the sequence read length, which affects the infile size.
##Returns  : $number_nodes, $read_nr_of_lines
##Arguments: $seq_length, $infile_size
##         : $seq_length  => Length of sequence reads
##         : $infile_size => Size of the infile

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $seq_length;
    my $infile_size;

    my $tmpl = {
	seq_length => { required => 1, defined => 1, strict_type => 1, store => \$seq_length},
	infile_size => { required => 1, defined => 1, strict_type => 1, store => \$infile_size},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $number_nodes = 0;  #Nodes to allocate
    my $read_position_weight = 1;  #Scales the read_start and read_stop position
    my $read_nr_of_lines;

    if ($seq_length > 75 && $seq_length <= 101) {

	$read_nr_of_lines = 190000000;  #Read batch size
	$number_nodes = floor($infile_size / (12 * $read_nr_of_lines) );  #Determines the number of nodes to use, 150000000 ~ 37,5 million reads, 13 = 2 sdtdev from sample population - currently poor estimate with compression confunding calculation.
	$log->info("Number of Nodes: ".$number_nodes, "\n");
    }
    if ($seq_length > 50 && $seq_length <= 75) {

	$read_nr_of_lines = 190000000;  #Read batch size
	$number_nodes = floor($infile_size / (9.75 * $read_nr_of_lines) );  #Determines the number of nodes to use, 150000000 ~ 37,5 million reads, 13 = 2 sdtdev from sample population - currently poor estimate with compression confunding calculation.
	$log->info("Number of Nodes: ".$number_nodes, "\n");
    }
    if ($seq_length >= 50 && $seq_length < 75) {

	$read_nr_of_lines = 130000000;  #Read batch size
	$number_nodes = floor($infile_size / (7 * $read_nr_of_lines) );  #Determines the number of nodes to use, 150000000 ~ 37,5 million reads, 13 = 2 sdtdev from sample population - currently poor estimate with compression confunding calculation.
	$log->info("Number of Nodes: ".$number_nodes, "\n");
    }
    if ($seq_length >= 35 && $seq_length < 50) {

	$read_nr_of_lines = 95000000;  #Read batch size
	$number_nodes = floor($infile_size / (6 * $read_nr_of_lines) );  #Determines the number of nodes to use, 150000000 ~ 37,5 million reads, 13 = 2 sdtdev from sample population - currently poor estimate with compression confunding calculation.
	$log->info("Number of Nodes: ".$number_nodes, "\n");
    }
    if ($number_nodes <= 1) {

	$number_nodes = 2;  #Ensure that at least 1 readbatch is processed
    }
    return $number_nodes, $read_nr_of_lines;
}


sub check_unique_ids {

##check_unique_ids

##Function : Test that the family_id and the sample_id(s) exists and are unique. Check if id sample_id contains "_".
##Returns  : ""
##Arguments: $active_parameter_href, $sample_ids_ref
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $sample_ids_ref        => Array to loop in for parameter {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_ids_ref;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_ids_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$sample_ids_ref},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my %seen;  #Hash to test duplicate sample_ids later

    if (! @$sample_ids_ref) {

	$log->fatal("Please provide sample_id(s)\n");
	exit 1;
    }

    foreach my $sample_id (@$sample_ids_ref) {

	$seen{$sample_id}++;  #Increment instance to check duplicates later

	if ($$family_id_ref eq $sample_id) {  #Family_id cannot be the same as sample_id

	    $log->fatal("Family_id: ".$$family_id_ref." equals sample_id: ".$sample_id.". Please make sure that the family_id and sample_id(s) are unique.\n");
	    exit 1;
	}
	if ($seen{$sample_id} > 1) {  #Check sample_id are unique

	    $log->fatal("Sample_id: ".$sample_id." is not uniqe.\n");
	    exit 1;
	}
	if ($sample_id =~/_/) {  #Sample_id contains "_", which is not allowed according to filename conventions

	    $log->fatal("Sample_id: ".$sample_id." contains '_'. Please rename sample_id according to MIP's filename convention, removing the '_'.\n");
	    exit 1;
	}
    }
}


sub update_config_file {

##update_config_file

##Function : Updates the config file to particular user/cluster for entries following specifications. Leaves other entries untouched.
##Returns  : ""
##Arguments: $active_parameter_href, $parameter_name_ref, $family_id_ref
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $parameter_name_ref    => MIP Parameter to update {REF}
##         : $family_id_ref         => Sets the family_id {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $parameter_name_ref;
    my $family_id_ref;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	parameter_name_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$parameter_name_ref},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ($active_parameter_href->{$$parameter_name_ref}) {  #Active parameter

	if (defined($active_parameter_href->{cluster_constant_path})) {  #Set the project specific path for this cluster

	    $active_parameter_href->{$$parameter_name_ref} =~ s/cluster_constant_path!/$active_parameter_href->{cluster_constant_path}/gi;  #Exchange cluster_constant_path! for current cluster path
	}
	if (defined($active_parameter_href->{analysis_constant_path})) { #Set the project specific path for this cluster

	    $active_parameter_href->{$$parameter_name_ref} =~ s/analysis_constant_path!/$active_parameter_href->{analysis_constant_path}/gi;  #Exchange analysis_constant_path! for the current analysis path
	}
	if (defined($$family_id_ref)) {  #Set the family_id

	    $active_parameter_href->{$$parameter_name_ref} =~ s/family_id!/$$family_id_ref/gi;  #Exchange FND! for the current family_id
	}
	if (defined($active_parameter_href->{outaligner_dir})) {  #Set the outaligner_dir used

	    $active_parameter_href->{$$parameter_name_ref} =~ s/aligner_outdir!/$active_parameter_href->{outaligner_dir}/gi;  #Exchange aligner_outdir! for the current outaligner_dir
	}
    }
}


sub check_auto_build {

##check_auto_build

##Function : Checks if autobuild is on and returns "1" if enabled or "0" if not
##Returns  : "0|1"
##Arguments: $parameter_href, $active_parameter_href, $parameter_name_ref, $sample_id_ref
##         : $parameter_href        => The parameter hash {REF}
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $parameter_name_ref    => MIP parameter name {REF}
##         : $sample_id_ref         => SampleId {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Optional
    my $sample_id_ref = $arg_href->{sample_id_ref};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $parameter_name_ref;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	parameter_name_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$parameter_name_ref},
	sample_id_ref => { default => \$$, strict_type => 1},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    if ( (defined($$sample_id_ref)) && ($$sample_id_ref) ) {

	if ($parameter_href->{$$family_id_ref}{$$sample_id_ref}{$$parameter_name_ref}{build_file} eq "yes_auto_build") {

	    return "1";  #Flag that autobuild is needed
	}
	if ($parameter_href->{$$family_id_ref}{$$sample_id_ref}{$$parameter_name_ref}{build_file} eq "yes_auto_downLoad") {

	    return "1";  #Flag that autobuild is needed
	}
	if ($parameter_href->{$$family_id_ref}{$$sample_id_ref}{$$parameter_name_ref}{build_file} eq 1) {

	    return "1";  #Flag that autobuild is needed
	}
	else {

	    return "0";  #No autobuild is needed
	}
    }
    else {

	if ($parameter_href->{$$parameter_name_ref}{build_file} eq "yes_auto_build") {

	    return "1";  #Flag that autobuild is needed
	}
	if ($parameter_href->{$$parameter_name_ref}{build_file} eq 1) {  #1 for arrays

	    return "1";  #Flag that autobuild is needed
	}
	elsif ( ($parameter_href->{$$parameter_name_ref}{build_file} eq "yes_auto_downLoad") || ($parameter_href->{$$parameter_name_ref}{build_file} eq 1) ) {

	    if ($parameter_href->{$$parameter_name_ref}{default} eq $active_parameter_href->{$$parameter_name_ref}) {

		return "1";  #Flag that autobuild is needed
	    }
	    else {

		$log->fatal("Could not find file ".$active_parameter_href->{$$parameter_name_ref}, "\n");
		$log->fatal("Make sure that file exists or use the default for this parameter to enable automatic download via Cosmid", "\n");
		exit 1;
	    }
	}
	else {

	    return "0";  #No autobuild is needed
	}
    }
}


sub parse_human_genome_reference {

##parse_human_genome_reference

##Function : Detect version and source of the human_genome_reference: Source (hg19 or GRCh).
##Returns  : ""
##Arguments: $file_info_href, $human_genome_reference_ref
##         : $file_info_href             => The file_info hash {REF}
##         : $human_genome_reference_ref => The human genome {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $file_info_href;
    my $human_genome_reference_ref;

    my $tmpl = {
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	human_genome_reference_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$human_genome_reference_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    if ($$human_genome_reference_ref =~/GRCh(\d+\.\d+|\d+)_homo_sapiens_/) {  #Used to change capture kit genome reference version later

	$file_info_href->{human_genome_reference_version} = $1;
	$file_info_href->{human_genome_reference_source} = "GRCh";  #Ensembl
    }
    elsif ($$human_genome_reference_ref =~/hg(\d+)_homo_sapiens/) {  #Used to change capture kit genome reference version later

	$file_info_href->{human_genome_reference_version} = $1;
	$file_info_href->{human_genome_reference_source} = "hg";  #Refseq
    }
    else {

	$log->warn("MIP cannot detect what kind of human_genome_reference you have supplied. If you want to automatically set the capture kits used please supply the reference on this format: [source]_[species]_[version].", "\n");
    }
    ## Removes ".file_ending" in filename.FILENDING(.gz)
    
    $file_info_href->{human_genome_reference_name_no_ending} = remove_file_ending({file_name_ref => $human_genome_reference_ref,
										   file_ending => ".fasta",
										  });

    $file_info_href->{human_genome_compressed} = check_gzipped({file_name_ref => $human_genome_reference_ref,
							       });
}


sub check_file_endings_to_build {

##check_file_endings_to_build

##Function : Checks files to be built by combining filename stub with fileendings.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, file_endings_ref, $parameter_name
##         : $parameter_href        => The parameter hash {REF}
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $file_endings_ref      => Reference to the file_endings to be added to the filename stub {REF}
##         : $parameter_name        => MIP parameter name

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $file_endings_ref;
    my $parameter_name;
    my $file_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	file_endings_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$file_endings_ref},
	parameter_name => { required => 1, defined => 1, strict_type => 1, store => \$parameter_name},
	file_name => { required => 1, defined => 1, strict_type => 1, store => \$file_name},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    foreach my $file_ending (@$file_endings_ref) {

	check_existance({parameter_href => $parameter_href,
			 active_parameter_href => $active_parameter_href,
			 item_name_ref => \catfile($file_name.$file_ending),
			 parameter_name_ref => \$parameter_name,
			 item_type_to_check => "file",
			});
    }
}


sub check_existance {

##check_existance

##Function : Checks if a file/directory exists and if auto_build is on or not. If file/directory does not extis and there is no autobuild, croaks and exists.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_id_ref, $item_name_ref, $parameter_name_ref, $item_type_to_check, $temp_directory_ref
##         : $parameter_href        => The parameters hash
##         : $active_parameter_href => The active parameter for this analysis hash
##         : $sample_id_ref         => Name of sample {REF}
##         : $item_name_ref         => Item to check for existance {REF}
##         : $parameter_name_ref    => MIP parameter name {REF}
##         : $item_type_to_check    => The type of item to check
##         : $temp_directory_ref    => The temporary directory

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};

    ## Optional
    my $sample_id_ref = $arg_href->{sample_id_ref};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $item_name_ref;
    my $parameter_name_ref;
    my $item_type_to_check;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	item_name_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$item_name_ref},
	parameter_name_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$parameter_name_ref},
	item_type_to_check => { required => 1, defined => 1, strict_type => 1, store => \$item_type_to_check},
	sample_id_ref => { default => \$$, strict_type => 1},
	temp_directory_ref => { default => \$$, strict_type => 1},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    if ($item_type_to_check eq "directory") {

	unless (-d $$item_name_ref) {  #Check existence of supplied directory

	    $log->fatal($USAGE, "\n");
	    $log->fatal("Could not find intended ".$$parameter_name_ref." directory: ".$$item_name_ref, "\n");
	    exit 1;
	}
    }
    elsif ($item_type_to_check eq "file") {

	unless (-f $$item_name_ref) {  #Check existence of supplied file in supplied reference dir

	    if ( (defined($$sample_id_ref)) && ($$sample_id_ref) ) {  #Individual files per sample_id

		## Check auto_build or not and return value
		$parameter_href->{$$family_id_ref}{$$sample_id_ref}{$$parameter_name_ref}{build_file} = check_auto_build({parameter_href => $parameter_href,
															  active_parameter_href => $active_parameter_href,
															  parameter_name_ref => $parameter_name_ref,
															  sample_id_ref => $sample_id_ref
															 });

		if ($parameter_href->{$$family_id_ref}{$$sample_id_ref}{$$parameter_name_ref}{build_file} == 0) {  #No autobuild

		    $log->fatal($USAGE, "\n");
		    $log->fatal("Could not find intended ".$$parameter_name_ref." file: ".$$item_name_ref, "\n");
		    exit 1;
		}
	    }
	    else {

		## Check auto_build or not and return value
		$parameter_href->{$$parameter_name_ref}{build_file} = check_auto_build({parameter_href => $parameter_href,
											active_parameter_href => $active_parameter_href,
											parameter_name_ref => $parameter_name_ref,
										       });

		if ($parameter_href->{$$parameter_name_ref}{build_file} == 0) {  #No autobuild

		    $log->fatal($USAGE, "\n");
		    $log->fatal("Could not find intended ".$$parameter_name_ref." file: ".$$item_name_ref, "\n");
		    exit 1;
		}
	    }
	}
	else {

	    if (defined($$sample_id_ref)) {

		$parameter_href->{$$family_id_ref}{$$sample_id_ref}{$$parameter_name_ref}{build_file} = 0;  #File exist in this check
	    }
	    else {

		if ( (defined($parameter_href->{$$parameter_name_ref}{build_file})) && ($parameter_href->{$$parameter_name_ref}{build_file} ne 1) ) { #If any of associated files do not exist make sure to build them

		    $parameter_href->{$$parameter_name_ref}{build_file} =  0;  #File exist in this check
		}
	    }
	}
    }
}


sub move_mosaik_nn {

##move_mosaik_nn

##Function : Locate MOSAIK path and move neural network files in place if lacking
##Returns  : ""
##Arguments: $active_parameter_href
##         : $active_parameter_href => The active parameters for this analysis hash {REF}

    my $active_parameter_href = $_[0];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my @paths = split(/:/,$ENV{PATH});  #Find Mosaik installation path

    for (my $paths_counter=0;$paths_counter<scalar(@paths);$paths_counter++) {

	if ($paths[$paths_counter] =~/MOSAIK/) {  #Select MOSAIK path

	    $paths[$paths_counter] =~ s/bin\//src\/networkFile/g;  #Location of NN files

	    $log->warn("Could not find Mosaik Network Files in ".$active_parameter_href->{reference_dir},"\n");
	    $log->info("Copying Mosaik Network Files ".$active_parameter_href->{mosaik_align_neural_network_se_file}." and ".$active_parameter_href->{mosaik_align_neural_network_pe_file}." to ".$active_parameter_href->{reference_dir}." from ".$paths[$paths_counter], "\n");
	    copy(catfile($paths[$paths_counter], $active_parameter_href->{mosaik_align_neural_network_se_file}), $active_parameter_href->{reference_dir});
	    copy(catfile($paths[$paths_counter], $active_parameter_href->{mosaikAlignNeuralNetworkPeFile}), $active_parameter_href->{reference_dir});
	    last;
	}
    }
}


sub check_user_supplied_info {

##check_user_supplied_info

##Function : Determine if the user supplied info on parameter either via cmd or config
##Returns  : "0|1"
##Arguments: $active_parameter_href, $data_ref, $parameter_name
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $data_ref              => Data to check for existence {REF}
##         : $parameter_name        => MIP parameter to evaluate

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $data_ref;
    my $parameter_name;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	data_ref => { required => 1, defined => 1, store => \$data_ref},
	parameter_name => { strict_type => 1, store => \$parameter_name},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $user_supplied_info_switch;

    if (ref($data_ref) eq "ARRAY") {  #Array reference

	if (! @$data_ref) {  #No user supplied sample info

   	    if (defined($active_parameter_href->{$parameter_name})) {  #User supplied info in config file

		$user_supplied_info_switch = 0;  #No user supplied cmd info, but present in config file overwrite using info from pedigree file
	    }
	    else {  #No sample_ids info in config file

		$user_supplied_info_switch = 0;  #No user supplied cmd info, not defined in config file, ADD it from pedigree file
	    }
	}
	else {

	    $user_supplied_info_switch = 1;  #User supplied cmd info, do NOT overwrite using info from pedigree file
	}
    }
    elsif (ref($data_ref) eq "HASH") {

	if (! %$data_ref) {

	    if (defined($active_parameter_href->{$parameter_name})) {  #User supplied info in config file

		$user_supplied_info_switch = 0;  #No user supplied cmd info, but present in config file overwrite using info from pedigree file
	    }
	    else {  #No sample_ids info in config file

		$user_supplied_info_switch = 0;  #No user supplied cmd info, not defined in config file, ADD it from pedigree file
	    }
	}
	else {

	    $user_supplied_info_switch = 1;  #User supplied cmd info, do NOT overwrite using info from pedigree file
	}
    }
    return $user_supplied_info_switch;
}


sub check_gzipped {

##check_gzipped

##Function : Check if a file is gzipped.
##Returns  : "0 (=uncompressed)| 1 (=compressed)"
##Arguments: $file_name_ref
##         : $file_name_ref => File name {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $file_name_ref;

    my $tmpl = {
	file_name_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$file_name_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $file_compression_status = 0;

    if ($$file_name_ref =~/.gz$/) {

	$file_compression_status = 1;
    }
    return $file_compression_status;
}


sub remove_file_ending {

##remove_file_ending

##Function : Removes ".file_ending" in filename.file_ending(.gz)
##Returns  : File name with supplied $file_ending or $file_ending(.gz) removed
##Arguments: $file_name_ref, $file_ending
##         : $file_name_ref => File name {REF}
##         : $file_ending   => File ending to be removed

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $file_name_ref;
    my $file_ending;

    my $tmpl = {
	file_name_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$file_name_ref},
	file_ending => { required => 1, defined => 1, strict_type => 1, store => \$file_ending},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $file_name_noending;

    if ( (defined($$file_name_ref)) && ($$file_name_ref =~/(\S+)($file_ending$|$file_ending.gz$)/) ) {

	$file_name_noending = $1;
    }
    return $file_name_noending;
}


sub check_target_bed_file_exist {

##check_target_bed_file_exist

##Function : Check that supplied target file ends with ".bed" and otherwise exists.
##Returns  : ""
##Arguments: $active_parameter_href, $file, $parameter_name
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $file                  => File to check for existance and file ending
##         : $parameter_name        => MIP parameter name

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $file;
    my $parameter_name;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	file => { required => 1, defined => 1, strict_type => 1, store => \$file},
	parameter_name => { required => 1, defined => 1, strict_type => 1, store => \$parameter_name},

    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    if ($file !~/.bed$/) {

	$log->fatal("Could not find intendended '.bed file ending' for target file: ".$file." in parameter '-".$parameter_name."'", "\n");
	exit 1;
    }
}


sub compare_array_elements {

##compare_array_elements

##Function : Compares the number of elements in two arrays and exits if the elements are not equal.
##Returns  : ""
##Arguments: $elements_ref, $array_queries_ref, $parameter_name, $parameter_name_query
##         : $elements_ref         => Array to match {REF}
##         : $array_queries_ref    => Array to be compared {REF}
##         : $parameter_name       => MIP reference parameter
##         : $parameter_name_query => MIP query parameter

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $elements_ref;
    my $array_queries_ref;
    my $parameter_name;
    my $parameter_name_query;

    my $tmpl = {
	elements_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$elements_ref},
	array_queries_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$array_queries_ref},
	parameter_name => { required => 1, defined => 1, strict_type => 1, store => \$parameter_name},
	parameter_name_query => { required => 1, defined => 1, strict_type => 1, store => \$parameter_name_query},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    if (scalar(@$elements_ref) != scalar(@$array_queries_ref)) {

	$log->fatal("The number of supplied '-".$parameter_name_query."' (=".scalar(@$array_queries_ref).") do not equal the number of '-".$parameter_name."' (=".scalar(@$elements_ref)."). Please specify a equal number of elements for both parameters", "\n");
	exit 1;
    }
}


sub print_check_exist_and_move_file {

##print_check_exist_and_move_file

##Function : Checks if a file exists and moves the file in place if file is lacking or has a size of 0 bytes.
##Returns  : ""
##Arguments: $FILEHANDLE, $intended_file_path_ref, $temporary_file_path_ref
##         : $FILEHANDLE              => FILEHANDLE to write to
##         : $intended_file_path_ref  => Path to file to check for existence {REF}
##         : $temporary_file_path_ref => File that has been created {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $FILEHANDLE;
    my $intended_file_path_ref;
    my $temporary_file_path_ref;

    my $tmpl = {
	FILEHANDLE => { required => 1, store => \$FILEHANDLE},
	intended_file_path_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$intended_file_path_ref},
	temporary_file_path_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$temporary_file_path_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "[ -s ".$$intended_file_path_ref." ] ";  #Check file exists and is larger than 0
    print $FILEHANDLE "&& rm ".$$temporary_file_path_ref." ";  #If other processes already has created file, remove temp file
    print $FILEHANDLE "|| ";  #File has not been created by other processes
    say $FILEHANDLE "mv ".$$temporary_file_path_ref." ".$$intended_file_path_ref,"\n";  #Move file in place
}


sub define_snpeff_files {

##define_snpeff_files

##Function : Defines and adds snpEff/snpsift files and features to hash
##Returns  : ""
##Arguments: $parameter_href
##         : $parameter_href => The parameter hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];
    
    my %snpeff_file;
    my @snpsift_downloadable_files = ("dbsnp_138.b37.excluding_sites_after_129.vcf",
				      "dbsnp_138.b37.vcf", "1000G_phase1.indels.b37.vcf",
				      "1000G_phase1.snps.high_confidence.b37.vcf",
	);

    foreach my $file (@snpsift_downloadable_files) {

	$snpeff_file{snpsift}{$file} = ({downloadable => "yes",  #Files that are downloadable via Cosmid
					});
	push(@{ $parameter_href->{$file}{associated_program} }, "psnpeff");
	$parameter_href->{$file}{data_type} = "SCALAR";
	$parameter_href->{$file}{build_file} = "yes_auto_build";  #Allow autoDownLoad, but yes_auto_build is set since the file is its own default, so no extra check is required (compared with yes_auto_downLoad)
    }
    return %snpeff_file;
}

sub define_annovar_tables {

##define_annovar_tables

##Function : Defines and adds annovar tables parameters to hash
##Returns  : ""
##Arguments: $parameter_href, $annovar_supported_table_names_ref, $annovar_genome_build_version_ref
##         : $parameter_href                    => The parameter hash {REF}
##         : $annovar_supported_table_names_ref => The supported annovar reference names array {REF}
##         : $annovar_genome_build_version_ref  => The current annovar genome build

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $annovar_supported_table_names_ref;
    my $annovar_genome_build_version_ref;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	annovar_supported_table_names_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$annovar_supported_table_names_ref},
	annovar_genome_build_version_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$annovar_genome_build_version_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my %annovar_table;  #Holds all annovar tables parameters and features

    ##Define annovar tables
    my @annovar_tables_gene_annos = ("refGene", "knownGene", "ensGene");  #Tables using annotation option "geneanno"
    my @annovar_tables_region_annos = ("mce46way", "gerp++elem", "segdup", "tfbs", "mirna");  #Tables using annotation option "regionanno"
    my @annovar_tables_filters = ("snp137", "snp135", "snp132", "snp131", "snp130", "snp129", "snp137NonFlagged", "snp135NonFlagged", "snp132NonFlagged", "snp131NonFlagged", "snp130NonFlagged", "1000g2012apr_all", "1000g2012apr_amr", "1000g2012apr_eur", "1000g2012apr_asn", "1000g2012apr_afr", "1000g2012feb_all", "esp6500si_all", "esp6500_all", "esp6500_aa", "esp6500_ea", "esp5400_all", "esp5400_aa", "esp5400_ea","clinvar_20131105", "ljb2_sift", "ljb2_pp2hdiv", "ljb2_pp2hvar", "ljb2_mt", "ljb2_ma", "ljb2_fathmm", "ljb2_siphy", "ljb2_lrt", "ljb_all", "ljb2_gerp++", "ljb2_phylop", "caddgt20", "caddgt10");  #Tables using annotation option "filter"
    my @annovar_tables_uscs_urls = ("mce46way", "segdup", "tfbs", "mirna");  #Tables using urlAlias "ucsc"
    my @annovar_generic_filters = ("esp6500si_all", "esp6500_all", "esp6500_aa", "esp6500_ea", "esp5400_all", "esp5400_aa", "esp5400_ea","clinvar_20131105");  #Tables using generic option
    my @annovar_generic_files = ($$annovar_genome_build_version_ref."_esp6500si_all.txt", $$annovar_genome_build_version_ref."_esp6500_all.txt", $$annovar_genome_build_version_ref."_esp6500_aa.txt", $$annovar_genome_build_version_ref."_esp6500_ea.txt", $$annovar_genome_build_version_ref."_esp5400_all.txt", $$annovar_genome_build_version_ref."_esp5400_aa.txt", $$annovar_genome_build_version_ref."_esp5400_ea.txt", $$annovar_genome_build_version_ref."_clinvar_20131105.txt");  #Generic table files
    my @annovar_ref_gene_files = ($$annovar_genome_build_version_ref."_refGene.txt", $$annovar_genome_build_version_ref."_refGeneMrna.fa", $$annovar_genome_build_version_ref."_refLink.txt", "GRCh37_MT_ensGene.txt", "GRCh37_MT_ensGeneMrna.fa");  #Cater for multiple download
    my @annovar_known_gene_files = ($$annovar_genome_build_version_ref."_knownGene.txt", $$annovar_genome_build_version_ref."_kgXref.txt", $$annovar_genome_build_version_ref."_knownGeneMrna.fa");  #Cater for multiple download
    my @annovar_ens_gene_files = ($$annovar_genome_build_version_ref."_ensGene.txt", $$annovar_genome_build_version_ref."_ensGeneMrna.fa", "GRCh37_MT_ensGene.txt", "GRCh37_MT_ensGeneMrna.fa");  #Cater for multiple download

    #Set UCSC alias for download from UCSC
    $annovar_table{mce46way}{ucsc_alias} = "phastConsElements46way";
    $annovar_table{segdup}{ucsc_alias} = "genomicSuperDups";
    $annovar_table{tfbs}{ucsc_alias} = "tfbsConsSites";
    $annovar_table{mirna}{ucsc_alias} = "wgRna";

    #Set GeneAnno files
    push(@{ $annovar_table{refGene}{file} }, @annovar_ref_gene_files);
    push(@{ $annovar_table{knownGene}{file} }, @annovar_known_gene_files);
    push(@{ $annovar_table{ensGene}{file} }, @annovar_ens_gene_files);

    for (my $tables_counter=0;$tables_counter<scalar(@$annovar_supported_table_names_ref);$tables_counter++) {

	annovar_table_parameters({annovar_table_href => \%annovar_table,
				  table_name_ref => \$annovar_supported_table_names[$tables_counter],
				  arrays_ref => $annovar_supported_table_names_ref,
				  parameterType => "dbtype",
				  parameter_value => $annovar_supported_table_names[$tables_counter],
				 });
	annovar_table_parameters({annovar_table_href => \%annovar_table,
				  table_name_ref => \$annovar_supported_table_names[$tables_counter],
				  arrays_ref => $annovar_supported_table_names_ref,
				  parameterType => "download",
				  parameter_value => $annovar_supported_table_names[$tables_counter],
				 });
	$parameter_href->{$annovar_supported_table_names[$tables_counter]}{build_file} = "yes_auto_build";  #Allow autobuild
    }


    #Tables using different download call from dbtype call
    $annovar_table{'1000g2012apr_all'}{download} = "ALL.sites.2012_04";
    $annovar_table{'1000g2012feb_all'}{download} = "ALL.sites.2012_02";
    $annovar_table{'1000g2012apr_afr'}{download} = "AFR.sites.2012_04";
    $annovar_table{'1000g2012apr_amr'}{download} = "AMR.sites.2012_04";
    $annovar_table{'1000g2012apr_eur'}{download} = "EUR.sites.2012_04";
    $annovar_table{'1000g2012apr_asn'}{download} = "ASN.sites.2012_04";

    #Set 1000G Table filename
    $annovar_table{'1000g2012apr_all'}{file}[0] = $$annovar_genome_build_version_ref."_ALL.sites.2012_04.txt";
    $annovar_table{'1000g2012feb_all'}{file}[0] = $$annovar_genome_build_version_ref."_ALL.sites.2012_02.txt";
    $annovar_table{'1000g2012apr_afr'}{file}[0] = $$annovar_genome_build_version_ref."_AFR.sites.2012_04.txt";
    $annovar_table{'1000g2012apr_amr'}{file}[0] = $$annovar_genome_build_version_ref."_AMR.sites.2012_04.txt";
    $annovar_table{'1000g2012apr_eur'}{file}[0] = $$annovar_genome_build_version_ref."_EUR.sites.2012_04.txt";
    $annovar_table{'1000g2012apr_asn'}{file}[0] = $$annovar_genome_build_version_ref."_ASN.sites.2012_04.txt";

    for (my $tables_counter=0;$tables_counter<scalar(@annovar_tables_gene_annos);$tables_counter++) {

	annovar_table_parameters({annovar_table_href => \%annovar_table,
				  table_name_ref => \$annovar_tables_gene_annos[$tables_counter],
				  arrays_ref => \@annovar_tables_gene_annos,
				  parameterType => "annotation",
				  parameter_value => "geneanno",
				 });
	annovar_table_parameters({annovar_table_href => \%annovar_table,
				  table_name_ref => \$annovar_tables_gene_annos[$tables_counter],
				  arrays_ref => \@annovar_tables_gene_annos,
				  parameterType => "urlAlias",
				  parameter_value => "annovar",
				 });
    }
    for (my $tables_counter=0;$tables_counter<scalar(@annovar_tables_region_annos);$tables_counter++) {

	annovar_table_parameters({annovar_table_href => \%annovar_table,
				  table_name_ref => \$annovar_tables_region_annos[$tables_counter],
				  arrays_ref => \@annovar_tables_region_annos,
				  parameterType => "annotation",
				  parameter_value => "regionanno",
				 });
	annovar_table_parameters({annovar_table_href => \%annovar_table,
				  table_name_ref => \$annovar_tables_region_annos[$tables_counter],
				  arrays_ref => \@annovar_tables_region_annos,
				  parameterType => "urlAlias",
				  parameter_value => "annovar",
				 });
	annovar_table_parameters({annovar_table_href => \%annovar_table,
				  table_name_ref => \$annovar_tables_region_annos[$tables_counter],
				  arrays_ref => \@annovar_tables_uscs_urls,
				  parameterType => "urlAlias",
				  parameter_value => "ucsc",
				 });  #Replace for ucsc tables NOTE: not all in RegionAnno
    }
    for (my $tables_counter=0;$tables_counter<scalar(@annovar_tables_filters);$tables_counter++) {

	annovar_table_parameters({annovar_table_href => \%annovar_table,
				  table_name_ref => \$annovar_tables_filters[$tables_counter],
				  arrays_ref => \@annovar_tables_filters,
				  parameterType => "annotation",
				  parameter_value => "filter",
				 });
	annovar_table_parameters({annovar_table_href => \%annovar_table,
				  table_name_ref => \$annovar_tables_filters[$tables_counter],
				  arrays_ref => \@annovar_tables_filters,
				  parameterType => "urlAlias",
				  parameter_value => "annovar",
				 });
	annovar_table_parameters({annovar_table_href => \%annovar_table,
				  table_name_ref => \$annovar_tables_filters[$tables_counter],
				  arrays_ref => \@annovar_tables_filters,
				  parameterType => "indexFile",
				  parameter_value => ".idx",
				 });
    }
    for (my $tables_counter=0;$tables_counter<scalar(@annovar_generic_filters);$tables_counter++) {

	annovar_table_parameters({annovar_table_href => \%annovar_table,
				  table_name_ref => \$annovar_generic_filters[$tables_counter],
				  arrays_ref => \@annovar_generic_filters,
				  parameterType => "dbtype",
				  parameter_value => "generic",
				 });
	annovar_table_parameters({annovar_table_href => \%annovar_table,
				  table_name_ref => \$annovar_generic_filters[$tables_counter],
				  arrays_ref => \@annovar_generic_filters,
				  parameterType => "file",
				  parameter_value => $annovar_generic_files[$tables_counter],
				 });
    }
    return %annovar_table;
}


sub annovar_table_parameters {

##annovar_table_parameters

##Function : Populates annovar_table hash by looping through array and adding table with identified membership and associated parameters into hash.
##           Parameters of type "file" are added as a hash of array since multiple files can be downloaded

##Returns  : ""
##Arguments: $annovar_table_href, $table_name_ref, $arrays_ref, $parameter_type, $parameter_value
##         : $annovar_table_href => annovar_table_href {REF}
##         : $table_name_ref     => annovar table name {REF}
##         : $arrays_ref         => Array to search for membership {REF}
##         : $parameter_type     => Type of table parameter
##         : $parameter_value    => Parameter value

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $annovar_table_href;
    my $table_name_ref;
    my $arrays_ref;
    my $parameter_type;
    my $parameter_value;

    my $tmpl = {
	annovar_table_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$annovar_table_href},
	arrays_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$arrays_ref},
	table_name_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$table_name_ref},
	parameterType => { required => 1, defined => 1, strict_type => 1, store => \$parameter_type},
	parameter_value => { required => 1, defined => 1, strict_type => 1, store => \$parameter_value},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    for (my $tables_counter=0;$tables_counter<scalar(@$arrays_ref);$tables_counter++) {

	if ($arrays_ref->[$tables_counter] eq $$table_name_ref) {  #Membership test

	    if ($parameter_type eq "file") {  #Add as array instead, since some annovar tables have multiple files downloaded for the same call

		push(@{ $annovar_table_href->{$$table_name_ref}{$parameter_type} }, $parameter_value);  #Add as array to hash_ref
	    }
	    else {

		$annovar_table_href->{$$table_name_ref}{$parameter_type} = $parameter_value;
	    }
	    last;  #No table should be represented twice within the same array
	}
    }
}


sub collect_seq_contigs {

##collect_seq_contigs

##Function : Collects sequences contigs used in analysis from human genome sequence dictionnary associated with $human_genome_reference
##Returns  : ""
##Arguments: $contigs_ref, $reference_dir_ref, $human_genome_reference_name_no_ending_ref
##         : $contigs_ref                               => Contig array {REF}
##         : $reference_dir_ref                         => The MIP reference directory {REF}
##         : $human_genome_reference_name_no_ending_ref => The associated human genome file without file ending

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $contigs_ref;
    my $reference_dir_ref;
    my $human_genome_reference_name_no_ending_ref;

    my $tmpl = {
	contigs_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$contigs_ref},
	reference_dir_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$reference_dir_ref},
	human_genome_reference_name_no_ending_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$human_genome_reference_name_no_ending_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $pqSeqDict = q?perl -nae 'if($F[0]=~/^\@SQ/) { if($F[1]=~/SN\:(\S+)/) {print $1, ",";} }' ?;
    my $SeqDictLocation = catfile($$reference_dir_ref, $$human_genome_reference_name_no_ending_ref.".dict");
    @$contigs_ref = `$pqSeqDict $SeqDictLocation `;  #Returns a comma seperated string of sequence contigs from dict file
    @$contigs_ref = split(/,/,join(',', @$contigs_ref));
}


sub collect_select_file_contigs {

##collect_select_file_contigs

##Function : Collects sequences contigs used in select file
##Returns  : ""
##Arguments: $contigs_ref, $select_file_path
##         : $contigs_ref      => Contig array {REF}
##         : $select_file_path => The select file path

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $contigs_ref;
    my $select_file_path;

    my $tmpl = {
	contigs_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$contigs_ref},
	select_file_path => { required => 1, defined => 1, strict_type => 1, store => \$select_file_path},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $pquery_seq_dict = q?perl -nae 'if ($_=~/contig\=(\w+)/) {print $1, ",";} if($_=~/#CHROM/) {last;}' ?;
    @$contigs_ref = `$pquery_seq_dict $select_file_path `;  #Returns a comma seperated string of sequence contigs from file
    @$contigs_ref = split(/,/,join(',', @$contigs_ref));

    if (! @$contigs_ref) {

	$log->fatal("Could not detect any '##contig' in meta data header in select file: ".$select_file_path."\n");
	exit 1;
    }
}


sub size_sort_select_file_contigs {

##size_sort_select_file_contigs

##Function : Sorts array depending on reference array. NOTE: Only entries present in reference array will survive in sorted array.
##Returns  : "@sorted_contigs"
##Arguments: $file_info_href, $consensus_analysis_type_ref, $hash_key_to_sort, $hash_key_sort_reference
##         : $file_info_href              => The file_info hash {REF}
##         : $consensus_analysis_type_ref => Consensus analysis_type {REF}
##         : $hash_key_to_sort            => The keys to sort
##         : $hash_key_sort_reference     => The hash keys sort reference

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $file_info_href;
    my $consensus_analysis_type_ref;
    my $hash_key_to_sort;
    my $hash_key_sort_reference;

    my $tmpl = {
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	consensus_analysis_type_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$consensus_analysis_type_ref},
	hash_key_to_sort => { required => 1, defined => 1, strict_type => 1, store => \$hash_key_to_sort},
	hash_key_sort_reference => { required => 1, defined => 1, strict_type => 1, store => \$hash_key_sort_reference},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my @sorted_contigs;

    ##Sort the contigs depending on reference array
    if ($file_info_href->{$hash_key_to_sort}) {

	foreach my $element (@{ $file_info_href->{$hash_key_sort_reference} }) {

	    if (! check_entry_hash_of_array({hash_ref => $file_info_href,
					     key => $hash_key_to_sort,
					     element => $element,
					    })
		) {

		push(@sorted_contigs, $element);
	    }
	}
    }

    ## Test if all contigs collected from select file was sorted by reference contig array
    if ( (@sorted_contigs) && (scalar(@{ $file_info_href->{$hash_key_to_sort} }) != scalar(@sorted_contigs)) ) {

	foreach my $element (@{ $file_info_href->{$hash_key_to_sort} }) {

	    if ( ! (any {$_ eq $element} @sorted_contigs) ) {  #If element is not part of array

		unless ( ($$consensus_analysis_type_ref eq "wes") && ($element=~/MT$|M$/) ) {  #Special case when analysing wes since Mitochondrial contigs have no baits in exome capture kits

		    $log->fatal("Could not detect '##contig'= ".$element." from meta data header in '-vcfparser_select_file' in reference contigs collected from '-human_genome_reference'\n");
		    exit 1;
		}
	    }
	}
    }
    return @sorted_contigs;
}

sub replace_config_parameters_with_cmd_info {

##replace_config_parameters_with_cmd_info

##Function : Replace config parameter with cmd info for config dynamic parameter
##Returns  :
##Arguments: $parameter_href, $active_parameter_href, $parameter_names_ref
##         : $parameter_href        => The parameter hash {REF}
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $parameter_names_ref   => MIP activate parameter names {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $parameter_names_ref;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	parameter_names_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$parameter_names_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    foreach my $parameter_name (@$parameter_names_ref) {

	if (defined($parameter_href->{$parameter_name}{value})) {  #Replace config parameter with cmd info for parameter

	    $active_parameter_href->{$parameter_name} = $parameter_href->{$parameter_name}{value};  #Transfer to active parameter
	}
	elsif ( (exists($parameter_href->{$parameter_name}{default})) && (! defined($active_parameter_href->{$parameter_name})) ) {

	    $active_parameter_href->{$parameter_name} = $parameter_href->{$parameter_name}{default};  #Transfer to active parameter
	}
    }
}


sub define_supported_cosmid_references {

##define_supported_cosmid_references

##Function : Defines the Cosmid manager hash keys and populates it from arguments
##Returns  : ""
##Arguments: $supported_cosmid_reference_href, $parameter_name, $cosmid_resource_name, $cosmid_resource_version, $human_genome_reference_version_ref, $compressed_switch
##         : $supported_cosmid_reference_href    => The supported cosmid references hash {REF}
##         : $parameter_name                     => MIP parameter name
##         : $cosmid_resource_name               => Cosmid Resource name
##         : $cosmid_resource_version            => Version of the cosmid Resource to download
##         : $human_genome_reference_version_ref => The human genome build used in the analysis
##         : $compressed_switch                  => If files after download are compressed or not

    my ($arg_href) = @_;

    my $compressed_switch = $arg_href->{'compressed_switch'} //= 0;

    ## Flatten argument(s)
    my $supported_cosmid_reference_href;
    my $parameter_name;
    my $cosmid_resource_name;
    my $cosmid_resource_version;
    my $human_genome_reference_version_ref;

    my $tmpl = {
	supported_cosmid_reference_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_cosmid_reference_href},
	parameter_name => { required => 1, defined => 1, strict_type => 1, store => \$parameter_name},
	cosmid_resource_name => { required => 1, defined => 1, strict_type => 1, store => \$cosmid_resource_name},
	cosmid_resource_version => { required => 1, defined => 1, strict_type => 1, store => \$cosmid_resource_version},
	human_genome_reference_version_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$human_genome_reference_version_ref},
	compressed_switch => { strict_type => 1, store => \$compressed_switch},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    $supported_cosmid_reference_href->{$parameter_name} = {

	cosmid_name => $cosmid_resource_name,
	version => $cosmid_resource_version,
	human_genome_reference_version => $$human_genome_reference_version_ref,
	compressed_switch => $compressed_switch,
    };
}


sub check_cosmid_yaml {

##check_cosmid_yaml

##Function : Locates and sets the cosmid directory to download to
##Returns  : Path to Cosmid Resource directory for current analysis
##Arguments: $active_parameter_href
##         : $active_parameter_href => The active parameters for this analysis hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my %cosmid_resources;  #Hash to load cosmid info to

    if (-f $active_parameter_href->{reference_dir}."/cosmid.yaml") {  #Cosmid.yaml file exists in reference directory

	## Loads a YAML file into an arbitrary hash and returns it.
	%cosmid_resources = File::Format::Yaml::load_yaml({yaml_file => catfile($active_parameter_href->{reference_dir}, "cosmid.yaml"),
							  });
	$log->info("Loaded: ".catfile($active_parameter_href->{reference_dir}, "cosmid.yaml") , "\n");
	
	unless (defined($cosmid_resources{directory})) {  #Set Directory entry if not defined

	    $cosmid_resources{directory} = catfile($active_parameter_href->{reference_dir}, "resources");  #Set the Cosmid default directory
	}
    }
    else {  #No cosmid.yaml exist in reference directory

	$cosmid_resources{directory} = catfile($active_parameter_href->{reference_dir}, "resources");  #Set the Cosmid default directory
    }
    return $cosmid_resources{directory};
}


sub adjust_core_number_to_seq_mode {

##adjust_core_number_to_seq_mode

##Function : Adjust the number of cores to be used in the analysis according to sequencing mode requirements.
##Returns  : ""
##Arguments: $core_number_ref, $sequence_run_type_ref
##         : $core_number_ref       => The maximum number of cores to be use before printing "wait" statement {REF}
##         : $sequence_run_type_ref => Type of sequencing [paired_end|single_end] {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $core_number_ref;
    my $sequence_run_type_ref;

    my $tmpl = {
	core_number_ref => { required => 1, default => \$$, strict_type => 1, store => \$core_number_ref},
	sequence_run_type_ref => { required => 1, default => \$$, strict_type => 1, store => \$sequence_run_type_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ($$sequence_run_type_ref eq "paired_end") {  #Second read direction if present

	$$core_number_ref =  $$core_number_ref + 2;  #2 processes per file
    }
    else {  #Single_end

	$$core_number_ref = $$core_number_ref + 1;  #Only 1 file and one process
    }
}


sub print_wait {

##print_wait

##Function : Calculates when to prints "wait" statement and prints "wait" to supplied FILEHANDLE when adequate.
##Returns  : Incremented $$core_counter_ref
##Arguments: $counter_ref, $core_number_ref, $core_counter_ref
##         : $counter_ref      => The number of used cores {REF}
##         : $core_number_ref  => The maximum number of cores to be use before printing "wait" statement {REF}
##         : $core_counter_ref => Scales the number of $core_number_ref cores used after each print "wait" statement {REF}
##         : $FILEHANDLE       => FILEHANDLE to print "wait" statment to

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $counter_ref;
    my $core_number_ref;
    my $core_counter_ref;
    my $FILEHANDLE;

    my $tmpl = {
	counter_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$counter_ref},
	core_number_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$core_number_ref},
	core_counter_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$core_counter_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ($$counter_ref == $$core_counter_ref * $$core_number_ref) {  #Using only nr of cores eq to lanes or core_processor_number

	say $FILEHANDLE "wait", "\n";
	$$core_counter_ref=$$core_counter_ref+1;  #Increase the maximum number of cores allowed to be used since "wait" was just printed
    }
}


sub check_build_download_prerequisites {

##check_build_download_prerequisites

##Function : Checks if some of the active prerequisites needs to be downloaded and calls subroutine to download them if required
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $infile_lane_no_ending_href, $job_id_href, $supported_cosmid_reference_href, $program_name, $family_id_ref
##         : $parameter_href                  => The parameter hash {REF}
##         : $active_parameter_href           => The active parameters for this analysis hash {REF}
##         : $sample_info_href                => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href      => The infile(s) without the ".ending" {REF}
##         : $job_id_href                     => The job_id hash {REF}
##         : $supported_cosmid_reference_href => The supported cosmid references hash {REF}
##         : $program_name                    => Active program
##         : $family_id_ref                   => The family_id_ref {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $supported_cosmid_reference_href;
    my $program_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	supported_cosmid_reference_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_cosmid_reference_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    for my $parameter_name (keys %$supported_cosmid_reference_href) {  #Supported cosmid references for MIP parameters

	if (defined($parameter_href->{$parameter_name}{associated_program})) {

	    if (! check_entry_hash_of_array({hash_ref => $parameter_href->{$parameter_name},
					     key => "associated_program",
					     element => "p".$program_name,
					    })
		) {  #If the cosmid supported parameter is associated with the MIP program

		if ( ($active_parameter_href->{"p".$program_name} == 1) && ($active_parameter_href->{dry_run_all} != 1) ) {  #Only enable autoDownload for active programs

		    if ($parameter_href->{$parameter_name}{build_file} eq 1) {  #Enable auto_build

			build_downloadable_prerequisites({parameter_href => $parameter_href,
							  active_parameter_href => $active_parameter_href,
							  sample_info_href => $sample_info_href,
							  infile_lane_no_ending_href => $infile_lane_no_ending_href,
							  job_id_href => $job_id_href,
							  supported_cosmid_reference_href => $supported_cosmid_reference_href,
							  program_name => $program_name,
							 });
			last;  #Perform once
		    }
		}
	    }
	}
    }
}


sub print_supported_annovar_table_names {

##print_supported_annovar_table_names

##Function : Print the by MIP supported annovar Table names to STDOUT and exists
##Returns  : ""
##Arguments: $active_parameter_href, $annovar_supported_table_names
##         : $active_parameter_href         => The active parameters for this analysis
##         : $annovar_supported_table_names => The supported annovar tables

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $annovar_supported_table_names_ref;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	annovar_supported_table_names_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$annovar_supported_table_names_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    if ($active_parameter_href->{log_file}) {

	$log->info("These annovar databases are supported by MIP:\n");

	foreach my $annovar_supported_table_name (@$annovar_supported_table_names_ref) {

	    $log->info($annovar_supported_table_name, "\n");
	}
    }
    else {

	say STDOUT "These annovar databases are supported by MIP:";

	foreach my $annovar_supported_table_name (@$annovar_supported_table_names_ref) {

	    say STDOUT $annovar_supported_table_name;
	}
    }
    exit;
}

sub check_entry_hash_of_array {

##check_entry_hash_of_array

##Function : Test element for being part of hash of array at supplied key.
##Returns  : Return "1" if element is not part of array
##Arguments: $hash_ref, $key, $element
##         : $hash_ref => Hash {REF}
##         : $key      => The key pointing to the array in the $hash_ref
##         : $element  => Element to look for in hash of array

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $hash_ref;
    my $key;
    my $element;

    my $tmpl = {
	hash_ref => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$hash_ref},
	key => { required => 1, defined => 1, strict_type => 1, store => \$key},
	element => { required => 1, defined => 1, strict_type => 1, store => \$element},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if (defined($$hash_ref{$key})) {  #Information on entry present

	if ( ! ( any {$_ eq $element} @{ $hash_ref->{$key} } ) ) {  #If element is not part of array

	    return 1;
	}
    }
}


sub check_most_complete_and_remove_file {

##check_most_complete_and_remove_file

##Function  : Checks if the file is recorded as the "most_complete_bam|vcf". If false writes removal of file(s) to supplied filehandle
##Returns   : ""
##Arguments : $FILEHANDLE, $file_path_ref, $file_ending, $most_complete_ref
##          : $FILEHANDLE        => SBATCH script FILEHANDLE to print to
##          : $file_path_ref     => Current file {REF}
##          : $file_ending       => File ending of $file_path_ref
##          : $most_complete_ref => The mostComplete file (BAM|VCF) {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $most_complete_ref;
    my $FILEHANDLE;
    my $file_path_ref;
    my $file_ending;

    my $tmpl = {
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	file_path_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$file_path_ref},
	file_ending => { required => 1, defined => 1, strict_type => 1, store => \$file_ending},
	most_complete_ref => { store => \$most_complete_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ( (defined($$most_complete_ref)) && (defined($$file_path_ref)) ) {  #Not to disturb first dry_run of analysis

	unless ($$most_complete_ref eq $$file_path_ref) {  #Do not remove mostCompleteBAM|VCF

	    ## Modify fileending of file to include e.g. .bai for bams
	    my $file_name = modify_file_ending({file_path_ref => $file_path_ref,
						file_ending => $file_ending,
					       });

	    ##Print removal of file to sbatch script
	    remove_file({file_ref => \$file_name,
			 FILEHANDLE => $FILEHANDLE,
			});
	    say $FILEHANDLE "\n";  #Remove file(s)
	}
    }
    else {

	## Modify fileending of file to include e.g. .bai for bams
	my $file_name = modify_file_ending({file_path_ref => $file_path_ref,
					    file_ending => $file_ending,
					   });

	##Print removal of file to sbatch script
	remove_file({file_ref => \$file_name,
		     FILEHANDLE => $FILEHANDLE,
		    });
	say $FILEHANDLE "\n";  #Remove file(s)
    }
}


sub modify_file_ending {

##modify_file_ending

##Function  : Modify fileending of file to include e.g. .bai for bams
##Returns   : ""
##Arguments : $file_path_ref, $file_ending
##          : $file_path_ref => Current file {REF}
##          : $file_ending   => File ending of $file_path_ref

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $file_path_ref;
    my $file_ending;

    my $tmpl = {
	file_path_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$file_path_ref},
	file_ending => { required => 1, defined => 1, strict_type => 1, store => \$file_ending},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Removes ".file_ending" in filename.FILENDING(.gz)
    my $file_name = remove_file_ending({file_name_ref => $file_path_ref,
					file_ending => $file_ending,
				       });

    if (defined($file_name)) {  #Successfully removed file ending using &remove_file_ending

	my $end = ".*";  #Remove all files with ending with ".*"

	if ($file_ending eq ".bam") {  #For BAM files

	    $end = ".ba*";  #Removes both .bam and .bai
	}
	if ($file_ending eq ".vcf") {  #For VCF files

	    $end = ".vcf*";  #Removes both .vcf and .vcf.idx
	}
	return $file_name.$end;
    }
    else {

	return $$file_path_ref;
    }
}


sub concatenate_vcfs {

##concatenate_vcfs

##Function : Concatenate VCFs
##Returns  : ""
##Arguments: $active_parameter_href, $FILEHANDLE, $arrays_ref, $infile_prefix, $infile_postfix, $outfile, $reorder_swith
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $FILEHANDLE            => SBATCH script FILEHANDLE to print to
##         : $arrays_ref            => Holding the number and part of file names to be combined
##         : $infile_prefix         => Will be combined with the each array element
##         : $infile_postfix        => Will be combined with the each array element
##         : $outfile               => The combined outfile
##         : $reorder_swith         => Reorder header

    my $active_parameter_href = $_[0];
    my $FILEHANDLE = $_[1];
    my $arrays_ref = $_[2];
    my $infile_prefix = $_[3];
    my $infile_postfix = $_[4];
    my $outfile = $_[5];
    my $reorder_swith = $_[6];

    unless (defined($infile_postfix)) {

	$infile_postfix = "";  #No postfix
    }
    unless (defined($outfile)) {

	$outfile = $infile_prefix.".vcf";
    }

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx4g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $active_parameter_href->{temp_directory},
	       java_jar => catfile($active_parameter_href->{snpeff_path}, "SnpSift.jar"),
	      });

    print $FILEHANDLE "split -j ";  #Joinf VCFs together

    foreach my $element (@$arrays_ref) {
	
	print $FILEHANDLE $infile_prefix.$element.$infile_postfix." ";  #files to combined
    }
    if ( (defined($_[6])) && $reorder_swith eq "reorder_header") {
	
	print $FILEHANDLE "| ";  #Pipe
	print $FILEHANDLE "perl ".catfile($active_parameter_href->{script_dir}, "vcfparser.pl")." ";  #Parses the vcf output
    }
    
    print $FILEHANDLE "> ".$outfile;  #OutFile
}


sub combinevariants {

##combinevariants

##Function : Writes sbatch code to supplied filehandle to combine variants in vcf format. Each array element is combined with the infilePre and Postfix.
##Returns  : ""
##Arguments: $active_parameter_href, $FILEHANDLE, $arrays_ref, $infile_prefix, $infile_postfix, $outfile
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $FILEHANDLE            => SBATCH script FILEHANDLE to print to
##         : $arrays_ref            => Holding the number and part of file names to be combined
##         : $infile_prefix         => Will be combined with the each array element
##         : $infile_postfix        => Will be combined with the each array element
##         : $outfile               => The combined outfile

    my $active_parameter_href = $_[0];
    my $FILEHANDLE = $_[1];
    my $arrays_ref = $_[2];
    my $infile_prefix = $_[3];
    my $infile_postfix = $_[4];
    my $outfile = $_[5];

    unless (defined($infile_postfix)) {

	$infile_postfix = "";  #No postfix
    }
    unless (defined($outfile)) {

	$outfile = $infile_prefix.".vcf";
    }
    say $FILEHANDLE "## GATK CombineVariants";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx4g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $active_parameter_href->{temp_directory},
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T CombineVariants ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$active_parameter_href->{human_genome_reference}." ";  #Reference file

    foreach my $element (@$arrays_ref) {

	print $FILEHANDLE "-V: ".$infile_prefix.$element.$infile_postfix." ";  #files to combined
    }
    print $FILEHANDLE "-genotypeMergeOptions UNSORTED ";  #Take the genotypes in any order. Should be fine since the same order and number of samples exists in all files

    say $FILEHANDLE "-o ".$outfile, "\n";  #OutFile
}


sub combinegvcfs {

##combinegvcfs

##Function : Writes sbatch code to supplied filehandle to combine variants in gvcf format. Each array element is combined with the infilePre and Postfix.
##Returns  : ""
##Arguments: $active_parameter_href, $FILEHANDLE, $arrays_ref, $infile_prefix, $infile_postfix, $outfile
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $FILEHANDLE            => SBATCH script FILEHANDLE to print to
##         : $arrays_ref            => Holding the number and part of file names to be combined
##         : $infile_prefix         => Will be combined with the each array element
##         : $infile_postfix        => Will be combined with the each array element
##         : $outfile               => The combined outfile

    my $active_parameter_href = $_[0];
    my $FILEHANDLE = $_[1];
    my $arrays_ref = $_[2];
    my $infile_prefix = $_[3];
    my $infile_postfix = $_[4];
    my $outfile = $_[5];

    unless (defined($infile_postfix)) {

	$infile_postfix = "";  #No postfix
    }
    unless (defined($outfile)) {

	$outfile = $infile_prefix.".vcf";
    }
    say $FILEHANDLE "## GATK CombineGVCFs";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx4g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $active_parameter_href->{temp_directory},
	       java_jar => catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar"),
	      });

    print $FILEHANDLE "-T CombineGVCFs ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{human_genome_reference})." ";  #Reference file

    foreach my $element (@$arrays_ref) {

	print $FILEHANDLE "-V: ".$infile_prefix.$element.$infile_postfix." ";  #files to combined
    }
    say $FILEHANDLE "-o ".$outfile, "\n";  #OutFile
}


sub concatenate_variants {

##concatenate_variants

##Function : Writes sbatch code to supplied filehandle to concatenate variants in vcf format. Each array element is combined with the infilePre and Postfix.
##Returns  : ""
##Arguments: $active_parameter_href, $FILEHANDLE, $elements_ref, $infile_prefix, $infile_postfix, $outfile, $human_genome_reference_ref
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $FILEHANDLE                 => SBATCH script FILEHANDLE to print to
##         : $elements_ref               => Holding the number and part of file names to be combined
##         : $infile_prefix              => Will be combined with the each array element
##         : $infile_postfix             => Will be combined with the each array element
##         : $outfile                    => The combined outfile
##         : $human_genome_reference_ref => Human genome reference {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $human_genome_reference_ref = $arg_href->{human_genome_reference_ref} //= \$arg_href->{active_parameter_href}{human_genome_reference};

    ## Flatten argument(s)
    my $active_parameter_href;
    my $elements_ref;
    my $FILEHANDLE;
    my $infile_prefix;
    my $infile_postfix;
    my $outfile;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	elements_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$elements_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	infile_prefix => { required => 1, defined => 1, strict_type => 1, store => \$infile_prefix},
	infile_postfix => { strict_type => 1, store => \$infile_postfix},
	outfile => { strict_type => 1, store => \$outfile},
	human_genome_reference_ref => { default => \$$, strict_type => 1, store => \$human_genome_reference_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    unless (defined($infile_postfix)) {

	$infile_postfix = "";  #No postfix
    }
    unless (defined($outfile)) {

	$outfile = $infile_prefix.".vcf";
    }

    say $FILEHANDLE "## GATK CatVariants";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx4g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $active_parameter_href->{temp_directory}
	      });

    print $FILEHANDLE "-cp ".catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar")." org.broadinstitute.gatk.tools.CatVariants ";  #Type of analysis to run
    print $FILEHANDLE "-l INFO ";  #Set the minimum level of logging
    print $FILEHANDLE "-R ".$$human_genome_reference_ref." ";  #Reference file
    print $FILEHANDLE "-assumeSorted ";  #assumeSorted should be true if the input files are already sorted

    foreach my $file_element (@$elements_ref) {

	print $FILEHANDLE "-V: ".$infile_prefix.$file_element.$infile_postfix." ";  #files to combined
    }
    say $FILEHANDLE "-out ".$outfile, "\n";  #OutFile
}


sub sort_vcf {

##sort_vcf

##Function : Writes sbatch code to supplied filehandle to sort variants in vcf format.
##Returns  : ""
##Arguments: $active_parameter_href, $FILEHANDLE, $sequence_dict_file, $infile, $outfile
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $FILEHANDLE            => SBATCH script FILEHANDLE to print to
##         : $sequence_dict_file    => Human reference sequence dict file
##         : $infile                => File to sort
##         : $outfile               => The sorted outfile

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $FILEHANDLE;
    my $sequence_dict_file;
    my $infile;
    my $outfile;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	sequence_dict_file => { required => 1, defined => 1, strict_type => 1, store => \$sequence_dict_file},
	infile => { required => 1, defined => 1, strict_type => 1, store => \$infile},
	outfile => { required => 1, defined => 1, strict_type => 1, store => \$outfile},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    say $FILEHANDLE "## Picard SortVcf";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx2g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $active_parameter_href->{temp_directory},
	       java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
	      });

    print $FILEHANDLE "SortVcf ";

    print $FILEHANDLE "INPUT=".$infile." ";  #File to sort
    print $FILEHANDLE "OUTPUT=".$outfile." ";  #OutFile
    say $FILEHANDLE "SEQUENCE_DICTIONARY=".$sequence_dict_file;
}


sub detect_sample_id_gender {

##detect_sample_id_gender

##Function : Detect gender of the current analysis
##Returns  : "$male_found $female_found $other_found"
##Arguments: $active_parameter_href, $sample_info_href
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $sample_info_href      => Info on samples and family hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_info_href;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $male_found = 0;
    my $female_found = 0;
    my $other_found = 0;

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	if ($sample_info_href->{sample}{$sample_id}{sex} =~/1|^male/) {  #Male

	    $male_found = 1;  #Male
	}
	elsif ($sample_info_href->{sample}{$sample_id}{sex} =~/2|female/) {  #Female

	    $female_found = 1;
	}
	else {  #Other

	    $male_found = 1;  #Include since it might be male to enable analysis of Y.
	    $other_found = 1;
	}
    }
    return $male_found, $female_found, $other_found;
}


sub remove_pedigree_elements {

##remove_pedigree_elements

##Function : Removes ALL keys at third level except keys in allowed_entries hash.
##Returns  : ""
##Arguments: $hash_ref
##         : $hash_ref => Hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $hash_ref;

    my $tmpl = {
	hash_ref => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$hash_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my @allowed_entries = ("family",
			   "default_gene_panels",
			   "sample",
			   "sample_id",
			   "sample_name",
			   "capture_kit",
			   "sex",
			   "mother",
			   "father",
			   "phenotype",
			   "sequence_type",
			   "expected_coverage",
	);

  FAMILY_INFO:
    for my $key (keys %$hash_ref) {
	
	if (! any {$_ eq $key} @allowed_entries) {  #If element is not part of array

		delete($hash_ref->{$key});
	}
    }

  SAMPLE:
    foreach my $sample_id (keys %{ $hash_ref->{sample} }) {

      SAMPLE_INFO:
	for my $pedigree_element (keys $hash_ref->{sample}{$sample_id})  {

	    if (! any {$_ eq $pedigree_element} @allowed_entries) {  #If element is not part of array

		delete($hash_ref->{sample}{$sample_id}{$pedigree_element});
	    }
	}
    }
}


sub write_use_large_pages {

##write_use_large_pages

##Function : Write useLargePages java flag to sbatch script if enabled
##Returns  : ""
##Arguments: $FILEHANDLE, $use_large_pages_ref
##         : $FILEHANDLE          => SBATCH script FILEHANDLE to print to
##         : $use_large_pages_ref => UseLargePages for requiring large memory pages (cross-platform flag) {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $FILEHANDLE;
    my $use_large_pages_ref;

    my $tmpl = {
	FILEHANDLE => { required => 1, store => \$FILEHANDLE},
	use_large_pages_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$use_large_pages_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ($$use_large_pages_ref) {

	print $FILEHANDLE "-XX:-UseLargePages ";  #UseLargePages for requiring large memory pages (cross-platform flag)
    }
}


sub deafult_log4perl_file {

##deafult_log4perl_file

##Function : Set the default Log4perl file using supplied dynamic parameters.
##Returns  : "$log_file"
##Arguments: $active_parameter_href, $cmd_input_ref, $script_ref, $date_ref, $date_time_stamp_ref, $family_id_ref, $outdata_dir_ref
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $cmd_input_ref         => User supplied info on cmd for log_file option {REF}
##         : $script_ref            => The script that is executed {REF}
##         : $date_ref              => The date {REF}
##         : $date_time_stamp_ref   => The date and time {REF}
##         : $family_id_ref         => The family_id {REF}
##         : $outdata_dir_ref       => Outdata directory {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $outdata_dir_ref = $arg_href->{outdata_dir_ref} //= \$arg_href->{active_parameter_href}{outdata_dir};

    ## Flatten argument(s)
    my $active_parameter_href;
    my $cmd_input_ref;
    my $script_ref;
    my $date_ref;
    my $date_time_stamp_ref;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	cmd_input_ref => { default => \$$, strict_type => 1, store => \$cmd_input_ref},
	script_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$script_ref},
	date_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$date_ref},
	date_time_stamp_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$date_time_stamp_ref},
	family_id_ref => { default => \$$, strict_type => 1},
	outdata_dir_ref => { default => \$$, strict_type => 1, store => \$outdata_dir_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    unless (defined($$cmd_input_ref)) {  #No input from cmd i.e. create default logging directory and set default

	make_path(catfile($$outdata_dir_ref, "mip_log", $$date_ref));
	my $log_file = catfile($$outdata_dir_ref, "mip_log", $$date_ref, $$script_ref."_".$$date_time_stamp_ref.".log");  #concatenates log filename
	return $log_file;
    }
}


sub check_human_genome_file_endings {

##check_human_genome_file_endings

##Function : Check the existance of associated Human genome files.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $file_info_href, $parameter_name_ref, $human_genome_reference_name_no_ending_ref, $reference_dir_ref,
##         : $parameter_href                            => The parameter hash {REF}
##         : $active_parameter_href                     => Holds all set parameter for analysis {REF}
##         : $file_info_href                            => The file_info hash {REF}
##         : $parameter_name_ref                        => The parameter under evaluation {REF}
##         : $human_genome_reference_name_no_ending_ref => The associated human genome file without file ending {REF}
##         : $reference_dir_ref                         => MIP reference directory {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $reference_dir_ref = $arg_href->{reference_dir_ref} //= \$arg_href->{active_parameter_href}{reference_dir};
    my $human_genome_reference_name_no_ending_ref = $arg_href->{human_genome_reference_name_no_ending_ref} //= \$arg_href->{file_info_href}{human_genome_reference_name_no_ending};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $file_info_href;
    my $parameter_name_ref;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	parameter_name_ref => { default => \$$, strict_type => 1, store => \$parameter_name_ref},
	reference_dir_ref => { default => \$$, strict_type => 1},
	human_genome_reference_name_no_ending_ref => { default => \$$, strict_type => 1},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    foreach my $file_ending (@{ $file_info_href->{human_genome_reference_file_endings} }) {

	my $path = catfile($active_parameter_href->{human_genome_reference});

	## Enable auto_build of metafiles
	$parameter_href->{$$parameter_name_ref.$file_ending}{build_file} = "yes_auto_build";

	if ($file_ending eq ".dict") {

	    ## Removes ".file_ending" in filename.FILENDING(.gz)
	    $path = remove_file_ending({file_name_ref => \$active_parameter_href->{human_genome_reference},
					file_ending => ".fasta",
				       });
	}

        $path = $path.$file_ending;  #Add current ending
	my $complete_parameter_name = $$parameter_name_ref.$file_ending;

	check_existance({parameter_href => $parameter_href,
			 active_parameter_href => $active_parameter_href,
			 item_name_ref => \$path,
			 parameter_name_ref => \$complete_parameter_name,
			 item_type_to_check => "file",
			});
    }
    if ($parameter_href->{$$parameter_name_ref.".dict"}{build_file} eq 0) {

	##Collect sequence contigs from human reference ".dict" file since it exists
	collect_seq_contigs({contigs_ref => \@{ $file_info_href->{contigs} },
			     reference_dir_ref => $reference_dir_ref,
			     human_genome_reference_name_no_ending_ref => $human_genome_reference_name_no_ending_ref,
			    });
    }
}


sub check_merge_picardtools_mergesamfiles_previous_bams {

##check_merge_picardtools_mergesamfiles_previous_bams

##Function : Checks if previous alignments have been supplied for each sample_id. Saves merge info in file_info hash.
##Returns  : ""
##Arguments: $active_parameter_href, $file_info_href
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $file_info_href        => The file_info hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $file_info_href;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

  SAMPLE_IDS:
    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	if (@{ $active_parameter_href->{picardtools_mergesamfiles_previous_bams} }) {  #Supplied info - check for which sample_id(s)

	  MERGE_FILES:
	    foreach my $bam_file (@{ $active_parameter_href->{picardtools_mergesamfiles_previous_bams} }) {

		if ($bam_file =~ /$sample_id/) {  #Look for sample_id in previously generated file to be merged with current run to be able to merge correct files

		    $file_info_href->{$sample_id}{picardtools_mergesamfiles_previous_bams} = 1;
		}
		else {

		    $file_info_href->{$sample_id}{picardtools_mergesamfiles_previous_bams} = 0;
		}
	    }
	}
	else {  #Not supplied - Set to 0

	    $file_info_href->{$sample_id}{picardtools_mergesamfiles_previous_bams} = 0;
	}
    }
}


sub create_fam_file {

##create_fam_file

##Function : Create .fam file to be used in variant calling analyses. Also checks if file already exists when using execution_mode=sbatch.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, sample_info_href, $pedigree_file, $execution_mode, $fam_file_path, $include_header, $FILEHANDLE, $family_id_ref
##         : $parameter_href        => Hash with paremters from yaml file {REF}
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $sample_info_href      => Info on samples and family hash {REF}
##         : $pedigree_file         => The supplied pedigree file to create the reduced ".fam" file from
##         : $execution_mode        => Either system (direct) or via sbatch
##         : $fam_file_path         => The family file path
##         : $include_header        => Wether to include header ("1") or not ("0")
##         : $FILEHANDLE            => Filehandle to write to {Optional unless execution_mode=sbatch}
##         : $family_id_ref         => The family_id {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $pedigree_file = $arg_href->{pedigree_file} //= $arg_href->{active_parameter_href}{pedigree_file};
    my $execution_mode;
    my $include_header;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $fam_file_path;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	fam_file_path => { required => 1, defined => 1, strict_type => 1, store => \$fam_file_path},
	FILEHANDLE => { store => \$FILEHANDLE},
	pedigree_file => { strict_type => 1, store => \$pedigree_file},
	execution_mode => { default => "sbatch",
			    allow => ["sbatch", "system"],
			    strict_type => 1, store => \$execution_mode},
	include_header => { default => 1,
			    allow => [0, 1],
			    strict_type => 1, store => \$include_header},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my @fam_headers = ("#family_id", "sample_id", "father", "mother", "sex", "phenotype");
    my @pedigree_lines;
    my $header;

    if ($include_header) {

	push(@pedigree_lines, join("\t", @fam_headers));
    }

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	my $sample_line = $$family_id_ref;

	foreach my $header (@fam_headers) {

	    if(defined($parameter_href->{dynamic_parameter}{$sample_id}{"plink_".$header})) {

		$sample_line .= "\t".$parameter_href->{dynamic_parameter}{$sample_id}{"plink_".$header};
	    }
	    elsif(defined($sample_info_href->{sample}{$sample_id}{$header})) {

		$sample_line .= "\t".$sample_info_href->{sample}{$sample_id}{$header};
	    }
	}
	push(@pedigree_lines, $sample_line);
    }
    if ($execution_mode eq "system") {  #Execute directly

	my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle
	open($FILEHANDLE, ">", $fam_file_path) or $log->logdie("Can't open '".$fam_file_path."': ".$!."\n");

	foreach my $line (@pedigree_lines) {

	    say $FILEHANDLE $line;
	}
	$log->info("Wrote: ".$fam_file_path, "\n");
	close($FILEHANDLE);
    }
    if ($execution_mode eq "sbatch") {

	unless (-f $fam_file_path) {  #Check to see if file already exists

	    if ($FILEHANDLE) {

		my $FILEHANDLE = $FILEHANDLE;

		say $FILEHANDLE "#Generating '.fam' file for use with GATK ","\n";
		print $FILEHANDLE "echo ";
		print $FILEHANDLE "-e ";  #Enable interpretation of i.e. \n
		print $FILEHANDLE q?-n "?;  #Do not output the trailing newline

		foreach my $line (@pedigree_lines) {

		    print $FILEHANDLE $line.q?\n?;
		}
		say $FILEHANDLE q?" ?." > ".$fam_file_path,"\n";
	    }
	    else {

		$log->fatal("Create fam file[subroutine]:Using 'execution_mode=sbatch' requires a filehandle to write to. Please supply filehandle to subroutine call.", "\n");
		exit 1;
	    }
	}
    }

    ## Add newly created family file to qc_sample_info
    $sample_info_href->{pedigree_minimal} = $fam_file_path;
}


sub check_annovar_tables {

##check_annovar_tables

##Function : Checks supported annovar Tables and that the supplied supported ones exists
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $annovar_table_href, $annovar_supported_table_names_ref
##         : $parameter_href                    => Holds all parameters
##         : $active_parameter_href             => Holds all set parameter for analysis
##         : $annovar_table_href                => annovar_table_href {REF}
##         : $annovar_supported_table_names_ref => The supported annovar reference names array {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $annovar_table_href;
    my $annovar_supported_table_names_ref;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	annovar_table_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$annovar_table_href},
	annovar_supported_table_names_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$annovar_supported_table_names_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $path;

    for (my $table_names_counter=0;$table_names_counter<scalar(@{ $active_parameter_href->{annovar_table_names} });$table_names_counter++) {  #All annovar_tables

	if (defined($annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] })) {  #Supported annovar database

	    if (defined($annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{file})) {

		for (my $files_counter=0;$files_counter<scalar(@{ $annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{file} });$files_counter++) {  #All annovar_table file(s), some tables have multiple files downloaded from the same call

		    $path = catfile($active_parameter_href->{annovar_path}, "humandb", $annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{file}[$files_counter]);
		    check_existance({parameter_href => $parameter_href,
				     active_parameter_href => $active_parameter_href,
				     item_name_ref => \$path,
				     parameter_name_ref => \$active_parameter_href->{annovar_table_names}[$table_names_counter],
				     item_type_to_check => "file",
				    });
		}
	    }
	    elsif (defined($annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{ucsc_alias})){

		$path = catfile($active_parameter_href->{annovar_path}, "humandb", $active_parameter_href->{annovar_genome_build_version}."_".$annovar_table_href->{ $active_parameter_href->{annovar_table_names}[$table_names_counter] }{ucsc_alias}.".txt");
		check_existance({parameter_href => $parameter_href,
				 active_parameter_href => $active_parameter_href,
				 item_name_ref => \$path,
				 parameter_name_ref => \$active_parameter_href->{annovar_table_names}[$table_names_counter],
				 item_type_to_check => "file",
				});
	    }
	    else {

		$path = catfile($active_parameter_href->{annovar_path}, "humandb", $active_parameter_href->{annovar_genome_build_version}."_".$active_parameter_href->{annovar_table_names}[$table_names_counter].".txt");
		check_existance({parameter_href => $parameter_href,
				 active_parameter_href => $active_parameter_href,
				 item_name_ref => \$path,
				 parameter_name_ref => \$active_parameter_href->{annovar_table_names}[$table_names_counter],
				 item_type_to_check => "file",
				});
	    }
	}
	else {  #annovar Table not supported by MIP

	    $log->error("You supplied annovar database: ".$active_parameter_href->{annovar_table_names}[$table_names_counter]." which is not supported by MIP. MIP can only process supported annovar databases\n");
	    print_supported_annovar_table_names({active_parameter_href => $active_parameter_href,
						 annovar_supported_table_names_ref => $annovar_supported_table_names_ref,
						});
	}
    }
}


sub collect_path_entries {

##collect_path_entries

##Function  : Collects all programs outfile path(s) created by MIP as Path->value located in %sample_info.
##Returns   : ""
##Arguments: $sample_info_href, $paths_ref
##         : $sample_info_href => Info on samples and family hash {REF}
##         : $paths_ref        => Holds the collected paths {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $sample_info_href;
    my $paths_ref;

    my $tmpl = {
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	paths_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$paths_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my %info = %$sample_info_href;  #Copy hash to enable recursive removal of keys

    my @outdirectories;  #Temporary array for collecting outDirectories within the same program
    my @outfileArray;  #Temporary array for collecting outfile within the same program

    while (my ($key, $value) = each %info) {

	if (ref($value) eq "HASH") {

	    collect_path_entries({sample_info_href => $value,
				  paths_ref => $paths_ref,
				 });
	}
	else {

	    if ($value) {  #Required for first dry-run

		## Check if key is "Path" and adds value to @paths_ref if true.
		check_and_add_to_array({paths_ref => $paths_ref,
					value => $value,
					key => $key,
				       });

		## Check if key is "OutDirectory" or "OutFile"  and adds joined value to @paths_ref if true.
		collect_outfile({paths_ref => $paths_ref,
				 outdirectories_ref => \@outdirectories,
				 outfiles_ref => \@outfileArray,
				 value => $value,
				 key => $key,
				});

		delete($info{$value});
	    }
	}
    }
}


sub check_and_add_to_array {

##check_and_add_to_array

##Function  : Check if KeyName is "Path" and adds to @paths_ref if true.
##Returns   : ""
##Arguments: $paths_ref, $value, $key
##         : $paths_ref => Holds the collected paths {REF}
##         : $value     => Hash value
##         : $keyName   => Hash key

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $paths_ref;
    my $value;
    my $key;

    my $tmpl = {
	paths_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$paths_ref},
	value => { required => 1, store => \$value},
	key => { required => 1, defined => 1, strict_type => 1, store => \$key},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ($key eq "path") {

	if (! ( any {$_ eq $value} @$paths_ref ) ) { #Do not add same path twice

	    push(@$paths_ref, $value);
	}
    }
}


sub collect_outfile {

##collect_outfile

##Function  : Check if KeyName is "OutDirectory" or "OutFile"  and adds to @paths_ref if true.
##Returns   : ""
##Arguments: $paths_ref, $outdirectories_ref, $outfiles_ref, $value, $key
##         : $paths_ref          => Holds the collected paths {REF}
##         : $outdirectories_ref => Holds temporary outdirectory path(s) {Optional, REF}
##         : $outfiles_ref       => Holds temporary outdirectory path(s) {Optional, REF}
##         : $value              => Hash value
##         : $key                => Hash key

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $paths_ref;
    my $outdirectories_ref;
    my $outfiles_ref;
    my $value;
    my $key;

    my $tmpl = {
	paths_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$paths_ref},
	outdirectories_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$outdirectories_ref},
	outfiles_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$outfiles_ref},
	value => { required => 1, defined => 1, store => \$value},
	key => { required => 1, defined => 1, strict_type => 1, store => \$key},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ($key eq "outdirectory") {

	push(@$outdirectories_ref, $value);
    }
    if ($key eq "outfile") {

	push(@$outfiles_ref, $value);
    }
    if ( (@$outdirectories_ref) && (@$outfiles_ref) ) {  #Both outdirectory and outfile have been collected, time to join

	my $path = catfile($outdirectories_ref->[0], $outfiles_ref->[0]);

	if (! ( any {$_ eq $path} @$paths_ref ) ) { #Do not add same path twice

	    push(@$paths_ref, catfile($outdirectories_ref->[0], $outfiles_ref->[0]));
	    @$outdirectories_ref = ();  #Restart
	    @$outfiles_ref = ();  #Restart
	}
    }
}


sub migrate_files_to_temp {

##migrate_files_to_temp

##Function : Copies files from source to temporary folder. Loop over files specified by $files_ref and collects files from $extract_files_ref.
##Returns  : ""
##Arguments: $active_parameter_href, $sample_info_href, $files_ref, $extract_files_ref, $FILEHANDLE, $insample_directory, $core_number, $file_ending, $sample_id, $family_id_ref
##         : $active_parameter_href => The active parameters for this analysis hash {REF},my $active_parameter_href = shift;
##         : $sample_info_href      => Info on samples and family hash {REF}
##         : $files_ref             => The array of files to copy
##         : $extract_files_ref     => The array to extract files from
##         : $FILEHANDLE            => Filehandle to write to
##         : $insample_directory    => The directory for the file to be copied
##         : $core_number           => The number of cores that can be used
##         : $file_ending           => File ending. Set to "" to not add any file ending or omit from call {Optional}
##         : $sample_id             => the sample_id {Optional}
##         : $family_id_ref         => The family_id_ref {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_info_href;
    my $files_ref;
    my $extract_files_ref;
    my $FILEHANDLE;
    my $insample_directory;
    my $core_number;
    my $file_ending;
    my $sample_id;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	files_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$files_ref},
	extract_files_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$extract_files_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	insample_directory => { required => 1, defined => 1, strict_type => 1, store => \$insample_directory},
	core_number => { required => 1, defined => 1, strict_type => 1, store => \$core_number},
	file_ending => { defined => 1, strict_type => 1, store => \$file_ending},
	sample_id => { defined => 1, strict_type => 1, store => \$sample_id},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $paired_end_tracker = 0;
    my $core_counter = 1;

    say $FILEHANDLE "## Copying file(s) to temporary directory";
    foreach my $file (@$files_ref) {

	my $sequence_run_mode;

	if ( (defined($sample_info_href)) && (defined($sample_id)) ) {

	    $sequence_run_mode = $sample_info_href->{sample}{$sample_id}{file}{$file}{sequence_run_type}; #Collect paired-end or single-end sequence run mode
	}
	print_wait({counter_ref => \$paired_end_tracker,
		    core_number_ref => \$core_number,
		    core_counter_ref => \$core_counter,
		    FILEHANDLE => $FILEHANDLE,
		   });

	## Copies file to temporary directory.
	migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			      path => catfile($insample_directory, $extract_files_ref->[$paired_end_tracker]),
			      temp_directory => $$temp_directory_ref,
			      file_ending => $file_ending,
			     });
	if ( (defined($sequence_run_mode)) && ($sequence_run_mode eq "paired_end") ) {

	    $paired_end_tracker = $paired_end_tracker+1; #Increment to collect correct read 2 from %infile

	    migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
				  path => catfile($insample_directory, $extract_files_ref->[$paired_end_tracker]),
				  temp_directory => $$temp_directory_ref,
				  file_ending => $file_ending,
				 });
	}
	$paired_end_tracker++; #Increment to correctly track both single-end runs and paired-end runs
    }
    say $FILEHANDLE "wait", "\n";
}

sub remove_files_at_temp {

##remove_files_at_temp

##Function : Removes files from at temporary folder. Loop over files specified by $files_ref and collects files from $extract_files_ref.
##Returns  : ""
##Arguments: $active_parameter_href, $sample_info_href, $file_info_href, $files_ref, $extract_files_ref, $FILEHANDLE, $insample_directory, $core_number, $infile_tag, $file_ending, $sample_id, $family_id_ref, $temp_directory_ref
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $sample_info_href      => Info on samples and family hash {Optional, REF}
##         : $file_info_href        => The file_info hash {Optional, REF}
##         : $files_ref             => The array of files to copy
##         : $extract_files_ref     => The array to extract files from
##         : $FILEHANDLE            => Filehandle to write t
##         : $insample_directory    => The directory for the file to be removed
##         : $core_number           => The number of cores that can be used
##         : $infile_tag            => The infile ending
##         : $file_ending           => File ending. Set to "" to not add any file ending or omit from call
##         : $sample_id             => the sample_id {Optional}
##         : $family_id_ref         => The family_id {REF}
##         : $temp_directory_ref    => The temporary directory {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $files_ref;
    my $extract_files_ref;
    my $FILEHANDLE;
    my $insample_directory;
    my $core_number;
    my $infile_tag;
    my $file_ending;
    my $sample_id;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { store => \$sample_info_href},
	file_info_href => { store => \$file_info_href},
	files_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$files_ref},
	extract_files_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$extract_files_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	insample_directory => { required => 1, defined => 1, strict_type => 1, store => \$insample_directory},
	core_number => { required => 1, defined => 1, strict_type => 1, store => \$core_number},
	infile_tag => { required => 1, defined => 1, strict_type => 1, store => \$infile_tag},
	file_ending => { required => 1, defined => 1, strict_type => 1, store => \$file_ending},
	sample_id => { strict_type => 1, store => \$sample_id},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $paired_end_tracker = 0;
    my $core_counter = 1;

    say $FILEHANDLE "## Removing file(s) at temporary directory";

    while (my ($file_index, $file) = each(@$files_ref) ) {  #For all files

	my $sequence_run_mode;

	if ( (defined($sample_info_href)) && (defined($sample_id)) ) {

	    $sequence_run_mode = $sample_info_href->{sample}{$sample_id}{file}{$file}{sequence_run_type};  #Collect paired-end or single-end sequence run mode
	}

	## Remove file(s) at temporary directory.
	if ($file_info_href) {  #Contigs

	    my $core_counter = 1;
	    while (my ($contig_index, $contig) = each(@{ $file_info_href->{contigs_size_ordered} }) ) {

		print_wait({counter_ref => \$contig_index,
			    core_number_ref => \$core_number,
			    core_counter_ref => \$core_counter,
			    FILEHANDLE => $FILEHANDLE,
			   });

		remove_file({file_ref => \catfile($$temp_directory_ref, $extract_files_ref->[$paired_end_tracker].$infile_tag."_".$contig.$file_ending),
			     FILEHANDLE => $FILEHANDLE,
			    });
		say $FILEHANDLE "& ";
	    }
	}
	else {

	    print_wait({counter_ref => \$file_index,
			core_number_ref => \$core_number,
			core_counter_ref => \$core_counter,
			FILEHANDLE => $FILEHANDLE,
		       });

	    ## Remove file(s) at temporary directory.
	    remove_file({file_ref => \catfile($$temp_directory_ref, $extract_files_ref->[$paired_end_tracker].$infile_tag.$file_ending),
			 FILEHANDLE => $FILEHANDLE,
			});
	    say $FILEHANDLE "& ";

	    if ( (defined($sequence_run_mode)) && ($sequence_run_mode eq "paired_end") ) {

		$paired_end_tracker = $paired_end_tracker+1;  #Increment to collect correct read 2

		## Remove file(s) at temporary directory.
		remove_file({file_ref => \catfile($$temp_directory_ref, $extract_files_ref->[$paired_end_tracker].$infile_tag.$file_ending),
			     FILEHANDLE => $FILEHANDLE,
			    });
		say $FILEHANDLE "& ";
	    }
	    $paired_end_tracker++;  #Increment to correctly track both single-end runs and paired-end runs
	}
    }
    say $FILEHANDLE "wait", "\n";
}


sub migrate_files_from_temp {

##migrate_files_from_temp

##Function : Copies files from temporary folder to source. Loop over files specified by $files_ref and collects files from $extract_files_ref.
##Returns  : ""
##Arguments: $files_ref, $extract_files_ref, $outsample_directory, $temp_directory, $core_number, $active_parameter_href, $sample_info_href, $sample_id, $FILEHANDLE
##         : $files_ref           => The array of files to copy
##         : $extract_files_ref   => The array to extract files from
##         : $outsample_directory => The directory for the file to be copied
##         : $temp_directory      => The node directory to copy to
##         : $file_ending         => The fileending to use for the outfile
##         : $core_number         => The number of cores that can be used
##         : $FILEHANDLE          => Filehandle to write to

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $files_ref;
    my $extract_files_ref;
    my $FILEHANDLE;
    my $outsample_directory;
    my $temp_directory;
    my $core_number;
    my $file_ending;

    my $tmpl = {
	files_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$files_ref},
	extract_files_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$extract_files_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	outsample_directory => { required => 1, defined => 1, strict_type => 1, store => \$outsample_directory},
	temp_directory => { required => 1, defined => 1, strict_type => 1, store => \$temp_directory},
	core_number => { required => 1, defined => 1, strict_type => 1, store => \$core_number},
	file_ending => { required => 1, defined => 1, strict_type => 1, store => \$file_ending},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_counter = 1;

    say $FILEHANDLE "## Copying file(s) from temporary folder";
    while (my ($file_index) = each($files_ref) ) {  #For all files

	print_wait({counter_ref => \$file_index,
		    core_number_ref => \$core_number,
		    core_counter_ref => \$core_counter,
		    FILEHANDLE => $FILEHANDLE,
		   });

	## Copies file from temporary directory.
	migrate_file_from_temp({temp_path => catfile($temp_directory, $extract_files_ref->[$file_index].$file_ending),
				file_path => $outsample_directory,
				FILEHANDLE => $FILEHANDLE,
			       });
    }
    say $FILEHANDLE "wait", "\n";
}

sub migrate_file_to_temp {

##migrate_file_to_temp

##Function : Copy file to temporary directory.
##Returns  : "$file_name"
##Arguments: $FILEHANDLE, $path, $temp_directory, $file_ending, $xargs, $xargs_file_name, $file_index,
##         : $FILEHANDLE      => Filehandle to write to
##         : $path            => The infile path
##         : $temp_directory  => The node directory to copy to
##         : $file_ending     => File ending {Optional}
##         : $xargs           => Use xargs if defined {Optional}
##         : $xargs_file_name => xargs file name {Optional, but required with xargs}
##         : $file_index      => Index of file elements that have been processed {Optional, but required with xargs}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $FILEHANDLE;
    my $path;
    my $temp_directory;
    my $file_ending;
    my $xargs;
    my $xargs_file_name;
    my $file_index;

    my $tmpl = {
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	path => { required => 1, defined => 1, strict_type => 1, store => \$path},
	temp_directory => { required => 1, defined => 1, strict_type => 1, store => \$temp_directory},
	file_ending => { strict_type => 1, store => \$file_ending},
	xargs => { strict_type => 1, store => \$xargs},
	xargs_file_name => { strict_type => 1, store => \$xargs_file_name},
	file_index => {strict_type => 1, store => \$file_index},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    ## Split relative path to file(s)
    my ($path_volume, $path_directory, $path_file_name) = File::Spec->splitpath($path);

    if (defined($file_ending)) {

	$path .= $file_ending;  #Add file_ending if supplied
    }

    unless (defined($xargs)) {

	print $FILEHANDLE "cp ";  #Copy
	print $FILEHANDLE "-p ";  #Preserve=mode,ownership,timestamps
    }

    print $FILEHANDLE $path." ";  #Infile
    print $FILEHANDLE $temp_directory." ";  #Temp file

    if (defined($xargs)) {

	if ( (defined($xargs_file_name)) && (defined($file_index))) {

	    print $FILEHANDLE "2> ".$xargs_file_name.".".$file_index.".stderr.txt ";
	}
	else {

	    $log->fatal("Lacking xargs_file_name or file_index in supplied arguments. Please supply arguments xargs_file_name and file_index if xargs is supplied");
	    exit 1;
	}
    }
    else {

	say $FILEHANDLE " & ";
    }
    print $FILEHANDLE "\n";

    return $path_file_name;
}


sub migrate_file_from_temp {

##migrate_file_from_temp

##Function : Copy file from temporary directory.
##Returns  : ""
##Arguments: $temp_path, $file_path, $FILEHANDLE, $xargs, $xargs_file_name, file_index
##         : $temp_path       => The node temp file path
##         : $file_path       => The node directory to copy to
##         : $FILEHANDLE      => Filehandle to write to
##         : $xargs           => Use xargs if defined {Optional}
##         : $xargs_file_name => xargs file name {Optional, but required with xargs}
##         : $file_index      => Index of file elements that have been processed {Optional, but required with xargs}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $temp_path;
    my $file_path;
    my $FILEHANDLE;
    my $xargs;
    my $xargs_file_name;
    my $file_index;

    my $tmpl = {
	temp_path => { required => 1, defined => 1, strict_type => 1, store => \$temp_path},
	file_path => { required => 1, defined => 1, strict_type => 1, store => \$file_path},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	xargs => { strict_type => 1, store => \$xargs},
	xargs_file_name => { strict_type => 1, store => \$xargs_file_name},
	file_index => {strict_type => 1, store => \$file_index},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    unless (defined($xargs)) {

	print $FILEHANDLE "cp ";  #Copy
	print $FILEHANDLE "-p ";  #Preserve=mode,ownership,timestamps
    }

    print $FILEHANDLE $temp_path." ";  #Infile
    print $FILEHANDLE $file_path." ";  #Local temp file

    if (defined($xargs)) {

	if ( (defined($xargs_file_name)) && (defined($file_index))) {

	    print $FILEHANDLE "2> ".$xargs_file_name.".".$file_index.".stderr.txt ";
	}
	else {

	    $log->fatal("Lacking xargs_file_name or file_index in supplied arguments. Please supply arguments xargs_file_name and file_index if xargs is supplied");
	    exit 1;
	}
    }
    else {

	say $FILEHANDLE "& ";
    }
    print $FILEHANDLE "\n";
}


sub remove_directory {

##remove_directory

##Function : Writes command to removes directory to filehandle.
##Returns  : ""
##Arguments: $directory_ref, $FILEHANDLE
##         : $directory_ref => the directory to remove
##         : $FILEHANDLE    => Filehandle to write to
##         : $options_ref   => Option to rm {Optional}

    my ($arg_href) = @_;

    ## Default(s)
    my $options_ref;

    ## Flatten argument(s)
    my $directory_ref;
    my $FILEHANDLE;

    my $tmpl = { 
	directory_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$directory_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	options_ref => { default => ["r", "f"],
			 allow => ["d", "f", "i", "P", "R", "r", "v", "W"],
			 strict_type => 1, store => \$options_ref},
    };
     
    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "rm ";  #Remove
    print $FILEHANDLE "-".join(" -", @$options_ref)." ";  #Options
    print $FILEHANDLE $$directory_ref." ";  #Directory to remove
}

sub remove_file {

##remove_file

##Function : Writes command to removes file to filehandle.
##Returns  : ""
##Arguments: $file_ref, $FILEHANDLE
##         : $file_ref    => the directory to remove
##         : $FILEHANDLE  => Filehandle to write to
##         : $options_ref => Option to rm {Optional}

    my ($arg_href) = @_;

    ## Default(s)
    my $options_ref;

    ## Flatten argument(s)
    my $file_ref;
    my $FILEHANDLE;

    my $tmpl = { 
	file_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$file_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	options_ref => { default => ["f"],
			 allow => ["d", "f", "i", "P", "R", "r", "v", "W"],
			 strict_type => 1, store => \$options_ref},
    };
     
    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "rm ";  #Remove
    print $FILEHANDLE "-".join(" -", @$options_ref)." ";  #Options
    print $FILEHANDLE $$file_ref." ";  #File to remove
}


sub remove_contig_file_at_temp_directory {

##remove_contig_file_at_temp_directory

##Function : Removes files at temporary directory dictated by supplied array.
##Returns  : ""
##Arguments: $files_ref, $FILEHANDLE, $core_number, $file_name, $file_ending, $temp_directory
##         : $files_ref      => Array to use for file iteration {REF}
##         : $FILEHANDLE     => Sbatch filehandle to write to
##         : $core_number    => The number of cores to use
##         : $file_name      => File name without ending attached
##         : $file_ending    => File ending
##         : $temp_directory => The temporary directory

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $files_ref;
    my $FILEHANDLE;
    my $core_number;
    my $file_name;
    my $file_ending;
    my $temp_directory;

    my $tmpl = {
	files_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$files_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	core_number => { required => 1, defined => 1, strict_type => 1, store => \$core_number},
	file_name => { required => 1, defined => 1, strict_type => 1, store => \$file_name},
	file_ending => { required => 1, defined => 1, strict_type => 1, store => \$file_ending},
	temp_directory => { required => 1, defined => 1, strict_type => 1, store => \$temp_directory},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_counter = 1;

    ## Remove infile at temporary Directory
    say $FILEHANDLE "## Remove file at temporary Directory";

    while (my ($file_index, $file) = each (@$files_ref) ) {

	print_wait({counter_ref => \$file_index,
		    core_number_ref => \$core_number,
		    core_counter_ref => \$core_counter,
		    FILEHANDLE => $FILEHANDLE,
		   });

	remove_file({file_ref => \catfile($temp_directory, $file_name."_".$file.$file_ending),
		     FILEHANDLE => $FILEHANDLE,
		    });
	say $FILEHANDLE "& ";
    }
    say $FILEHANDLE "wait", "\n";
}


sub java_core {

##java_core

##Function : Writes java core commands to filehandle.
##Returns  : ""
##Arguments: $FILEHANDLE, $memory_allocation, $java_use_large_pages_ref, $java_temporary_directory, $java_jar
##         : $FILEHANDLE               => Filehandle to write to
##         : $memory_allocation        => Memory allocation for java
##         : $java_use_large_pages_ref => Use java large pages {REF}
##         : $java_temporary_directory => Redirect tmp files to java temp {Optional}
##         : $java_jar                 => The JAR

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $FILEHANDLE;
    my $memory_allocation;
    my $java_use_large_pages_ref;
    my $java_temporary_directory;
    my $java_jar;

    my $tmpl = {
	FILEHANDLE => { required => 1, store => \$FILEHANDLE},
	memory_allocation => { required => 1, defined => 1, strict_type => 1, store => \$memory_allocation},
	java_use_large_pages_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$java_use_large_pages_ref},
	java_temporary_directory => { strict_type => 1, store => \$java_temporary_directory},
	java_jar => { strict_type => 1, store => \$java_jar},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "java ";
    print $FILEHANDLE "-".$memory_allocation." ";

    write_use_large_pages({FILEHANDLE => $FILEHANDLE,
			   use_large_pages_ref => $java_use_large_pages_ref,
			  });

    if (defined($java_temporary_directory)) {

	print $FILEHANDLE "-Djava.io.tmpdir=".$java_temporary_directory." ";  #Temporary Directory
    }
    if (defined($java_jar)) {

	print $FILEHANDLE "-jar ".$java_jar." ";
    }
}


sub check_email_address {

##check_email_address

##Function : Check the syntax of the email adress is valid not that it is actually exists.
##Returns  : ""
##Arguments: $email_ref
##         : $email_ref => The email adress

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $email_ref;

    my $tmpl = {
	email_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$email_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    $$email_ref =~ /[ |\t|\r|\n]*\"?([^\"]+\"?@[^ <>\t]+\.[^ <>\t][^ <>\t]+)[ |\t|\r|\n]*/;

    unless (defined($1)) {

	$log->fatal("The supplied email: ".$$email_ref." seem to be malformed. ", "\n");
	exit 1;
    }
}


sub break_string {

##break_string

##Function : Breaks the string supplied on format key1:value1_value2,keyN:valueN_valueN,..n . Add key to %file_info_href and values as array. This enables association of values to key supplied in config or cmd.
##Returns  : ""
##Arguments: $file_info_href, $parameter_value_ref, $parameter_name, $associated_program
##         : $file_info_href      => The file_info hash {REF}
##         : $parameter_value_ref => MIP parameter value {REF}
##         : $parameter_name      => MIP parameter name {REF}
##         : $associated_program  => The parameters program {REF}

    my $file_info_href = $_[0];
    my $parameter_value_ref = $_[1];
    my $parameter_name_ref = $_[2];
    my $associated_program_ref = $_[3];

    ## Break string into key value pairs
    my @file_keys = split(',', join(',', $$parameter_value_ref));

    foreach my $element (@file_keys) {

	my @temps = split(/:/, $element);
	@{ $file_info_href->{$$associated_program_ref}{$$parameter_name_ref}{$temps[0]} } = split('_', $temps[1]);  #Save info_key associated with file_name
    }
}


sub add_capture_kit {

##add_capture_kit

##Function : Return a capture kit depending on user info. If arg->{user_supplied_parameter_switchRef} is set, go a head and add capture kit no matter what the switch was.
##Returns  : "Set capture kit or ''"
##Arguments: $file_info_href, $supported_capture_kit_href, $capture_kit, $user_supplied_parameter_switch
##         : $file_info_href                 => The file info hash {REF}
##         : $supported_capture_kit_href     => The supported capture kits hash {REF}
##         : $capture_kit                    => The capture kit to add
##         : $user_supplied_parameter_switch => Has user supplied parameter {OPTIONAL}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $file_info_href;
    my $supported_capture_kit_href;
    my $capture_kit;
    my $user_supplied_parameter_switch;

    my $tmpl = {
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	supported_capture_kit_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_capture_kit_href},
	capture_kit => { strict_type => 1, store => \$capture_kit},
	user_supplied_parameter_switch => { strict_type => 1, store => \$user_supplied_parameter_switch},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    unless (defined($user_supplied_parameter_switch)) {  #No detected supplied capture kit

	if ( defined($supported_capture_kit_href->{$capture_kit}) ) {  #Supported capture kit alias

	    return  $supported_capture_kit_href->{$capture_kit};
	}
	else {  #Return unchanged capture_kit string

	    return $capture_kit;
	}
    }
    if ( (defined($user_supplied_parameter_switch)) && (! $user_supplied_parameter_switch) ) {  #Only add if user supplied no info on parameter

	if ( defined($supported_capture_kit_href->{$capture_kit}) ) {  #Supported capture kit alias

	    return  $supported_capture_kit_href->{$capture_kit};
	}
	else {  #Return unchanged capture_kit string

	    return $capture_kit;
	}
    }
}

sub gather_bam_files {

##gather_bam_files

##Function : Concatenates BAMs. Writes to sbatch FILEHANDLE
##Returns  : ""
##Arguments: $active_parameter_href, $elements_ref, $FILEHANDLE, $infile, $create_index, $temp_directory_ref
##         : $active_parameter_href => Holds all set parameter for analysis
##         : $elements_ref          => The array of splits to gather
##         : $FILEHANDLE            => Filehandle to write to
##         : $infile                => The infile
##         : $create_index          => Create index
##         : $temp_directory_ref    => The temporary directory {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $create_index = $arg_href->{create_index} //= "TRUE";

    ## Flatten argument(s)
    my $active_parameter_href;
    my $elements_ref;
    my $FILEHANDLE;
    my $infile;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	elements_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$elements_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	infile => { required => 1, defined => 1, strict_type => 1, store => \$infile},
	create_index => { default => "TRUE", strict_type => 1, store => \$create_index},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    say $FILEHANDLE "## gather_bam_files";

    ## Writes java core commands to filehandle.
    java_core({FILEHANDLE => $FILEHANDLE,
	       memory_allocation => "Xmx4g",
	       java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
	       java_temporary_directory => $$temp_directory_ref,
	       java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
	      });

    print $FILEHANDLE "GatherBamFiles ";
    print $FILEHANDLE "CREATE_INDEX=".$create_index." ";  #Create a BAM index when writing a coordinate-sorted BAM file.

    for (my $elementsCounter=0;$elementsCounter<scalar(@$elements_ref);$elementsCounter++) {

	print $FILEHANDLE "INPUT=".catfile($$temp_directory_ref, $infile."_".$elements_ref->[$elementsCounter].".bam")." ";
    }
    say $FILEHANDLE "OUTPUT=".catfile($$temp_directory_ref, $infile.".bam")." ";
}


sub xargs_migrate_contig_files {

##xargs_migrate_contig_files

##Function : Migrates file(s) to or from temporary directory (depending on supplied arguments) using xargs.
##Returns  : "xargs_file_counter"
##Arguments: $contigs_ref, $FILEHANDLE, $XARGSFILEHANDLE, $file_name, $temp_directory, $program_info_path, $infile, $indirectory, $outfile, $outdirectory, $core_number, $first_command, $xargs_file_counter, $file_ending
##         : $contigs_ref        => Contigs to iterate over {REF}
##         : $FILEHANDLE         => Sbatch filehandle to write to
##         : $XARGSFILEHANDLE    => XARGS filehandle to write to
##         : $file_name          => File name
##         : $temp_directory     => The temporary directory
##         : $program_info_path  => The program info path
##         : $infile             => Infile name without ending attached
##         : $indirectory        => In directory
##         : $outfile            => OutFile name without ending attached
##         : $outdirectory       => Out directory
##         : $core_number        => The number of cores to use
##         : $first_command      => The inital command
##         : $xargs_file_counter => The xargs file counter
##         : $file_ending        => File ending

    my ($arg_href) = @_;

    ## Default(s)
    my $first_command;
    my $file_ending;
    my $xargs_file_counter;
    my $core_number;

    ## Flatten argument(s)
    my $contigs_ref;
    my $FILEHANDLE;
    my $XARGSFILEHANDLE;
    my $file_name;
    my $temp_directory;
    my $program_info_path;
    my $infile;
    my $indirectory;
    my $outfile;
    my $outdirectory;

    my $tmpl = {
	contigs_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$contigs_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	XARGSFILEHANDLE => { required => 1, defined => 1, store => \$XARGSFILEHANDLE},
	file_name => { required => 1, defined => 1, strict_type => 1, store => \$file_name},
	temp_directory => { required => 1, defined => 1, strict_type => 1, store => \$temp_directory},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	infile => { strict_type => 1, store => \$infile},
	indirectory => { strict_type => 1, store => \$indirectory},
	outfile => { strict_type => 1, store => \$outfile},
	outdirectory => { strict_type => 1, store => \$outdirectory},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
	core_number => { default => 1,
			 allow => qr/^\d+$/,
			 strict_type => 1, store => \$core_number},
	first_command => { default => "cp -p",
			   strict_type => 1, store => \$first_command},
	file_ending => { default => ".vcf*",
			 strict_type => 1, store => \$file_ending},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $xargs_file_name;

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     xargs_file_counter => $xargs_file_counter,
							     first_command => $first_command,
							    });

    foreach my $contig (@$contigs_ref) {

	if (defined($infile)) {

	    ## Copy file(s) to temporary directory.
	    migrate_file_to_temp({FILEHANDLE => $XARGSFILEHANDLE,
				  path => catfile($indirectory, $infile."_".$contig.$file_ending),
				  temp_directory => $temp_directory,
				  xargs => "xargs",
				  xargs_file_name => $xargs_file_name,
				  file_index => $contig,
				 });
	}
	if ( (defined($outfile)) && (defined($outdirectory)) ) {

	    ## Copy file(s) from temporary directory.
	    migrate_file_from_temp({temp_path => catfile($temp_directory, $outfile."_".$contig.$file_ending),
				    file_path => $outdirectory,
				    FILEHANDLE => $XARGSFILEHANDLE,
				    xargs => "xargs",
				    xargs_file_name => $xargs_file_name,
				    file_index => $contig,
				   });
	}
    }
    return $xargs_file_counter;
}


sub xargs_command {

##xargs_command

##Function : Creates the command line for xargs. Writes to sbatch FILEHANDLE and opens xargs FILEHANDLE
##Returns  : "xargs_file_counter + 1, $xargs_file_name"
##Arguments: $FILEHANDLE, $XARGSFILEHANDLE, $file_name, $core_number, $first_command, $program_info_path, $memory_allocation, $java_use_large_pages_ref, $java_temporary_directory, $java_jar, $xargs_file_counter
##         : $FILEHANDLE               => Sbatch filehandle to write to
##         : $XARGSFILEHANDLE          => XARGS filehandle to write to
##         : $file_name                => File name
##         : $core_number              => The number of cores to use
##         : $first_command            => The inital command
##         : $program_info_path        => The program info path
##         : $memory_allocation        => Memory allocation for java
##         : $java_use_large_pages_ref => Use java large pages {REF}
##         : $java_temporary_directory => Redirect tmp files to java temp {Optional}
##         : $java_jar                 => The JAR
##         : $xargs_file_counter       => The xargs file counter

    my ($arg_href) = @_;

    ## Default(s)
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $FILEHANDLE;
    my $XARGSFILEHANDLE;
    my $file_name;
    my $core_number;
    my $first_command;
    my $program_info_path;
    my $memory_allocation;
    my $java_use_large_pages_ref;
    my $java_temporary_directory;
    my $java_jar;

    my $tmpl = {
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	XARGSFILEHANDLE => { required => 1, defined => 1, store => \$XARGSFILEHANDLE},
	file_name => { required => 1, defined => 1, strict_type => 1, store => \$file_name},
	core_number => { required => 1, defined => 1, strict_type => 1, store => \$core_number},
	first_command => { required => 1, defined => 1, strict_type => 1, store => \$first_command},
	program_info_path => { strict_type => 1, store => \$program_info_path},
	memory_allocation => { strict_type => 1, store => \$memory_allocation},
	java_use_large_pages_ref => { default => \$$, strict_type => 1, store => \$java_use_large_pages_ref},
	java_temporary_directory => { strict_type => 1, store => \$java_temporary_directory},
	java_jar => { strict_type => 1, store => \$java_jar},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my $xargs_file_name;

    ##Check if there is a xargs_file_name to concatenate
    if (defined($program_info_path)) {

	$xargs_file_name = $program_info_path.".".$xargs_file_counter;
    }

    print $FILEHANDLE "cat ".$file_name.".".$xargs_file_counter.".xargs ";  #Read xargs command file
    print $FILEHANDLE "| ";  #Pipe
    print $FILEHANDLE "xargs ";
    print $FILEHANDLE "-i ";  #replace-str; Enables us to tell xargs where to put the command file lines
    print $FILEHANDLE "--verbose ";  #Print the command line on the standard error output before executing it
    print $FILEHANDLE "-n1 ";  #Use at most max-args arguments per command line
    print $FILEHANDLE q?-P?.$core_number.q? ?;  #Run up to max-procs processes at a time
    print $FILEHANDLE q?sh -c "?;  #The string following this command will be interpreted as a shell command

    if ( $first_command eq "java") {

	## Writes java core commands to filehandle.
	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => $memory_allocation,
		   java_use_large_pages_ref => $java_use_large_pages_ref,
		   java_temporary_directory => $java_temporary_directory,
		   java_jar => $java_jar,
		  });
    }
    else {

	print $FILEHANDLE $first_command." ";
    }
    say $FILEHANDLE q? {} "?, "\n";  #Set placeholder
    open ($XARGSFILEHANDLE, ">",$file_name.".".$xargs_file_counter.".xargs") or $log->logdie("Can't write to '".$file_name.".".$xargs_file_counter.".xargs"."' :".$!."\n\n");  #Open XARGSFILEHANDLE
    return ( ($xargs_file_counter + 1), $xargs_file_name);  #Increment to not overwrite xargs file with next call (if used) and xargs_file_name stub
}


sub split_bam {

##split_bam

##Function : Split BAM file per contig and index new BAM. Creates the command line for xargs. Writes to sbatch FILEHANDLE and opens xargs FILEHANDLE
##Returns  : ""
##Arguments: $FILEHANDLE, $XARGSFILEHANDLE, $contigs_ref, $xargs_file_counter, $file_name, $program_info_path, $core_number, $first_command, $infile, $temp_directory_ref
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $FILEHANDLE            => Sbatch filehandle to write to
##         : $XARGSFILEHANDLE       => XARGS filehandle to write to
##         : $xargs_file_counter    => The xargs file counter
##         : $memory_allocation     => Memory allocation for ja
##         : $contigs_ref           => The contigs to process
##         : $file_name             => File name - ususally sbatch
##         : $program_info_path     => The program info path
##         : $core_number           => The number of cores to use
##         : $first_command         => The inital command
##         : $infile                => The infile
##         : $temp_directory_ref    => The temporary directory

    my ($arg_href) = @_;

    ## Default(s)
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $first_command;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $contigs_ref;
    my $FILEHANDLE;
    my $XARGSFILEHANDLE;
    my $file_name;
    my $program_info_path;
    my $core_number;
    my $infile;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	contigs_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$contigs_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	XARGSFILEHANDLE => { required => 1, defined => 1, store => \$XARGSFILEHANDLE},
	file_name => { required => 1, defined => 1, strict_type => 1, store => \$file_name},
	program_info_path => { required => 1, defined => 1, strict_type => 1, store => \$program_info_path},
	core_number => { required => 1, defined => 1, strict_type => 1, store => \$core_number},
	infile => { required => 1, defined => 1, strict_type => 1, store => \$infile},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
	first_command => { default => "samtools ",
			   strict_type => 1, store => \$first_command},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $xargs_file_name;

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     first_command => $first_command,
							     xargs_file_counter => $xargs_file_counter,
							    });

    ## Split by contig
    foreach my $contig (@$contigs_ref) {

	print $XARGSFILEHANDLE "view ";
	print $XARGSFILEHANDLE "-h "; #Include header
	print $XARGSFILEHANDLE "-b ";  #BAM output
	print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile.".bam")." ";  #InFile
	print $XARGSFILEHANDLE $contig." ";
	print $XARGSFILEHANDLE "> ".catfile($$temp_directory_ref, $infile."_".$contig.".bam")." ";  #Write to file
	print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	print $XARGSFILEHANDLE "; ";  #Wait

	## Writes java core commands to filehandle.
	java_core({FILEHANDLE => $XARGSFILEHANDLE,
		   memory_allocation => "Xmx4g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $$temp_directory_ref,
		   java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
		  });

	print $XARGSFILEHANDLE "BuildBamIndex ";
	print $XARGSFILEHANDLE "INPUT=".catfile($$temp_directory_ref, $infile."_".$contig.".bam")." ";  #InFile
	say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
    }
    return $xargs_file_counter;
}


sub split_bam_sambamba {

##split_bam_sambamba

##Function : Split BAM file per contig and index new BAM. Creates the command line for xargs. Writes to sbatch FILEHANDLE and opens xargs FILEHANDLE
##Returns  : ""
##Arguments: $active_parameter_href, $contigs_ref, $FILEHANDLE, $XARGSFILEHANDLE, $memory_allocation, $file_name, $program_info_path, $core_number, $infile, $temp_directory_ref, $xargs_file_counter, $first_command
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $contigs_ref           => The contigs to process
##         : $FILEHANDLE            => Sbatch filehandle to write to
##         : $XARGSFILEHANDLE       => XARGS filehandle to write to
##         : $memory_allocation     => Memory allocation for ja
##         : $file_name             => File name - ususally sbatch
##         : $program_info_path     => The program info path
##         : $core_number           => The number of cores to use
##         : $infile                => The infile
##         : $temp_directory_ref    => The temporary directory
##         : $xargs_file_counter    => The xargs file counter
##         : $first_command         => The inital command

    my ($arg_href) = @_;

    ## Default(s)
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $first_command;
    my $xargs_file_counter;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $contigs_ref;
    my $FILEHANDLE;
    my $XARGSFILEHANDLE;
    my $file_name;
    my $program_info_path;
    my $core_number;
    my $infile;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	contigs_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$contigs_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	XARGSFILEHANDLE => { required => 1, defined => 1, store => \$XARGSFILEHANDLE},
	file_name => { required => 1, defined => 1, strict_type => 1, store => \$file_name},
	program_info_path => { required => 1, defined => 1, strict_type => 1, store => \$program_info_path},
	core_number => { required => 1, defined => 1, strict_type => 1, store => \$core_number},
	infile => { required => 1, defined => 1, strict_type => 1, store => \$infile},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	xargs_file_counter => { default => 0,
				allow => qr/^\d+$/,
				strict_type => 1, store => \$xargs_file_counter},
	first_command => { default => "sambamba ",
			   strict_type => 1, store => \$first_command},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $xargs_file_name;

    ## Create file commands for xargs
    ($xargs_file_counter, $xargs_file_name) = xargs_command({FILEHANDLE => $FILEHANDLE,
							     XARGSFILEHANDLE => $XARGSFILEHANDLE,
							     file_name => $file_name,
							     program_info_path => $program_info_path,
							     core_number => $core_number,
							     first_command => $first_command,
							     xargs_file_counter => $xargs_file_counter,
							    });

    ## Split by contig
    foreach my $contig (@$contigs_ref) {

	print $XARGSFILEHANDLE "view ";  #Command
	print $XARGSFILEHANDLE "-h ";  #Include header
	print $XARGSFILEHANDLE "--format bam ";  #BAM output
	print $XARGSFILEHANDLE "--show-progress ";  #Show progress bar in STDERR
	print $XARGSFILEHANDLE "--output-filename=".catfile($$temp_directory_ref, $infile."_".$contig.".bam")." ";  #Write to file
	print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile.".bam")." ";  #InFile
	print $XARGSFILEHANDLE $contig." ";
	print $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	print $XARGSFILEHANDLE "; ";  #Wait

	## Index
	print $XARGSFILEHANDLE $first_command." ";  #Program
	print $XARGSFILEHANDLE "index ";  #Command
	print $XARGSFILEHANDLE "--show-progress ";  #Show progress bar in STDERR
	print $XARGSFILEHANDLE catfile($$temp_directory_ref, $infile."_".$contig.".bam")." ";  #InFile
	say $XARGSFILEHANDLE "2> ".$xargs_file_name.".".$contig.".stderr.txt ";  #Redirect xargs output to program specific stderr file
    }
    return $xargs_file_counter;
}


sub find_max_seq_length_for_sample_id {

##find_max_seq_length_for_sample_id

##Function : Finds the maximum sequence length of the reads for all sequencing file(s).
##Returns  : $max_sequence_length
##Arguments: $active_parameter_href, $sample_info_href, $infile_lane_no_ending_href, $sample_id_ref
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $sample_id_ref              => The sample_id {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href = $arg_href->{active_parameter_href};
    my $sample_info_href = $arg_href->{sample_info_href};
    my $infile_lane_no_ending_href = $arg_href->{infile_lane_no_ending_href};
    my $sample_id_ref = $arg_href->{sample_id_ref};

    my $max_sequence_length = 0;

    foreach my $infile (@{ $infile_lane_no_ending_href->{$$sample_id_ref} }) {  #For all infiles per lane

	my $seq_length = $sample_info_href->{sample}{$$sample_id_ref}{file}{$infile}{sequence_length};

	if ($seq_length > $max_sequence_length) {

	    $max_sequence_length = $seq_length;
	}
    }
    return $max_sequence_length;
}

sub set_contigs {

##set_contigs

##Function : Set contig prefix and contig names depending on reference used. Exclude mitochondrial contig if analysis_type is "wes".
##Returns  : ""
##Arguments: $active_parameter_href, $file_info_href
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $file_info_href        => The file info hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $file_info_href;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ($active_parameter_href->{human_genome_reference}=~/hg\d+/) {  #Refseq - prefix and M

	@{ $file_info_href->{contigs} } = ("chr1", "chr2", "chr3", "chr4", "chr5", "chr6", "chr7", "chr8", "chr9", "chr10", "chr11", "chr12", "chr13", "chr14", "chr15", "chr16", "chr17", "chr18", "chr19", "chr20", "chr21", "chr22", "chrX", "chrY", "chrM");  #Chr for filtering of bam file

	@{ $file_info_href->{contigs_size_ordered} } = ("chr1", "chr2", "chr3", "chr4", "chr5", "chr6", "chr7", "chrX", "chr8", "chr9", "chr10", "chr11", "chr12", "chr13", "chr14", "chr15", "chr16", "chr17", "chr18", "chr19", "chr20", "chr21", "chr22", "chrY", "chrM");  #Chr for filtering of bam file
    }
    elsif ($active_parameter_href->{human_genome_reference}=~/GRCh\d+/) {  #Ensembl - no prefix and MT

	@{ $file_info_href->{contigs} } = ("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "X", "Y", "MT");  #Chr for filtering of bam file

	@{ $file_info_href->{contigs_size_ordered} } = ("1", "2", "3", "4", "5", "6", "7", "X", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "Y", "MT");  #Chr for filtering of bam file
    }

    ## Detect if all samples has the same sequencing type and return consensus if reached
    my $consensus_analysis_type = detect_overall_analysis_type({analysis_type_hef => \%{ $active_parameter_href->{analysis_type} },
							       });
    if ($consensus_analysis_type eq "wes") {

	pop(@{ $file_info_href->{contigs} });  #Remove Mitochondrial contig
	pop(@{ $file_info_href->{contigs_size_ordered} });  #Remove Mitochondrial contig
    }
}


sub clear_trap {

##clear_trap

##Function : Clear trap for signal(s), e.g. in exome analysis since the might be no variants in MT or Y contigs. This will cause premature exit from sbatch
##Returns  : ""
##Arguments: $FILEHANDLE, $trap_signals_ref
##         : $FILEHANDLE       => The FILEHANDLE to write to
##         : $trap_signals_ref => Array with signals to clear trap for {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $trap_signals_ref = $arg_href->{trap_signals_ref} //= ["ERR"];

    ## Flatten argument(s)
    my $FILEHANDLE;

    my $tmpl = {
	FILEHANDLE => { required => 1, store => \$FILEHANDLE},
	trap_signals_ref => { default => [], strict_type => 1, store => \$trap_signals_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Clear trap for signal ERR
    say $FILEHANDLE "## Clear trap for signal(s) ".join(" ", @$trap_signals_ref);
    say $FILEHANDLE "trap - ".join(" ", @$trap_signals_ref);
    say $FILEHANDLE "trap", "\n";
}


sub enable_trap {

##enable_trap

##Function : Enable trap for signal(s).
##Returns  : ""
##Arguments: $trap_signals_ref, $trap_function, $FILEHANDLE
##         : $FILEHANDLE       => The FILEHANDLE to write to
##         : $trap_signals_ref => Array with signals to clear trap for {REF}
##         : $trap_function    => The trap function argument

    my ($arg_href) = @_;

    ## Default(s)
    my $trap_signals_ref = $arg_href->{trap_signals_ref} //= ["ERR"];
    my $trap_function = $arg_href->{trap_function} //= "error",

    ## Flatten argument(s)
    my $FILEHANDLE;

    my $tmpl = {
	FILEHANDLE => { required => 1, store => \$FILEHANDLE},
	trap_signals_ref => { default => [], strict_type => 1, store => \$trap_signals_ref},
	trap_function => { strict_type => 1, store => \$trap_function},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    say $FILEHANDLE "## Enable cleared trap for signal(s) ".join(" ", @$trap_signals_ref)." again";
    say $FILEHANDLE "trap ".$trap_function." ".join(" ", @$trap_signals_ref), "\n";
}


sub collect_gene_panels {

##collect_gene_panels

##Function : Collect databases(s) from a database file and adds them to sample_info
##Returns  : ""
##Arguments: $sample_info_href, $family_id_ref, $program_name_ref, $aggregate_gene_panel_file, $aggregate_gene_panels_key
##         : $sample_info_href          => Info on samples and family hash {REF}
##         : $family_id_ref             => The family ID {REF}
##         : $program_name_ref          => The program name {REF}
##         : $aggregate_gene_panel_file => The database file
##         : $aggregate_gene_panels_key => The database key i.e. select or range

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $sample_info_href;
    my $family_id_ref;
    my $program_name_ref;
    my $aggregate_gene_panel_file;
    my $aggregate_gene_panels_key;

    my $tmpl = {
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	family_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$family_id_ref},
	program_name_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$program_name_ref},
	aggregate_gene_panel_file => { required => 1, defined => 1, strict_type => 1, store => \$aggregate_gene_panel_file},
	aggregate_gene_panels_key => { required => 1, defined => 1, strict_type => 1, store => \$aggregate_gene_panels_key},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my %gene_panel;  #Collect each gene panel features
    my %header = (gene_panel => "gene_panel",
		  version => "version",
		  updated_at => "updated_at",
		  display_name => "display_name",
	);

    my $sub_database_regexp = q?perl -nae 'if ($_=~/^##gene_panel=/) {chomp($_);my @entries=split(/,/, $_); my $entry = join(",", $_); print $entry.":" } if($_=~/^#\w/) {last;}'?;
    my $ret = `$sub_database_regexp $aggregate_gene_panel_file`;  #Collect header_lines(s) from select_file header
    my @header_lines = split(/:/, $ret);  #Split each gene panel meta data header line into array element

  LINE:
    foreach my $line (@header_lines) {

	my @features = split(/,/, $line);  #Split each memember database line into features

      ELEMENT:
	foreach my $feature_element (@features) {

	    KEY_VALUE:
	    foreach my $gene_panel_header_element (keys %header) {  #Parse the features using defined header keys

		if ($feature_element=~/$gene_panel_header_element=/) {
		    
		    my @temps = split("=", $feature_element);
		    $gene_panel{ $header{$gene_panel_header_element} } = $temps[1];  #Value
		    last;
		}
	    }
	}

	if (defined($gene_panel{gene_panel})) {
	    
	    my $gene_panel_name = $gene_panel{gene_panel};  #Create unique gene panel ID

	    ## Add new entries
	    foreach my $feature (keys %gene_panel) {

		$sample_info_href->{$$program_name_ref}{$aggregate_gene_panels_key}{gene_panel}{$gene_panel_name}{$feature} = $gene_panel{$feature};
	    }
	}
	else {

	    $log->warn("Unable to write ".$aggregate_gene_panels_key." aggregate gene panel(s) to qc_sample_info. Lacking ##gene_panel=<ID=[?] or version=[?] in aggregate gene panel(s) header."."\n");
	}
	%gene_panel = ();  #Reset hash for next line
    }
}


sub add_most_complete_vcf {

##add_most_complete_vcf

##Function : Adds the most complete vcf file to sample_info
##Returns  : ""
##Arguments: $active_parameter_href, $sample_info_href, $path, $program_name, $family_id_ref, $vcfparser_outfile_counter
##         : $active_parameter_href     => The active parameters for this analysis hash {REF}
##         : $sample_info_href          => Info on samples and family hash {REF}
##         : $path                      => Path to file
##         : $program_name              => Program name
##         : $family_id_ref             => The family ID {REF}
##         : $vcfparser_outfile_counter => Number of outfile files from in vcfParser (select, range)

    my ($arg_href) = @_;

    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $vcfparser_outfile_counter;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_info_href;
    my $path;
    my $program_name;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	path => { required => 1, defined => 1, strict_type => 1, store => \$path},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	vcfparser_outfile_counter => { default => 0, strict_type => 1, store => \$vcfparser_outfile_counter},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ( ($active_parameter_href->{ "p".$program_name } == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	if ($vcfparser_outfile_counter == 1) {

	    $sample_info_href->{vcf_file}{clinical}{path} = $path;
	}
	else {

	    $sample_info_href->{vcf_file}{research}{path} = $path;
	}
    }
}


sub check_commandin_path {

##check_commandin_path

##Function : Checking commands in your path and executable
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href
##         : $parameter_href        => The parameter hash {REF}
##         : $active_parameter_href => The active parameters for this analysis hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my %seen;  #Track program paths that have already been checked

    foreach my $parameter_name (keys %$active_parameter_href) {

	if ( (exists($parameter_href->{$parameter_name}{type})) && ($parameter_href->{$parameter_name}{type} eq "program")) {

	    my $program_name_paths_ref = \@{ $parameter{$parameter_name}{program_name_path} };  #Alias

	    if ( (@$program_name_paths_ref) && ($active_parameter_href->{$parameter_name} > 0) ) {  #Only check path(s) for active programs

		foreach my $program (@{ $program_name_paths_ref }) {

		    unless($seen{$program}) {

			if(can_run($program)) {  #IPC::Cmd

			    $log->info("Program check: ".$program." installed\n");
			    $seen{$program} = 1;
			}
			else {

			    $log->fatal("Could not detect ".$program." in your Path\n");
			    exit 1;
			}
		    }
		}
	    }
	}
    }
}


sub update_sample_info_hash {

##update_sample_info_hash

##Function : Update sample_info with information from pedigree
##Returns  : ""
##Arguments: $sample_info_href, $temp_href, $family_id_ref
##         : $temp_href        => Allowed parameters from pedigre file hash {REF}
##         : $sample_info_href => Info on samples and family hash {REF}
##         : $family_id_ref    => The family ID {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $sample_info_href;
    my $temp_href;
    my $family_id_ref;

    my $tmpl = {
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	temp_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$temp_href},
	family_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    foreach my $sample_id (keys %{ $sample_info_href->{sample} }) {

	foreach my $key (keys $sample_info_href->{sample}{$sample_id}) {

	    if (exists($temp_href->{sample}{$sample_id}{$key})) {  #Previous run information, which should be updated using pedigree from current analysis

		$temp_href->{sample}{$sample_id}{$key} = delete($sample_info_href->{sample}{$sample_id}{$key});  #Required to update info
	    }
	    else {

		$temp_href->{sample}{$sample_id}{$key} = $sample_info_href->{sample}{$sample_id}{$key};
	    }
	}
    }
    %{$sample_info_href} = %$temp_href;  #Copy hash with updated keys from what was in sample_info (should be only pedigree %allowed_entries)
}


sub update_to_absolute_path {

##update_to_absolute_path

##Function : Change relative path to absolute path for certain parameter_names
##Returns  : ""
##Arguments: $parameter_href
##         : $parameter_href => The parameter hash {REF}

    my ($arg_href) = @_;

    ##Flatten argument(s)
    my $parameter_href;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Adds dynamic aggregate information from definitions to parameter hash
    add_to_parameter({parameter_href => \%parameter,
		      aggregates_ref => ["update_path:absolute_path"],  #Collect all path that should be made absolute
		     });

    foreach my $parameter_name (@{ $parameter_href->{dynamic_parameter}{absolute_path} }) {

	my $parameter_type = $parameter_href->{$parameter_name}{data_type};  #Alias

	if ($parameter_type eq "ARRAY") {  #Array reference

	    foreach my $parameter_value (@{ $parameter_href->{$parameter_name}{value} }) {

		if($parameter_value ne "nocmd_input") {

		    my $element_separator_ref = \$parameter_href->{$parameter_name}{element_separator};  #Alias - Find what seperates array
		    my @seperate_elements = split($$element_separator_ref, $parameter_value);  #Split into seperate elements if written in 1 string on cmd
		    my @absolute_path_elements;

		    foreach my $element (@seperate_elements) {

			## Find aboslute path for supplied path or croaks and exists if path does not exists
			push(@absolute_path_elements, find_absolute_path({path => $element,
									  parameter_name => $parameter_name,
									 }));
		    }
		    $parameter_value = join(",", @absolute_path_elements);  #Replace original input with abolute path entries
		}
	    }
	}
	elsif ($parameter_type eq "HASH") {  #Hash reference

	    my $parameter_value_ref = $parameter_href->{$parameter_name}{value};  #Alias

	    foreach my $key (keys %$parameter_value_ref) {  #Cannot use each since we are updating key

		if ( (defined($parameter_value_ref)) && ($parameter_value_ref->{$key} ne "nocmd_input") ) {

		    ## Find aboslute path for supplied path or croaks and exists if path does not exists
		    my $updated_key = find_absolute_path({path => $key,
							  parameter_name => $parameter_name,
							 });
		    $parameter_value_ref->{$updated_key} = delete($parameter_value_ref->{$key});
		}
	    }
	}
	elsif ($parameter_type eq "SCALAR") {  #Scalar - not a reference

	    my $parameter_value = $parameter_href->{$parameter_name}{value};  #Alias
	    	    
	    if ( (defined($parameter_value)) && ($parameter_value ne "nocmd_input") ) {  #Scalar
		
		## Find aboslute path for supplied path or croaks and exists if path does not exists
		$parameter_value = find_absolute_path({path => $parameter_value,
						       parameter_name => $parameter_name,
						      });
		$parameter_href->{$parameter_name}{value} = $parameter_value;
	    }
	}
    }
}


sub find_absolute_path {

##find_absolute_path

##Function : Find aboslute path for supplied path or croaks and exists if path does not exists
##Returns  : "$path - absolute path"
##Arguments: $path, $parameter_name
##         : $path           => The supplied path to be updated/evaluated
##         : $parameter_name => The parameter to be evaluated

    my ($arg_href) = @_;

    ##Flatten argument(s)
    my $path;
    my $parameter_name;

    my $tmpl = {
	path => { required => 1, defined => 1, store => \$path},
	parameter_name => { required => 1, defined => 1, strict_type => 1, store => \$parameter_name},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $tmp_path = $path;

    $path = abs_path($path);

    unless(defined($path)) {

	warn("Could not find absolute path for ".$parameter_name.": ".$tmp_path.". Please check the supplied path!\n");
	exit 1;
    }
    return $path;
}

sub order_parameter_names {

##order_parameter_names

##Function : Adds the order of first level keys from yaml file to array
##Returns  : ""
##Arguments: $order_parameters_ref
##         : $order_parameters_ref => The parameter array {REF}
##         : $file_path            => File path

    my ($arg_href) = @_;

    ##Flatten argument(s)
    my $order_parameters_ref;
    my $file_path;

    my $tmpl = {
	order_parameters_ref => { required => 1, default => [], strict_type => 1, store => \$order_parameters_ref},
	file_path => { required => 1, defined => 1, strict_type => 1, store => \$file_path},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    open(my $DFY, "<", $file_path) or die("Can't open '".$file_path."': ".$!."\n");

    while (<$DFY>) {

	chomp $_; #Remove new line

	if ( ($. == 1) && ($_=~/---/) ) { #Header

	    next;
	}
	if ( ($_!~/^#/) && ($_=~/^(\w+):/) ) { # First level key

	    my $parameter_name = $1;
	    push(@$order_parameters_ref, $parameter_name); #Add to enable later evaluation of parameters in proper order & write to MIP log file
	    next;
	}
    }
    close($DFY);
}

sub add_to_sampleInfo {

##add_to_sampleInfo

##Function : Adds parameter info to sample_info
##Returns  : ""
##Arguments: $active_parameter_href, $sample_info_href, $file_info_href, $family_id_ref
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $sample_info_href      => Info on samples and family hash {REF}
##         : $file_info_href        => The file_info hash {REF}
##         : $family_id_ref         => The family_id_ref {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $human_genome_reference_ref = $arg_href->{human_genome_reference_ref} //= \$arg_href->{active_parameter_href}{human_genome_reference};
    my $outdata_dir = $arg_href->{outdata_dir} //= $arg_href->{active_parameter_href}{outdata_dir};

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	human_genome_reference_ref => { default => \$$, strict_type => 1},
	outdata_dir => { strict_type => 1},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if (defined($active_parameter_href->{analysis_type})) {

	$sample_info_href->{analysis_type} = $active_parameter_href->{analysis_type};
    }
    if (defined($active_parameter_href->{expected_coverage})) {

	$sample_info_href->{expected_coverage} = $active_parameter_href->{expected_coverage};
    }
    if (defined($active_parameter_href->{gatk_path})) {

	if ($active_parameter_href->{gatk_path}=~/GenomeAnalysisTK-([^,]+)/) {

	    $sample_info_href->{program}{gatk}{version} = $1;
	}
	else {  #Fall back on actually calling program

	    my $jar_path = catfile($active_parameter_href->{gatk_path}, "GenomeAnalysisTK.jar");
	    my $ret = (`java -jar $jar_path --version 2>&1`);
	    chomp($ret);
	    $sample_info_href->{program}{gatk}{version} = $ret;
	}
    }
    if (defined($active_parameter_href->{picardtools_path})) {  #To enable addition of version to sample_info

	if ($active_parameter_href->{picardtools_path}=~/picard-tools-([^,]+)/) {

	    $sample_info_href->{program}{picardtools}{version} = $1;
	}
	else {  #Fall back on actually calling program

	    my $jar_path = catfile($active_parameter_href->{picardtools_path}, "picard.jar");
	    my $ret = (`java -jar $jar_path CreateSequenceDictionary --version 2>&1`);
	    chomp($ret);
	    $sample_info_href->{program}{picardtools}{version} = $ret;
	}
    }
    if ( ($active_parameter_href->{pbwa_mem} == 1) || ($active_parameter_href->{psambamba_depth} == 1) || ($active_parameter_href->{psambamba_markduplicates} == 1)) {  #To enable addition of version to sample_info as Sambamba does nit generate version tag in output

	if (! $active_parameter_href->{dry_run_all}) {

	    my $regexp = q?perl -nae 'if($_=~/sambamba\s(\S+)/) {print $1;last;}'?;
	    my $ret = (`sambamba 2>&1 | $regexp`);
	    chomp($ret);
	    $sample_info_href->{program}{sambamba}{version} = $ret;
	}
    }
    if (defined($active_parameter_href->{pcnvnator})) {  #To enable addition of version to sample_info

	if ( ($active_parameter_href->{pcnvnator} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    my $regexp = q?perl -nae 'if($_=~/CNVnator\s+(\S+)/) {print $1;last;}'?;
	    my $ret = (`cnvnator 2>&1 | $regexp`);
	    chomp($ret);
	    $sample_info_href->{program}{cnvnator}{version} = $ret;
	}
    }
    if (defined($$human_genome_reference_ref)) {  #To enable addition of version to sample_info

	$sample_info_href->{human_genome_build}{path} = $$human_genome_reference_ref;
	$sample_info_href->{human_genome_build}{source} = $file_info_href->{human_genome_reference_source};
	$sample_info_href->{human_genome_build}{version} = $file_info_href->{human_genome_reference_version};
    }
    if (defined($active_parameter_href->{pedigree_file}) ) {

	$sample_info_href->{pedigree_file}{path} = $active_parameter_href->{pedigree_file};  #Add pedigree_file to sample_info
	$sample_info_href->{pedigree_file_analysis}{path} = catfile($outdata_dir, $$family_id_ref, "qc_pedigree.yaml");  #Add pedigree_file info used in this analysis to SampleInfoFile
    }
    if (defined($active_parameter_href->{log_file})) {

	my $path = dirname(dirname($active_parameter_href->{log_file}));
	$sample_info_href->{log_file_dir} = $path;  #Add log_file_dir to SampleInfoFile
	$sample_info_href->{last_log_file_path} = $active_parameter_href->{log_file};
    }
}


sub eval_parameter_hash {

##eval_parameter_hash

##Function : Evaluate parameters in parameters hash
##Returns  : ""
##Arguments: $parameter_href, $file_path
##         : $parameter_href => Hash with paremters from yaml file {REF}
##         : $file_path      => Path to yaml file

    my ($arg_href) = @_;

    ##Flatten argument(s)
    my $parameter_href;
    my $file_path;

    my $tmpl = {
	parameter_href => { required => 1, default => {}, strict_type => 1, store => \$parameter_href},
	file_path => { required => 1, defined => 1, strict_type => 1, store => \$file_path},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my %mandatory_key;
    $mandatory_key{associated_program}{key_data_type} = "ARRAY";
    $mandatory_key{data_type}{key_data_type} = "SCALAR";
    $mandatory_key{data_type}{values} = ["SCALAR", "ARRAY", "HASH"];
    $mandatory_key{type}{key_data_type} = "SCALAR";
    $mandatory_key{type}{values} = ["mip", "path", "program", "program_argument"];

    my %non_mandatory_key;
    $non_mandatory_key{build_file}{key_data_type} = "SCALAR";
    $non_mandatory_key{build_file}{values} = ["no_auto_build", "yes_auto_build", "yes_auto_downLoad"];
    $non_mandatory_key{mandatory}{key_data_type} = "SCALAR";
    $non_mandatory_key{mandatory}{values} = ["no"];
    $non_mandatory_key{exists_check}{key_data_type} = "SCALAR";
    $non_mandatory_key{exists_check}{values} = ["file", "directory"];
    $non_mandatory_key{chain}{key_data_type} = "SCALAR";
    $non_mandatory_key{file_tag}{key_data_type} = "SCALAR";
    $non_mandatory_key{program_name_path}{key_data_type} = "ARRAY";
    $non_mandatory_key{element_separator}{key_data_type} = "SCALAR";
    $non_mandatory_key{reduce_io}{key_data_type} = "SCALAR";
    $non_mandatory_key{reduce_io}{values} = [1];
    $non_mandatory_key{program_type}{key_data_type} = "SCALAR";
    $non_mandatory_key{program_type}{values} = ["aligners", "variant_callers", "structural_variant_callers"];
    $non_mandatory_key{outdir_name}{key_data_type} = "SCALAR";
    $non_mandatory_key{file_endings}{key_data_type} = "ARRAY";
    $non_mandatory_key{remove_redundant_file}{key_data_type} = "SCALAR";
    $non_mandatory_key{remove_redundant_file}{values} = ["yes"];
    $non_mandatory_key{remove_redundant_file_setting}{key_data_type} = "SCALAR";
    $non_mandatory_key{remove_redundant_file_setting}{values} = ["single", "merged", "family", "variant_annotation"];
    $non_mandatory_key{reference}{key_data_type} = "SCALAR";
    $non_mandatory_key{reference}{values} = ["reference_dir"];

    check_keys({parameter_href => $parameter_href,
		mandatory_key_href => \%mandatory_key,
		non_mandatory_key_href => \%non_mandatory_key,
		file_path_ref => \$file_path,
	       });
}


sub check_keys {

##check_keys

##Function : Evaluate keys in hash
##Returns  : ""
##Arguments: $parameter_href, $mandatory_key_href, $non_mandatory_key_href, $file_path
##         : $parameter_href         => Hash with parameters from yaml file {REF}
##         : $mandatory_key_href     => Hash with mandatory key {REF}
##         : $non_mandatory_key_href => Hash with non mandatory key {REF}
##         : $file_path_ref          => Path to yaml file {REF}

    my ($arg_href) = @_;

    ##Flatten argument(s)
    my $parameter_href;
    my $mandatory_key_href;
    my $non_mandatory_key_href;
    my $file_path_ref;

    my $tmpl = {
	parameter_href => { required => 1, default => {}, strict_type => 1, store => \$parameter_href},
	mandatory_key_href => { required => 1, default => {}, strict_type => 1, store => \$mandatory_key_href},
	non_mandatory_key_href => { required => 1, default => {}, strict_type => 1, store => \$non_mandatory_key_href},
	file_path_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$file_path_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    foreach my $parameter (keys %$parameter_href) {

	foreach my $mandatory_key (keys %$mandatory_key_href) {

	    ## Mandatory key exists
	    if (exists($parameter_href->{$parameter}{$mandatory_key})) {

		## Check key data type
		check_data_type({parameter_href => $parameter_href,
				 key_href => $mandatory_key_href,
				 parameter => $parameter,
				 key => $mandatory_key,
				 file_path_ref => $file_path_ref,
				});
		## Evaluate key values
		check_values({parameter_href => $parameter_href,
			      key_href => $mandatory_key_href,
			      parameter => $parameter,
			      key => $mandatory_key,
			      file_path_ref => $file_path_ref,
			     });
	    }
	    else {

		warn("Missing mandatory key: '".$mandatory_key."' for parameter: '".$parameter."' in file: '".$$file_path_ref."'\n");
		exit 1;
	    }
	}
	foreach my $non_mandatory_key (keys %$non_mandatory_key_href) {

	    ## Non_mandatory key exists
	    if (exists($parameter_href->{$parameter}{$non_mandatory_key})) {

		## Check key data type
		check_data_type({parameter_href => $parameter_href,
				 key_href => $non_mandatory_key_href,
				 parameter => $parameter,
				 key => $non_mandatory_key,
				 file_path_ref => $file_path_ref,
				});

		## Evaluate key values
		check_values({parameter_href => $parameter_href,
			      key_href => $non_mandatory_key_href,
			      parameter => $parameter,
			      key => $non_mandatory_key,
			      file_path_ref => $file_path_ref,
			     });
	    }
	}
    }
}


sub check_values {

##check_values

##Function : Evaluate key values
##Returns  : ""
##Arguments: $parameter_href, $key_href, $key, $file_path_ref
##         : $parameter_href => Hash with parameters from yaml file {REF}
##         : $key_href       => Hash with  key {REF}
##         : $key            => Hash with non  key
##         : $file_path_ref  => Path to yaml file {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $key_href;
    my $parameter;
    my $key;
    my $file_path_ref;

    my $tmpl = {
	parameter_href => { required => 1, default => {}, strict_type => 1, store => \$parameter_href},
	key_href => { required => 1, default => {}, strict_type => 1, store => \$key_href},
	parameter => { required => 1, defined => 1, strict_type => 1, store => \$parameter},
	key => { required => 1, defined => 1, strict_type => 1, store => \$key},
	file_path_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$file_path_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Check value(s)
    if ($key_href->{$key}{values}) {

	my $value_ref = \$parameter_href->{$parameter}{$key};

	if ( ! (any {$_ eq $$value_ref} @{ $key_href->{$key}{values} }) ) {

	    warn("Found illegal value '".$$value_ref."' for parameter: '".$parameter."' in key: '".$key."' in file: '".$$file_path_ref."'\n");
	    warn("Allowed entries: '".join("', '", @{ $key_href->{$key}{values} })."'\n");
	    exit 1;
	}
    }
}


sub check_data_type {

##check_data_type

##Function : Check key data type
##Returns  : ""
##Arguments: $parameter_href, $key_href, $key, $file_path_ref
##         : $parameter_href => Hash with paremters from yaml file {REF}
##         : $key_href       => Hash with  key {REF}
##         : $key            => Hash with non  key
##         : $file_path_ref  => Path to yaml file {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $key_href;
    my $parameter;
    my $key;
    my $file_path_ref;

    my $tmpl = {
	parameter_href => { required => 1, default => {}, strict_type => 1, store => \$parameter_href},
	key_href => { required => 1, default => {}, strict_type => 1, store => \$key_href},
	parameter => { required => 1, defined => 1, strict_type => 1, store => \$parameter},
	key => { required => 1, defined => 1, strict_type => 1, store => \$key},
	file_path_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$file_path_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Check data_type
    my $data_type = ref($parameter_href->{$parameter}{$key});

    if ($data_type) {  #Array or hash

	## Wrong data_type
	unless ($data_type eq $key_href->{$key}{key_data_type}) {

	    warn("Found '".$data_type."' but expected datatype '".$key_href->{$key}{key_data_type}."' for parameter: '".$parameter."' in key: '".$key."' in file: '".$$file_path_ref."'\n");
	    exit 1;
	}
    }
    elsif ($key_href->{$key}{key_data_type} ne "SCALAR") {

	## Wrong data_type
	warn("Found 'SCALAR' but expected datatype '".$key_href->{$key}{key_data_type}."' for parameter: '".$parameter."' in key: '".$key."' in file: '".$$file_path_ref."'\n");
	exit 1;
    }
}


sub compare_hash_keys {

##compare_hash_keys

##Function : Compare keys in two hashes
##Returns  : ""
##Arguments: $reference_href, $comparison_href
##         : $reference_href  => Reference hash {REF}
##         : $comparison_href => Hash to be compared to reference {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $reference_href;
    my $comparison_href;

    my $tmpl = {
	reference_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$reference_href},
	comparison_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$comparison_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my @allowed_unique_keys = ("vcfparser_outfile_count", $reference_href->{family_id});
    my @unique;

    foreach my $key (keys %$reference_href) {

	unless (exists($comparison_href->{$key})) {

	    push(@unique, $key);
	}
    }
    foreach my $element (@unique) {

	if ( ! (any {$_ eq $element} @allowed_unique_keys) ) { #Do not print if allowed_unique_keys that have been created dynamically from previous runs

	    warn("Found illegal key: ".$element." in config file that is not defined in definitions.yaml\n");
	    exit 1;
	}
    }
}

sub check_vep_directories {

##check_vep_directories

##Function : Compare VEP directory and VEP chache versions
##Returns  : ""
##Arguments: $vep_directory_path_ref, $vep_directory_cache_ref
##         : $vep_directory_path_ref  => VEP directory path {REF}
##         : $vep_directory_cache_ref => VEP cache directory path {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $vep_directory_path_ref;
    my $vep_directory_cache_ref;

    my $tmpl = {
	vep_directory_path_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$vep_directory_path_ref},
	vep_directory_cache_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$vep_directory_cache_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    if ($$vep_directory_path_ref=~/ensembl-tools-release-(\d+)/) {

	my $vep_directory_path_version = $1;

	unless ($$vep_directory_cache_ref=~/ensembl-tools-release-$vep_directory_path_version/) {

	    print $log->fatal("Differing versions between '-vep_directory_path': ".$$vep_directory_path_ref." and '-vep_directory_cache': ".$$vep_directory_cache_ref, "\n");
	    exit 1;
	}
    }

}


sub vt_core {

##vt_core

##Function : Split multi allelic records into single records and normalize
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_lane_no_ending_href, $job_id_href, $infile_path, $outfile_path, $family_id, $FILEHANDLE, $core_number, $decompose, $normalize, $max_af, $calculate_af, $sed, $program, $program_directory, $bgzip, $tabix, $instream, $cmd_break, $xargs_file_name, $contig_ref
##         : $parameter_href             => Hash with paremters from yaml file {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $infile_path                => Infile path
##         : $outfile_path               => Outfile path
##         : $family_id                  => The family ID
##         : $FILEHANDLE                 => Filehandle to write to
##         : $core_number                => The number of cores to allocate
##         : $decompose                  => Vt program decomnpose for splitting multiallelic variants
##         : $normalize                  => Vt program normalize for normalizing to reference used in analysis
##         : $max_af                     => MIP script for adding MAX_AF to frequency reference used in analysis
##         : $calculate_af               => MIP script for adding AF_ to frequency reference used in analysis
##         : $sed                        => Sed program for changing vcf #FORMAT field in variant vcfs
##         : $program                    => The program name
##         : $program_directory          => Program directory to write to in sbatch script
##         : $bgzip                      => Compress output from vt using bgzip
##         : $tabix                      => Index compressed output using tabix
##         : $instream                   => Data to vt is supplied as a unix pipe
##         : $cmd_break                  => Command line separator ['"\n\n"'|";"]
##         : $xargs_file_name            => The xargs sbatch script file name {OPTIONAL}
##         : $contig_ref                 => The contig to extract {OPTIONAL, REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $human_genome_reference_ref = $arg_href->{human_genome_reference_ref} //= \$arg_href->{active_parameter_href}{human_genome_reference};
    my $outfile_path = $arg_href->{outfile_path} //= $arg_href->{infile_path};
    my $core_number;
    my $decompose;
    my $normalize;
    my $max_af;
    my $calculate_af;
    my $sed;
    my $program;
    my $program_directory;
    my $bgzip;
    my $tabix;
    my $instream;
    my $cmd_break;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $infile_path;
    my $FILEHANDLE;
    my $contig_ref;
    my $xargs_file_name;

    my $tmpl = {
	parameter_href => { default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { default => {}, strict_type => 1, store => \$job_id_href},
	infile_path => { required => 1, defined => 1, strict_type => 1, store => \$infile_path},
	FILEHANDLE => { store => \$FILEHANDLE},
	xargs_file_name => { strict_type => 1, store => \$xargs_file_name},
	contig_ref => { default => \$$, strict_type => 1, store => \$contig_ref},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	human_genome_reference_ref => { default => \$$, strict_type => 1},
	outfile_path => { strict_type => 1},
	core_number => { default => 1,
			 allow => qr/^\d+$/,
			 strict_type => 1, store => \$core_number},
	decompose => { default => 0,
		       allow => [0, 1],
		       strict_type => 1, store => \$decompose},
	normalize => { default => 0,
		       allow => [0, 1],
		       strict_type => 1, store => \$normalize},
	max_af => { default => 0,
		    allow => [0, 1],
		    strict_type => 1, store => \$max_af},
	calculate_af => { default => 0,
			  allow => [0, 1],
			  strict_type => 1, store => \$calculate_af},
	sed  => { default => 0,
		  allow => [0, 1],
		  strict_type => 1, store => \$sed},
	program => { default => "vt", strict_type => 1, store => \$program},
	program_directory => { default => "vt", strict_type => 1, store => \$program_directory},
	bgzip => { default => 0,
		   allow => [0, 1],
		   strict_type => 1, store => \$bgzip},
	tabix => { default => 0,
		   allow => [0, 1],
		   strict_type => 1, store => \$tabix},
	instream => { default => 0,
		      allow => [0, 1],
		      strict_type => 1, store => \$instream},
	cmd_break => { default => "\n\n", strict_type => 1, store => \$cmd_break},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $file_name;
    my $program_info_path;
    my $random_integer = int(rand(10000));  #Generate a random integer between 0-10,000.

    unless (defined($FILEHANDLE)){ #Run as individual sbatch script

	$FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

	## Creates program directories (info & programData & programScript), program script filenames and writes sbatch header
	($file_name, $program_info_path) = program_prerequisites({active_parameter_href => $active_parameter_href,
								  job_id_href => $job_id_href,
								  FILEHANDLE => $FILEHANDLE,
								  directory_id => $$family_id_ref,
								  program_name => $program,
								  program_directory => lc($program_directory),
								  core_number => $core_number,
								  process_time => 20,
								 });
    }

    ## Split multi allelic records into single records and normalize
    if ( ($active_parameter_href->{vt_decompose} > 0) || ($active_parameter_href->{vt_normalize} > 0) || (defined($active_parameter_href->{vt_genmod_filter_1000g})) || ($active_parameter_href->{psnpeff} > 0) ) {

	if ( ! $instream) {  #Use less to initate processing

	    say $FILEHANDLE "## vt - Decompose (split multi allelic records into single records) and/or normalize variants and/or add MAX_AF";
	    print $FILEHANDLE "less ";
	    print $FILEHANDLE $infile_path." ";  #Infile
	}
	if ($sed) {  #Replace #FORMAT field prior to smart decomposition (variant vcfs)

	    print $FILEHANDLE "| ";  #Pipe
	    print $FILEHANDLE q?sed 's/ID=AD,Number=./ID=AD,Number=R/' ?;
	}
	if ( ($active_parameter_href->{vt_decompose} > 0) && ($decompose) ) {

	    print $FILEHANDLE "| ";  #Pipe
	    print $FILEHANDLE "vt decompose ";  #Decomposes multiallelic variants into biallelic in a VCF file
	    print $FILEHANDLE "-s ";  #Smart decomposition
	    print $FILEHANDLE "- ";  #InStream

	    if ( (defined($xargs_file_name)) && (defined($$contig_ref)) ) {  #Write stderr for xargs process

		print $FILEHANDLE "2> ".$xargs_file_name.".".$$contig_ref.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    }
	}
	if ( ($active_parameter_href->{vt_normalize} > 0) && ($normalize) ) {  #Write stderr for xargs process

	    print $FILEHANDLE "| ";  #Pipe
	    print $FILEHANDLE "vt normalize ";  #Normalize variants in a VCF.The normalized variants are reordered and output in an ordered fashion
	    print $FILEHANDLE "-n ";  #Do not fail when REF is inconsistent with reference sequence for non SNPs
	    print $FILEHANDLE "-r ".$$human_genome_reference_ref." ";  #Reference file
	    print $FILEHANDLE "- ";  #InStream

	    if ( (defined($xargs_file_name)) && (defined($$contig_ref)) ) {  #Write stderr for xargs process

		print $FILEHANDLE "2>> ".$xargs_file_name.".".$$contig_ref.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    }
	}
	if ( ($active_parameter_href->{psnpeff} > 0) && ($calculate_af) ) {  #$calculate_af should not be set to 1 if reference was not part of snpeff parameter

	    print $FILEHANDLE "| ";  #Pipe
	    print $FILEHANDLE "perl ".catfile($Bin, "calculate_af.pl")." ";  #Add AF_
	    print $FILEHANDLE "- ";  #InStream

	    if ( (defined($xargs_file_name)) && (defined($$contig_ref)) ) {  #Write stderr for xargs process

		print $FILEHANDLE "2> ".$xargs_file_name.".".$$contig_ref.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    }
	}
	if ( (exists($active_parameter_href->{vt_genmod_filter_1000g})) && ($max_af) ) {

	    print $FILEHANDLE "| ";  #Pipe
	    print $FILEHANDLE "perl ".catfile($Bin, "max_af.pl")." ";  #Add MAX_AF
	    print $FILEHANDLE "- ";  #InStream

	    if ( (defined($xargs_file_name)) && (defined($$contig_ref)) ) {  #Write stderr for xargs process

		print $FILEHANDLE "2> ".$xargs_file_name.".".$$contig_ref.".stderr.txt ";  #Redirect xargs output to program specific stderr file
	    }
	}
	if ( (-e $infile_path.".tbi") || ($bgzip) ) {  #tabix has been/will be used on file, compress again

	    print $FILEHANDLE "| ";  #Pipe
	    print $FILEHANDLE "bgzip ";  #Compression algorithm
	    print $FILEHANDLE "-c ";  #Write on standard output, keep original files unchanged
	}
	print $FILEHANDLE "> ".$outfile_path."_splitted_".$random_integer." ";  #Temporary outfile
	print $FILEHANDLE $cmd_break;

	if ( (-e $infile_path.".tbi") || ($tabix) ) {  #tabix index

	    print $FILEHANDLE "tabix ";
	    print $FILEHANDLE "-p vcf ";  #Preset
	    print $FILEHANDLE "-f ";  #Force to overwrite the index
	    print $FILEHANDLE $outfile_path."_splitted_".$random_integer." ";  #Temporary outfile
	    print $FILEHANDLE $cmd_break;

	    ## Move index in place
	    print $FILEHANDLE "mv ";
	    print $FILEHANDLE $outfile_path."_splitted_".$random_integer.".tbi ";
	    print $FILEHANDLE $outfile_path.".tbi ";
	    print $FILEHANDLE $cmd_break;
	}

	## Move processed reference to original place
	print $FILEHANDLE "mv ";
	print $FILEHANDLE $outfile_path."_splitted_".$random_integer." ";
	print $FILEHANDLE $outfile_path." ";
	print $FILEHANDLE $cmd_break;
    }

    unless($arg_href->{FILEHANDLE}) {  #Unless FILEHANDLE was supplied close it and submit

	close($FILEHANDLE);

	if ( ($active_parameter_href->{"p".$program} == 1) && (! $active_parameter_href->{dry_run_all}) ) {

	    submit_job({active_parameter_href => $active_parameter_href,
			sample_info_href => $sample_info_href,
			infile_lane_no_ending_href => $infile_lane_no_ending_href,
			job_id_href => $job_id_href,
			dependencies => "no_dependency_add_to_case",
			path => $parameter_href->{"p".$program}{chain},
			sbatch_file_name => $file_name
		       });
	}
    }
}


sub check_vt_for_references {

##check_vt_for_references

##Function : Check if vt has processed references
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_lane_no_ending_href, $job_id_href, $vt_references_ref
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $vt_references_ref          => The references to check with vt {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $vt_decompose;
    my $vt_normalize;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $vt_references_ref;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	vt_references_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$vt_references_ref},
	vt_decompose => { default => 0,
			  allow => [0, 1],
			  strict_type => 1, store => \$vt_decompose},
	vt_normalize => { default => 0,
			  allow => [0, 1],
			  strict_type => 1, store => \$vt_normalize},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my %seen;  #Avoid checking the same reference multiple times

    if ( ($vt_decompose) || ($vt_normalize) ) {

	foreach my $parameter_name (@$vt_references_ref) {

	    if ($parameter_href->{$parameter_name}{data_type} eq "SCALAR") {

		my $annotation_file = catfile($active_parameter{$parameter_name});

		unless (exists($seen{$annotation_file})) {

		    ## Check if vt has processed references using regexp
		    check_vt({parameter_href => $parameter_href,
			      active_parameter_href =>$active_parameter_href,
			      sample_info_href => $sample_info_href,
			      infile_lane_no_ending_href => $infile_lane_no_ending_href,
			      job_id_href => $job_id_href,
			      reference_file_path => $annotation_file,
			      parameter_name => $parameter_name,
			     });
		}
		$seen{$annotation_file} = undef;
	    }
	    elsif ($parameter_href->{$parameter_name}{data_type} eq "ARRAY") {  #ARRAY reference

		foreach my $annotation_file (@{ $active_parameter_href->{$parameter_name} }) {

		    unless (exists($seen{$annotation_file})) {

			## Check if vt has processed references using regexp
			check_vt({parameter_href => $parameter_href,
				  active_parameter_href =>$active_parameter_href,
				  sample_info_href => $sample_info_href,
				  infile_lane_no_ending_href => $infile_lane_no_ending_href,
				  job_id_href => $job_id_href,
				  reference_file_path => $annotation_file,
				  parameter_name => $parameter_name,
				 });
		    }
		    $seen{$annotation_file} = undef;
		}
	    }
	    elsif ($parameter_href->{$parameter_name}{data_type} eq "HASH") {  #Hash reference

		for my $annotation_file (keys $active_parameter_href->{$parameter_name}) {

		    unless (exists($seen{$annotation_file})) {

			## Check if vt has processed references using regexp
			check_vt({parameter_href => $parameter_href,
				  active_parameter_href =>$active_parameter_href,
				  sample_info_href => $sample_info_href,
				  infile_lane_no_ending_href => $infile_lane_no_ending_href,
				  job_id_href => $job_id_href,
				  reference_file_path => $annotation_file,
				  parameter_name => $parameter_name,
				 });
		    }
		    $seen{$annotation_file} = undef;
		}
	    }
	}
    }
}


sub check_vt {

##check_vt

##Function : Check if vt has processed references using regexp
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $infile_lane_no_ending_href, $job_id_href, $reference_file_path, $parameter_name
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $job_id_href                => The job_id hash {REF}
##         : $reference_file_path        => The reference file path
##         : $parameter_name             => The MIP parameter_name

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $infile_lane_no_ending_href;
    my $job_id_href;
    my $reference_file_path;
    my $parameter_name;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	job_id_href => { default => {}, strict_type => 1, store => \$job_id_href},
	reference_file_path => { required => 1, defined => 1, strict_type => 1, store => \$reference_file_path},
	parameter_name => { required => 1, defined => 1, strict_type => 1, store => \$parameter_name},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my %vt_regexp;

    $vt_regexp{decompose}{vt_decompose}{vcf_key} = "OLD_MULTIALLELIC";
    $vt_regexp{normalize}{vt_normalize}{vcf_key} = "OLD_VARIANT";
    $vt_regexp{max_af}{vt_genmod_filter}{vcf_key} = "MAX_AF";
    $vt_regexp{calulate_af}{vt_genmod_filter}{vcf_key} = "calculateAF";

    $vt_regexp{decompose}{vt_decompose}{switch} = 0;
    $vt_regexp{normalize}{vt_normalize}{switch} = 0;
    $vt_regexp{max_af}{vt_genmod_filter}{switch} = 0;
    $vt_regexp{calulate_af}{vt_genmod_filter}{switch} = 0;

    my @max_af_references = (q?ALL.wgs.phase\d+.\S+.vcf?, q?ExAC.r\d+.\d+.sites.vep.vcf?);
    my @calulate_af_references = (q?ExAC.r\d+.\d+.sites.vep.vcf?);

    if (-e $reference_file_path) {  #Downloaded and vt later (for downloadable references otherwise file existens error is thrown downstream)

	foreach my $vt_program (keys %vt_regexp) {

	    foreach my $associated_program (@{ $parameter_href->{$parameter_name}{associated_program} }) {

		if ($active_parameter_href->{$associated_program} > 0) {  #Active or dry run for associated program

		    foreach my $vt_parameter_name (keys $vt_regexp{$vt_program}) {  #MIP flags

			my $regexp = q?perl -nae 'if($_=~/ID\=?.$vt_regexp{$vt_program}{$vt_parameter_name}{vcf_key}.q?/) {print $_} if($_=~/#CHROM/) {last}'?;
			my $ret = `less $reference_file_path | $regexp`; #Detect if vt program has processed reference

			unless ($ret) {  #No tracks of vt processing found

			    if ( ($vt_program eq "decompose") || ($vt_program eq "normalize") ){

				$vt_regexp{$vt_program}{$vt_parameter_name}{switch} = 1;
				$log->warn("Cannot detect that ".$vt_program." has processed reference: ".$reference_file_path."\n");
			    }
			    if ( ($vt_program eq "maxAF") && (any {$reference_file_path=~/$_/} @max_af_references) ) {

				$vt_regexp{$vt_program}{$vt_parameter_name}{switch} = 1;
				$log->warn("Cannot detect that ".$vt_program." has processed reference: ".$reference_file_path."\n");
			    }
			    if ( ($vt_program eq "calulate_af") && (any {$reference_file_path=~/$_/} @calulate_af_references) ) {

				$vt_regexp{$vt_program}{$vt_parameter_name}{switch} = 1;
				$log->warn("Cannot detect that ".$vt_program." has processed reference: ".$reference_file_path."\n");
			    }
			}
			else {  #Found vt processing track

			    $log->info("Reference check: ".$reference_file_path." vt:".$vt_program." - PASS\n");
			}
		    }
		    last;  #No need to test the same reference over and over
		}
	    }
	}
	foreach my $vt_program (keys %vt_regexp) {

	    foreach my $vt_parameter_name (keys $vt_regexp{$vt_program}) {  #MIP flags

		if ($vt_regexp{$vt_program}{$vt_parameter_name}{switch}) {

		    ## Split multi allelic records into single records and normalize
		    vt_core({parameter_href => $parameter_href,
			     active_parameter_href => $active_parameter_href,
			     sample_info_href => $sample_info_href,
			     infile_lane_no_ending_href => $infile_lane_no_ending_href,
			     job_id_href => $job_id_href,
			     infile_path => $reference_file_path,
			     program_directory => "vt",
			     decompose => $vt_regexp{decompose}{vt_decompose}{switch},
			     normalize => $vt_regexp{normalize}{vt_normalize}{switch},
			     max_af => $vt_regexp{max_af}{vt_genmod_filter}{switch},
			     calculate_af => $vt_regexp{calulate_af}{vt_genmod_filter}{switch},
			    });

		    if ( ($vt_program eq "decompose") || ($vt_program eq "normalize") ){

			## Update switch to avoid modifying same reference twice
			$vt_regexp{decompose}{vt_decompose}{switch} = 0;
			$vt_regexp{normalize}{vt_normalize}{switch} = 0;
		    }
		}
	    }
	}
    }
}


sub bgzip {

##bgzip

##Function : Compress or decompress original file or stream to outfile (if supplied)
##Returns  : ""
##Arguments: $infile_path, $outfile_path, $compress
##         : $infile_path  => In file path
##         : $outfile_path => Out file path
##         : $compress     => Compress file
##         : $FILEHANDLE   => Filehandle to write to

    my ($arg_href) = @_;

    ## Default(s)
    my $compress;

    ## Flatten argument(s)
    my $infile_path;
    my $outfile_path;
    my $FILEHANDLE;

    my $tmpl = {
	infile_path => { required => 1, defined => 1, strict_type => 1, store => \$infile_path},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	outfile_path => { strict_type => 1, store => \$outfile_path},
	compress => { default => 1,
		      allow => [0, 1],
		      strict_type => 1, store => \$compress},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "bgzip ";

    if ( ($compress) && defined($outfile_path) ) {  #Compress and stream

	print $FILEHANDLE "-c ";

	if ($infile_path ne "-") {  #Bgzip will assume stream

	    print $FILEHANDLE $infile_path." ";
	}
	print $FILEHANDLE "> ".$outfile_path." ";
    }
    elsif ($compress) {  #Compress original file

	print $FILEHANDLE $infile_path." ";
    }
    elsif ( (! $compress) && defined($outfile_path) ){  #Decompress and stream

	print $FILEHANDLE "-d ";
	print $FILEHANDLE "-c ";
	print $FILEHANDLE $infile_path." ";
	print $FILEHANDLE "> ".$outfile_path." ";
    }
    else {  #Decompress original file

	print $FILEHANDLE "-d ";
	print $FILEHANDLE $infile_path." ";
    }
}

sub tabix {

##tabix

##Function : Index file using tabix
##Returns  : ""
##Arguments: $infile_path, $preset, $FILEHANDLE
##         : $infile_path => Infile path
##         : $preset      => Preset, file format
##         : $FILEHANDLE  => Filehandle to write to

    my ($arg_href) = @_;

    ## Default(s)
    my $preset;

    ## Flatten argument(s)
    my $infile_path;
    my $FILEHANDLE;

    my $tmpl = {
	infile_path => { required => 1, defined => 1, strict_type => 1, store => \$infile_path},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	preset => { default => "vcf", strict_type => 1, store => \$preset},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "tabix ";
    print $FILEHANDLE "-p ".$preset." ";  #Preset
    print $FILEHANDLE "-f ";  #Force to overwrite the index
    print $FILEHANDLE $infile_path." ";  #Temporary outfile
}


sub remove_files {

##remove_files

##Function : Removes intermediate files from the MIP analysis depending on set MIP parameters
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $lane_href, $infile_lane_no_ending_href, $program_name, $reduce_io_ref, $sample_id, $insample_directory, $FILEHANDLE, family_id_ref, $outaligner_dir_ref, $call_type
##         : $parameter_href             => The parameter hash {REF}
##         : $active_parameter_href      => The active parameters for this analysis hash {REF}
##         : $sample_info_href           => Info on samples and family hash {REF}
##         : $file_info_href             => The file_info hash {REF}
##         : $lane_href                  => The lane info hash {REF}
##         : $infile_lane_no_ending_href => The infile(s) without the ".ending" {REF}
##         : $program_name               => The program name
##         : $reduce_io_ref              => Reduce IO - modulates processBlocks {REF}
##         : $sample_id                  => The sample_id
##         : $insample_directory         => The directory for in sample files to be removed
##         : $FILEHANDLE                 => Filehandle to write to
##         : $family_id_ref              => The family_id {REF}
##         : $outaligner_dir_ref         => The outaligner_dir used in the analysis {REF}
##         : $call_type                  => The variant call type

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};
    my $call_type;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $lane_href;
    my $infile_lane_no_ending_href;
    my $program_name;
    my $reduce_io_ref;
    my $sample_id;
    my $insample_directory;
    my $FILEHANDLE;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	lane_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$lane_href},
	infile_lane_no_ending_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$infile_lane_no_ending_href},
	program_name => { required => 1, defined => 1, strict_type => 1, store => \$program_name},
	reduce_io_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$reduce_io_ref},
	sample_id => { strict_type => 1, store => \$sample_id},
	insample_directory => { strict_type => 1, store => \$insample_directory},
	FILEHANDLE => { store => \$FILEHANDLE},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1, store => \$outaligner_dir_ref},
	call_type => { default => "BOTH", strict_type => 1, store => \$call_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $vcfparser_contigs_ref = \@{ $file_info_href->{contigs_size_ordered} };  #Set default

    ## Last modules in each processing block that should have the output data deleted
    my $last_module_bamcalibrationblock = "pgatk_haplotypecaller";
    my $last_module_variantannotationblock = "psnpeff";

    foreach my $program (@{ $parameter_href->{dynamic_parameter}{program} }) {

	if ($active_parameter_href->{$program} > 0) {

	    if ( (defined($parameter_href->{$program}{remove_redundant_file}))
		 && ($parameter_href->{$program}{remove_redundant_file} eq "yes")) {

		if (defined($sample_id)) {

		    my $indirectory =  $parameter_href->{$program}{$sample_id}{indirectory};
		    my $outfile_tag = $file_info_href->{$sample_id}{$program}{file_tag};

		    ## Single files
		    if ($parameter_href->{$program}{remove_redundant_file_setting} eq "single") {  #Infiles for prior to potential merge

		      INFILE:
			foreach my $infile (@{ $infile_lane_no_ending_href->{$sample_id} }) {

			  FILE_ENDINGS:
			    foreach my $file_ending (@{ $parameter_href->{$program}{file_endings} }) {

				my $file_path;

				if (defined($outfile_tag)) {

				    $file_path = catfile($indirectory, $infile.$outfile_tag.$file_ending);
				}
				else {

				    $file_path = catfile($indirectory, $infile.$file_ending);
				}

				my $most_complete_ref;

				if ($file_ending=~/vcf|bam/) {

				    ## Detect which most_complete_path to use depending on file_ending
				    $most_complete_ref = detect_most_complete_file({sample_info_href => $sample_info_href,
										    file_ending_ref => \$file_ending,
										    sample_id_ref => \$sample_id,
										    family_id_ref => $family_id_ref,
										   });
				}
				## Checks if the file is recorded as the "most_complete_bam|vcf". If false writes removal of file(s) to supplied filehandle
				check_most_complete_and_remove_file({FILEHANDLE => $FILEHANDLE,
								     most_complete_ref => $most_complete_ref,
								     file_path_ref => \$file_path,
								     file_ending => $file_ending,
								    });
			    }
			}
		    }
		    ## Merged files
		    if ($parameter_href->{$program}{remove_redundant_file_setting} eq "merged") {  #Merge infiles

			## Add merged infile name after merging all BAM files per sample_id
			my $infile = $file_info_href->{$sample_id}{merge_infile};  #Alias

			if ( ( ! $$reduce_io_ref) || ($program eq $last_module_bamcalibrationblock) ) {  #Delete intermediate files or last module in processBlock

			  FILE_ENDINGS:
			    foreach my $file_ending (@{ $parameter_href->{$program}{file_endings} }) {

			      CONTIGS:
				foreach my $contig (@$vcfparser_contigs_ref) {

				    my $file_path = catfile($indirectory, $infile.$outfile_tag."_".$contig.$file_ending);

				    ## Detect which most_complete_path to use depending on file_ending
				    my $most_complete_ref = detect_most_complete_file({sample_info_href => $sample_info_href,
										       file_ending_ref => \$file_ending,
										       sample_id_ref => \$sample_id,
										       family_id_ref => \$active_parameter_href->{family_id},
										      });

				    ## Checks if the file is recorded as the "most_complete_bam|vcf". If false writes removal of file(s) to supplied filehandle
				    check_most_complete_and_remove_file({FILEHANDLE => $FILEHANDLE,
									 most_complete_ref => $most_complete_ref,
									 file_path_ref => \$file_path,
									 file_ending => $file_ending,
									});
				}
			    }
			}
		    }
		}
		else {  #Otherwise these files would be removed for every sample_id

		    my $indirectory =  $parameter_href->{$program}{indirectory};
		    my $outfile_tag = $file_info_href->{$$family_id_ref}{$program}{file_tag};

		    ## Family files
		    if ($parameter_href->{$program}{remove_redundant_file_setting} eq "family") {

		      FILE_ENDINGS:
			foreach my $file_ending (@{ $parameter_href->{$program}{file_endings} }) {

			    my $file_path = catfile($indirectory, $$family_id_ref.$outfile_tag.$call_type."*".$file_ending);

			    ## Detect which most_complete_path to use depending on file_ending
			    my $most_complete_ref = detect_most_complete_file({sample_info_href => $sample_info_href,
									       file_ending_ref => \$file_ending,
									       family_id_ref => \$active_parameter_href->{family_id},
									      });

			    ## Checks if the file is recorded as the "most_complete_bam|vcf". If false writes removal of file(s) to supplied filehandle
			    check_most_complete_and_remove_file({FILEHANDLE => $FILEHANDLE,
								 most_complete_ref => $most_complete_ref,
								 file_path_ref => \$file_path,
								 file_ending => $file_ending,
								});
			}
		    }
		    elsif ($parameter_href->{$program}{remove_redundant_file_setting} eq "variant_annotation") {

			if ( ( ! $$reduce_io_ref) || ($program eq $last_module_variantannotationblock) ) {  #Delete intermediate files or last module in processBlock

			    $outfile_tag = $file_info_href->{$$family_id_ref}{$program}{file_tag};

			    foreach my $file_ending (@{ $parameter_href->{$program}{file_endings} }) {

				my $file_path = catfile($indirectory, $$family_id_ref.$outfile_tag.$call_type."*".$file_ending);

				## Detect which most_complete_path to use depending on file_ending
				my $most_complete_ref = detect_most_complete_file({sample_info_href => $sample_info_href,
										   file_ending_ref => \$file_ending,
										   family_id_ref => \$active_parameter_href->{family_id},
										  });

				## Checks if the file is recorded as the "most_complete_bam|vcf". If false writes removal of file(s) to supplied filehandle
				check_most_complete_and_remove_file({FILEHANDLE => $FILEHANDLE,
								     most_complete_ref => $most_complete_ref,
								     file_path_ref => \$file_path,
								     file_ending => $file_ending,
								    });
			    }
			}
		    }
		}
	    }
	}
    }
}


sub detect_most_complete_file {

##detect_most_complete_file

##Function : Detect which most_complete_path to use depending on file_ending
##Returns  : ""
##Arguments: $active_parameter_href, $file_ending_ref, $sample_id_ref
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $file_ending_ref       => FileEnding (.file_ending){REF}
##         : $sample_id_ref         => Sample ID {REF}
##         : $family_id_ref         => Family ID {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $family_id_ref = $arg_href->{family_id_ref} //= \$arg_href->{active_parameter_href}{family_id};

    ## Flatten argument(s)
    my $sample_info_href;
    my $file_ending_ref;
    my $sample_id_ref;

    my $tmpl = {
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_ending_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$file_ending_ref},
	sample_id_ref => { store => \$sample_id_ref},
	family_id_ref => { default => \$$, strict_type => 1, store => \$family_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Set mostcompletePaths
    my $most_complete_bam_ref;
    my $most_complete_vcf_ref =  \$sample_info_href->{vcf_file}{ready_vcf}{path};

    if (defined($$sample_id_ref)) {

	$most_complete_bam_ref = \$sample_info_href->{sample}{$$sample_id_ref}{most_complete_bam}{path};
    }

    ## Decide which mostcompletePaths to use
    if ($$file_ending_ref eq ".bam") {

	return $most_complete_bam_ref;
    }
    if ($$file_ending_ref eq ".vcf") {

	return $most_complete_vcf_ref;
    }
}


sub remove_array_element {

##remove_array_element

##Function : Removes contigs from supplied contigs_ref
##Returns  : ""
##Arguments: $contigs_ref, $remove_contigs_ref
##         : $contigs_ref        => The select file contigs {REF}
##         : $remove_contigs_ref => Remove this contig

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $contigs_ref;
    my $remove_contigs_ref;

    my $tmpl = {
	contigs_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$contigs_ref},
	remove_contigs_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$remove_contigs_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    for (my $index=0;$index<scalar(@$contigs_ref);$index++) {

	foreach my $remove_contig (@$remove_contigs_ref) {

	    if( ($contigs_ref->[$index] eq $remove_contig) || ($contigs_ref->[$index] eq "chr".$remove_contig) ) {

		splice(@$contigs_ref, $index, 1);  #Remove $element from array
	    }
	}
    }
}


sub detect_founders {

##detect_founders

##Function : Detect number of founders (i.e. parents ) based on pedigree file
##Returns  : ""|1
##Arguments: $active_parameter_href,
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $sample_info_href      => Info on samples and family hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_info_href;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my @founders;

    foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	my $father_info = $sample_info_href->{sample}{$sample_id}{father};  #Alias
	my $mother_info = $sample_info_href->{sample}{$sample_id}{mother};  #Alias

	if ( (defined($father_info)) && ($father_info ne 0) ) {  #Child

	    if (any {$_ eq $father_info} @{ $active_parameter_href->{sample_ids} }) {  #If element is part of array

		push(@founders, $father_info);
	    }
	}
	if ( (defined($mother_info)) && ($mother_info ne 0) ) {  #Child

	    if (any {$_ eq $mother_info} @{ $active_parameter_href->{sample_ids} } ) {  #If element is part of array

		push(@founders, $mother_info);
	    }
	}
    }
    return scalar(@founders);
}


sub detect_trio {

##detect_trio

##Function : Detect family constellation based on pedigree file
##Returns  : ""|1
##Arguments: $active_parameter_href, $sample_info_href
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $sample_info_href      => Info on samples and family hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_info_href;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my %trio;

    if (scalar(@{ $active_parameter_href->{sample_ids} }) eq 1) {

	$log->info("Found single sample: ".$active_parameter_href->{sample_ids}[0], "\n");
	return
    }
    elsif (scalar(@{ $active_parameter_href->{sample_ids} }) eq 3) {

	foreach my $sample_id (@{ $active_parameter_href->{sample_ids} }) {

	    my $father_info = $sample_info_href->{sample}{$sample_id}{father};  #Alias
	    my $mother_info = $sample_info_href->{sample}{$sample_id}{mother};  #Alias

	    if ( ($father_info ne 0) && ($mother_info ne 0) ) {  #Child

		$trio{child} = $sample_id;

		if (any {$_ eq $father_info} @{ $active_parameter_href->{sample_ids} }) {  #If element is part of array

		    $trio{father} = $father_info;
		}
		if (any {$_ eq $mother_info} @{ $active_parameter_href->{sample_ids} } ) {  #If element is part of array

		    $trio{mother} = $mother_info;
		}
	    }
	}
	if (scalar(keys %trio) == 3) {

	    $log->info("Found trio: Child = ".$trio{child}.", Father = ".$trio{father}.", Mother = ".$trio{mother}, "\n");
	    return 1
	}
    }
}


sub check_string {

##check_string

##Function : Detect "regexp" in string
##Returns  : ""|1
##Arguments: $string
##         : $string => String to be searched
##         : $regexp => regexp to use on string

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $string;
    my $regexp;

    my $tmpl = {
	string => { required => 1, defined => 1, strict_type => 1, store => \$string},
	regexp => { required => 1, defined => 1, strict_type => 1, store => \$regexp},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ($string=~/$regexp/) {

	return 1
    }
}


sub add_to_parameter {

##add_to_parameter

##Function : Adds dynamic aggregate information from definitions to parameter hash
##Returns  : ""
##Arguments: $parameter_href, $aggregates_ref
##         : $parameter_href => The parameter hash {REF}
##         : $aggregates_ref => The data to aggregate and add to parameter hash{REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $aggregates_ref;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	aggregates_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$aggregates_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    foreach my $key (keys %$parameter_href) {

	foreach my $aggregate_element (@$aggregates_ref) {

	    my @tmps = split(":", $aggregate_element);
	    my $second_key = $tmps[0];
	    my $string_to_match = $tmps[1];

	    if ( (defined($parameter_href->{$key}{$second_key})) && ($parameter_href->{$key}{$second_key} eq $string_to_match) ) {

		push(@{ $parameter_href->{dynamic_parameter}{$string_to_match} }, $key);
	    }
	}
    }
}


sub check_prioritize_variant_callers {

##check_prioritize_variant_callers

##Function : Check that all active variant callers have a prioritization order and that the prioritization elements match a supported variant caller.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href
##         : $parameter_href        => The parameter hash {REF}
##         : $active_parameter_href => The active parameters for this analysis hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my @priority_calls = split(",", $active_parameter_href->{gatk_combinevariants_prioritize_caller});
    my @variant_caller_aliases;  #No matching variant caller

    ## Check that all active variant callers have a priority order
    foreach my $variant_caller (@{ $parameter_href->{dynamic_parameter}{variant_callers} }) {

	my $program_outdirectory_name_ref = \$parameter_href->{$variant_caller}{outdir_name};
	push(@variant_caller_aliases, $$program_outdirectory_name_ref);

	if ($active_parameter_href->{$variant_caller} > 0) { #Only active programs

	    if (! ( any {$_ eq $$program_outdirectory_name_ref} @priority_calls ) ) {  #If element is not part of string

		$log->fatal("gatk_combinevariants_prioritize_caller does not contain active variant caller: '".$$program_outdirectory_name_ref."'");
		exit 1;
	    }
	}
	if ($active_parameter_href->{$variant_caller} == 0) { #Only NOT active programs

	    if ( ( any {$_ eq $$program_outdirectory_name_ref} @priority_calls ) ) {  #If element IS part of string

		$log->fatal("gatk_combinevariants_prioritize_caller contains deactivated variant caller: '".$$program_outdirectory_name_ref."'");
		exit 1;
	    }
	}
    }

    ## Check that prioritize string contains valid variant call names
    foreach my $prioritize_call (@priority_calls) {

	if (! ( any {$_ eq $prioritize_call} @variant_caller_aliases ) ) {  #If element is not part of string

	    $log->fatal("gatk_combinevariants_prioritize_caller: '".$prioritize_call."' does not match any supported variant caller: '".join(",", @variant_caller_aliases)."'");
	    exit 1;
	}
    }
}

sub vcf_to_bcf {

##vcf_to_bcf

##Function : Compress vcf to bcf and index.
##Returns  : ""
##Arguments: $infile, $FILEHANDLE, $outfile
##         : $infile     => The file to compress and index (no file_ending)
##         : $FILEHANDLE => SBATCH script FILEHANDLE to print to
##         : $outfile    => Out file (no file_ending) {Optional}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $infile;
    my $FILEHANDLE;
    my $outfile;

    my $tmpl = {
	infile => { required => 1, defined => 1, strict_type => 1, store => \$infile},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	outfile => { strict_type => 1, store => \$outfile},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    say $FILEHANDLE "## Compress vcf to bcf";
    print $FILEHANDLE "bcftools ";
    print $FILEHANDLE "view ";  #VCF/BCF conversion
    print $FILEHANDLE "-O b ";  #Output type - b: compressed BCF
    print $FILEHANDLE $infile.".vcf ";  #Infile

    if (defined($outfile)) {

	say $FILEHANDLE "> ".$outfile.".bcf", "\n";  #Outfile
    }
    else {

	say $FILEHANDLE "> ".$infile.".bcf", "\n";  #Outfile
    }

    say $FILEHANDLE "## Index bcf";
    print $FILEHANDLE "bcftools ";
    print $FILEHANDLE "index ";  #VCF/BCF index

    if (defined($outfile)) {

	say $FILEHANDLE $outfile.".bcf", "\n";  #Bcf file to index
    }
    else {

	say $FILEHANDLE $infile.".bcf", "\n";  #Bcf file to index
    }
}


sub check_aligner {

##check_aligner

##Function : Check that the correct number of aligners is used in MIP and sets the outaligner_dir flag accordingly.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $broadcasts_ref, $outaligner_dir_ref
##         : $parameter_href        => The parameter hash {REF}
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $broadcasts_ref        => Holds the parameters info for broadcasting later {REF}
##         : $outaligner_dir_ref    => The outaligner_dir used in the analysis {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $outaligner_dir_ref = $arg_href->{outaligner_dir_ref} //= \$arg_href->{active_parameter_href}{outaligner_dir};

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $broadcasts_ref;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	broadcasts_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$broadcasts_ref},
	outaligner_dir_ref => { default => \$$, strict_type => 1},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my %aligner;

    foreach my $aligner (@{ $parameter_href->{dynamic_parameter}{aligners} }) {

	if ($active_parameter_href->{$aligner} > 0) {  #Active aligner

	    $aligner{total_active_aligner_count}++;
	    push(@{ $aligner{active_aligners} }, $aligner);
	    $parameter_href->{active_aligner} = $aligner;  #Save the active aligner for downstream use

	    if ($$outaligner_dir_ref eq "not_set_yet") {

		$$outaligner_dir_ref = $parameter_href->{$aligner}{outdir_name};  #Set outaligner_dir parameter depending on active aligner

		my $info = "Set outaligner_dir to: ".$$outaligner_dir_ref;
		push(@$broadcasts_ref, $info);  #Add info to broadcasts
	    }
	}
    }
    if ($aligner{total_active_aligner_count} > 1) {

	$log->fatal($USAGE, "\n");
	$log->fatal("You have activate more than 1 aligner: ".join(", ", @{ $aligner{active_aligners} }).". MIP currently only supports 1 aligner per analysis.", "\n");
	exit 1;
    }
}


sub cnvnator_his {

##cnvnator_his

##Function : Generates a histogram
##Returns  : ""
##Arguments: $root_file, $contig_ref, $cnv_bin_size_ref, $chromosome_reference, $FILEHANDLE, $stdout_file , $stderr_file
##         : $root_file            => The root file
##         : $contig_ref           => Contig to analyze {REF}
##         : $cnv_bin_size_ref     => The cnvnator bin size {REF}
##         : $chromosome_reference => The chrmosome reference X.fa file
##         : $FILEHANDLE           => Filehandle to write to
##         : $stdout_file          => The stdout output file {Optional}
##         : $stderr_file          => The stderr output file {Optional}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $root_file;
    my $contig_ref;
    my $cnv_bin_size_ref;
    my $chromosome_reference;
    my $FILEHANDLE;
    my $stdout_file;
    my $stderr_file;

    my $tmpl = {
	root_file => { required => 1, defined => 1, strict_type => 1, store => \$root_file},
	contig_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$contig_ref},
	cnv_bin_size_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$cnv_bin_size_ref},
	chromosome_reference => { required => 1, defined => 1, strict_type => 1, store => \$chromosome_reference},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	stdout_file => { strict_type => 1, store => \$stdout_file},
	stderr_file => { strict_type => 1, store => \$stderr_file},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "cnvnator ";
    print $FILEHANDLE "-root ".$root_file." ";  #ROOT file
    print $FILEHANDLE "-chrom ".$$contig_ref." ";  #chromosome name
    print $FILEHANDLE "-his ".$$cnv_bin_size_ref." ";
    print $FILEHANDLE "-d ".$chromosome_reference." ";

    if (defined($stdout_file)) {

	print $FILEHANDLE "1>> ".$stdout_file." ";
    }
    if (defined($stderr_file)) {

	print $FILEHANDLE "2>> ".$stderr_file." ";
    }
    print $FILEHANDLE "; ";
}

sub cnvnator_stat {

##cnvnator_stat

##Function : Calculates statistics
##Returns  : ""
##Arguments: $root_file, $contig_ref, $cnv_bin_size_ref, $chromosome_reference, $FILEHANDLE, $stdout_file, $stderr_file
##         : $root_file        => The root file
##         : $contig_ref       => Contig to analyze {REF}
##         : $cnv_bin_size_ref => The cnvnator bin size {REF}
##         : $FILEHANDLE       => Filehandle to write to
##         : $stdout_file      => The stdout output file {Optional}
##         : $stderr_file      => The stderr output file {Optional}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $root_file;
    my $contig_ref;
    my $cnv_bin_size_ref;
    my $FILEHANDLE;
    my $stdout_file;
    my $stderr_file;

    my $tmpl = {
	root_file => { required => 1, defined => 1, strict_type => 1, store => \$root_file},
	contig_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$contig_ref},
	cnv_bin_size_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$cnv_bin_size_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	stdout_file => { strict_type => 1, store => \$stdout_file},
	stderr_file => { strict_type => 1, store => \$stderr_file},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "cnvnator ";
    print $FILEHANDLE "-root ".$root_file." ";  #ROOT file
    print $FILEHANDLE "-chrom ".$$contig_ref." ";  #chromosome name
    print $FILEHANDLE "-stat ".$$cnv_bin_size_ref." ";

    if (defined($stdout_file)) {

	print $FILEHANDLE "1>> ".$stdout_file." ";
    }
    if (defined($stderr_file)) {

	print $FILEHANDLE "2> ".$stderr_file." ";
    }
    print $FILEHANDLE "; ";
}

sub cnvnator_partition {

##cnvnator_partition

##Function : Read depth signal partioning
##Returns  : ""
##Arguments: $root_file, $contig_ref, $cnv_bin_size_ref, $chromosome_reference, $FILEHANDLE, $stdout_file, $stderr_file
##         : $root_file        => The root file
##         : $contig_ref       => Contig to analyze {REF}
##         : $cnv_bin_size_ref => The cnvnator bin size {REF}
##         : $FILEHANDLE       => Filehandle to write to
##         : $stdout_file      => The stdout output file {Optional}
##         : $stderr_file      => The stderr output file {Optional}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $root_file;
    my $contig_ref;
    my $cnv_bin_size_ref;
    my $FILEHANDLE;
    my $stdout_file;
    my $stderr_file;

    my $tmpl = {
	root_file => { required => 1, defined => 1, strict_type => 1, store => \$root_file},
	contig_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$contig_ref},
	cnv_bin_size_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$cnv_bin_size_ref},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	stdout_file => { strict_type => 1, store => \$stdout_file},
	stderr_file => { strict_type => 1, store => \$stderr_file},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "cnvnator ";
    print $FILEHANDLE "-root ".$root_file." ";  #ROOT file
    print $FILEHANDLE "-chrom ".$$contig_ref." ";  #chromosome name
    print $FILEHANDLE "-partition ".$$cnv_bin_size_ref." ";

    if (defined($stdout_file)) {

	print $FILEHANDLE "1>> ".$stdout_file." ";
    }
    if (defined($stderr_file)) {

	print $FILEHANDLE "2>> ".$stderr_file." ";
    }
    print $FILEHANDLE "; ";
}

sub cnvnator_calling {

##cnvnator_calling

##Function : CNV Calling
##Returns  : ""
##Arguments: $root_file, $contig_ref, $cnv_bin_size_ref, $chromosome_reference, $FILEHANDLE, $outfile, $stderr_file
##         : $root_file            => The root file
##         : $contig_ref           => Contig to analyze {REF}
##         : $cnv_bin_size_ref     => The cnvnator bin size {REF}
##         : $chromosome_reference => The chrmosome reference X.fa file
##         : $FILEHANDLE           => Filehandle to write to
##         : $outfile              => The outfile
##         : $stderr_file          => The stderr output file {Optional}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $root_file;
    my $contig_ref;
    my $cnv_bin_size_ref;
    my $chromosome_reference;
    my $FILEHANDLE;
    my $stderr_file;
    my $outfile;

    my $tmpl = {
	root_file => { required => 1, defined => 1, strict_type => 1, store => \$root_file},
	contig_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$contig_ref},
	cnv_bin_size_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$cnv_bin_size_ref},
	chromosome_reference => { required => 1, defined => 1, strict_type => 1, store => \$chromosome_reference},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	outfile => { required => 1, defined => 1, strict_type => 1, store => \$outfile},
	stderr_file => { strict_type => 1, store => \$stderr_file},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "cnvnator ";
    print $FILEHANDLE "-root ".$root_file." ";  #ROOT file
    print $FILEHANDLE "-chrom ".$$contig_ref." ";  #chromosome name
    print $FILEHANDLE "-call ".$$cnv_bin_size_ref." ";

    if (defined($stderr_file)) {

	print $FILEHANDLE "2> ".$stderr_file." ";
    }
    print $FILEHANDLE "> ".$outfile.".tmp ";
    print $FILEHANDLE "; ";

    ## Convert to vcf
    print $FILEHANDLE "cnvnator2VCF.pl ";
    print $FILEHANDLE $outfile.".tmp ";  #Infile
    print $FILEHANDLE $chromosome_reference." ";
    print $FILEHANDLE "> ".$outfile;
}


sub rename_vcf_samples {

##rename_vcf_samples

##Function : Rename vcf samples. The samples array will replace the sample names in the same order as supplied.
##Returns  : ""
##Arguments: $sample_ids_ref, $temp_directory_ref, $infile, $outfile, $FILEHANDLE, $output_type
##         : $sample_ids_ref     => Samples to rename in the same order as in the vcf {REF}
##         : $temp_directory_ref => Temporary directory {REF}
##         : $infile             => The vcf infile to rename samples for
##         : $outfile            => Output vcf with samples renamed
##         : $FILEHANDLE         => Filehandle to write to
##         : $output_type        => Output type

    my ($arg_href) = @_;

    ## Default(s)
    my $output_type;

    ## Flatten argument(s)
    my $sample_ids_ref;
    my $temp_directory_ref;
    my $infile;
    my $outfile;
    my $FILEHANDLE;

    my $tmpl = {
	sample_ids_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$sample_ids_ref},
	temp_directory_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$temp_directory_ref},
	infile => { required => 1, defined => 1, strict_type => 1, store => \$infile},
	outfile => { required => 1, defined => 1, strict_type => 1, store => \$outfile},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	output_type => { default => "v",
			 allow => ["b", "u", "z", "v"],
			 strict_type => 1, store => \$output_type},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Create new sample names file
    say $FILEHANDLE "## Create new sample(s) names file";
    print $FILEHANDLE q?printf "?;

    foreach my $sample_id (@$sample_ids_ref) {

	print $FILEHANDLE $sample_id.q?\n?;
    }
    print $FILEHANDLE q?" ?;
    say $FILEHANDLE "> ".catfile($$temp_directory_ref, "sample_name.txt")." ";
    say $FILEHANDLE "\n";

    ## Rename samples in VCF
    say $FILEHANDLE "## Rename sample(s) names ion VCF file";
    print $FILEHANDLE "bcftools ";
    print $FILEHANDLE "reheader ";  #Modify header of VCF/BCF files, change sample names.
    print $FILEHANDLE "-s ";  #New sample names
    print $FILEHANDLE catfile($$temp_directory_ref, "sample_name.txt")." ";
    print $FILEHANDLE " ".$infile." ";  #Infile

    print $FILEHANDLE "| ";  #Pipe
    print $FILEHANDLE "bcftools ";
    print $FILEHANDLE "view ";
    print $FILEHANDLE "--output-type v ";  #Generate uncompressed vcf
    print $FILEHANDLE "> ".$outfile." ";
    say $FILEHANDLE "\n";
}


sub remove_element {

##remove_element

##Function : Removes an element from array and return new array while leaving orginal elements_ref untouched.
##Returns  : "@array"
##Tags     : helper, remove, ARRAY, contigs
##Arguments: $elements_ref, $remove_contigs_ref, $contig_switch
##         : $elements_ref       => Array to remove an element from {REF}
##         : $remove_contigs_ref => Remove this contig
##         : $contig_switch      => Expect contigs in elements_ref

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $elements_ref;
    my $remove_contigs_ref;
    my $contig_switch;

    my $tmpl = {
	elements_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$elements_ref},
	remove_contigs_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$remove_contigs_ref},
	contig_switch => { allow => [0, 1],
			   strict_type => 1, store => \$contig_switch},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my @array = @$elements_ref;  #Make local copy

    for (my $index=0;$index<scalar(@array);$index++) {

	foreach my $remove_contig (@$remove_contigs_ref) {

	    if($contig_switch) {  #Make sure that contig is removed independent of genome source

		if( ($elements_ref->[$index] eq $remove_contig) || ($elements_ref->[$index] eq "chr".$remove_contig) ) {

		    splice(@array, $index, 1);  #Remove $element from array
		}
	    }
	    elsif( ($elements_ref->[$index] eq $remove_contig) ) {  #Arbitrary element from array

		splice(@array, $index, 1);  #Remove $element from array
	    }
	}
    }
    return @array
}


sub collect_read_length {

##collect_read_length

##Function : Collect read length from an infile
##Returns  : "readLength"
##Arguments: $directory, $read_file, $file
##         : $directory => Directory of file
##         : $read_file => Command used to read file
##         : $file      => File to parse

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $directory;
    my $read_file_command;
    my $file;

    my $tmpl = {
	directory => { required => 1, defined => 1, strict_type => 1, store => \$directory},
	read_file_command => { required => 1, defined => 1, strict_type => 1, store => \$read_file_command},
	file => { required => 1, defined => 1, strict_type => 1, store => \$file},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $seq_length_regexp = q?perl -ne 'if ($_!~/@/) {chomp($_);my $seq_length = length($_);print $seq_length;last;}' ?;  #Prints sequence length and exits

    my $pwd = cwd();  #Save current direcory
    chdir($directory);  #Move to sample_id infile directory

    my $ret = `$read_file_command $file | $seq_length_regexp;`;  #Collect sequence length
    return $ret;
}


sub track_progress {

##track_progress

##Function : Output SLURM info on each job via sacct command and write to MIP Log file(.status)
##Returns  : ""
##Arguments: $job_id_href, $FILEHANDLE, $log_file_ref
##         : $job_id_href  => The job_id hash {REF}
##         : $FILEHANDLE   => Sbatch filehandle to write to
##         : $log_file_ref => The log file {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $job_id_href;
    my $FILEHANDLE;
    my $log_file_ref;

    my $tmpl = {
	job_id_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$job_id_href},
	FILEHANDLE => { store => \$FILEHANDLE},
	log_file_ref => { default => \$$, strict_type => 1, store => \$log_file_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if (keys %$job_id_href) {

	print $FILEHANDLE "\t".q?sacct --format=jobid,jobname%50,account,partition,alloccpus,TotalCPU,elapsed,start,end,state,exitcode -j ?;
	print $FILEHANDLE join(',', @{ $job_id_href->{PAN}{PAN} }), " ";
	print $FILEHANDLE q?| ?;
	print $FILEHANDLE q?perl -nae 'my @headers=(jobid,jobname,account,partition,alloccpus,TotalCPU,elapsed,start,end,state,exitcode); if($. == 1) {print "#".join("\t", @headers), "\n"} if ($.>=3 && $F[0]!~/.batch/) {print join("\t", @F), "\n"}' ?;
	say $FILEHANDLE q?> ?.$$log_file_ref.".status";
    }
}

sub print_program {

##print_program

##Function : Print all supported programs in '-ppm' mode
##Returns  : ""
##Arguments: $parameter_href, $print_program_mode
##         : $parameter_href     => The parameter hash {REF}
##         : $print_program_mode => Mode to run modules in

    my ($arg_href) = @_;

    ## Default(s)
    my $print_program_mode = $arg_href->{print_program_mode} //= 2;

    ## Flatten argument(s)
    my $parameter_href;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	print_program_mode => { allow => [0, 1, 2],
				strict_type => 1, store => \$print_program_mode},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    add_to_parameter({parameter_href => $parameter_href,
		      aggregates_ref => ["type:program"],
		     });

    my @order_parameters;

    ## Adds the order of first level keys from yaml file to array
    order_parameter_names({order_parameters_ref => \@order_parameters,
			   file_path => catfile($Bin, "definitions", "define_parameters.yaml"),
			  });

    foreach my $order_parameter_element (@order_parameters) {

	if ( ( any {$_ eq $order_parameter_element} @{ $parameter_href->{dynamic_parameter}{program} } ) ) { #Only process programs

	    unless ($order_parameter_element=~/pmadeline|pmosaik|pbwa_sampe|pbwa_aln|ppicardtools_mergerapidreads|pbamcalibrationblock|pvariantannotationblock|pannovar/) {

		print STDOUT "--".$order_parameter_element." ".$print_program_mode." ";
	    }
	}
    }
    print STDOUT "\n";
}


sub check_program_mode {

##check_program_mode

##Function : Check correct value for program mode in MIP.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href
##         : $parameter_href        => The parameter hash {REF}
##         : $active_parameter_href => The active parameters for this analysis hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my @allowed_values = (0, 1, 2);

    foreach my $program (@{ $parameter_href->{dynamic_parameter}{program} }) {

	if (! ( any {$_ eq $active_parameter_href->{$program}} @allowed_values ) ) { #If element is not part of array

	    $log->fatal("'".$active_parameter_href->{$program}."' Is not an allowed mode for program '--".$program."'. Set to: ".join("|", @allowed_values));
	    exit 1;
	}
    }
}


sub help {

##help

##Function : Print help text and exit with supplied exit code
##Returns  : ""
##Arguments: $USAGE, $exit_code
##         : $USAGE     => Help text
##         : $exit_code => Exit code

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $USAGE;
    my $exit_code;

    my $tmpl = {
	USAGE => {required => 1, defined => 1, strict_type => 1, store => \$USAGE},
	exit_code => { default => 0, strict_type => 1, store => \$exit_code},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    say STDOUT $USAGE;
    exit $exit_code;
}


sub select_bwamem_binary {

##select_bwamem_binary

##Function : Detect version and source of the human_genome_reference: Source (hg19 or GRCh) and return the correct bwa_mem binary
##Returns  : ""
##Arguments: $human_genome_reference_source, $human_genome_reference_version
##         : $human_genome_reference_source  => Human genome reference source {REF}
##         : $human_genome_reference_version => Human genome reference version {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $human_genome_reference_source_ref;
    my $human_genome_reference_version_ref;

    my $tmpl = {
	human_genome_reference_source_ref => {required => 1, defined => 1, default => \$$, strict_type => 1, store => \$human_genome_reference_source_ref},
	human_genome_reference_version_ref => {required => 1, defined => 1, default => \$$, strict_type => 1, store => \$human_genome_reference_version_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if($$human_genome_reference_source_ref eq "GRCh") {

	if ($$human_genome_reference_version_ref > 37) {

	    return "run-bwamem";
	}
	else {  #HumanGenome version less than GrCh37

	    return "bwa mem";
	}
    }
    else {  #hgXX build

	if ($$human_genome_reference_version_ref > 19) {

	    return "run-bwamem";
	}
	else {  #HumanGenome version less than hg19

	    return "bwa mem";
	}
    }
}


sub update_exome_target_bed {

##update_exome_target_bed

##Function : Update exome_target_bed files with human_genome_reference_source_ref and human_genome_reference_version_ref
##Returns  : ""
##Arguments: $exome_target_bed_file_href, $human_genome_reference_source_ref, human_genome_reference_version_ref
##         : $exome_target_bed_file_href        => ExomeTargetBedTestFile hash {REF}
##         : human_genome_reference_source_ref  => The human genome reference source {REF}
##         : human_genome_reference_version_ref => The human genome reference version {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $exome_target_bed_file_href;
    my $human_genome_reference_source_ref;
    my $human_genome_reference_version_ref;

    my $tmpl = {
	exome_target_bed_file_href => { required => 1, store => \$exome_target_bed_file_href},
	human_genome_reference_source_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$human_genome_reference_source_ref},
	human_genome_reference_version_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$human_genome_reference_version_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    foreach my $exome_target_bed_file (keys %$exome_target_bed_file_href) {

	my $original_file_name = $exome_target_bed_file;

	if ( ($exome_target_bed_file =~ s/genome_reference_source/$$human_genome_reference_source_ref/) && ($exome_target_bed_file =~ s/_version/$$human_genome_reference_version_ref/) ){  #Replace with actual version

	    $exome_target_bed_file_href->{$exome_target_bed_file} = delete($exome_target_bed_file_href->{$original_file_name});  #The delete operator returns the value being deleted i.e. updating hash key while preserving original info
	}
    }
}



sub check_sample_id_in_parameter_path {

##check_sample_id_in_parameter_path

##Function : Check sample_id provided in hash path parameter is included in the analysis and only represented once
##Returns  : ""
##Tags     : check, sampleids, hash
##Arguments: $active_parameter_href, $sample_ids_ref, $parameter_name
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $sample_ids_ref        => Array to loop in for parameter {REF}
##         : $parameter_names_ref   => Parameter name list {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_ids_ref;
    my $parameter_names_ref;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_ids_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$sample_ids_ref},
	parameter_names_ref => { required => 1, defined => 1, default => [], store => \$parameter_names_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    foreach my $parameter_name (@$parameter_names_ref) {  #Lopp through all hash parameters supplied

	my %seen;  #Hash to test duplicate sample_ids later

	foreach my $key (keys $active_parameter_href->{$parameter_name} ) {

	    my @parameter_samples = split(",", $active_parameter_href->{$parameter_name}{$key});

	    foreach my $sample_id (@parameter_samples) {

		$seen{$sample_id}++;  #Increment instance to check duplicates later

		if ($seen{$sample_id} > 1) {  #Check sample_id are unique

		    $log->fatal("Sample_id: ".$sample_id." is not uniqe in '-".$parameter_name." '".$key."=".join(",", @parameter_samples),"\n");
		    exit 1;
		}
	    }
	}
	foreach my $sample_id (@$sample_ids_ref) {

	    if ( ! (any {$_ eq $sample_id} (keys %seen)) ) {  #If sample_id is not present in parameter_name hash

		$log->fatal("Could not detect ".$sample_id." for '--".$parameter_name."'. Provided sample_ids are: ".join(", ", (keys %seen)), "\n");
		exit 1;
	    }
	}
    }
}

sub check_sample_id_in_parameter {

##check_sample_id_in_parameter

##Function : Check sample_id provided in hash parameter is included in the analysis and only represented once
##Returns  : ""
##Tags     : check, sampleids, hash
##Arguments: $active_parameter_href, $sample_ids_ref, $parameter_name
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $sample_ids_ref        => Array to loop in for parameter {REF}
##         : $parameter_names_ref   => Parameter name list {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_ids_ref;
    my $parameter_names_ref;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_ids_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$sample_ids_ref},
	parameter_names_ref => { required => 1, defined => 1, default => [], store => \$parameter_names_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    foreach my $parameter_name (@$parameter_names_ref) {  #Lopp through all hash parameters supplied

	if (defined($active_parameter_href->{$parameter_name})) {

	    foreach my $sample_id (@$sample_ids_ref) {

		## Check that a value exists
		if (! defined($active_parameter_href->{$parameter_name}{$sample_id})) {

		    $log->fatal("Could not find value for ".$sample_id." for parameter '--".$parameter_name."'", "\n");
		    exit 1;
		}

		## If sample_id is not present in parameter_name hash
		if ( ! (any {$_ eq $sample_id} (keys $active_parameter_href->{$parameter_name})) ) {

		    $log->fatal("Could not detect ".$sample_id." for parameter '--".$parameter_name."'. Provided sample_ids for parameter are: ".join(", ", (keys $active_parameter_href->{$parameter_name})), "\n");
		    exit 1;
		}
	    }
	}
    }
}


sub get_exom_target_bed_file {

##get_exom_target_bed_file

##Function : Get exome_target_bed file for specfic sample_id and add file_ending from file_infoHash if supplied
##Returns  : "exome_target_bedFile(file_ending)"
##Tags     : get, capturekit, sampleids
##Arguments: $active_parameter_href, $sample_id_ref, $file_ending_ref
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $sample_id_ref         => The sample_id {REF}
##         : $file_ending_ref       => File ending to add to file {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $sample_id_ref;
    my $file_ending_ref;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
	file_ending_ref => { store => \$file_ending_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    my %seen;

    foreach my $exome_target_bed_file (keys $active_parameter_href->{exome_target_bed}) {

	my @capture_kit_samples = split(",", $active_parameter_href->{exome_target_bed}{$exome_target_bed_file});

	map { $seen{$_}++ } (@capture_kit_samples);  #Count number of times sample_id has been seen

	if (any {$_ eq $$sample_id_ref} @capture_kit_samples) {  #If capture_kit sample_id is associated with exome_target_bedFile

	    if (defined($$file_ending_ref)) {

		$exome_target_bed_file .= $$file_ending_ref;
	    }
	    return $exome_target_bed_file;
	}
    }
    if ( ! defined($seen{$$sample_id_ref})) {

	$log->fatal("Could not detect ".$sample_id_ref." in '-exome_target_bed' associated files in sub routine get_exom_target_bed_file", "\n");
	exit 1;
    }
}


sub sambamba_flagstat {

##sambamba_flagstat

##Function : Process BAM with sambamba flagstat to produce metric file for downstream analysis
##Returns  : ""
##Arguments: $infile_path, $outfile_path, $stderr_file_path, $FILEHANDLE
##         : $infile_path      => Infile path
##         : $outfile_path     => outfile path
##         : $stderr_file_path => Stderr file path to write to
##         : $FILEHANDLE       => Sbatch filehandle to write to

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $infile_path;
    my $outfile_path;
    my $stderr_file_path;
    my $FILEHANDLE;

    my $tmpl = {
	infile_path => { required => 1, defined => 1, strict_type => 1, store => \$infile_path},
	outfile_path => { required => 1, defined => 1, strict_type => 1, store => \$outfile_path},
	stderr_file_path => { required => 1, defined => 1, strict_type => 1, store => \$stderr_file_path},
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "sambamba ";  #Program
    print $FILEHANDLE "flagstat ";
    print $FILEHANDLE catfile($infile_path)." ";  #OutFile
    print $FILEHANDLE "> ".catfile($outfile_path)." ";  #Metric file
    say $FILEHANDLE "2>> ".$stderr_file_path, "\n";  #Redirect xargs output to program specific stderr file
}


sub alias_assembly_version {

##alias_assembly_version

##Function : Alias genome source and version to be compatible with VEP
##Returns  : "$$assembly_version_ref"
##Arguments: $assembly_version_ref
##         : $assembly_version_ref => The genome source and version to be checked

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $assembly_version_ref;

    my $tmpl = {
	assembly_version_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$assembly_version_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    if ($$assembly_version_ref=~/hg(\d+)/) {

	my $version_number = $1;
	if ($version_number > 20) {

	    $$assembly_version_ref = "GRCh".$version_number;
	}
    }
}


sub generate_contig_specific_target_bed_file {

##generate_contig_specific_target_bed_file

##Function : Generate contig specific interval_list
##Returns  : ""
##Arguments: $active_parameter_href, $file_info_href, $FILEHANDLE, $exome_target_bed_file, $temp_directory_ref, $reference_dir_ref, $file_ending
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $file_info_href        => The file_info hash {REF}
##         : $FILEHANDLE            => Filehandle to write to
##         : $exome_target_bed_file => Target file to split
##         : $temp_directory_ref    => The temporary directory {REF}
##         : $reference_dir_ref     => MIP reference directory {REF}
##         : $file_ending           => File ending to add {Optional}

    my ($arg_href) = @_;

    ## Default(s)
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};
    my $reference_dir_ref = $arg_href->{reference_dir_ref} //= \$arg_href->{active_parameter_href}{reference_dir};

    ## Flatten argument(s)
    my $active_parameter_href;
    my $file_info_href;
    my $FILEHANDLE;
    my $exome_target_bed_file_ref;
    my $file_ending;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	FILEHANDLE => { store => \$FILEHANDLE},
	exome_target_bed_file_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$exome_target_bed_file_ref},
	file_ending => { strict_type => 1, store => \$file_ending},
	temp_directory_ref => { default => \$$, strict_type => 1, store => \$temp_directory_ref},
	reference_dir_ref => { default => \$$, strict_type => 1, store => \$reference_dir_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my $core_number = $active_parameter_href->{core_processor_number};
    my $core_counter = 1;

    say $FILEHANDLE "## Generate contig specific interval_list\n";

    while (my ($contig_index, $contig) = each(@{ $file_info_href->{contigs_size_ordered} }) ) {

	print_wait({counter_ref => \$contig_index,
		    core_number_ref => \$core_number,
		    core_counter_ref => \$core_counter,
		    FILEHANDLE => $FILEHANDLE,
		   });

	## Splits a target file into new contig specific target file
	split_target_file({FILEHANDLE => $FILEHANDLE,
			   indirectory_ref => $reference_dir_ref,
			   outdirectory_ref => $temp_directory_ref,
			   infile_ref => \basename($$exome_target_bed_file_ref),
			   contig_ref => \$contig,
			   file_ending => $file_ending,
			  });
    }
    say $FILEHANDLE "wait", "\n";
}


sub replace_iupac {

##replace_iupac

##Function : Replace the IUPAC code in alternative allels with N for input stream and writes to stream.
##Returns  : ""
##Arguments: $FILEHANDLE, $stderr_path, $xargs
##         : $FILEHANDLE  => Sbatch filehandle to write to
##         : $stderr_path => Stderr path to errors write to
##         : $xargs       => Write on xargs format

    my ($arg_href) = @_;

    ## Default(s)
    my $xargs;

    ## Flatten argument(s)
    my $FILEHANDLE;
    my $stderr_path;

    my $tmpl = {
	FILEHANDLE => { required => 1, defined => 1, strict_type => 1, store => \$FILEHANDLE},
	stderr_path => { strict_type => 1, store => \$stderr_path},
	xargs => { default => 1,
		   allow => [0, 1],
		   strict_type => 1, store => \$xargs},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "| ";  #Pipe
    print $FILEHANDLE "perl -nae ";

    if ($xargs) {  #Add escape char

	print $FILEHANDLE q?\'if($_=~/^#/) {print $_;} else { @F[4] =~ s/W|K|Y|R|S|M/N/g; print join(\"\\\t\", @F), \"\\\n\"; }\' ?;  #substitute IUPAC code with N to not break vcf specifications (GRCh38)
    }
    else {

	print $FILEHANDLE q?'if($_=~/^#/) {print $_;} else { @F[4] =~ s/W|K|Y|R|S|M/N/g; print join("\t", @F), "\n"; }' ?;  #substitute IUPAC code with N to not break vcf specifications (GRCh38)
    }
    if ($stderr_path) {

	print $FILEHANDLE "2>> ".$stderr_path." ";  #Redirect output to program specific stderr file
    }
}


sub get_matching_values_key {

##get_matching_values_key

##Function : Return the key if the hash value and query match
##Returns  : "key pointing to matched value"
##Arguments: $active_parameter_href, $query_value_ref, $parameter_name
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $query_value_ref       => The value to query in the hash {REF}
##         : $parameter_name        => MIP parameter name

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $query_value_ref;
    my $parameter_name;

    my $tmpl = {
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	query_value_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$query_value_ref},
	parameter_name => { required => 1, defined => 1, strict_type => 1, store => \$parameter_name},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my %reversed = reverse %{ $active_parameter_href->{$parameter_name} };  #Values are now keys and vice versa

    if ( exists $reversed{$$query_value_ref} ) {

	return $reversed{$$query_value_ref};
    }
}


sub detect_overall_analysis_type {

##detect_overall_analysis_type

##Function : Detect if all samples has the same sequencing type and return consensus or mixed
##Returns  : "consensus/mixed analysis_type"
##Arguments: $analysis_type_hef
##         : $analysis_type_hef => The analysis_type hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $analysis_type_hef;

    my $tmpl = {
	analysis_type_hef  => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$analysis_type_hef},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    my @analysis_types = ("wes", "wgs", "rapid");

    foreach my $analysis_type (@analysis_types) {

	if (all { $_ eq $analysis_type } values %$analysis_type_hef) {

	    return $analysis_type;
	}
    }
    return "mixed"  # No consensus, then it must be mixed
}


sub bcftools_norm {

##bcftools_norm

##Function : BcfTools norm, Left-align and normalize indels, split multiallelics
##Returns  : ""
##Arguments: $FILEHANDLE, $reference_path_ref, $infile_path, $outfile_path, $multiallelic, $multiallelic_type, $stderr_file_path
##         : $FILEHANDLE         => Filehandle to write to
##         : $reference_path_ref => Human genome reference path {REF}
##         : $infile_path        => Infile path to read from
##         : $outfile_path       => Outfile path to write to
##         : $multiallelic       => To split/join multiallelic calls or not
##         : $multiallelic_type  => Type of multiallelic to split/join {OPTIONAL}
##         : $stderr_file_path   => Stderr file path to write to {OPTIONAL}

    my ($arg_href) = @_;

    ## Default(s)
    my $multiallelic_type;

    ## Flatten argument(s)
    my $FILEHANDLE;
    my $reference_path_ref;
    my $infile_path;
    my $outfile_path;
    my $multiallelic;
    my $stderr_file_path;

    my $tmpl = {
	FILEHANDLE => { required => 1, defined => 1, store => \$FILEHANDLE},
	reference_path_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$reference_path_ref},
	infile_path => { strict_type => 1, store => \$infile_path},
	outfile_path => { required => 1, defined => 1, strict_type => 1, store => \$outfile_path},
	multiallelic => { allow => ["+", "-"],
			  strict_type => 1, store => \$multiallelic},
	multiallelic_type => { default => "both",
			       allow => ["snps", "indels", "both", "any"],
			       strict_type => 1, store => \$multiallelic_type},
	stderr_file_path => { strict_type => 1, store => \$stderr_file_path},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    print $FILEHANDLE "bcftools ";
    print $FILEHANDLE "norm ";  #Left-align and normalize indels

    if (defined($multiallelic)) {

	print $FILEHANDLE "--multiallelics ";
	print $FILEHANDLE $multiallelic.$multiallelic_type." ";  #split multiallelic (-) or join biallelics (+), type: snps|indels|both|any [both]
    }
    print $FILEHANDLE "-f ".$$reference_path_ref." ";  #Reference file
    print $FILEHANDLE "-o ".$outfile_path." "; #OutFile

    if (defined($infile_path)) {

	print $FILEHANDLE $infile_path." ";
    }
    if (defined($stderr_file_path)) {

	say $FILEHANDLE "2>> ".$stderr_file_path." ";  #Redirect xargs output to program specific stderr file
    }
}


sub detect_phenotype {

##detect_phenotype

##Function : Map each sample_ids phenotype to dynamic parameter
##Returns  : ""
##Arguments: $parameter_href, $phenotype, $sample_id_ref
##         : $parameter_href => Holds all parameters
##         : $phenotype      => Phenotype
##         : $sample_id_ref  => The sample_id {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $phenotype;
    my $sample_id_ref;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	phenotype => { required => 1, defined => 1, strict_type => 1, store => \$phenotype},
	sample_id_ref => { required => 1, defined => 1, default => \$$, strict_type => 1, store => \$sample_id_ref},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    if ($phenotype eq 2) {  #Affected

	push(@{ $parameter_href->{dynamic_parameter}{affected} }, $$sample_id_ref);
    }
    elsif ($phenotype eq 1) {  #Unaffected

	push(@{ $parameter_href->{dynamic_parameter}{unaffected} }, $$sample_id_ref);
    }
    elsif ( ($phenotype eq -9) || (! $phenotype) ) {  #Missing

	push(@{ $parameter_href->{dynamic_parameter}{missing} }, $$sample_id_ref);
    }
    else {

	$log->fatal("Not allowed phenotype".$phenotype." detected in pedigree file");
    }
}


sub get_user_supplied_info {

##get_user_supplied_info

##Function : Detect if user supplied info on parameters otherwise collected from pedigree
##Returns  : "user_supply_switchHash where 1=user input and 0=no user input"
##Arguments: $parameter_href, active_parameter_href
##         : $parameter_href        => Holds all parameters {REF}
##         : $active_parameter_href => The active parameters for this analysis hash {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Define what should be checked
    my %user_supply_switch = (sample_ids => 0,
			      exome_target_bed => 0,
			      analysis_type => 0,
			      expected_coverage => 0,
	);

    ## Detect user supplied info
    foreach my $parameter (keys %user_supply_switch) {

	if (ref($parameter_href->{$parameter}{value}) eq "HASH") {

	    $user_supply_switch{$parameter} = check_user_supplied_info({active_parameter_href => $active_parameter_href,
									data_ref => \%{ $parameter_href->{$parameter}{value} },
									parameter_name => $parameter,
								       });
	}
	if (ref($parameter_href->{$parameter}{value}) eq "ARRAY") {

	    $user_supply_switch{$parameter} = check_user_supplied_info({active_parameter_href => $active_parameter_href,
									data_ref => \@{ $parameter_href->{$parameter}{value} },
									parameter_name => $parameter,
								       });
	}
	else {

	    $user_supply_switch{$parameter} = check_user_supplied_info({active_parameter_href => $active_parameter_href,
									data_ref => $parameter_href->{$parameter}{value},
									parameter_name => $parameter,
								       });
	}
    }
    return %user_supply_switch;
}


sub get_pedigree_sample_info {

##get_pedigree_sample_info

##Function : Reformat pedigree keys to plink format and collect sample info to various hashes
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $sample_info_href, $file_info_href, $supported_capture_kit_href, $exom_target_bed_test_file_tracker_href, $pedigree_sample_href, $reformatHashRef, $user_supply_switch_href, $sample_id
##         : $parameter_href                         => The parameter hash {REF}
##         : $active_parameter_href                  => The active parameters for this analysis hash {REF}
##         : $sample_info_href                       => Info on samples and family hash {REF}
##         : $file_info_href                         => The associated reference file endings {REF}
##         : $supported_capture_kit_href             => The supported capture kits hash {REF}
##         : $exom_target_bed_test_file_tracker_href => Collect which sample_ids have used a certain capture_kit
##         : $pedigree_sample_href                   => YAML sample info hash {REF}
##         : $user_supply_switch_href                => The user supplied info switch {REF}
##         : $sample_id                              => Sample ID

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $sample_info_href;
    my $file_info_href;
    my $supported_capture_kit_href;
    my $exom_target_bed_test_file_tracker_href;
    my $pedigree_sample_href;
    my $user_supply_switch_href;
    my $sample_id;

    my $tmpl = {
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	sample_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$sample_info_href},
	file_info_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$file_info_href},
	supported_capture_kit_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$supported_capture_kit_href},
	exom_target_bed_test_file_tracker_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$exom_target_bed_test_file_tracker_href},
	pedigree_sample_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$pedigree_sample_href},
	user_supply_switch_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$user_supply_switch_href},
	sample_id => { required => 1, defined => 1, strict_type => 1, store => \$sample_id},
    };

    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Add input to sample_info hash for at sample level
    foreach my $key (keys %$pedigree_sample_href) {

	$sample_info_href->{sample}{$sample_id}{$key} = $pedigree_sample_href->{$key};

	## Add sex to dynamic parameters
	if ($key eq "sex") {

	    push(@{ $parameter_href->{dynamic_parameter}{$pedigree_sample_href->{$key}} }, $sample_id);

	    ## Reformat to plink format
	    if ($pedigree_sample_href->{$key} eq "male") {

		$parameter_href->{dynamic_parameter}{$sample_id}{plink_sex} = 1;
	    }
	    elsif ($pedigree_sample_href->{$key} eq "female") {

		$parameter_href->{dynamic_parameter}{$sample_id}{plink_sex} = 2;
	    }
	    else {

		$parameter_href->{dynamic_parameter}{$sample_id}{plink_sex} = "other";
	    }
	}

	## Add phenotype to dynamic parameters
	if ($key eq "phenotype") {

	    push(@{ $parameter_href->{dynamic_parameter}{$pedigree_sample_href->{$key}} }, $sample_id);

	    ## Reformat to plink format
	    if ($pedigree_sample_href->{$key} eq "unaffected") {

		$parameter_href->{dynamic_parameter}{$sample_id}{plink_phenotype} = 1;
	    }
	    elsif ($pedigree_sample_href->{$key} eq "affected") {

		$parameter_href->{dynamic_parameter}{$sample_id}{plink_phenotype} = 2;
	    }
	    else {

		$parameter_href->{dynamic_parameter}{$sample_id}{plink_phenotype} = 0;
	    }
	}
    }

    ## Add analysis_type for each individual
    if ($sample_info_href->{sample}{$sample_id}{analysis_type}) {  #Add analysis_type

	if (! $user_supply_switch_href->{analysis_type}) {

	    my $analysis_type = $sample_info_href->{sample}{$sample_id}{analysis_type};  #Alias
	    $active_parameter_href->{analysis_type}{$sample_id} = $analysis_type;
	}
    }

    ## Add expected_coverage for each individual
    if ($sample_info_href->{sample}{$sample_id}{expected_coverage}) {  #Add expected_coverage

	if (! $user_supply_switch_href->{expected_coverage}) {

	    my $expected_coverage = $sample_info_href->{sample}{$sample_id}{expected_coverage};  #Alias
	    $active_parameter_href->{expected_coverage}{$sample_id} = $expected_coverage;
	}
    }

    ## Add capture kit for each individual
    if ( ($sample_info_href->{sample}{$sample_id}{capture_kit}) ) {

	my $capture_kit = $sample_info_href->{sample}{$sample_id}{capture_kit};  #Alias

	## Return a capture kit depending on user info
	my $exome_target_bed_file = add_capture_kit({file_info_href => $file_info_href,
						     supported_capture_kit_href => $supported_capture_kit_href,
						     capture_kit => $capture_kit,
						     user_supplied_parameter_switch => $user_supply_switch_href->{exome_target_bed},
						    });
	if($exome_target_bed_file) {

	    push(@{ $exom_target_bed_test_file_tracker_href->{$exome_target_bed_file} }, $sample_id);

	}
    }
}


sub check_founder_id {

##check_founder_id

##Function : Check that founder_ids are included in the pedigree info
##Returns  : ""
##Arguments: $pedigree_href, $pedigree_sample_ids_ref
##         : $pedigree_href           => Pedigree info {REF}
##         : $pedigree_sample_ids_ref => Array of pedigree samples {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $pedigree_href;
    my $pedigree_sample_ids_ref;
    
    my $tmpl = { 
	pedigree_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$pedigree_href},
	pedigree_sample_ids_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$pedigree_sample_ids_ref},
    };
    
   
    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];
    
    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");
    
  SAMPLE:
    foreach my $pedigree_sample_href (@{ $pedigree_href->{samples} }) {
	
	my @founders = ($pedigree_sample_href->{father}, $pedigree_sample_href->{mother});

      FOUNDER:
	foreach my $founder (@founders) {

	    if ($founder) {
		
		if (! ( any {$_ eq $founder} @$pedigree_sample_ids_ref ) ) {  #If element is not part of array
		    
		    $log->fatal("Could not find founder sample_id: ".$founder." in pedigree file\n");
		    exit 1;
		}
	    }	
	}
    }
}


sub remove_contigs {

##remove_contigs

##Function : Removes contig_names from contigs array if no male or other found
##Returns  : ""
##Arguments: $active_parameter_href, $contigs_ref
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $contigs_ref           => Contigs array to update {REF}
##         : $contig_names_ref      => Contig names to remove {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href;
    my $contigs_ref;
    my $contig_names_ref;

    my $tmpl = { 
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	contigs_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$contigs_ref},
	contig_names_ref => { required => 1, defined => 1, default => [], strict_type => 1, store => \$contig_names_ref},
    };
    
    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];

    ## Removes contigY|chrY from contigs if no males or 'other' found in analysis
    if (! $active_parameter_href->{male_found}) {
	
	## Removes contigs from supplied contigs_ref
	remove_array_element({contigs_ref => $contigs_ref,
			      remove_contigs_ref => $contig_names_ref,
			     });
    }
}


sub update_mip_reference_path {
    
##update_mip_reference_path
    
##Function : Update path for supplied reference(s) associated with parameter that should reside in the mip reference directory to full path.
##Returns  : ""
##Arguments: $parameter_href, $active_parameter_href, $parameter_name
##         : $parameter_href        => The parameter hash {REF}
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $parameter_name        => Parameter to update
    
    my ($arg_href) = @_;
    
    ## Flatten argument(s)
    my $parameter_href;
    my $active_parameter_href;
    my $parameter_name;
    
    my $tmpl = { 
	parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$parameter_href},
	active_parameter_href => { required => 1, defined => 1, default => {}, strict_type => 1, store => \$active_parameter_href},
	parameter_name => { required => 1, defined => 1, strict_type => 1, store => \$parameter_name},
    };
    
    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];
    
    my $reference_dir_ref = \$active_parameter_href->{reference_dir};
    
    if ($parameter_href->{$parameter_name}{data_type} eq "SCALAR"
	&& defined($active_parameter_href->{$parameter_name}) ) {
	
	my ($volume, $directory, $file_name) = File::Spec->splitpath($active_parameter_href->{$parameter_name});  #Split to restate
	$active_parameter_href->{$parameter_name} = $file_name;  #Restate to allow for changing mip reference directory between runs
	$active_parameter_href->{$parameter_name} = catfile($$reference_dir_ref, $active_parameter_href->{$parameter_name});  #Update original value
    }
    elsif ($parameter_href->{$parameter_name}{data_type} eq "ARRAY") {
	
	foreach my $file (@{ $active_parameter_href->{$parameter_name} }) {
	    
	    my ($volume, $directory, $file_name) = File::Spec->splitpath($file);  #Split to restate
	    $file = catfile($$reference_dir_ref, $file_name);  #Update original element
	}
    }
    elsif ($parameter_href->{$parameter_name}{data_type} eq "HASH") {
	
	foreach my $file (keys $active_parameter_href->{$parameter_name}) {
	    
	    my ($volume, $directory, $file_name) = File::Spec->splitpath($file);  #Split to restate
	    $active_parameter_href->{$parameter_name}{ catfile($$reference_dir_ref, $file_name) } = delete($active_parameter_href->{$parameter_name}{$file});  #Update original value
	}
    }
}


sub check_vcfanno_toml {

##

##Function : Check that the supplied vcfanno toml frequency file match record 'file=' within toml config file
##Returns  : ""
##Arguments: $vcfanno_file_toml, $vcfanno_file_freq
##         : $vcfanno_file_toml => Toml config file
##         : $vcfanno_file_freq => Frequency file recorded inside toml file

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $vcfanno_file_toml;
    my $vcfanno_file_freq;

    my $tmpl = { 
	vcfanno_file_toml => { required => 1, defined => 1, strict_type => 1, store => \$vcfanno_file_toml},
	vcfanno_file_freq => { required => 1, defined => 1, strict_type => 1, store => \$vcfanno_file_freq},
    };
     
    check($tmpl, $arg_href, 1) or die qw[Could not parse arguments!];
    
    my $FILEHANDLE = IO::Handle->new();  #Create anonymous filehandle

    ## Retrieve logger object
    my $log = Log::Log4perl->get_logger("MIP");

    open($FILEHANDLE, "<", $vcfanno_file_toml) or $log->logdie("Can't open '".$vcfanno_file_toml."': ".$!."\n");

    while (<$FILEHANDLE>) {

	chomp $_; #Remove newline
	
	if($_=~/^file="(\S+)"/) {

	    my $file_path_freq = $1;

	    if($file_path_freq ne $vcfanno_file_freq) {

		$log->fatal("The supplied vcfanno_config_file: ".$vcfanno_file_freq." does not match record 'file=".$file_path_freq."' in the sv_vcfanno_config file: ".$vcfanno_file_toml);
		exit 1;
	    }
	    last;
	}
    }
    close($FILEHANDLE);
}


##Investigate potential autodie error
if ($@ and $@->isa("autodie::exception")) {

    if ($@->matches("default")) {

	say "Not an autodie error at all";
    }
    if ($@->matches("open")) {

	say "Error from open";
    }
    if ($@->matches(":io" )) {

	say "Non-open, IO error.\n";
    }
}
elsif ($@) {

    say "A non-autodie exception.";
}

####
#Decommissioned
####


sub prepare_gatk_target_intervals {

##prepare_gatk_target_intervals

##Function : Prepare target interval file. Copies file to temporary directory, and adds fileExtension to fit GATK
##Returns  : "$target_interval_path"
##Arguments: $analysis_type_ref, $target_interval_file_list_ref, $reference_dir_ref, $temp_directory_ref, $FILEHANDLE
##         : $analysis_type_ref             => The analysis type {REF}
##         : $target_interval_file_list_ref => Target interval list file {REF}
##         : $reference_dir_ref             => Reference directory {REF}
##         : $temp_directory_ref            => Temporary directory {REF}
##         : $FILEHANDLE                    => Filehandle to write to

    my ($arg_href) = @_;

    ## Default(s)
    my $call_type = $arg_href->{call_type} //= "BOTH";
    my $add_ending = $arg_href->{add_ending} //= 1;

    ## Flatten argument(s)
    my $analysis_type_ref = $arg_href->{analysis_type_ref};
    my $FILEHANDLE = $arg_href->{FILEHANDLE};
    my $reference_dir_ref = $arg_href->{reference_dir_ref};
    my $target_interval_file_list_ref = $arg_href->{target_interval_file_list_ref};
    my $temp_directory_ref = $arg_href->{temp_directory_ref};

    if ( ($$analysis_type_ref eq "wes") || ($$analysis_type_ref eq "rapid") ) { #Exome/rapid analysis

	my $target_interval_path = catfile($$temp_directory_ref, $$target_interval_file_list_ref);

	## Copies file to temporary directory.
	migrate_file_to_temp({FILEHANDLE => $FILEHANDLE,
			      path => catfile($$reference_dir_ref, $$target_interval_file_list_ref),
			      temp_directory => $$temp_directory_ref,
			     });
	say $FILEHANDLE "wait ";

	if ($add_ending) {

	    $target_interval_path .= ".intervals";

	    ## Add the by GATK required ".interval" ending
	    print $FILEHANDLE "mv ";
	    print $FILEHANDLE catfile($$temp_directory_ref, $$target_interval_file_list_ref)." ";
	    say $FILEHANDLE catfile($$temp_directory_ref, $$target_interval_file_list_ref.".intervals")." ";
	}
	return $target_interval_path;
    }
}


sub MergeTargetListFlag {

##MergeTargetListFlag

##Function : Detects if there are different capture kits across sample_ids. Creates a temporary merged interval_list for all interval_list that have been supplied and returns temporary list.
##Returns  : "Filepath"
##Arguments: $active_parameter_href, $FILEHANDLE, $contig_ref
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $FILEHANDLE            => FILEHANDLE to write to
##         : $contig_ref            => The contig to extract {REF}

    my ($arg_href) = @_;

    ## Default(s)
    my $temp_directory_ref = $arg_href->{temp_directory_ref} //= \$arg_href->{active_parameter_href}{temp_directory};

    ## Flatten argument(s)
    my $active_parameter_href = $arg_href->{active_parameter_href};
    my $FILEHANDLE = $arg_href->{FILEHANDLE};

    ##Determine file to print to module (untouched/merged and/or splited)
    my $outdirectory = $active_parameter_href->{temp_directory};  #For merged and/or splitet

    if (scalar(keys %{ $active_parameter_href->{exome_target_bed} }) > 1) {  #Merge files

	say $FILEHANDLE "\n## Generate merged interval_list\n";

	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx2g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $$temp_directory_ref,
		   java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
		  });

	print $FILEHANDLE "IntervalListTools ";
	print $FILEHANDLE "UNIQUE=TRUE ";  #Merge overlapping and adjacent intervals to create a list of unique intervals

	foreach my $targetFile (keys $active_parameter_href->{exome_target_bed}) {

	    print $FILEHANDLE "INPUT=".$targetFile." ";
	}
	say $FILEHANDLE "OUTPUT=".catfile($$temp_directory_ref, "merged.interval_list"), "\n";  #Merged outfile
    }
}


sub GATKTargetListFlag {

##GATKTargetListFlag

##Function : Detects if there are different capture kits across sample_ids. Creates a temporary merged interval_list for all interval_list that have been supplied and returns temporary list. Will also extract specific contigs if requested and return that list if enabled.
##Returns  : "Filepath"
##Arguments: $active_parameter_href, $FILEHANDLE, $contig_ref
##         : $active_parameter_href => The active parameters for this analysis hash {REF}
##         : $FILEHANDLE             => FILEHANDLE to write to
##         : $contig_ref              => The contig to extract {REF}

    my ($arg_href) = @_;

    ## Flatten argument(s)
    my $active_parameter_href = $arg_href->{active_parameter_href};
    my $FILEHANDLE = $arg_href->{FILEHANDLE};
    my $contig_ref = $arg_href->{contig_ref};

    my %GATKTargetPaddedBedIntervalListTracker;
    my @GATKTargetPaddedBedIntervalListFiles;

    for (my $sample_id_counter=0;$sample_id_counter<scalar(@{ $active_parameter_href->{sample_ids} });$sample_id_counter++) {  #Collect infiles for all sample_ids

	if (defined($active_parameter_href->{ $active_parameter_href->{family_id} }{ $active_parameter_href->{sample_ids}[$sample_id_counter] }{GATKTargetPaddedBedIntervalLists})) {

	    $active_parameter_href->{GATKTargetPaddedBedIntervalLists} = catfile($active_parameter_href->{reference_dir}, $active_parameter_href->{ $active_parameter_href->{family_id} }{ $active_parameter_href->{sample_ids}[$sample_id_counter] }{GATKTargetPaddedBedIntervalLists});  #Transfer to active_parameter top level

	    $GATKTargetPaddedBedIntervalListTracker{ $active_parameter_href->{GATKTargetPaddedBedIntervalLists} }++;  #Increment to track file record

	    if ($GATKTargetPaddedBedIntervalListTracker{ $active_parameter_href->{GATKTargetPaddedBedIntervalLists} } == 1) {  #Not detected previously

		push(@GATKTargetPaddedBedIntervalListFiles, $active_parameter_href->{ $active_parameter_href->{family_id} }{ $active_parameter_href->{sample_ids}[$sample_id_counter] }{GATKTargetPaddedBedIntervalLists});
	    }
	}
    }

    ##Determine file to print to module (untouched/merged and/or splited)
    my $outdirectory = $active_parameter_href->{temp_directory};  #For merged and/or splitet

    if (scalar(@GATKTargetPaddedBedIntervalListFiles) > 1) {  #Merge files

	say $FILEHANDLE "\n## Generate merged interval_list\n";

	java_core({FILEHANDLE => $FILEHANDLE,
		   memory_allocation => "Xmx2g",
		   java_use_large_pages_ref => \$active_parameter_href->{java_use_large_pages},
		   java_temporary_directory => $active_parameter_href->{temp_directory},
		   java_jar => catfile($active_parameter_href->{picardtools_path}, "picard.jar"),
		  });

	print $FILEHANDLE "IntervalListTools ";
	print $FILEHANDLE "UNIQUE=TRUE ";  #Merge overlapping and adjacent intervals to create a list of unique intervals

	for (my $file_counter=0;$file_counter<scalar(@GATKTargetPaddedBedIntervalListFiles);$file_counter++) {

	    print $FILEHANDLE "INPUT=".catfile($active_parameter_href->{reference_dir}, $GATKTargetPaddedBedIntervalListFiles[$file_counter])." ";
	}
	say $FILEHANDLE "OUTPUT=".catfile($outdirectory, "merged.interval_list"), "\n";  #Merged outfile

	if (defined($$contig_ref)) {

	    my $indirectory = $active_parameter_href->{temp_directory};
	    my $infile = "merged.interval_list";
	    return split_target_file({FILEHANDLE => $FILEHANDLE,
				      indirectory_ref => \$indirectory,
				      outdirectory_ref => \$outdirectory,
				      infile_ref => \$infile,
				      contig_ref => $contig_ref,
				     });
	}
        return catfile($outdirectory, "merged.interval_list");  #No split
    }
    elsif (defined($$contig_ref)) {  #Supply original file but create splitted temp file

	return split_target_file({FILEHANDLE => $FILEHANDLE,
				  indirectory_ref => \$active_parameter_href->{reference_dir},
				  outdirectory_ref => \$outdirectory,
				  infile_ref => \$GATKTargetPaddedBedIntervalListFiles[0],
				  contig_ref => $contig_ref,
				 });
    }
    else {#No merge and no split. return original and only file

	return  catfile($active_parameter_href->{reference_dir}, $GATKTargetPaddedBedIntervalListFiles[0]);
    }
}


sub CheckTemplateFilesPaths {

##CheckTemplateFilesPaths

##Function : Checks that file paths in template files exist
##Returns  : ""
##Arguments: $file_name_ref, $parameter_name
##         : $file_name_ref   => File name {REF}
##         : $parameter_name => MIP parameter name

    my $file_name_ref = $_[0];
    my $parameter_name = $_[1];

    ## Retrieve logger object now that log_file has been set
    my $log = Log::Log4perl->get_logger("MIP");

    open(my $TF, "<", $$file_name_ref) or $log->logdie("Can't open '".$$file_name_ref."':".$!."\n");

    while (<$TF>) {

	chomp $_;

	if (m/^\s+$/) {	 # Avoid blank lines
            next;
        }
	if (m/^\#/) {  # Avoid "#"
            next;
        }
	if ($_ =~/(\S+)/) {

	    my $file_path = $_;

	    if ($file_path=~/^(RD!)/) {  #intersectCollect file

		my @file_path = split('\t', $file_path);
		$file_path[0] =~ s/^RD!/$active_parameter{reference_dir}/g;

		check_existance(\%parameter, \%active_parameter, \$file_path[0], \$parameter_name, "file");  #Only check paths that pointing to reference directory
	    }
	    if ($parameter_name eq "gatk_haplotypecallerRefBAMInfile") {  #Only Paths should be present i.e. check all lines

		check_existance(\%parameter, \%active_parameter, \$file_path, \$parameter_name, "file");
	    }
	}
    }
    close(TF);
}
